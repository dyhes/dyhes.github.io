<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Hadoop & Spark 以下是关于 Hadoop 与 Spark 的全面解析，涵盖核心架构、技术特点、适用场景及两者对比，综合多篇权威资料整理而成：\n🧩 Hadoop：分布式批处理基石 核心定位 Hadoop 是 Apache 基金会开源的分布式系统基础架构，核心设计目标是低成本存储与处理超大规模数据（PB 级），通过廉价硬件集群实现高容错性。\n三大核心组件 组件 作用 关键技术特性 HDFS 分布式文件系统 数据分块存储（默认128MB）、多副本冗余（默认3副本）、流式访问（一次写入多次读取） MapReduce 分布式计算框架 分阶段处理（Map 映射 + Reduce 归约）、批处理优化、自动容错 YARN 资源调度管理器 解耦资源调度与计算逻辑，支持多框架（如Spark、Flink）共享集群资源 生态系统扩展 Hive：SQL 化查询接口，将 HQL 转化为 MapReduce 任务 HBase：基于 HDFS 的列式 NoSQL 数据库，支持实时读写 ZooKeeper：分布式协调服务，保障集群状态一致性 适用场景 ✅ 离线批处理：日志分析、数据仓库ETL ✅ \u200b海量冷数据存储\u200b：历史归档、非结构化数据存储 ✅ \u200b高容错需求\u200b：硬件故障频繁的廉价集群环境\n⚡ Spark：内存计算引擎 核心定位 Spark 是 UC Berkeley 开发的高速通用计算引擎，核心突破是通过内存计算显著提升迭代计算效率，适用于实时处理与复杂分析。\n技术架构创新 弹性分布式数据集（RDD）： 分布式数据抽象，支持分区存储、容错恢复（基于血缘 Lineage 重建数据） DAG 调度引擎： 将有向无环图拆分为 Stage 和 Task，优化任务依赖与并行度 多语言 API： 支持 Scala、Python、Java、R，降低开发门槛 核心组件库 组件 功能 Spark SQL 结构化数据处理，兼容 SQL 与 DataFrame API Spark Streaming 微批次流处理，支持 Kafka/Flink 集成 MLlib 机器学习库（分类、聚类、推荐算法） GraphX 图计算引擎（PageRank、社交网络分析） 适用场景 ✅ 实时计算：欺诈检测、物联网数据流处理 ✅ \u200b迭代算法\u200b：机器学习模型训练、图计算 ✅ \u200b交互式查询\u200b：数据探索与即时分析\n"><title>【BigData】Base</title><link rel=canonical href=https://dyhes.github.io/p/bigdatabase/><link rel=stylesheet href=/scss/style.min.f7091bff8043bd3e53b22be6c05dd86b506e8dec4d0d75d249d2dfb0fe074a46.css><meta property='og:title' content="【BigData】Base"><meta property='og:description' content="Hadoop & Spark 以下是关于 Hadoop 与 Spark 的全面解析，涵盖核心架构、技术特点、适用场景及两者对比，综合多篇权威资料整理而成：\n🧩 Hadoop：分布式批处理基石 核心定位 Hadoop 是 Apache 基金会开源的分布式系统基础架构，核心设计目标是低成本存储与处理超大规模数据（PB 级），通过廉价硬件集群实现高容错性。\n三大核心组件 组件 作用 关键技术特性 HDFS 分布式文件系统 数据分块存储（默认128MB）、多副本冗余（默认3副本）、流式访问（一次写入多次读取） MapReduce 分布式计算框架 分阶段处理（Map 映射 + Reduce 归约）、批处理优化、自动容错 YARN 资源调度管理器 解耦资源调度与计算逻辑，支持多框架（如Spark、Flink）共享集群资源 生态系统扩展 Hive：SQL 化查询接口，将 HQL 转化为 MapReduce 任务 HBase：基于 HDFS 的列式 NoSQL 数据库，支持实时读写 ZooKeeper：分布式协调服务，保障集群状态一致性 适用场景 ✅ 离线批处理：日志分析、数据仓库ETL ✅ \u200b海量冷数据存储\u200b：历史归档、非结构化数据存储 ✅ \u200b高容错需求\u200b：硬件故障频繁的廉价集群环境\n⚡ Spark：内存计算引擎 核心定位 Spark 是 UC Berkeley 开发的高速通用计算引擎，核心突破是通过内存计算显著提升迭代计算效率，适用于实时处理与复杂分析。\n技术架构创新 弹性分布式数据集（RDD）： 分布式数据抽象，支持分区存储、容错恢复（基于血缘 Lineage 重建数据） DAG 调度引擎： 将有向无环图拆分为 Stage 和 Task，优化任务依赖与并行度 多语言 API： 支持 Scala、Python、Java、R，降低开发门槛 核心组件库 组件 功能 Spark SQL 结构化数据处理，兼容 SQL 与 DataFrame API Spark Streaming 微批次流处理，支持 Kafka/Flink 集成 MLlib 机器学习库（分类、聚类、推荐算法） GraphX 图计算引擎（PageRank、社交网络分析） 适用场景 ✅ 实时计算：欺诈检测、物联网数据流处理 ✅ \u200b迭代算法\u200b：机器学习模型训练、图计算 ✅ \u200b交互式查询\u200b：数据探索与即时分析\n"><meta property='og:url' content='https://dyhes.github.io/p/bigdatabase/'><meta property='og:site_name' content='飞鸿踏雪泥'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='BigData'><meta property='article:published_time' content='2025-06-18T00:00:00+00:00'><meta property='article:modified_time' content='2025-07-15T00:57:45+08:00'><meta name=twitter:title content="【BigData】Base"><meta name=twitter:description content="Hadoop & Spark 以下是关于 Hadoop 与 Spark 的全面解析，涵盖核心架构、技术特点、适用场景及两者对比，综合多篇权威资料整理而成：\n🧩 Hadoop：分布式批处理基石 核心定位 Hadoop 是 Apache 基金会开源的分布式系统基础架构，核心设计目标是低成本存储与处理超大规模数据（PB 级），通过廉价硬件集群实现高容错性。\n三大核心组件 组件 作用 关键技术特性 HDFS 分布式文件系统 数据分块存储（默认128MB）、多副本冗余（默认3副本）、流式访问（一次写入多次读取） MapReduce 分布式计算框架 分阶段处理（Map 映射 + Reduce 归约）、批处理优化、自动容错 YARN 资源调度管理器 解耦资源调度与计算逻辑，支持多框架（如Spark、Flink）共享集群资源 生态系统扩展 Hive：SQL 化查询接口，将 HQL 转化为 MapReduce 任务 HBase：基于 HDFS 的列式 NoSQL 数据库，支持实时读写 ZooKeeper：分布式协调服务，保障集群状态一致性 适用场景 ✅ 离线批处理：日志分析、数据仓库ETL ✅ \u200b海量冷数据存储\u200b：历史归档、非结构化数据存储 ✅ \u200b高容错需求\u200b：硬件故障频繁的廉价集群环境\n⚡ Spark：内存计算引擎 核心定位 Spark 是 UC Berkeley 开发的高速通用计算引擎，核心突破是通过内存计算显著提升迭代计算效率，适用于实时处理与复杂分析。\n技术架构创新 弹性分布式数据集（RDD）： 分布式数据抽象，支持分区存储、容错恢复（基于血缘 Lineage 重建数据） DAG 调度引擎： 将有向无环图拆分为 Stage 和 Task，优化任务依赖与并行度 多语言 API： 支持 Scala、Python、Java、R，降低开发门槛 核心组件库 组件 功能 Spark SQL 结构化数据处理，兼容 SQL 与 DataFrame API Spark Streaming 微批次流处理，支持 Kafka/Flink 集成 MLlib 机器学习库（分类、聚类、推荐算法） GraphX 图计算引擎（PageRank、社交网络分析） 适用场景 ✅ 实时计算：欺诈检测、物联网数据流处理 ✅ \u200b迭代算法\u200b：机器学习模型训练、图计算 ✅ \u200b交互式查询\u200b：数据探索与即时分析\n"><link rel="shortcut icon" href=/github.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_b567f26f71c49c33.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>飞鸿踏雪泥</a></h1><h2 class=site-description>没有记录，就没有发生</h2></div></header><ol class=menu-social><li><a href=https://leetcode.cn/u/dyhes/ target=_blank title=LeetCode rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 13h7.5"/><path d="M9.424 7.268l4.999-4.999"/><path d="M16.633 16.644l-2.402 2.415a3.189 3.189.0 01-4.524.0l-3.77-3.787a3.223 3.223.0 010-4.544l3.77-3.787a3.189 3.189.0 014.524.0l2.302 2.313"/></svg></a></li><li><a href=https://github.com/dyhes target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:dyheslin@gmail.com target=_blank title=Gmail rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-gmail"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M16 20h3a1 1 0 001-1V5a1 1 0 00-1-1h-3v16z"/><path d="M5 20h3V4H5A1 1 0 004 5v14a1 1 0 001 1z"/><path d="M16 4l-4 4-4-4"/><path d="M4 6.5l8 7.5 8-7.5"/></svg></a></li><li><a href=mailto:1325574784@qq.com target=_blank title=Mail rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M13 19H5a2 2 0 01-2-2V7a2 2 0 012-2h14a2 2 0 012 2v5.5"/><path d="M3 7l9 6 9-6"/><path d="M19 16l-2 3h4l-2 3"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/categories/><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
<span>Categories</span></a></li><li><a href=/tags/><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#hadoop--spark>Hadoop & Spark</a><ol><li><a href=#-hadoop分布式批处理基石>🧩 <strong>Hadoop：分布式批处理基石</strong></a><ol><li><a href=#核心定位><strong>核心定位</strong></a></li><li><a href=#三大核心组件><strong>三大核心组件</strong></a></li><li><a href=#生态系统扩展><strong>生态系统扩展</strong></a></li><li><a href=#适用场景><strong>适用场景</strong></a></li></ol></li><li><a href=#-spark内存计算引擎>⚡ <strong>Spark：内存计算引擎</strong></a><ol><li><a href=#核心定位-1><strong>核心定位</strong></a></li><li><a href=#技术架构创新><strong>技术架构创新</strong></a></li><li><a href=#核心组件库><strong>核心组件库</strong></a></li><li><a href=#适用场景-1><strong>适用场景</strong></a></li></ol></li><li><a href=#-hadoop-vs-spark核心差异对比>🔄 <strong>Hadoop vs Spark：核心差异对比</strong></a></li><li><a href=#-典型协同应用场景>🌐 <strong>典型协同应用场景</strong></a></li><li><a href=#-总结如何选型>🚀 <strong>总结：如何选型？</strong></a></li></ol></li><li><a href=#hbase>HBase</a><ol><li><a href=#-hbase-详细介绍>🧠 HBase 详细介绍</a><ol><li><a href=#-核心特性>🔍 <strong>核心特性</strong></a></li><li><a href=#-系统架构>⚙️ <strong>系统架构</strong></a></li><li><a href=#-数据模型>📊 <strong>数据模型</strong></a></li><li><a href=#-读写流程>📡 <strong>读写流程</strong></a></li><li><a href=#-典型应用场景>🚀 <strong>典型应用场景</strong></a></li><li><a href=#-与传统数据库对比>🔄 <strong>与传统数据库对比</strong></a></li><li><a href=#-总结>💎 <strong>总结</strong></a></li></ol></li></ol></li><li><a href=#hive>Hive</a><ol><li><a href=#-hive-是什么>🧠 <strong>Hive 是什么？</strong></a></li><li><a href=#-核心架构与组件>⚙️ <strong>核心架构与组件</strong></a></li><li><a href=#-数据存储模型>🗂️ <strong>数据存储模型</strong></a></li><li><a href=#-工作流程详解>🔄 <strong>工作流程详解</strong></a></li><li><a href=#-核心优势与局限性>⚖️ <strong>核心优势与局限性</strong></a><ol><li><a href=#优势><strong>优势</strong></a></li><li><a href=#局限性><strong>局限性</strong></a></li></ol></li><li><a href=#-适用场景-vs-不适用场景>🌐 <strong>适用场景 vs 不适用场景</strong></a></li><li><a href=#-hive-vs-传统数据库>🔄 <strong>Hive vs 传统数据库</strong></a></li><li><a href=#-总结-1>💎 <strong>总结</strong></a></li></ol></li><li><a href=#hdfs>HDFS</a><ol><li><a href=#hdfs-的定义与背景>HDFS 的定义与背景</a></li><li><a href=#核心设计目标>核心设计目标</a></li><li><a href=#架构解析>架构解析</a></li><li><a href=#数据存储机制>数据存储机制</a></li><li><a href=#读写流程详解>读写流程详解</a><ol><li><a href=#写入流程><strong>写入流程</strong></a></li><li><a href=#读取流程><strong>读取流程</strong></a></li></ol></li><li><a href=#优缺点分析>优缺点分析</a></li><li><a href=#典型应用场景>典型应用场景</a></li><li><a href=#操作实践示例>操作实践示例</a><ol><li><a href=#常用命令><strong>常用命令</strong></a></li><li><a href=#实战流程><strong>实战流程</strong></a></li></ol></li><li><a href=#附录关键参数配置>附录：关键参数配置</a></li></ol></li><li><a href=#数据湖>数据湖</a><ol><li><a href=#-核心定义与特点>🧠 <strong>核心定义与特点</strong></a></li><li><a href=#-核心架构与技术组件>⚙️ <strong>核心架构与技术组件</strong></a></li><li><a href=#-核心价值与优势>💡 <strong>核心价值与优势</strong></a></li><li><a href=#-挑战与风险>⚠️ <strong>挑战与风险</strong></a></li><li><a href=#-数据湖-vs-数据仓库-vs-湖仓一体>🔄 <strong>数据湖 vs 数据仓库 vs 湖仓一体</strong></a></li><li><a href=#-典型应用场景-1>🌐 <strong>典型应用场景</strong></a></li><li><a href=#-总结-2>💎 <strong>总结</strong></a></li></ol></li><li><a href=#数据湖存储格式>数据湖存储格式</a><ol><li><a href=#-物理存储层分布式系统支撑弹性扩展>🗄️ 物理存储层：分布式系统支撑弹性扩展</a></li><li><a href=#-数据组织逻辑原始格式与非结构化兼容>📂 数据组织逻辑：原始格式与非结构化兼容</a></li><li><a href=#-文件格式技术高性能列式存储>⚙️ 文件格式技术：高性能列式存储</a></li><li><a href=#-分层架构设计逻辑隔离与治理>🏗️ 分层架构设计：逻辑隔离与治理</a></li><li><a href=#-关键挑战与优化实践>⚠️ 关键挑战与优化实践</a></li><li><a href=#-总结-3>💎 总结</a></li></ol></li><li><a href=#湖仓一体>湖仓一体</a><ol><li><a href=#-核心定义与背景>📚 <strong>核心定义与背景</strong></a></li><li><a href=#-核心架构与关键技术>⚙️ <strong>核心架构与关键技术</strong></a></li><li><a href=#-核心优势>💡 <strong>核心优势</strong></a></li><li><a href=#-典型应用场景-2>🌐 <strong>典型应用场景</strong></a></li><li><a href=#-挑战与选型建议>⚠️ <strong>挑战与选型建议</strong></a></li><li><a href=#-总结-4>💎 <strong>总结</strong></a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/nutrition/ style=background-color:#93b5cf;color:>积雪粮</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/bigdatabase/>【BigData】Base</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jun 18, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>6 minute read</time></div></footer></div></header><section class=article-content><h2 id=hadoop--spark>Hadoop & Spark</h2><p>以下是关于 <strong>Hadoop</strong> 与 <strong>Spark</strong> 的全面解析，涵盖核心架构、技术特点、适用场景及两者对比，综合多篇权威资料整理而成：</p><hr><h3 id=-hadoop分布式批处理基石>🧩 <strong>Hadoop：分布式批处理基石</strong></h3><h4 id=核心定位><strong>核心定位</strong></h4><p>Hadoop 是 Apache 基金会开源的<strong>分布式系统基础架构</strong>，核心设计目标是<strong>低成本存储与处理超大规模数据</strong>（PB 级），通过廉价硬件集群实现高容错性。</p><h4 id=三大核心组件><strong>三大核心组件</strong></h4><div class=table-wrapper><table><thead><tr><th><strong>组件</strong></th><th><strong>作用</strong></th><th><strong>关键技术特性</strong></th></tr></thead><tbody><tr><td><strong>HDFS</strong></td><td>分布式文件系统</td><td>数据分块存储（默认128MB）、多副本冗余（默认3副本）、流式访问（一次写入多次读取）</td></tr><tr><td><strong>MapReduce</strong></td><td>分布式计算框架</td><td>分阶段处理（Map 映射 + Reduce 归约）、批处理优化、自动容错</td></tr><tr><td><strong>YARN</strong></td><td>资源调度管理器</td><td>解耦资源调度与计算逻辑，支持多框架（如Spark、Flink）共享集群资源</td></tr></tbody></table></div><h4 id=生态系统扩展><strong>生态系统扩展</strong></h4><ul><li><strong>Hive</strong>：SQL 化查询接口，将 HQL 转化为 MapReduce 任务</li><li><strong>HBase</strong>：基于 HDFS 的列式 NoSQL 数据库，支持实时读写</li><li><strong>ZooKeeper</strong>：分布式协调服务，保障集群状态一致性</li></ul><h4 id=适用场景><strong>适用场景</strong></h4><p>✅ <strong>离线批处理</strong>：日志分析、数据仓库ETL
✅ ​<strong>海量冷数据存储</strong>​：历史归档、非结构化数据存储
✅ ​<strong>高容错需求</strong>​：硬件故障频繁的廉价集群环境</p><hr><h3 id=-spark内存计算引擎>⚡ <strong>Spark：内存计算引擎</strong></h3><h4 id=核心定位-1><strong>核心定位</strong></h4><p>Spark 是 UC Berkeley 开发的<strong>高速通用计算引擎</strong>，核心突破是通过<strong>内存计算</strong>显著提升迭代计算效率，适用于实时处理与复杂分析。</p><h4 id=技术架构创新><strong>技术架构创新</strong></h4><ul><li><strong>弹性分布式数据集（RDD）</strong>：
分布式数据抽象，支持分区存储、容错恢复（基于血缘 Lineage 重建数据）</li><li><strong>DAG 调度引擎</strong>：
将有向无环图拆分为 Stage 和 Task，优化任务依赖与并行度</li><li><strong>多语言 API</strong>：
支持 Scala、Python、Java、R，降低开发门槛</li></ul><h4 id=核心组件库><strong>核心组件库</strong></h4><div class=table-wrapper><table><thead><tr><th><strong>组件</strong></th><th><strong>功能</strong></th></tr></thead><tbody><tr><td><strong>Spark SQL</strong></td><td>结构化数据处理，兼容 SQL 与 DataFrame API</td></tr><tr><td><strong>Spark Streaming</strong></td><td>微批次流处理，支持 Kafka/Flink 集成</td></tr><tr><td><strong>MLlib</strong></td><td>机器学习库（分类、聚类、推荐算法）</td></tr><tr><td><strong>GraphX</strong></td><td>图计算引擎（PageRank、社交网络分析）</td></tr></tbody></table></div><h4 id=适用场景-1><strong>适用场景</strong></h4><p>✅ <strong>实时计算</strong>：欺诈检测、物联网数据流处理
✅ ​<strong>迭代算法</strong>​：机器学习模型训练、图计算
✅ ​<strong>交互式查询</strong>​：数据探索与即时分析</p><hr><h3 id=-hadoop-vs-spark核心差异对比>🔄 <strong>Hadoop vs Spark：核心差异对比</strong></h3><div class=table-wrapper><table><thead><tr><th><strong>维度</strong></th><th><strong>Hadoop</strong></th><th><strong>Spark</strong></th><th><strong>技术本质</strong></th></tr></thead><tbody><tr><td><strong>计算模型</strong></td><td>基于磁盘的批处理（MapReduce）</td><td>基于内存的 DAG 调度</td><td>Spark 避免磁盘 I/O 瓶颈，速度提升 10-100 倍</td></tr><tr><td><strong>延迟</strong></td><td>高延迟（分钟级）</td><td>低延迟（亚秒级）</td><td>Spark Streaming 支持准实时响应</td></tr><tr><td><strong>容错机制</strong></td><td>数据副本 + 任务重试</td><td>RDD 血缘追溯 + CheckPoint</td><td>Hadoop 依赖物理冗余，Spark 依赖逻辑重建</td></tr><tr><td><strong>资源需求</strong></td><td>磁盘密集型，内存要求低</td><td>内存密集型，需大内存配置</td><td>Spark 在资源不足时性能骤降</td></tr><tr><td><strong>适用负载</strong></td><td>离线批处理、海量存储</td><td>实时计算、迭代分析、机器学习</td><td>Spark 覆盖场景更广，但存储依赖 HDFS</td></tr></tbody></table></div><blockquote><p>💡 <strong>协同关系</strong>：Spark 常运行在 Hadoop YARN 上，使用 HDFS 存储数据，形成 <strong>“HDFS 存 + Spark 算”</strong> 的黄金组合。</p></blockquote><hr><h3 id=-典型协同应用场景>🌐 <strong>典型协同应用场景</strong></h3><ol><li>数据湖架构<ul><li><strong>HDFS</strong> 存储原始数据（日志、传感器数据）</li><li><strong>Spark</strong> 清洗并转换数据 → <strong>Hive</strong> 执行 SQL 分析 → <strong>MLlib</strong> 训练模型</li></ul></li><li>实时风控系统<ul><li>Kafka 接入交易流 → <strong>Spark Streaming</strong> 实时聚合 → 结果写入 <strong>HBase</strong> 供查询</li></ul></li><li>历史数据分析<ul><li><strong>Hadoop MapReduce</strong> 处理 TB 级归档数据 → 结果导入 <strong>Spark</strong> 进行可视化</li></ul></li></ol><hr><h3 id=-总结如何选型>🚀 <strong>总结：如何选型？</strong></h3><ul><li><strong>选 Hadoop 当</strong>：
需低成本存储 PB 级数据 + 离线批处理为主 + 硬件容错优先级高。</li><li><strong>选 Spark 当</strong>：
需实时/迭代计算（如机器学习） + 开发效率要求高 + 集群内存资源充足。</li><li><strong>最佳实践</strong>：
​<strong>混合架构</strong>——HDFS 为底座，YARN 管理资源，Spark 加速计算，兼顾性能与成本。</li></ul><blockquote><p>技术演进趋势：Spark 正逐步替代 MapReduce 成为主流计算引擎，但 HDFS 和 YARN 仍是分布式生态基石。</p></blockquote><h2 id=hbase>HBase</h2><h3 id=-hbase-详细介绍>🧠 HBase 详细介绍</h3><p>HBase（Hadoop Database）是一个开源的、分布式的、面向列的 NoSQL 数据库，专为海量数据存储与实时读写设计。其核心技术源于 Google 的 Bigtable 论文，核心定位是解决传统关系型数据库在大规模数据场景下的扩展性、实时性瓶颈。以下是其核心特性和工作原理的全面解析：</p><hr><h4 id=-核心特性>🔍 <strong>核心特性</strong></h4><ol><li><strong>分布式与可扩展性</strong><ul><li>基于 Hadoop HDFS 存储数据，可通过添加廉价服务器水平扩展集群规模，理论上支持 PB 级数据存储。</li><li>自动分片（Region 分裂）和负载均衡机制，确保数据均匀分布。</li></ul></li><li><strong>面向列存储</strong><ul><li>数据按列族（Column Family）分组存储，每个列族独立物理存储，支持动态添加列。</li><li>稀疏存储优化：空列不占空间，适合半结构化/非结构化数据（如日志、传感器数据）。</li></ul></li><li><strong>高可靠与实时性</strong><ul><li>通过 WAL（预写日志）、HDFS 多副本机制保障数据可靠性。</li><li>读写延迟在毫秒级，适用于实时查询场景（如金融风控、广告点击分析）。</li></ul></li><li><strong>多版本控制</strong><ul><li>每个单元格（Cell）支持多版本数据，通过时间戳区分，便于历史追溯和时序分析。</li></ul></li></ol><hr><h4 id=-系统架构>⚙️ <strong>系统架构</strong></h4><p>HBase 采用主从架构，核心组件如下：</p><ul><li><strong>HMaster</strong>：
负责元数据管理、Region 分配、故障恢复。支持多主热备，通过 ZooKeeper 选举避免单点故障。</li><li><strong>RegionServer</strong>：
实际处理读写请求，每个 Server 管理多个 Region（表的分片）。包含 MemStore（内存缓存）和 HFile（磁盘存储）。</li><li><strong>ZooKeeper</strong>：
协调集群状态，监控 RegionServer 存活，存储元数据位置（如 <code>hbase:meta</code> 表）。</li><li><strong>HDFS</strong>：
底层存储引擎，保障数据高可用。
<strong>数据流向示例</strong>：
<code>Client → ZooKeeper（定位Region）→ RegionServer → MemStore → HFile（HDFS）</code></li></ul><hr><h4 id=-数据模型>📊 <strong>数据模型</strong></h4><ol><li>行键（Row Key）<ul><li>数据的唯一标识，按字典序排序，设计需避免热点问题（如加盐散列）。</li></ul></li><li>列族（Column Family）<ul><li>表的纵向分组单位（如 <code>info</code>、<code>stats</code>），需预定义。列族内的列（Qualifier）可动态扩展。</li></ul></li><li>时间戳（Timestamp）<ul><li>数据版本标识，默认按倒序存储，支持按时间范围查询。</li></ul></li><li>存储单元（Cell）<ul><li>由 <code>(RowKey, 列族:列, Timestamp)</code> 唯一确定的数据值。</li></ul></li></ol><blockquote><p>示例表结构：</p><div class=table-wrapper><table><thead><tr><th>RowKey</th><th>CF1:Name</th><th>CF1:Age</th><th>CF2:LastLogin</th></tr></thead><tbody><tr><td>user001</td><td>Alice</td><td>28</td><td>20240501</td></tr><tr><td>user002</td><td>Bob</td><td>32</td><td>20240502</td></tr></tbody></table></div></blockquote><hr><h4 id=-读写流程>📡 <strong>读写流程</strong></h4><ul><li><strong>写入流程</strong>：<ol><li>客户端提交写请求至 RegionServer；</li><li>数据先写入 WAL（保障持久性），再存入 MemStore；</li><li>MemStore 满后 Flush 到 HDFS 生成 HFile。</li></ol></li><li><strong>读取流程</strong>：<ol><li>从 MemStore 查询最新数据；</li><li>若未命中，扫描 HFile（利用 Bloom Filter 快速过滤无效文件）；</li><li>结果合并后返回客户端。</li></ol></li></ul><hr><h4 id=-典型应用场景>🚀 <strong>典型应用场景</strong></h4><ol><li>实时分析<ul><li>电商用户行为分析、广告点击实时统计。</li></ul></li><li>物联网（IoT）<ul><li>存储传感器时序数据（如温度、轨迹），支持时间范围查询。</li></ul></li><li>社交网络<ul><li>用户关系图谱、动态消息流（Feeds）存储。</li></ul></li><li>金融风控<ul><li>交易流水实时监测，识别欺诈行为。</li></ul></li><li>日志系统<ul><li>聚合服务器日志，支持快速检索与分析。</li></ul></li></ol><hr><h4 id=-与传统数据库对比>🔄 <strong>与传统数据库对比</strong></h4><div class=table-wrapper><table><thead><tr><th><strong>维度</strong></th><th><strong>HBase</strong></th><th><strong>关系型数据库 (RDBMS)</strong></th></tr></thead><tbody><tr><td><strong>数据模型</strong></td><td>列式存储，无固定 Schema</td><td>行式存储，严格 Schema</td></tr><tr><td><strong>扩展性</strong></td><td>水平扩展（线性增长）</td><td>垂直扩展或复杂分库分表</td></tr><tr><td><strong>事务支持</strong></td><td>单行事务，无跨行 ACID</td><td>完整 ACID 及复杂事务</td></tr><tr><td><strong>查询能力</strong></td><td>仅支持 RowKey 范围扫描，无 JOIN</td><td>支持 SQL 复杂查询与多表关联</td></tr><tr><td><strong>适用数据</strong></td><td>海量非结构化/半结构化数据</td><td>结构化数据，中小规模</td></tr></tbody></table></div><hr><h4 id=-总结>💎 <strong>总结</strong></h4><p>HBase 凭借其分布式架构、列式存储和实时读写能力，成为处理海量数据的首选之一。尤其适合需要高吞吐、低延迟访问的非结构化数据场景（如日志、IoT、实时分析）。但其局限在于不支持复杂查询与事务，需通过 Phoenix 等工具或结合 Hive/Spark 弥补。合理设计 RowKey 和列族、利用多版本机制，可最大化发挥其性能优势。</p><h2 id=hive>Hive</h2><p>以下是对 <strong>Hive</strong> 的全面解析，涵盖其核心定位、架构设计、数据模型、工作原理、适用场景及与传统数据库的对比，综合多篇权威资料整理而成：</p><hr><h3 id=-hive-是什么>🧠 <strong>Hive 是什么？</strong></h3><p>Hive 是由 <strong>Facebook 开源</strong>（2010 年贡献给 Apache）的 <strong>分布式数据仓库工具</strong>，核心目标是<strong>降低大数据分析门槛</strong>。它通过类 SQL 语言（HiveQL）提供数据查询能力，将结构化数据文件（如日志、CSV）映射为数据库表，并自动将 HiveQL 翻译成 <strong>MapReduce、Tez 或 Spark 任务</strong>在 Hadoop 集群上执行。
​<strong>本质</strong>​：</p><blockquote><p>“Hive 是 Hadoop 生态的 SQL 抽象层，让用户无需编写 MapReduce 代码即可处理 PB 级数据。”</p></blockquote><hr><h3 id=-核心架构与组件>⚙️ <strong>核心架构与组件</strong></h3><p>Hive 采用<strong>元数据驱动</strong>的架构，核心组件如下：</p><div class=table-wrapper><table><thead><tr><th><strong>组件</strong></th><th><strong>功能</strong></th><th><strong>关键技术细节</strong></th></tr></thead><tbody><tr><td><strong>用户接口</strong></td><td>CLI、JDBC/ODBC、Web UI，支持多种交互方式</td><td>用户通过接口提交 HiveQL 查询语句</td></tr><tr><td><strong>元存储（Metastore）</strong></td><td>存储表结构、分区、数据位置等元数据（如表名、列类型、HDFS 路径）</td><td><strong>默认 Derby（测试用），生产环境推荐 MySQL</strong>，避免单点故障</td></tr><tr><td><strong>驱动器（Driver）</strong></td><td>解析 HiveQL → 生成执行计划 → 优化 → 提交计算任务</td><td>包含编译器（词法/语法分析）、优化器（逻辑优化）、执行器（任务调度）</td></tr><tr><td><strong>执行引擎</strong></td><td>将逻辑计划转化为物理任务（MapReduce/Tez/Spark）</td><td><strong>Hive 3.x+ 推荐 Tez 或 Spark</strong>，比 MapReduce 快 10 倍以上</td></tr><tr><td><strong>存储层</strong></td><td>数据实际存储在 <strong>HDFS</strong> 中，支持文本、ORC、Parquet 等格式</td><td>ORC/Parquet 列式存储可提升查询性能 50%+</td></tr></tbody></table></div><hr><h3 id=-数据存储模型>🗂️ <strong>数据存储模型</strong></h3><p>Hive 数据模型采用分层结构，与 HDFS 深度集成：</p><ol><li>数据库（Database）<ul><li>逻辑命名空间，对应 HDFS 目录：<code>/user/hive/warehouse/&lt;db_name>.db</code></li></ul></li><li>表（Table）<ul><li><strong>内部表</strong>：数据由 Hive 管理，删除表时数据一并删除</li><li><strong>外部表</strong>：数据由用户管理，仅删除元数据（适用于共享数据场景）</li></ul></li><li>分区（Partition）<ul><li>按列值（如日期、地区）划分数据，减少全表扫描</li><li>对应 HDFS 子目录：<code>/table/dt=20231001/country=US</code></li></ul></li><li>分桶（Bucket）<ul><li>对分区内数据哈希分桶（如按用户 ID），提升 Join 和采样效率</li><li>示例：<code>CLUSTERED BY(user_id) INTO 32 BUCKETS</code></li></ul></li></ol><blockquote><p><strong>数据格式示例</strong>：
采用 ORC 格式存储的日志表，按日期分区后查询速度提升 80%。</p></blockquote><hr><h3 id=-工作流程详解>🔄 <strong>工作流程详解</strong></h3><p>一次 HiveQL 查询的执行流程：</p><ol><li><strong>提交查询</strong>：用户通过 CLI 执行 <code>SELECT * FROM logs WHERE dt='20231001';</code></li><li><strong>语法解析</strong>：Driver 将 HiveQL 解析为<strong>抽象语法树（AST）</strong></li><li><strong>逻辑计划生成</strong>：编译器将 AST 转为逻辑执行计划（如过滤条件、扫描分区）</li><li><strong>物理计划优化</strong>：优化器合并操作、减少 Shuffle 数据量</li><li>任务执行：<ul><li>若查询涉及分区 <code>dt='20231001'</code>，直接读取对应 HDFS 目录</li><li>执行引擎（如 Tez）运行任务，YARN 分配资源</li></ul></li><li><strong>结果返回</strong>：数据经聚合后输出到用户接口</li></ol><blockquote><p><strong>延迟主要来源</strong>：任务调度（约 60% 时间）、数据 Shuffle（30%），小查询也可能需数秒。</p></blockquote><hr><h3 id=-核心优势与局限性>⚖️ <strong>核心优势与局限性</strong></h3><h4 id=优势><strong>优势</strong></h4><ul><li><strong>低学习成本</strong>：HiveQL 类 SQL 语法，降低大数据分析门槛</li><li><strong>扩展性强</strong>：无缝扩展 Hadoop 集群节点，支持 PB 级数据处理</li><li><strong>灵活性高</strong>：支持 UDF（用户自定义函数）、多种文件格式（JSON/ORC/Parquet）</li><li><strong>容错性</strong>：基于 HDFS 多副本机制，节点故障自动恢复</li></ul><h4 id=局限性><strong>局限性</strong></h4><ul><li><strong>高延迟</strong>：任务启动需 10–60 秒，<strong>不适合实时查询</strong></li><li><strong>弱事务支持</strong>：不支持行级更新/删除（仅 Hive 3.x+ 支持有限 ACID）</li><li><strong>迭代计算差</strong>：HiveQL 无法高效表达机器学习迭代算法（需 Spark 补充）</li></ul><hr><h3 id=-适用场景-vs-不适用场景>🌐 <strong>适用场景 vs 不适用场景</strong></h3><div class=table-wrapper><table><thead><tr><th><strong>适合场景</strong></th><th><strong>不适用场景</strong></th></tr></thead><tbody><tr><td><strong>离线批处理</strong>：TB 级日志分析、ETL 清洗</td><td>联机事务处理（OLTP）</td></tr><tr><td><strong>数据仓库</strong>：历史数据存储与聚合查询</td><td>低延迟交互式查询（&lt;1 秒响应）</td></tr><tr><td><strong>即席查询（Ad-hoc）</strong>：数据探索与报表</td><td>高频数据更新（如订单系统）</td></tr><tr><td><strong>大规模数据转换</strong>：结构转换、格式转换</td><td>复杂图计算或流处理</td></tr></tbody></table></div><blockquote><p><strong>典型案例</strong>：</p><ul><li>电商用户行为日志分析（日处理 PB 级点击流）</li><li>金融行业历史交易数据归档与合规审计</li></ul></blockquote><hr><h3 id=-hive-vs-传统数据库>🔄 <strong>Hive vs 传统数据库</strong></h3><div class=table-wrapper><table><thead><tr><th><strong>维度</strong></th><th><strong>Hive</strong></th><th><strong>传统数据库（MySQL/Oracle）</strong></th></tr></thead><tbody><tr><td><strong>设计目标</strong></td><td>大规模数据分析（OLAP）</td><td>事务处理与实时查询（OLTP）</td></tr><tr><td><strong>数据规模</strong></td><td>PB 级，横向扩展</td><td>TB 级，垂直扩展</td></tr><tr><td><strong>延迟</strong></td><td>分钟级</td><td>毫秒级</td></tr><tr><td><strong>事务支持</strong></td><td>有限（仅 Hive 3.x+）</td><td>完整 ACID</td></tr><tr><td><strong>存储与计算</strong></td><td>分离（HDFS + 计算引擎）</td><td>耦合（本地存储 + 内置引擎）</td></tr><tr><td><strong>数据更新</strong></td><td>批量覆盖或追加，不支持行级更新</td><td>支持高频行级增删改</td></tr></tbody></table></div><blockquote><p>💡 <strong>本质差异</strong>：
Hive 是 ​<strong>Schema-on-Read</strong>​（写入时不校验结构，读取时解析），传统数据库是 ​<strong>Schema-on-Write</strong>。</p></blockquote><hr><h3 id=-总结-1>💎 <strong>总结</strong></h3><p>Hive 的核心价值在于<strong>用 SQL 解锁 Hadoop 生态的数据分析能力</strong>，成为大数据批处理的黄金标准。其优势在于易用性、扩展性和对海量静态数据的处理能力，但高延迟与弱事务支持限制了实时场景的应用。
​<strong>最佳实践建议</strong>​：</p><ul><li><strong>架构设计</strong>：Hive + ORC/Parquet + Tez 引擎，提升查询性能</li><li><strong>数据治理</strong>：合理使用分区（时间/业务维度）和分桶（高频 Join 字段）</li><li><strong>生态协同</strong>：实时场景用 <strong>HBase/Kafka</strong>，迭代计算用 <strong>Spark</strong>，形成互补</li></ul><blockquote><p>技术趋势：Hive 正与 <strong>Spark 引擎深度整合</strong>，并增强 ACID 特性，向实时数仓演进。</p></blockquote><h2 id=hdfs>HDFS</h2><p>以下是对**HDFS（Hadoop Distributed File System）**的全面解析，结合其设计目标、架构原理、核心特性及适用场景，综合多篇权威资料整理而成：</p><hr><h3 id=hdfs-的定义与背景>HDFS 的定义与背景</h3><ol><li><strong>产生背景</strong>
随着数据规模从GB级增长至PB级，单机存储无法满足需求，需在多台机器上分布式存储文件。传统文件系统难以管理跨机器数据，HDFS应运而生，成为<strong>管理多台服务器文件的分布式文件系统</strong>。</li><li><strong>核心定位</strong>
HDFS是Hadoop生态的底层存储系统，设计目标为：<ul><li>高容错性：在廉价硬件上稳定运行</li><li>高吞吐量：支持流式数据访问，适合批处理</li><li>超大规模数据：处理TB/PB级数据及百万级文件数量。</li></ul></li></ol><hr><h3 id=核心设计目标>核心设计目标</h3><ol><li><strong>硬件故障是常态</strong>
通过多副本机制（默认3副本）自动处理节点故障，数据丢失后自动恢复。</li><li><strong>流式数据访问</strong>
优化顺序读写而非随机访问，牺牲低延迟换取高吞吐。</li><li><strong>简化一致性模型</strong>
采用 ​<strong>​“一次写入、多次读取”​</strong>​（WORM）模式，写入后仅支持追加，避免复杂一致性问题。</li><li><strong>移动计算而非数据</strong>
将计算任务调度至数据存储节点执行，减少网络传输开销。</li></ol><hr><h3 id=架构解析>架构解析</h3><p>HDFS采用<strong>主从（Master/Slave）架构</strong>，核心组件如下：</p><div class=table-wrapper><table><thead><tr><th><strong>组件</strong></th><th><strong>核心职责</strong></th><th><strong>关键特性</strong></th></tr></thead><tbody><tr><td><strong>NameNode</strong> (主节点)</td><td>管理元数据：文件目录树、块映射关系、副本策略。元数据驻留内存（FsImage + EditLog）</td><td>单点故障风险（需HA方案），内存容量决定文件数量上限。</td></tr><tr><td><strong>DataNode</strong> (从节点)</td><td>存储实际数据块（默认128MB/块），定期向NameNode发送心跳与块报告，执行数据读写与副本复制</td><td>数据本地化存储，磁盘空间决定存储容量。</td></tr><tr><td><strong>Secondary NameNode</strong></td><td>定期合并FsImage和EditLog，减轻NameNode负担。<strong>非热备节点</strong>，无法直接接管NameNode故障。</td><td>防止EditLog过大导致NameNode重启过慢。</td></tr></tbody></table></div><hr><h3 id=数据存储机制>数据存储机制</h3><ol><li>分块存储<ul><li>文件被切分为固定大小的块（默认128MB），分散存储在不同DataNode。</li><li><strong>块大小权衡</strong>：过小增加寻址时间，过大降低传输效率（寻址时间≈传输时间1%为最佳）。</li></ul></li><li>多副本冗余<ul><li>每个块默认存3副本，分布策略：同一机架1副本 + 不同机架2副本，平衡可靠性与带宽。</li></ul></li><li>数据完整性校验<ul><li>写入时生成校验和（checksum），读取时验证，损坏则从其他副本恢复。</li></ul></li></ol><hr><h3 id=读写流程详解>读写流程详解</h3><h4 id=写入流程><strong>写入流程</strong></h4><ol><li>客户端向NameNode申请写入，NameNode校验路径与权限。</li><li>文件分块后，客户端按流水线写入：<ul><li>DataNode A → B → C（默认3副本），减少网络瓶颈。</li></ul></li><li>数据先写入本地缓存，达到块大小时刷入HDFS，写入完成同步元数据。</li></ol><h4 id=读取流程><strong>读取流程</strong></h4><ol><li>客户端从NameNode获取块位置信息（按网络拓扑排序，优先本地副本）。</li><li>直接从最近的DataNode并行读取块数据，流式返回客户端。</li></ol><hr><h3 id=优缺点分析>优缺点分析</h3><div class=table-wrapper><table><thead><tr><th><strong>优势</strong></th><th><strong>局限性</strong></th></tr></thead><tbody><tr><td><strong>高容错性</strong>：多副本自动恢复故障</td><td><strong>低延迟访问差</strong>：毫秒级请求不适用</td></tr><tr><td><strong>高吞吐量</strong>：适合批量数据处理</td><td><strong>小文件存储低效</strong>：占用NameNode内存，寻址时间长</td></tr><tr><td><strong>水平扩展性</strong>：通过添加DataNode扩容</td><td><strong>不支持并发写/随机修改</strong>：仅追加写入</td></tr><tr><td><strong>低成本</strong>：部署于廉价硬件</td><td><strong>单点故障</strong>：原生NameNode非高可用（需HA方案）</td></tr></tbody></table></div><hr><h3 id=典型应用场景>典型应用场景</h3><ul><li><strong>批处理分析</strong>：MapReduce/Spark计算任务的底层存储（如日志分析、ETL）。</li><li><strong>海量冷数据存储</strong>：历史数据归档（如视频、图片）。</li><li><strong>数据湖底座</strong>：集中存储多源异构数据，供上层计算引擎使用。</li></ul><blockquote><p>⚠️ <strong>不适用场景</strong>：实时数据库、高频更新系统、小文件存储（需合并为SequenceFile或使用其他存储如HBase）。</p></blockquote><hr><h3 id=操作实践示例>操作实践示例</h3><h4 id=常用命令><strong>常用命令</strong></h4><pre tabindex=0><code>hdfs dfs -mkdir /data              # 创建目录
hdfs dfs -put local.txt /data/     # 上传文件
hdfs dfs -cat /data/local.txt      # 查看文件
hdfs dfs -rm /data/local.txt       # 删除文件
</code></pre><h4 id=实战流程><strong>实战流程</strong></h4><ol><li>启动HDFS集群：<pre tabindex=0><code>hdfs namenode -format    # 首次格式化
start-dfs.sh             # 启动服务
</code></pre></li><li>使用MapReduce处理HDFS数据（如词频统计）：<ul><li>将数据上传至HDFS → 提交MapReduce作业 → 结果写回HDFS。</li></ul></li></ol><hr><h3 id=附录关键参数配置>附录：关键参数配置</h3><div class=table-wrapper><table><thead><tr><th><strong>参数</strong></th><th><strong>默认值</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td><code>dfs.blocksize</code></td><td>128MB</td><td>定义数据块大小</td></tr><tr><td><code>dfs.replication</code></td><td>3</td><td>设置数据副本数量</td></tr><tr><td><code>dfs.namenode.checkpoint.period</code></td><td>3600秒</td><td>Secondary NameNode合并元数据间隔</td></tr></tbody></table></div><blockquote><p>资料来源：[1][2][3][4][5][7][8][9]，HDFS的深度优化需结合业务负载调整参数，并可通过Kerberos强化安全、QJM实现NameNode高可用。</p></blockquote><h2 id=数据湖>数据湖</h2><p>数据湖（Data Lake）是一种高度可扩展的统一存储架构，用于集中存储企业或组织的全量原始数据（包括结构化、半结构化和非结构化数据），支持按原样保存数据，并通过灵活的查询和分析工具挖掘数据价值。以下是其核心要点：</p><hr><h3 id=-核心定义与特点>🧠 <strong>核心定义与特点</strong></h3><ol><li><strong>统一存储原始数据</strong><ul><li>存储未经处理的原始数据副本，保留业务数据的原始状态（如日志、传感器流、图像、视频等）。</li><li>数据类型全覆盖：<ul><li><strong>结构化数据</strong>（如关系型数据库表）</li><li><strong>半结构化数据</strong>（JSON、XML、CSV）</li><li><strong>非结构化数据</strong>（文档、PDF、音视频）。</li></ul></li></ul></li><li><strong>按需处理与分析</strong><ul><li>无需预先定义数据结构（Schema-on-Read），允许在读取时动态解析数据格式。</li><li>支持多种计算引擎（如Spark、Flink、Presto）进行批处理、实时分析、机器学习等任务。</li></ul></li><li><strong>低成本与高扩展性</strong><ul><li>基于分布式存储（如AWS S3、HDFS），可横向扩展至PB级数据量。</li><li>利用对象存储的廉价特性，显著降低存储成本。</li></ul></li></ol><hr><h3 id=-核心架构与技术组件>⚙️ <strong>核心架构与技术组件</strong></h3><ol><li><strong>存储系统</strong><ul><li><strong>云对象存储主导</strong>（如AWS S3、Azure ADLS），替代传统HDFS，提供高可靠性和弹性带宽。</li><li><strong>开放文件格式</strong>：Parquet（结构化数据标准）、ORC、TF Record等。</li></ul></li><li><strong>元数据管理系统（Catalog）</strong><ul><li>记录数据位置、结构、血缘关系等元信息，避免数据湖退化为“数据沼泽”。</li><li>支持Apache Iceberg、Hudi等表格式标准，实现ACID事务和数据版本控制。</li></ul></li><li><strong>计算引擎层</strong><ul><li>支持多模式计算：<ul><li><strong>批处理</strong>：Spark、Hive</li><li><strong>流处理</strong>：Flink、Kafka</li><li><strong>交互式查询</strong>：Presto、Trino。</li></ul></li></ul></li></ol><hr><h3 id=-核心价值与优势>💡 <strong>核心价值与优势</strong></h3><ol><li>打破数据孤岛<ul><li>整合多源异构数据（如业务数据库、IoT设备、社交媒体），形成企业级数据统一视图。</li></ul></li><li>赋能数据探索与AI<ul><li>数据科学家可直接访问原始数据，训练机器学习模型（如用户行为预测、图像识别）。</li></ul></li><li>敏捷性与低成本<ul><li>快速接入新数据源，无需预定义Schema，缩短数据上线时间。</li></ul></li></ol><hr><h3 id=-挑战与风险>⚠️ <strong>挑战与风险</strong></h3><ol><li>数据沼泽化风险<ul><li>缺乏元数据管理时，数据难以查找和理解，导致利用率下降。</li></ul></li><li>查询性能瓶颈<ul><li>非结构化数据处理效率低于预聚合的数据仓库，需依赖计算引擎优化。</li></ul></li><li>安全与治理难题<ul><li>需额外工具（如Apache Ranger）实现权限控制、数据脱敏和合规审计。</li></ul></li></ol><hr><h3 id=-数据湖-vs-数据仓库-vs-湖仓一体>🔄 <strong>数据湖 vs 数据仓库 vs 湖仓一体</strong></h3><div class=table-wrapper><table><thead><tr><th><strong>维度</strong></th><th><strong>数据湖</strong></th><th><strong>数据仓库</strong></th><th><strong>湖仓一体</strong>（融合方案）</th></tr></thead><tbody><tr><td><strong>数据状态</strong></td><td>原始数据（未清洗）</td><td>清洗后的聚合数据</td><td>原始数据 + 处理后的高质量数据</td></tr><tr><td><strong>Schema策略</strong></td><td>读取时定义（Schema-on-Read）</td><td>写入时定义（Schema-on-Write）</td><td>双向支持</td></tr><tr><td><strong>适用场景</strong></td><td>数据探索、AI训练</td><td>标准报表、BI分析</td><td>实时分析、跨场景统一平台</td></tr><tr><td><strong>事务支持</strong></td><td>弱（依赖表格式扩展）</td><td>强（ACID）</td><td>原生支持ACID（如Delta Lake）</td></tr></tbody></table></div><hr><h3 id=-典型应用场景-1>🌐 <strong>典型应用场景</strong></h3><ol><li>企业数据中台<ul><li>整合CRM、ERP等多系统数据，提供统一分析入口。</li></ul></li><li>AI/ML模型训练<ul><li>存储海量原始数据集（如医疗影像、语音记录），支撑深度学习。</li></ul></li><li>IoT数据分析<ul><li>实时接入传感器数据流，监测设备状态并预测故障。</li></ul></li></ol><hr><h3 id=-总结-2>💎 <strong>总结</strong></h3><p>数据湖是企业构建数据驱动能力的<strong>核心基础设施</strong>，其价值在于以<strong>低成本存储全量原始数据</strong>，并通过开放生态支持<strong>灵活分析</strong>。然而，需通过元数据治理、表格式标准（如Iceberg）和计算引擎优化规避“数据沼泽”风险。未来，数据湖将向<strong>湖仓一体架构</strong>演进，在统一平台上兼顾实时分析与事务一致性。</p><h2 id=数据湖存储格式>数据湖存储格式</h2><p>数据湖的存储形态是其架构设计的核心，它以<strong>分布式、原始格式、多类型数据统一存储</strong>为基础，通过分层设计实现海量数据的弹性管理。以下从物理存储、数据组织、技术实现三个维度详细解析其形态特征：</p><hr><h3 id=-物理存储层分布式系统支撑弹性扩展>🗄️ 物理存储层：分布式系统支撑弹性扩展</h3><ol><li><strong>核心存储系统</strong><ul><li><strong>对象存储主导</strong>：云环境下采用 <strong>AWS S3、阿里云 OSS、Azure Blob</strong> 等对象存储服务，提供高可靠、无限扩展的存储池，成本仅为传统存储的1/10。</li><li><strong>开源方案</strong>：本地部署常用 <strong>HDFS（Hadoop分布式文件系统）</strong> 或 <strong>Ceph</strong>，支持PB级数据横向扩展；<strong>MinIO</strong> 作为开源对象存储，兼容S3接口。</li></ul></li><li><strong>存储特性</strong><ul><li><strong>冷热分层</strong>：自动将高频访问数据（热数据）存入SSD，低频数据（冷数据）转入廉价机械盘或归档存储，优化成本效率。</li><li><strong>冗余与容错</strong>：通过多副本（如HDFS默认3副本）或纠删码技术（如S3）保障数据安全，节点故障时自动恢复。</li></ul></li></ol><hr><h3 id=-数据组织逻辑原始格式与非结构化兼容>📂 数据组织逻辑：原始格式与非结构化兼容</h3><ol><li><strong>数据存储原则</strong><ul><li><strong>原始格式保留</strong>：数据以原生形态（如CSV日志、JSON流、视频文件）直接存储，避免预处理导致信息损失，支持后续灵活分析。</li><li><strong>无预定义Schema</strong>：采用 <strong>Schema-on-Read</strong>（读时建模），写入时不强制结构化，读取时按需解析。</li></ul></li><li><strong>数据分类与标签</strong><ul><li><strong>按主题分区</strong>：例如按业务域（客户/交易）或来源（IoT设备/社交媒体）划分目录，辅以时间戳（如<code>/logs/dt=20240618</code>）。</li><li><strong>元数据标注</strong>：通过标签标记数据敏感度、生成时间、所有者等属性，便于治理与检索。</li></ul></li><li><strong>优化技术</strong><ul><li><strong>分区（Partitioning）</strong>：按时间、地域等维度物理分割数据，减少全表扫描（如查询仅需扫描特定日期分区）。</li><li><strong>分桶（Bucketing）</strong>：对分区内数据哈希分桶（如按用户ID），提升Join查询效率。</li></ul></li></ol><hr><h3 id=-文件格式技术高性能列式存储>⚙️ 文件格式技术：高性能列式存储</h3><ol><li><strong>开放文件格式</strong><div class=table-wrapper><table><thead><tr><th><strong>格式</strong></th><th><strong>适用场景</strong></th><th><strong>优势</strong></th></tr></thead><tbody><tr><td><strong>Parquet</strong></td><td>结构化数据分析（如SQL查询）</td><td>列式存储高压缩比，减少I/O开销</td></tr><tr><td><strong>ORC</strong></td><td>Hive生态批处理</td><td>支持谓词下推，加速过滤操作</td></tr><tr><td><strong>Avro</strong></td><td>流数据序列化</td><td>Schema动态演进，兼容前后版本</td></tr><tr><td><strong>Delta Lake/Iceberg</strong></td><td>ACID事务支持</td><td>支持事务、版本回溯、元数据管理</td></tr><tr><td>列式存储（如Parquet）可将查询性能提升50%+，尤其适合聚合分析。</td><td></td><td></td></tr></tbody></table></div></li><li><strong>压缩与编码</strong><ul><li>使用 <strong>Snappy</strong>、<strong>Gzip</strong> 压缩算法平衡CPU开销与存储空间，典型压缩率3–10倍。</li><li>数据编码优化（如字典编码）减少重复值存储空间。</li></ul></li></ol><hr><h3 id=-分层架构设计逻辑隔离与治理>🏗️ 分层架构设计：逻辑隔离与治理</h3><p>数据湖通常采用<strong>四层逻辑架构</strong>，实现数据从原始到可用的流转：</p><ol><li>原始层（Raw/Landing Zone）<ul><li>存储未经处理的原始数据，保留全量细节，作为数据探索的“原料库”。</li></ul></li><li>清洗层（Cleaned/Curated Zone）<ul><li>对原始数据格式标准化、去重、脱敏，生成可复用的中间数据集。</li></ul></li><li>应用层（Trusted/Production Zone）<ul><li>集成业务逻辑（如用户画像模型），输出可直接用于报表、API的高质量数据。</li></ul></li><li>沙盒层（Sandbox）<ul><li>供数据科学家实验性分析，隔离生产环境风险。</li></ul></li></ol><blockquote><p><strong>数据流动示例</strong>：
原始日志 → 清洗层（过滤无效记录） → 应用层（聚合用户行为） → 沙盒层（训练推荐模型）</p></blockquote><hr><h3 id=-关键挑战与优化实践>⚠️ 关键挑战与优化实践</h3><ol><li><strong>治理难题</strong><ul><li><strong>元数据管理</strong>：采用 <strong>Apache Atlas</strong> 记录数据血缘、格式、权限，避免“数据沼泽”。</li><li><strong>小文件问题</strong>：定期合并小文件（如Spark <code>coalesce</code>），减少元数据压力。</li></ul></li><li><strong>性能优化</strong><ul><li><strong>索引与统计</strong>：为高频查询字段（如时间戳）构建统计信息，加速查询。</li><li><strong>缓存机制</strong>：Alluxio等缓存热数据，降低对象存储延迟。</li></ul></li></ol><hr><h3 id=-总结-3>💎 总结</h3><p>数据湖的存储形态是<strong>以分布式对象存储或HDFS为底座，按原始格式分层存放多源异构数据，辅以分区/分桶优化、列式压缩技术和四层逻辑隔离</strong>的综合体系。其核心价值在于<strong>低成本存全量、按需建模分析</strong>，但需依赖元数据治理（如Atlas）和开放格式（如Parquet）规避无序风险。未来随着 <strong>Delta Lake/Iceberg 等事务层普及</strong>，数据湖将进一步向实时化、强一致性演进。</p><h2 id=湖仓一体>湖仓一体</h2><p>湖仓一体（Data Lakehouse）是一种<strong>融合数据湖（Data Lake）与数据仓库（Data Warehouse）优势的新型数据架构</strong>，旨在解决传统数据架构中数据孤岛、存储冗余、分析效率低等问题。其核心是通过统一存储层、事务支持、开放格式等技术，实现低成本存储原始数据的同时，提供高性能分析、数据治理及多场景计算能力。以下是其核心要点：</p><hr><h3 id=-核心定义与背景>📚 <strong>核心定义与背景</strong></h3><ol><li><strong>融合架构</strong><ul><li><strong>数据湖优势</strong>：低成本存储任意类型原始数据（结构化、半结构化、非结构化）。</li><li><strong>数据仓库优势</strong>：强数据治理、事务支持（ACID）、高效分析能力（如SQL查询、BI报表）。</li><li><strong>湖仓一体</strong>：将两者结合，在统一平台上实现“原始数据灵活存储”与“高质量数据快速分析”的协同。</li></ul></li><li><strong>诞生背景</strong><ul><li>传统架构痛点：<ul><li>数据湖缺乏治理，易成“数据沼泽”；数据仓库扩展成本高，难支持半结构化/非结构化数据。</li><li>湖仓分离导致数据冗余、ETL流程长、一致性难保障（如金融行业需实时分析交易流）。</li></ul></li><li><strong>技术演进</strong>：2020年由Databricks提出概念，2023年入选“中国大数据十大关键词”，成为云原生时代主流架构。</li></ul></li></ol><hr><h3 id=-核心架构与关键技术>⚙️ <strong>核心架构与关键技术</strong></h3><ol><li><strong>分层设计</strong><ul><li><strong>统一存储层</strong>：基于对象存储（如AWS S3、HDFS），支持Parquet/ORC等开放格式，实现冷热数据分级（热数据实时访问，冷数据低成本归档）。</li><li><strong>事务管理层</strong>：通过Delta Lake、Apache Iceberg等框架提供ACID事务，确保并发读写一致性（如避免金融交易脏读）。</li><li><strong>计算引擎层</strong>：支持Spark、Flink、Presto等多引擎，实现批处理、流计算、机器学习统一调度。</li><li><strong>数据治理层</strong>：统一元数据管理（如Apache Ranger）、数据血缘追踪、权限控制（列级安全），提升数据可信度。</li></ul></li><li><strong>关键技术突破</strong><ul><li><strong>存算分离</strong>：存储与计算资源独立扩展，降低扩容成本（如存储用S3，计算用Spark集群）。</li><li><strong>Schema演进</strong>：支持动态调整数据结构（如Iceberg隐藏分区），无需重写数据。</li><li><strong>流批一体</strong>：直接处理实时数据流（如IoT传感器数据），替代复杂的Lambda架构。</li></ul></li></ol><hr><h3 id=-核心优势>💡 <strong>核心优势</strong></h3><div class=table-wrapper><table><thead><tr><th><strong>维度</strong></th><th><strong>传统数据湖</strong></th><th><strong>传统数据仓库</strong></th><th><strong>湖仓一体</strong></th></tr></thead><tbody><tr><td><strong>存储成本</strong></td><td>低（原始数据）</td><td>高（需ETL清洗）</td><td>✅ 更低（存算分离+开放格式）</td></tr><tr><td><strong>数据类型支持</strong></td><td>全类型（原始格式）</td><td>仅结构化</td><td>✅ 全类型统一存储</td></tr><tr><td><strong>事务一致性</strong></td><td>弱（易脏读）</td><td>强（ACID）</td><td>✅ 支持ACID事务</td></tr><tr><td><strong>查询性能</strong></td><td>慢（无优化）</td><td>快（预聚合）</td><td>✅ 接近数仓（列式存储+索引）</td></tr><tr><td><strong>实时分析</strong></td><td>需额外流处理系统</td><td>延迟高（批量导入）</td><td>✅ 原生支持流计算</td></tr></tbody></table></div><ol><li>成本效率<ul><li>存储成本降低50%+（利用对象存储），计算资源按需伸缩（如电商大促时扩容）。</li></ul></li><li>数据一致性<ul><li>避免湖仓混合架构的ETL延迟与数据不一致（如零售业库存实时同步）。</li></ul></li><li>敏捷分析<ul><li>BI工具（如Tableau）直接查询原始数据，数据科学家用同一平台训练AI模型（如用户画像分析）。</li></ul></li></ol><hr><h3 id=-典型应用场景-2>🌐 <strong>典型应用场景</strong></h3><ol><li>实时数仓<ul><li>金融风控：交易流实时分析（如反欺诈检测），湖仓一体支持毫秒级响应。</li></ul></li><li>AI/ML平台<ul><li>医疗影像分析：存储原始CT图像（非结构化），直接训练病灶识别模型。</li></ul></li><li>数据中台<ul><li>电商数据整合：统一用户行为日志（半结构化）、订单数据（结构化），生成实时大屏报表。</li></ul></li><li>IoT物联网<ul><li>工厂传感器数据：流式摄入设备状态，预测故障并触发维修工单。</li></ul></li></ol><hr><h3 id=-挑战与选型建议>⚠️ <strong>挑战与选型建议</strong></h3><ol><li><strong>现存挑战</strong><ul><li>技术成熟度：ACID事务在PB级数据下的稳定性待验证。</li><li>迁移成本：历史数仓需转换为Iceberg/Delta格式。</li><li>架构复杂性：多引擎协同运维难度高（如Spark+Flink+MLflow）。</li></ul></li><li><strong>选型建议</strong><ul><li><strong>适合企业</strong>：数据量超PB级、需混合分析（BI+AI）、追求实时性的场景（如金融、物联网）。</li><li>推荐方案：<ul><li>云厂商：AWS（Redshift+S3+Glue）、Azure（Synapse+ADLS）、阿里云（MaxCompute）。</li><li>开源：Apache Doris（存算分离+实时更新）、Delta Lake（ACID事务）。</li></ul></li></ul></li></ol><hr><h3 id=-总结-4>💎 <strong>总结</strong></h3><p>湖仓一体是数据架构从“存得下”迈向“用得好”的关键演进，它<strong>以统一存储为底座、事务管理为枢纽、开放生态为引擎</strong>，解决了数据价值链条的断裂问题。随着Delta Lake/Iceberg等技术的普及，湖仓一体正成为企业数据平台的<strong>新一代标准架构</strong>，尤其适合需兼顾实时性、成本与复杂分析的场景。未来，其与Serverless、AI-native技术的结合将进一步释放数据潜能。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/bigdata/>BigData</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on Jul 15, 2025 00:57 CST</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/mac.db_store-file/><div class=article-image><img src=/covers/cover20.jpg loading=lazy data-key data-hash=/covers/cover20.jpg></div><div class=article-details><h2 class=article-title>【Mac】.DB_Store file</h2></div></a></article><article><a href=/p/javagc/><div class=article-details><h2 class=article-title>【Java】GC</h2></div></a></article><article><a href=/p/java%E8%B0%83%E4%BC%98/><div class=article-details><h2 class=article-title>【Java】调优</h2></div></a></article><article><a href=/p/shopeejavaparser/><div class=article-details><h2 class=article-title>【Shopee】JavaParser</h2></div></a></article><article><a href=/p/shopeegraph/><div class=article-details><h2 class=article-title>【Shopee】Graph</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 飞鸿踏雪泥</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>