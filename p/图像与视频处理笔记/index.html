<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Image Restoration\nThe task of image restoration is to recover a clean image from its corrupted observation.\nLow-Light Image Enhancement\nGamma correction use a power law formula to images for pixel-wise enhancement with $I_{out} = A×I_{in}^γ$\nIntroduction Image Types Reflection Images\nsense radiation that has been reflected from the surfaces of objects. The information extracted is primarily an object’s shape, texture, color, reflectivity,\n-most visible optical images，radar images, sonar images, electron microscope images. Emission Images\n"><title>【图像与视频处理】笔记</title><link rel=canonical href=https://dyhes.github.io/p/%E5%9B%BE%E5%83%8F%E4%B8%8E%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/><link rel=stylesheet href=/scss/style.min.f7091bff8043bd3e53b22be6c05dd86b506e8dec4d0d75d249d2dfb0fe074a46.css><meta property='og:title' content="【图像与视频处理】笔记"><meta property='og:description' content="Image Restoration\nThe task of image restoration is to recover a clean image from its corrupted observation.\nLow-Light Image Enhancement\nGamma correction use a power law formula to images for pixel-wise enhancement with $I_{out} = A×I_{in}^γ$\nIntroduction Image Types Reflection Images\nsense radiation that has been reflected from the surfaces of objects. The information extracted is primarily an object’s shape, texture, color, reflectivity,\n-most visible optical images，radar images, sonar images, electron microscope images. Emission Images\n"><meta property='og:url' content='https://dyhes.github.io/p/%E5%9B%BE%E5%83%8F%E4%B8%8E%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/'><meta property='og:site_name' content='飞鸿踏雪泥'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2024-10-29T00:00:00+00:00'><meta property='article:modified_time' content='2025-10-22T16:27:30+08:00'><meta name=twitter:title content="【图像与视频处理】笔记"><meta name=twitter:description content="Image Restoration\nThe task of image restoration is to recover a clean image from its corrupted observation.\nLow-Light Image Enhancement\nGamma correction use a power law formula to images for pixel-wise enhancement with $I_{out} = A×I_{in}^γ$\nIntroduction Image Types Reflection Images\nsense radiation that has been reflected from the surfaces of objects. The information extracted is primarily an object’s shape, texture, color, reflectivity,\n-most visible optical images，radar images, sonar images, electron microscope images. Emission Images\n"><link rel="shortcut icon" href=/github.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_b567f26f71c49c33.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>飞鸿踏雪泥</a></h1><h2 class=site-description>没有记录，就没有发生</h2></div></header><ol class=menu-social><li><a href=https://leetcode.cn/u/dyhes/ target=_blank title=LeetCode rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 13h7.5"/><path d="M9.424 7.268l4.999-4.999"/><path d="M16.633 16.644l-2.402 2.415a3.189 3.189.0 01-4.524.0l-3.77-3.787a3.223 3.223.0 010-4.544l3.77-3.787a3.189 3.189.0 014.524.0l2.302 2.313"/></svg></a></li><li><a href=https://github.com/dyhes target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:dyheslin@gmail.com target=_blank title=Gmail rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-gmail"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M16 20h3a1 1 0 001-1V5a1 1 0 00-1-1h-3v16z"/><path d="M5 20h3V4H5A1 1 0 004 5v14a1 1 0 001 1z"/><path d="M16 4l-4 4-4-4"/><path d="M4 6.5l8 7.5 8-7.5"/></svg></a></li><li><a href=mailto:1325574784@qq.com target=_blank title=Mail rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M13 19H5a2 2 0 01-2-2V7a2 2 0 012-2h14a2 2 0 012 2v5.5"/><path d="M3 7l9 6 9-6"/><path d="M19 16l-2 3h4l-2 3"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/categories/><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
<span>Categories</span></a></li><li><a href=/tags/><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#introduction>Introduction</a><ol><li><a href=#image-types>Image Types</a><ol><li><a href=#sampling-image>Sampling Image</a></li><li><a href=#quantization-image>Quantization Image</a></li><li><a href=#color-image>Color Image</a></li></ol></li><li><a href=#video>Video</a></li></ol></li><li><a href=#basic-image-processing>Basic Image Processing</a><ol><li><a href=#notion>Notion</a></li><li><a href=#basic-gray-level-image-processing>Basic Gray-Level Image Processing</a><ol><li><a href=#operations-type>Operations Type</a></li><li><a href=#image-histogram>Image Histogram</a></li><li><a href=#nonlinear-point-operations>Nonlinear Point Operations</a></li><li><a href=#arithmetic-operations-between-images>Arithmetic Operations between Images</a></li><li><a href=#geometric-image-operations>Geometric Image Operations</a></li></ol></li><li><a href=#basic-binary-image-processing>Basic Binary Image Processing</a><ol><li><a href=#image-thresholding>Image Thresholding</a></li><li><a href=#region-labeling>Region Labeling</a></li><li><a href=#region-counting>Region Counting</a></li><li><a href=#minor-region-removal>Minor Region Removal</a></li><li><a href=#logical-operations>Logical Operations</a></li><li><a href=#representation--compression>Representation & Compression</a></li></ol></li></ol></li><li><a href=#linear-image-filter>Linear Image Filter</a><ol><li><a href=#definitions>Definitions</a><ol><li><a href=#linear-system>Linear System</a></li><li><a href=#linear-time-invariance-lti-system>Linear time invariance (LTI) system</a></li><li><a href=#two-dimensional-system>Two dimensional System</a></li><li><a href=#filtering-system>Filtering System</a></li><li><a href=#linear-image-enhancement>linear image enhancement</a></li></ol></li><li><a href=#linear-spatial-filter>linear spatial filter</a><ol><li><a href=#moving-average-filter>Moving Average Filter</a></li><li><a href=#sharping-spatial-filter>Sharping spatial filter</a></li></ol></li><li><a href=#linear-frequency-filter>Linear frequency filter</a><ol><li><a href=#definitions-1>Definitions</a></li><li><a href=#type-1>Type</a></li><li><a href=#smoothing>Smoothing</a></li><li><a href=#sharpening>Sharpening</a></li><li><a href=#selective-filtering>Selective Filtering</a></li></ol></li><li><a href=#limitation>Limitation</a></li></ol></li><li><a href=#nonlinear-filter>Nonlinear Filter</a><ol><li><a href=#noise-model>Noise Model</a><ol><li><a href=#white-gaussian-noise>White Gaussian noise</a></li><li><a href=#salt--pepper-noise>Salt & pepper noise</a></li></ol></li><li><a href=#order-statistic-filter>Order-Statistic Filter</a><ol><li><a href=#max-filter>Max Filter</a></li><li><a href=#min-filter>Min Filter</a></li></ol></li><li><a href=#median-smoother>Median Smoother</a><ol><li><a href=#weighted-median-smoother>Weighted Median Smoother</a></li><li><a href=#center-weighted-median-smoothers>Center Weighted Median Smoothers</a></li><li><a href=#weighted-median-smoother-with-negative-weight>Weighted Median Smoother with negative weight</a></li><li><a href=#vector-weighted-median-filters>Vector Weighted Median Filters</a></li><li><a href=#application>Application</a></li></ol></li></ol></li><li><a href=#image-compression>Image Compression</a><ol><li><a href=#lossless-coding>Lossless Coding</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/star/ style=background-color:#2e317c;color:>一天星</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E5%9B%BE%E5%83%8F%E4%B8%8E%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/>【图像与视频处理】笔记</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Oct 29, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>19 minute read</time></div></footer></div></header><section class=article-content><p><strong>Image Restoration</strong></p><p>The task of image restoration is to <strong>recover</strong> a clean image from its <strong>corrupted</strong> observation.</p><p><strong>Low-Light Image Enhancement</strong></p><p><strong>Gamma correction</strong> use a power law formula to images for pixel-wise enhancement with $I_{out} = A×I_{in}^γ$</p><h2 id=introduction>Introduction</h2><h3 id=image-types>Image Types</h3><ul><li><p>Reflection Images</p><p>sense radiation that has been reflected from the <strong>surfaces</strong> of objects. The information extracted is primarily an object’s shape, texture, color, reflectivity,</p><ul><li>-most visible optical images，radar images, sonar images, electron microscope images.</li></ul></li><li><p>Emission Images</p><p>the objects being imaged are <strong>self-luminous</strong>. The information may reveal the <strong>internal structure</strong> of an object.</p><p>thermal or infrared images, MRI images</p></li><li><p>Absorption Images</p><p>yield information about the internal structure of objects. The radiation passes through objects and is <strong>absorbed or partially absorbed</strong>.</p><p>X-ray images, certain types of sonic images.</p></li></ul><h4 id=sampling-image>Sampling Image</h4><p>Sampling is the process of converting a continuous-<strong>space</strong> (or continuous-space/time) signal into a discrete-space (or discrete-space/time) signal.</p><p>The number of rows and columns in a sampled image is also often selected to be a <strong>power of 2</strong>.</p><ul><li>to simplify <strong>computer addressing</strong> of the samples</li><li>to make algorithms, such as discrete Fourier transforms, efficient</li></ul><p>Images are nearly always <strong>rectangular</strong>.</p><h4 id=quantization-image>Quantization Image</h4><p>Quantization is the process of converting a continuous-<strong>valued</strong> image, which has a continuous range (set of values that it can take), into a discrete-valued image, which has a discrete range.</p><h5 id=gray-scale>Gray Scale</h5><p>The gray level of a quantized image pixel is one of a finite set of numbers, which is the gray level range $(0, 2^B-1)$</p><ul><li>B=1(binary images);</li><li>B=8, Each gray level occupies a byte, 8-bit depths</li><li>color images (Multivalued images) require 24 bits per pixel</li></ul><h4 id=color-image>Color Image</h4><ul><li>RGB(Red, Green, Blue), color cameras, display systems</li><li>YIQ(luminance, in-phase chromatic, quadratic chromatic), broadcast television</li></ul><h5 id=storage>Storage</h5><p>The storage required for a single monochromatic digital still image that has (row x column) dimensions N * M and B bits of gray-level resolution is <strong>N * M * B</strong> bits.</p><h3 id=video>Video</h3><p>Video quantization is <strong>essentially</strong> the same as image quantization. However, video sampling involves taking samples along a new and different (time) dimension.</p><p>The human eye asks the refresh rate more than <strong>50</strong> frames/s</p><p><strong>Analog video systems</strong>, such as television and monitors, represent video as a <strong>one-dimensional electrical signal</strong> and Progressively scan line by line from top to bottom.</p><p>For High-resolution computer monitors , the scan rate is 1/72 s/frame, and the refresh rate <strong>72</strong></p><p>Digital video is obtained either by sampling an analog video signal V(t), or by directly sampling the 3D space-time intensity distribution that is incident on a sensor.</p><ul><li>2D spatial intensity array</li><li>3D space-time array</li></ul><p>The data volume of digital video is usually described in terms of <strong>bandwidth</strong> or bit rate (Kilo-/Mega-/Giga- bits/s, bps). 100Mbps, <strong>Cable</strong>:1Gbps</p><p>Digital video can be <strong>compressed</strong> very effectively because of the redundancy inherent in the data, and because of an increased understanding of what components in the video stream are actually visible</p><h2 id=basic-image-processing>Basic Image Processing</h2><h3 id=notion>Notion</h3><p>Only monochromatic images are considered.</p><p>Image f(n), n=(n1, n2), N * M (rows, columns), n1=0<del>N-1, n2=0</del>M-1.</p><p>The image f(n) is assumed to be quantized to K levels {0, . . . , K - 1).</p><h3 id=basic-gray-level-image-processing>Basic Gray-Level Image Processing</h3><h4 id=operations-type>Operations Type</h4><h5 id=point-operation>Point Operation</h5><p>Point operations are defined as functions of pixel intensity only, <strong>not considering spatial information</strong>, such as a pixel’s location and the values of its neighbors</p><h5 id=arithmetic-operation>Arithmetic operation</h5><p>Arithmetic operations between images of the <strong>same spatial dimensions</strong>, not considering spatial information, for noise reduction and change or motion detection.</p><h5 id=geometric-operation>Geometric operation</h5><p>Geometric operations are functions of <strong>spatial position only</strong>, such as image translation, rotation, distortion, bend or video morph.</p><h4 id=image-histogram>Image Histogram</h4><p>The histogram $H_f$ of the digital image $f$ is a plot or graph of the <strong>frequency of occurrence</strong> of each gray level in $f$</p><ul><li>The histogram $H_f$ contains <strong>no spatial</strong> information.</li><li>The histogram supplies a method of determining an image’s <strong>gray-level distribution</strong>.</li></ul><h5 id=aod>AOD</h5><p>AOD (average optical density) is the basic measure of an image’s <strong>overall average brightness</strong> or gray level.</p><p>AOD is a meter for estimating the <strong>center</strong> of an image’s gray-level distribution.
$$
AOD(f)=\frac{1}{MN}\sum_{n_1=0}^{N-1}\sum_{n_2=0}^{M-1}f(n_1,n_2)
\newline=\frac{1}{MN}\sum_{k=0}^{K-1}kH_f(k)
$$</p><h5 id=-linear-point-operation># linear Point Operation</h5><h5 id=additive-image-offset>Additive Image Offset</h5><p>$$
g(n)=f(n)+L
\newline
h_g(k) = h_f(k-L)
$$</p><p><strong>Calibrate</strong> images to a given average brightness level.
$$
g(n)=f(n)-L+\frac{K}{2}
$$</p><h5 id=multiplicative-image-scaling>Multiplicative Image Scaling</h5><p>$$
g(n)=\lfloor Pf(n)+0.5\rfloor
$$</p><p>multiply and rounding</p><h5 id=image-negative>Image Negative</h5><p>$$
g(n)=K-1 - f(n)
$$</p><h5 id=full-scale-histogram-stretch>Full-scale Histogram Stretch</h5><p>full-scale histogram stretch, or contrast stretch, expands the image histogram to <strong>fill the entire available gray-scale range</strong>.</p><p><img src=https://i.ibb.co/XkJNw1Sf/image-20240927125203449.png loading=lazy alt=image-20240927125203449></p><h4 id=nonlinear-point-operations>Nonlinear Point Operations</h4><h5 id=logarithmic-point-operation>Logarithmic Point Operation</h5><p>$$
g(n)=FSHS(\lfloor log(1 + f(n)) \rfloor)
$$</p><p>Larger (brighter) gray levels are compressed much more severely than smaller gray levels.</p><p>dim objects in the original are now allocated a much larger percentage of the grayscale range, hence <strong>improving their visibility</strong>.</p><h5 id=histogram-equalization>Histogram Equalization</h5><p>Histogram equalization, or <strong>histogram flattening</strong>, to make an image fill the available gray-scale range, and be <strong>uniformly distributed</strong> over that range.</p><p>The idealized goal is a flat histogram. An image with a perfectly flat histogram contains the largest possible amount of information or complexity.</p><p>Steps:</p><ol><li><p>get histogram of image</p><p>$H_f(k), k \in [0, K-1]$</p></li><li><p>get relative frequency (normalized histogram)</p><p>$p_f(k) = \frac{H_f(k)}{MN}, k \in [0, K-1]$</p></li><li><p>get absolute frequency (cumulative histogram)</p><p>$P_f(k) = \sum_{r=0}^kp_f(r), k \in [0, K-1]$</p></li><li><p>replace k with k'</p><p>$k^{&rsquo;}=FSHS[P_f(k)], k \in [0, K-1]$</p></li></ol><p>eg.</p><p><img src=https://i.ibb.co/MyCxH6Gq/image-20241003175425324.png loading=lazy alt=image-20241003175425324></p><h4 id=arithmetic-operations-between-images>Arithmetic Operations between Images</h4><ul><li>Image sum</li><li>image difference</li><li>Pointwise image product</li><li>Pointwise image quotient</li></ul><h4 id=geometric-image-operations>Geometric Image Operations</h4><ul><li>Image Translation</li><li>Image Rotation</li><li>Image Zoom<ul><li>nearest neighbor interpolation</li><li>bilinear interpolation</li></ul></li></ul><h3 id=basic-binary-image-processing>Basic Binary Image Processing</h3><h4 id=image-thresholding>Image Thresholding</h4><p><img src=https://i.ibb.co/s9MCgHck/image-20241003183157784.png loading=lazy alt=image-20241003183157784></p><p>Thresholding is most commonly and effectively applied to images that can be characterized as having <strong>bimodal</strong> histograms.</p><h4 id=region-labeling>Region Labeling</h4><p>A simple but powerful tool for identifying and labeling the various objects in a binary image is a process called region labeling, blob coloring, or connected component identification.</p><p>It is useful since once they are individually labeled, the objects can be separately manipulated, displayed or modified</p><h4 id=region-counting>Region Counting</h4><p>A simple application of region labeling is the measurement of object area.</p><p>This can be accomplished by defining a vector c with elements c(k) that are the pixel area (pixel count) of region k</p><h4 id=minor-region-removal>Minor Region Removal</h4><p><img src=https://i.ibb.co/Y4FHKkKf/image-20241003185339142.png loading=lazy alt=image-20241003185339142></p><h4 id=logical-operations>Logical Operations</h4><ul><li><p>NOT</p></li><li><p>AND</p></li><li><p>OR</p></li><li><p>XOR</p></li><li><p>MAJ</p><p>returns value &ldquo;1&rdquo; if and only if a majority of (xl , . . . , xn ) equal &ldquo;1&rdquo;</p></li></ul><h5 id=dilation-filter>dilation filter</h5><p>$$
g(n)=OR[Bf(n)]
$$</p><p>expands the foreground, removing bays of too-narrow width, and removing small holes</p><h5 id=erosion-filter>erosion filter</h5><p>shrinks the foreground, removes fingers of too-narrow width, removes &ldquo;l&rdquo;-valued small objects.
$$
g(n)=AND[Bf(n)]
$$</p><h5 id=relationship>relationship</h5><p>$$
dilation(f,B)=NOT(erosion[NOT(f),B])
\newline
erosion(f,B)=NOT(dilation[NOT(f),B])
$$</p><p>Erode and dilate filters have the effect of changing the sizes of objects, as well as <strong>smoothing</strong> them.</p><p>Erode and dilate shrink and expand the sizes of &ldquo;l&rdquo;- valued objects in a binary image. However, they are <strong>not inverse</strong> operations of one another.</p><p>They are approximate inverses in the sense that if they are performed <strong>in sequence</strong> on the same image with the same window B, and the object and holes that are not eliminated will be returned to their <strong>approximate</strong> sizes.</p><h5 id=open-filter-and-close-filter>open filter and close filter</h5><p>size-preserving smoothing morphologic operators
$$
open(f,B)=erosion[dilation(f,B),B]
\newline
close(f,B)=dilation[erosion(f,B),B]
$$
The open and close filters are <strong>biased</strong> filters in the sense that they remove one type of &ldquo;noise&rdquo; (either extraneous WHITE or BLACK features), but not both.</p><p>It is worth noting that the close and open filters are again in fact, the same filters, in the dual sense.
$$
open(f,B)=NOT(close[NOT(f),B])
\newline
close(f,B)=NOT(open[NOT(f),B])
$$</p><h5 id=close-open-filter-and-open-close-filter>close-open filter and open-close filter</h5><p>unbiased smoothing morphologic operators
$$
close-open(f,B)=close[open(f,B),B]
\newline
open-close(f,B)=open[close(f,B),B]
$$
If the filters are properly alternated as in the construction of the close-open and open-close filters, then the dual filters become increasingly similar. However, the <strong>smoothing</strong> power can most easily be increased by simply taking the window size to be larger.</p><p>Once again, the close-open and open-close filters are dual filters <strong>under complementation</strong>.</p><h5 id=majority-filter>majority filter</h5><p>binary median filter, filter has <strong>similar</strong> attributes as the close-open and open-close filters:</p><ul><li>it removes too-small objects, holes, gaps, bays and peninsulas (both “1”-valued and “0”-valued small features)</li><li>it also does not generally change the size of objects or of background.</li></ul><p>The majority filter is <strong>less biased</strong> than any of the other morphologic filters, since it does not have an initial erode or dilate operation to set the bias.</p><p>The majority filter is a <strong>power, unbiased shape smoother</strong>. However, for a given filter size, it <strong>does not have the same degree of smoothing power</strong> as close-open or open-close.</p><h5 id=morphologic-boundary-detection>Morphologic Boundary Detection</h5><p>$$
boundary(f,B)=XOR[f,dilation(f,B)]
$$</p><h4 id=representation--compression>Representation & Compression</h4><ul><li>run-length coding seeks to <strong>exploit the redundancy</strong> of long run lengths or runs of constant value &ldquo;1&rdquo; or &ldquo;0&rdquo; in the binary data. – for the coding/compression of binary images containing large areas of constant value &ldquo;1&rdquo; and &ldquo;0&rdquo;.</li><li>chain coding, is appropriate for binary images containing binary <strong>contours</strong>. – The chain code is also an information-rich, highly manipulable representation for shape analysis</li></ul><h2 id=linear-image-filter>Linear Image Filter</h2><p><strong>Linear system theory and linear filtering</strong> play a central role in digital image and video processing.</p><ul><li>modifying, improving, or representing digital visual data are expressed in terms of linear systems concepts.</li><li>Linear filters are used for image/video contrast improvement, denoising, and sharpening, target matching and feature enhancement</li></ul><h3 id=definitions>Definitions</h3><h4 id=linear-system>Linear System</h4><p>with the properties of superposition and homogeneity.
$$
x_1(t)+x_2(t)\to y_1(t)+y_2(t) \space for \space any \space x_1(t), x_2(t)
\newline
ax_1(t)\to ay_1(t) \space for \space any \space a
$$</p><h4 id=linear-time-invariance-lti-system>Linear time invariance (LTI) system</h4><p>$$
x(t)\to y(t)
\newline
x(t-T)\to y(t-T)
$$</p><h4 id=two-dimensional-system>Two dimensional System</h4><p>A two dimensional System is a process of image transformation.</p><p><img src=https://i.ibb.co/DfNVKHdb/image-20241003203638563.png loading=lazy alt=image-20241003203638563></p><p>Two-dimensional system is linear and shift invariance ( LSI )</p><p>The system L is <strong>linear</strong> if</p><ul><li>for any $g_1(m,n)=L[f_1(m,n)]$ and $g_2(m,n)=L[f_2(m,n)]$, $ag_1(m,n)+bg_2(m,n) = L[af_1(m,n)+bf_2(m,n)]$ for any a and b</li></ul><p>The system L is shift invariance if</p><ul><li>for any( p , q) $g(m-p,n-q)=L[f(m-p,n-q)]$</li></ul><h4 id=filtering-system>Filtering System</h4><p>A filtering system is a system that <strong>removes redundant or unwanted information</strong> from an information stream.</p><p>Linear filtering system, which means the filtering process between the input and output is <strong>linear</strong> operation.</p><p>In image processing, the filtering process represents the process of image <strong>enhancement</strong>, including the image/video contrast improvement, denoising, and sharpening, target matching and feature enhancement.</p><ul><li>linear filtering in spatial domain</li><li>linear filtering in frequency domain</li></ul><p>linear image enhancement – means a process of smoothing irregularities or noise that has somehow corrupted the image, while modifying the original image information as little as possible. – Sharping the image to highlight the details</p><h4 id=linear-image-enhancement>linear image enhancement</h4><ul><li>means a process of <strong>smoothing irregularities or noise</strong> that has somehow corrupted the image, while modifying the original image information as <strong>little</strong> as possible.</li><li><strong>Sharping</strong> the image to highlight the details</li></ul><h5 id=type>Type</h5><ul><li>Spatial domain, operating directly on the pixels of an image</li><li>Frequency domain, operating on the <strong>Fourier transform</strong> of an image, rather than on the image itself.</li></ul><h3 id=linear-spatial-filter>linear spatial filter</h3><p>Filtering operations that are performed <strong>directly on the pixels</strong> of an image, and the computations performed on the pixels of the neighborhoods are linear.</p><p>The linear operations consist of <strong>multiplying</strong> each pixel in the neighborhood by a corresponding coefficient and <strong>summing</strong> the results to obtain the response at each point.</p><p>If the neighborhood is of size m×n, m×n coefficients are required, they are arranged as a <strong>matrix</strong>, called a filter, mask, filter mask, kernel, template, or window.</p><h4 id=moving-average-filter>Moving Average Filter</h4><p>Its output at a given position is the average of all pixels covered by the filter, thus it is used to <strong>blur</strong> the image or to reduce the noise.</p><h5 id=noise-reduction>Noise Reduction</h5><p>The noise is usually modeled as an additive noise or as a multiplicative noise. We will assume a zero-mean additive white noise model.</p><p>We model the observed noisy image f as a sum of an original image o and a noise image q, $f=o+q$</p><p>The goal of enhancement is to recover an image g that resembles o as closely as possible by reducing q</p><p>Given an image f to be filtered and a window (filter mask) B, then the moving average-filtered image g is given by
$$
g(n)=AVG[Bf(n)]
$$
Since the average is a linear operation, it is also true that
$$
g(n)=AVG[Bo(n)]+AVG[Bq(n)]
$$
Because the noise process q is assumed to be zero mean, then the last term will tend to zero as the filter window is increased.</p><p>Thus, the moving average filter has the desirable effect of reducing zero-mean image noise toward zero.</p><p>However, the filter also affects the original image information. The moving average filter will <strong>blur</strong> the image, especially as the window span is increased.</p><p>Balancing this tradeoff is often a difficult task.</p><h4 id=sharping-spatial-filter>Sharping spatial filter</h4><p>The principal objective of sharpening is to <strong>highlight transitions in intensity</strong>. Highlight the details, enhance the blurred image</p><p>Image blurring can be accomplished in the spatial domain by pixel averaging in a neighborhood. Because averaging is analogous to integration, it is logical to conclude that sharpening can be accomplished by <strong>spatial differentiation</strong>.</p><p>Fundamentally, the strength of response of a <strong>derivative operator</strong> is proportional to the degree of intensity discontinuity of the image at the point at which the operator is applied.</p><p>Thus, image differentiation enhances edges and other discontinuities (such as noise) and deemphasizes areas with slowly varying intensities.</p><p><img src=https://i.ibb.co/dJ3FyF1g/image-20241003213931612.png loading=lazy alt=image-20241003213931612></p><p>Second-order derivative enhances fine detail much better than the first-order derivates.</p><h5 id=the-laplacian>The Laplacian</h5><p>Isotropic filters are <strong>rotation invariant</strong>, in this sense that rotating the image and then applying the filter gives the same result as applying the filter to the image first and then rotating the result.</p><p>The simplest isotropic derivative operator is the Laplacian.</p><p><img src=https://i.ibb.co/TBPKC90Y/image-20241003214431623.png loading=lazy alt=image-20241003214431623></p><p><img src=https://i.ibb.co/VYm8v9K1/image-20241003214520351.png loading=lazy alt=image-20241003214520351></p><p>If we need to sharping an image while preserving the background features, we can simply <strong>add</strong> the Laplacian image to the original.</p><p>Laplacian contains both positive and negative values, and all the negative values are <strong>clipped at 0</strong> by the display.</p><p>Thus it need to be scaled, a typical way is to add to it its minimum value to bring the new minimum to zero and then scale the result to the full[0, L-1] intensity range.</p><h3 id=linear-frequency-filter>Linear frequency filter</h3><p>In frequency domain, the operations is performed on the <strong>Fourier transform</strong> of an image.</p><p>Despite the <strong>computational</strong> efficiency of the spatial domain techniques, some image processing tasks are more easier or more meaningful to implement in the frequency domain.</p><h4 id=definitions-1>Definitions</h4><h5 id=impulse-response>Impulse Response</h5><p>the <strong>output</strong> of a system when its input is <strong>unit impulse function</strong>.</p><p>For a discrete-time systems, impulse response is generally expressed in <strong>sequence h[n</strong>]. The corresponding discrete input signal, i.e. the unit impulse function satisfies Kronecker delta function.</p><p><img src=https://i.ibb.co/dsqbmwZF/image-20241004141848099.png loading=lazy alt=image-20241004141848099></p><h5 id=two-dimensional-impulse-function>Two-dimensional impulse function</h5><p><img src=https://i.ibb.co/vC8BmGNY/image-20241004142131257.png loading=lazy alt=image-20241004142131257></p><p>The impulse response of a two-dimensional input-output system L is</p><ul><li>the response of system L, at spatial position (m, n), to an impulse located at spatial position ( p , q)</li><li>if the system L is space invariant, then $h(m-p,n-q) = L[\delta(m-p,n-q)]$</li></ul><h5 id=discrete-space-image>Discrete-space image</h5><p>Any discrete-space image f may be expressed in terms of the impulse function.
$$
f(m,n) = \sum_{p=-\infty}^\infty \sum_{q=-\infty}^\infty f(m-p,n-q)\delta(p,q)
\newline= \sum_{p=-\infty}^\infty \sum_{q=-\infty}^\infty f(p,q)\delta(m-p,n-q)
$$</p><h5 id=frequency-response>Frequency Response</h5><p>The discrete-space Fourier transform (<strong>DSFT</strong>) of the system <strong>impulse response</strong>.</p><p>According to the Fourier transform, the convolution in the space domain equals the product in the frequency domain.</p><p><img src=https://i.ibb.co/67PPbzg2/image-20241004144353221.png loading=lazy alt=image-20241004144353221>
$$
g(m,n) = f(m,n)*h(m,n)
$$
The output of the system L can be expressed in terms of the frequency response by
$$
G(u,v) = F(u,v)H(u,v)
$$</p><h5 id=principal>Principal</h5><p>Images we see are all in spatial domain, we can’t recognize the images in frequency domain, so if we need to process the image in frequency domain, we need</p><ul><li>Transform the image to the frequency domain using Fourier transform</li><li>Filter in the frequency domain</li><li>Transform the image back to the spatial domain using inverse Fourier transform</li></ul><h4 id=type-1>Type</h4><ul><li>low-pass</li><li>bandpass</li><li>high-pass</li><li>oriented</li></ul><p>For a given filter type, different degrees of <strong>smoothing (sharping)</strong> can be obtained by adjusting the filter bandwidth.</p><p>A narrower bandwidth low-pass filter will reject more of the high-frequency noise – but it may also degrade the image content by attenuating important high-frequency image details. This is a tradeoff that is difficult to balance.</p><h4 id=smoothing>Smoothing</h4><p>Smoothing(blurring) is achieved in the frequency domain by <strong>high-frequency attenuation</strong>(by lowpass filtering)</p><h5 id=ideal>Ideal</h5><p>ideal low-pass filter (ideal LPF) was designed explicitly with no sidelobes in frequency domain by forcing the frequency response to be zero outside of a given radial cutoff frequency.</p><p><img src=https://i.ibb.co/Xx0qGXGf/image-20241004135745680.png loading=lazy alt=image-20241004135745680></p><p>From the figure and the equation, we know that all frequencies on or inside a circle are passed without attenuation, whereas all frequencies outside the circle are completely attenuated(filtered out).</p><p>The point of transition between H(u,v) = 1 and H(u,v) = 0 is called <strong>cutoff frequency</strong>.</p><p><strong>drawbacks</strong></p><p>truncating in the frequency domain causes <strong>ringing</strong> in the space domain, which creates more of a problem because of the edge response of the ideal LPF.</p><h5 id=butterworth>Butterworth</h5><p>The transfer function of a Butterworth lowpass filter(BLPF) of order n, and with cutoff frequency at a distance D0 from the origin.</p><p><img src=https://i.ibb.co/N6M5N817/image-20241004140738618.png loading=lazy alt=image-20241004140738618></p><p>The cutoff frequency defines as the point for which H(u,v) is <strong>down to 50%</strong> from its maximum value of 1.0.</p><p>Unlike the ILPF, the BLPF transfer function doesn’t have a sharp discontinuity that gives a clear cutoff between passed and filtered frequencies.</p><p>A BLPF of order 1 has no ringing in the spatial domain.</p><p>Ringing increases as a function of filter order.</p><p>BLPF of order 2 are a <strong>good compromise</strong> between effective lowpass filtering and acceptable ringing.</p><h5 id=gaussian>Gaussian</h5><p>Filter sidelobes in either the space or frequency domain contribute a <strong>negative effect</strong> to the responses of noise-smoothing linear image enhancement filters.</p><ul><li>Frequency domain sidelobes lead to <strong>noise leakage</strong>.</li><li>Space domain sidelobes lead to <strong>ringing artifacts</strong>.</li></ul><p>Gaussian filter is a filter with sidelobes in neither domain.</p><p><strong>impulse response</strong></p><p><img src=https://i.ibb.co/qYGfCtqg/image-20241004144757490.png loading=lazy alt=image-20241004144757490></p><p><strong>frequency response</strong></p><p><img src=https://i.ibb.co/5hzYfPG5/image-20241004144834975.png loading=lazy alt=image-20241004144834975></p><h4 id=sharpening>Sharpening</h4><p><strong>Edges and other abrupt changes</strong> in intensities are associated with high- frequency components.</p><p>Image sharpening can be achieved in the frequency domain by high-pass filtering – which attenuates the low frequency components without disturbing high-frequency information in the Fourier transform.</p><p>A high-pass filter is obtained from a given lowpass filter using equation
$$
H_{HP}(u,v)=1-H_{LP}(u,v)
$$
That is, when low-pass filter attenuates frequencies, the high-pass filter pass them, and vice versa.</p><p>If we get the result of high-pass filter, then we can enhance an image by</p><p><img src=https://i.ibb.co/9SKN2zk/image-20241004145234159.png loading=lazy alt=image-20241004145234159></p><h5 id=ideal-1>Ideal</h5><p><img src=https://i.ibb.co/7N08JJQY/image-20241004145344978.png loading=lazy alt=image-20241004145344978></p><p>The IHPF sets to zero all frequencies inside the circle, and pass all frequencies outside the circle.</p><p>As ILPF, IHPF has the same ringing properties(for the truncating function in frequency domain)</p><h5 id=butterworth-1>Butterworth</h5><p><img src=https://i.ibb.co/qMz7STF3/image-20241004145431636.png loading=lazy alt=image-20241004145431636></p><p>Butterworth high-pass filters smoother than IHPFs.</p><p>As BLPF, the lower the order is, the less the effect of ringing of BHPF</p><h4 id=selective-filtering>Selective Filtering</h4><ul><li>Filters that operate over the entire frequency rectangle are called bandreject or bandpass filters</li><li>Filters that process specific bands of frequencies or small region are called notch filters</li></ul><h5 id=bandreject-filters>Bandreject filters</h5><p>ideal, Butterworth, Gaussian</p><p><img src=https://i.ibb.co/RTrvHqqL/image-20241004151540226.png loading=lazy alt=image-20241004151540226></p><p>The bandreject filter could be used to <strong>reduce the cyclicity noise</strong>.</p><h5 id=bandpass-filters>Bandpass filters</h5><p>A bandpass filter is obtained from a bandreject in the same manner that we obtained a highpass filter from a lowpass filter.</p><h5 id=notch-filters>Notch filters</h5><p>Notch filters are the most useful of the selective filters.</p><p>A notch filter rejects(or passes) frequencies in a <strong>predefined</strong> neighborhood about the center of the frequency rectangle.</p><p>Notch reject filters are <strong>constructed as products of highpass filters</strong> whose centers have been translated to the centers of the notches.</p><p><img src=https://i.ibb.co/Kcprf99d/image-20241004152558696.png loading=lazy alt=image-20241004152558696></p><p>Notch filters also used to reduce the cyclicity noise.</p><p>Although the bandreject filter also used to reduce the cyclicity noise, but it also attenuate the other part except the noise.</p><p>The notch filters <strong>only affect the noise</strong>.</p><h3 id=limitation>Limitation</h3><p>The removal of broadband noise from most images by means of linear filtering is <strong>impossible without some degradation</strong> (blurring) of the image information content.</p><p>Due to the fact that complete frequency separation between signal and broadband noise is rarely practicable.</p><h2 id=nonlinear-filter>Nonlinear Filter</h2><ul><li>Nonlinear methods effectively <strong>preserve edges and details</strong> of images, whereas methods using linear operators tend to blur and distort them.</li><li>Additionally, nonlinear image enhancement tools are <strong>less susceptible to noise</strong>.</li></ul><h3 id=noise-model>Noise Model</h3><p>The principal sources of noise in digital images arise during <strong>image acquisition and/or transmission</strong></p><h4 id=white-gaussian-noise>White Gaussian noise</h4><p>The probability density function is <strong>Gaussian</strong>, and the frequency spectrum of noise is <strong>uniform</strong>.</p><p>Because of its mathematical tractability in both the spatial and frequency domain, Gaussian noise models are used frequently in practice.</p><p><img src=https://i.ibb.co/XqXG80C/image-20241012150735599.png loading=lazy alt=image-20241012150735599></p><h4 id=salt--pepper-noise>Salt & pepper noise</h4><p>Salt & pepper noise also called as <strong>impulse</strong> noise, the probability of impulse noise is given by</p><p><img src=https://i.ibb.co/gLLfQX3v/image-20241012151600566.png loading=lazy alt=image-20241012151600566></p><p>If b>a, then intensity b will appear as a light dot in image, this light dot called <strong>salt noise</strong>, intensity a will appear as a dark dot, called <strong>pepper noise</strong>.</p><h3 id=order-statistic-filter>Order-Statistic Filter</h3><p>Order-statistic filters are nonlinear spatial filters whose response is based on ordering(ranking) the pixels contained in the image area encompassed by the filter, and then <strong>replacing the value of the center pixel</strong> with the value determined by the ranking result.</p><h4 id=max-filter>Max Filter</h4><p>This filter is useful for reducing pepper noise (dark dot). The value of the center is replaced by the max.</p><p>May also remove some dark pixels from the borders of the dark objects.</p><h4 id=min-filter>Min Filter</h4><p>This filter is useful for reducing salt noise (bright dot). The value of the center is replaced by the min.</p><p>May also remove some white points around the border of light objects.</p><h3 id=median-smoother>Median Smoother</h3><p><img src=https://i.ibb.co/vvRXDZWW/image-20241012155324649.png loading=lazy alt=image-20241012155324649></p><p><strong>Recursive</strong></p><p>Running medians can be extended to a recursive mode by replacing the “causal” input samples in the median smoother by previously derived output samples. The output of the recursive median smoother is given by</p><p><img src=https://i.ibb.co/5WfLYzsN/image-20241012155557263.png loading=lazy alt=image-20241012155557263></p><p>With the same amount of operations, recursive median smoothers have <strong>better noise attenuation capabilities</strong> than their non recursive counterparts</p><p>Given N samples x1 , . . , xN, the sample mean and sample median minimize the expression for p = 2 and p = 1, respectively.</p><p><img src=https://i.ibb.co/sd9BVyfx/image-20241012160006731.png loading=lazy alt=image-20241012160006731></p><p>The sample mean is given by the sample whose <strong>sum of square distance</strong> to all samples in the set is the <strong>smallest</strong>.</p><p>The median of an odd number of samples emerges as the sample whose <strong>sum of absolute distances</strong> to all other samples in the set is the <strong>smallest</strong>.</p><p>The analogy between the sample mean and median extends into the statistical domain of parameter estimation,</p><ul><li>the sample mean is the maximum likelihood (ML) estimator of location of a constant parameter in Gaussian noise.</li><li>the sample median is the maximum likelihood (ML) estimator of location of a constant parameter in salt & pepper noise.</li></ul><h4 id=weighted-median-smoother>Weighted Median Smoother</h4><p>Although the median is a robust estimator that possesses many optimality properties, the performance of running medians is limited by the fact that it is <strong>temporally blind</strong>. That is, all observation samples are treated <strong>equally</strong> regardless of their location within the observation window.</p><p><img src=https://i.ibb.co/mrTQ04D7/image-20241012160446847.png loading=lazy alt=image-20241012160446847></p><p><strong>positive real-valued weights</strong></p><p><img src=https://i.ibb.co/Y76sgCPB/image-20241012161919320.png loading=lazy alt=image-20241012161919320></p><h4 id=center-weighted-median-smoothers>Center Weighted Median Smoothers</h4><p>The CWM smoother is realized by allowing <strong>only the center</strong> observation sample to be weighted. Thus, the output of the CWM smoother is given by</p><p><img src=https://i.ibb.co/0T52MVn/image-20241012161305584.png loading=lazy alt=image-20241012161305584></p><h4 id=weighted-median-smoother-with-negative-weight>Weighted Median Smoother with negative weight</h4><p>Positive weights WM Smoother has low-pass type filtering characteristics.</p><p>A large number of engineering applications require bandpass or high-pass frequency filtering characteristics.</p><p>there is a logical way to generalize the median to an equivalently rich class of weighted median filters that admit both positive and negative weights.</p><p><img src=https://i.ibb.co/Y7Jgnh3G/image-20241012161714196.png loading=lazy alt=image-20241012161714196></p><p><strong>steps and example</strong></p><p><img src=https://i.ibb.co/d41KDwZ2/image-20241012161743117.png loading=lazy alt=image-20241012161743117></p><h4 id=vector-weighted-median-filters>Vector Weighted Median Filters</h4><p>The weighted median filtering operation of a <strong>color image</strong> can be achieved in a number of ways, two of which we summarize below.</p><ul><li>Marginal WM filter</li><li>Vector WM filter</li></ul><p>The simplest approach to WM filtering a color image is to <strong>process each component independently</strong> by a scalar WM filter.</p><ul><li>A drawback associated with this method is that different components can be strongly correlated and, if each component is processed separately, this <strong>correlation is not exploited</strong>.</li><li>In addition, since each component is filtered independently, the filter outputs can combine to produce colors not present in the original image.</li><li>The advantage of marginal processing is the <strong>computational simplicity</strong></li></ul><p><img src=https://i.ibb.co/27dQHD8n/image-20241012162429845.png loading=lazy alt=image-20241012162429845></p><h4 id=application>Application</h4><ul><li>Image Noise Cleaning</li><li>Image Zooming</li><li>Image Sharpening</li><li>Edge Detection</li></ul><h2 id=image-compression>Image Compression</h2><h3 id=lossless-coding>Lossless Coding</h3><ul><li>represent an image signal with the smallest possible number of bits without loss of any information</li><li>speed up transmission and minimizing storage requirements</li></ul><p><strong>foundation</strong></p><ul><li>Redundancy - correlation among the image:</li><li>Spatial correlation among neighbor pixels</li><li>Temporal correlation among video frames</li><li>Spectral correlation between image samples</li></ul><p>Standards for lossless compression:</p><ul><li>Lossless JPEG standard</li><li>Facsimile compression standards</li><li>JBIG compression standard</li></ul><p>$$
template
$$</p><p>$template$</p></section><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on Oct 22, 2025 16:27 CST</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/numericalnotes/><div class=article-details><h2 class=article-title>【Numerical】Notes</h2></div></a></article><article><a href=/p/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0/><div class=article-details><h2 class=article-title>【软件体系结构】笔记</h2></div></a></article><article><a href=/p/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%94%E8%AE%B0/><div class=article-details><h2 class=article-title>【分布式数据库】笔记</h2></div></a></article><article><a href=/p/computer-architecturenotes/><div class=article-details><h2 class=article-title>【Computer Architecture】Notes</h2></div></a></article><article><a href=/p/computer-networknotes/><div class=article-details><h2 class=article-title>【Computer Network】Notes</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 飞鸿踏雪泥</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>