<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="__forceinline__ 在 CUDA 编程中，__forceinline__ 是一个编译器指令，用于强制将函数内联（Inline）到调用位置，即使编译器自身的优化策略不建议内联。以下是对其核心机制和应用场景的综合解析：\n核心作用与语义 强制内联的意图\n__forceinline__ 通过覆盖编译器的默认优化策略，强制将函数体直接嵌入调用处，以消除函数调用的开销（如参数传递、栈帧管理）。这种机制常用于高频调用的短小函数（如数学运算、内存操作）。\n与 inline 的区别\ninline：仅向编译器发出建议，最终是否内联由编译器决定（可能因函数复杂度或优化级别被忽略）。 __forceinline__：绕过编译器的启发式分析，强制内联（除非遇到硬件或语法限制）。例如在 CUDA 的归约操作中，高频调用的辅助函数常使用此关键字。 CUDA 设备函数的特殊支持\nCUDA 允许在 __device__ 或 __global__ 函数前使用 __forceinline__，以优化 GPU 线程的执行效率。例如：\n__forceinline__ __device__ float add(float a, float b) { return a + b; } 适用场景与性能影响 高频短函数优化\n适用于循环内部或线程级高频调用的简单操作（如向量加法、比较运算）。例如在 Warp 级归约（Warp Reduce）中，通过强制内联减少指令延迟：\n__forceinline__ __device__ void warpReduce(float* val) { for (int offset = 16; offset > 0; offset /= 2) *val += __shfl_down_sync(0xffffffff, *val, offset); } 避免函数调用开销\n在 GPU 核函数中，每个线程的独立执行路径若频繁调用外部函数，内联可减少上下文切换成本。例如将共享内存的归约逻辑直接嵌入主核函数。\n代码膨胀的权衡\n强制内联可能导致代码体积增大，影响指令缓存效率。需在以下场景谨慎使用：\n函数体较大（如包含复杂分支或循环） 被多处调用的通用函数 限制与编译器行为 无法内联的情况\n即使使用 __forceinline__，以下情况仍可能阻止内联：\n函数包含递归调用或虚函数 使用动态参数列表（Variadic Arguments） 包含内联汇编（Inline Assembly）或 __declspec(naked) 修饰 调试模式（如 CUDA 的 -G 编译选项禁用优化） 编译器兼容性\nCUDA 工具链：完全支持 __forceinline__，常用于设备函数优化。 其他编译器：非标准关键字，需使用编译器特定扩展（如 GCC 的 __attribute__((always_inline)) 或 MSVC 的 __forceinline）。 最佳实践 优先用于小型设备函数\n在 CUDA 中，将短小的 __device__ 函数标记为 __forceinline__，尤其是在 Warp 级或 Block 级并行操作中：\n"><title>【CUDA】Notes</title><link rel=canonical href=https://dyhes.github.io/p/cudanotes/><link rel=stylesheet href=/scss/style.min.f7091bff8043bd3e53b22be6c05dd86b506e8dec4d0d75d249d2dfb0fe074a46.css><meta property='og:title' content="【CUDA】Notes"><meta property='og:description' content="__forceinline__ 在 CUDA 编程中，__forceinline__ 是一个编译器指令，用于强制将函数内联（Inline）到调用位置，即使编译器自身的优化策略不建议内联。以下是对其核心机制和应用场景的综合解析：\n核心作用与语义 强制内联的意图\n__forceinline__ 通过覆盖编译器的默认优化策略，强制将函数体直接嵌入调用处，以消除函数调用的开销（如参数传递、栈帧管理）。这种机制常用于高频调用的短小函数（如数学运算、内存操作）。\n与 inline 的区别\ninline：仅向编译器发出建议，最终是否内联由编译器决定（可能因函数复杂度或优化级别被忽略）。 __forceinline__：绕过编译器的启发式分析，强制内联（除非遇到硬件或语法限制）。例如在 CUDA 的归约操作中，高频调用的辅助函数常使用此关键字。 CUDA 设备函数的特殊支持\nCUDA 允许在 __device__ 或 __global__ 函数前使用 __forceinline__，以优化 GPU 线程的执行效率。例如：\n__forceinline__ __device__ float add(float a, float b) { return a + b; } 适用场景与性能影响 高频短函数优化\n适用于循环内部或线程级高频调用的简单操作（如向量加法、比较运算）。例如在 Warp 级归约（Warp Reduce）中，通过强制内联减少指令延迟：\n__forceinline__ __device__ void warpReduce(float* val) { for (int offset = 16; offset > 0; offset /= 2) *val += __shfl_down_sync(0xffffffff, *val, offset); } 避免函数调用开销\n在 GPU 核函数中，每个线程的独立执行路径若频繁调用外部函数，内联可减少上下文切换成本。例如将共享内存的归约逻辑直接嵌入主核函数。\n代码膨胀的权衡\n强制内联可能导致代码体积增大，影响指令缓存效率。需在以下场景谨慎使用：\n函数体较大（如包含复杂分支或循环） 被多处调用的通用函数 限制与编译器行为 无法内联的情况\n即使使用 __forceinline__，以下情况仍可能阻止内联：\n函数包含递归调用或虚函数 使用动态参数列表（Variadic Arguments） 包含内联汇编（Inline Assembly）或 __declspec(naked) 修饰 调试模式（如 CUDA 的 -G 编译选项禁用优化） 编译器兼容性\nCUDA 工具链：完全支持 __forceinline__，常用于设备函数优化。 其他编译器：非标准关键字，需使用编译器特定扩展（如 GCC 的 __attribute__((always_inline)) 或 MSVC 的 __forceinline）。 最佳实践 优先用于小型设备函数\n在 CUDA 中，将短小的 __device__ 函数标记为 __forceinline__，尤其是在 Warp 级或 Block 级并行操作中：\n"><meta property='og:url' content='https://dyhes.github.io/p/cudanotes/'><meta property='og:site_name' content='飞鸿踏雪泥'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='CUDA'><meta property='article:published_time' content='2025-05-19T00:00:00+00:00'><meta property='article:modified_time' content='2025-06-15T19:46:57+08:00'><meta name=twitter:title content="【CUDA】Notes"><meta name=twitter:description content="__forceinline__ 在 CUDA 编程中，__forceinline__ 是一个编译器指令，用于强制将函数内联（Inline）到调用位置，即使编译器自身的优化策略不建议内联。以下是对其核心机制和应用场景的综合解析：\n核心作用与语义 强制内联的意图\n__forceinline__ 通过覆盖编译器的默认优化策略，强制将函数体直接嵌入调用处，以消除函数调用的开销（如参数传递、栈帧管理）。这种机制常用于高频调用的短小函数（如数学运算、内存操作）。\n与 inline 的区别\ninline：仅向编译器发出建议，最终是否内联由编译器决定（可能因函数复杂度或优化级别被忽略）。 __forceinline__：绕过编译器的启发式分析，强制内联（除非遇到硬件或语法限制）。例如在 CUDA 的归约操作中，高频调用的辅助函数常使用此关键字。 CUDA 设备函数的特殊支持\nCUDA 允许在 __device__ 或 __global__ 函数前使用 __forceinline__，以优化 GPU 线程的执行效率。例如：\n__forceinline__ __device__ float add(float a, float b) { return a + b; } 适用场景与性能影响 高频短函数优化\n适用于循环内部或线程级高频调用的简单操作（如向量加法、比较运算）。例如在 Warp 级归约（Warp Reduce）中，通过强制内联减少指令延迟：\n__forceinline__ __device__ void warpReduce(float* val) { for (int offset = 16; offset > 0; offset /= 2) *val += __shfl_down_sync(0xffffffff, *val, offset); } 避免函数调用开销\n在 GPU 核函数中，每个线程的独立执行路径若频繁调用外部函数，内联可减少上下文切换成本。例如将共享内存的归约逻辑直接嵌入主核函数。\n代码膨胀的权衡\n强制内联可能导致代码体积增大，影响指令缓存效率。需在以下场景谨慎使用：\n函数体较大（如包含复杂分支或循环） 被多处调用的通用函数 限制与编译器行为 无法内联的情况\n即使使用 __forceinline__，以下情况仍可能阻止内联：\n函数包含递归调用或虚函数 使用动态参数列表（Variadic Arguments） 包含内联汇编（Inline Assembly）或 __declspec(naked) 修饰 调试模式（如 CUDA 的 -G 编译选项禁用优化） 编译器兼容性\nCUDA 工具链：完全支持 __forceinline__，常用于设备函数优化。 其他编译器：非标准关键字，需使用编译器特定扩展（如 GCC 的 __attribute__((always_inline)) 或 MSVC 的 __forceinline）。 最佳实践 优先用于小型设备函数\n在 CUDA 中，将短小的 __device__ 函数标记为 __forceinline__，尤其是在 Warp 级或 Block 级并行操作中：\n"><link rel="shortcut icon" href=/github.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_b567f26f71c49c33.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>飞鸿踏雪泥</a></h1><h2 class=site-description>没有记录，就没有发生</h2></div></header><ol class=menu-social><li><a href=https://leetcode.cn/u/dyhes/ target=_blank title=LeetCode rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 13h7.5"/><path d="M9.424 7.268l4.999-4.999"/><path d="M16.633 16.644l-2.402 2.415a3.189 3.189.0 01-4.524.0l-3.77-3.787a3.223 3.223.0 010-4.544l3.77-3.787a3.189 3.189.0 014.524.0l2.302 2.313"/></svg></a></li><li><a href=https://github.com/dyhes target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:dyheslin@gmail.com target=_blank title=Gmail rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-gmail"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M16 20h3a1 1 0 001-1V5a1 1 0 00-1-1h-3v16z"/><path d="M5 20h3V4H5A1 1 0 004 5v14a1 1 0 001 1z"/><path d="M16 4l-4 4-4-4"/><path d="M4 6.5l8 7.5 8-7.5"/></svg></a></li><li><a href=mailto:1325574784@qq.com target=_blank title=Mail rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M13 19H5a2 2 0 01-2-2V7a2 2 0 012-2h14a2 2 0 012 2v5.5"/><path d="M3 7l9 6 9-6"/><path d="M19 16l-2 3h4l-2 3"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/categories/><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
<span>Categories</span></a></li><li><a href=/tags/><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#__forceinline__>__forceinline__</a><ol><li><a href=#核心作用与语义>核心作用与语义</a></li><li><a href=#适用场景与性能影响>适用场景与性能影响</a></li><li><a href=#限制与编译器行为>限制与编译器行为</a></li><li><a href=#最佳实践>最佳实践</a></li><li><a href=#代码示例cuda-归约优化>代码示例（CUDA 归约优化）</a></li><li><a href=#总结>总结</a></li></ol></li><li><a href=#__global__>__global__</a><ol><li><a href=#基本定义与核心作用>基本定义与核心作用</a></li><li><a href=#核心特性>核心特性</a></li><li><a href=#使用场景>使用场景</a></li><li><a href=#与其他关键字的对比>与其他关键字的对比</a></li><li><a href=#注意事项>注意事项</a></li><li><a href=#总结-1>总结</a></li></ol></li><li><a href=#__constant__>__constant__</a><ol><li><a href=#基本定义与核心作用-1>基本定义与核心作用</a></li><li><a href=#核心特性与优化机制>核心特性与优化机制</a></li><li><a href=#使用场景-1>使用场景</a></li><li><a href=#初始化与操作>初始化与操作</a></li><li><a href=#与其他内存类型的对比>与其他内存类型的对比</a></li><li><a href=#注意事项-1>注意事项</a></li><li><a href=#总结-2>总结</a></li></ol></li><li><a href=#存储层次结构>存储层次结构</a><ol><li><a href=#存储层次概览>存储层次概览</a></li><li><a href=#核心存储类型详解>核心存储类型详解</a><ol><li><a href=#寄存器register><strong>寄存器（Register）</strong></a></li><li><a href=#共享内存shared-memory><strong>共享内存（Shared Memory）</strong></a></li><li><a href=#全局内存global-memory><strong>全局内存（Global Memory）</strong></a></li><li><a href=#常量内存constant-memory><strong>常量内存（Constant Memory）</strong></a></li><li><a href=#纹理内存texture-memory><strong>纹理内存（Texture Memory）</strong></a></li></ol></li><li><a href=#存储访问优化原则>存储访问优化原则</a></li><li><a href=#典型应用场景对比>典型应用场景对比</a></li><li><a href=#高级特性与注意事项>高级特性与注意事项</a></li></ol></li><li><a href=#执行范式>执行范式</a><ol><li><a href=#执行范式核心步骤>执行范式核心步骤</a></li><li><a href=#内核执行特性>内核执行特性</a></li><li><a href=#与其他编程模型的对比>与其他编程模型的对比</a></li><li><a href=#典型代码示例完整流程>典型代码示例（完整流程）</a></li><li><a href=#高级特性扩展>高级特性扩展</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/nutrition/ style=background-color:#93b5cf;color:>积雪粮</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/cudanotes/>【CUDA】Notes</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>May 19, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>5 minute read</time></div></footer></div></header><section class=article-content><h2 id=__forceinline__>__forceinline__</h2><p>在 CUDA 编程中，<code>__forceinline__</code> 是一个编译器指令，用于强制将函数内联（Inline）到调用位置，即使编译器自身的优化策略不建议内联。以下是对其核心机制和应用场景的综合解析：</p><hr><h3 id=核心作用与语义>核心作用与语义</h3><ol><li><p><strong>强制内联的意图</strong><br><code>__forceinline__</code> 通过覆盖编译器的默认优化策略，<strong>强制将函数体直接嵌入调用处</strong>，以消除函数调用的开销（如参数传递、栈帧管理）。这种机制常用于高频调用的短小函数（如数学运算、内存操作）。</p></li><li><p><strong>与 <code>inline</code> 的区别</strong></p><ul><li><code>inline</code>：仅向编译器发出建议，最终是否内联由编译器决定（可能因函数复杂度或优化级别被忽略）。</li><li><code>__forceinline__</code>：绕过编译器的启发式分析，<strong>强制内联</strong>（除非遇到硬件或语法限制）。例如在 CUDA 的归约操作中，高频调用的辅助函数常使用此关键字。</li></ul></li><li><p><strong>CUDA 设备函数的特殊支持</strong><br>CUDA 允许在 <code>__device__</code> 或 <code>__global__</code> 函数前使用 <code>__forceinline__</code>，以优化 GPU 线程的执行效率。例如：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__forceinline__</span> <span class=n>__device__</span> <span class=kt>float</span> <span class=nf>add</span><span class=p>(</span><span class=kt>float</span> <span class=n>a</span><span class=p>,</span> <span class=kt>float</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span> <span class=k>return</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span><span class=p>;</span> <span class=p>}</span>
</span></span></code></pre></div></li></ol><hr><h3 id=适用场景与性能影响>适用场景与性能影响</h3><ol><li><p><strong>高频短函数优化</strong><br>适用于循环内部或线程级高频调用的简单操作（如向量加法、比较运算）。例如在 Warp 级归约（Warp Reduce）中，通过强制内联减少指令延迟：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__forceinline__</span> <span class=n>__device__</span> <span class=kt>void</span> <span class=nf>warpReduce</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span> <span class=n>val</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>offset</span> <span class=o>=</span> <span class=mi>16</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>;</span> <span class=n>offset</span> <span class=o>/=</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>*</span><span class=n>val</span> <span class=o>+=</span> <span class=n>__shfl_down_sync</span><span class=p>(</span><span class=mh>0xffffffff</span><span class=p>,</span> <span class=o>*</span><span class=n>val</span><span class=p>,</span> <span class=n>offset</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></li><li><p><strong>避免函数调用开销</strong><br>在 GPU 核函数中，每个线程的独立执行路径若频繁调用外部函数，内联可减少上下文切换成本。例如将共享内存的归约逻辑直接嵌入主核函数。</p></li><li><p><strong>代码膨胀的权衡</strong><br>强制内联可能导致<strong>代码体积增大</strong>，影响指令缓存效率。需在以下场景谨慎使用：</p><ul><li>函数体较大（如包含复杂分支或循环）</li><li>被多处调用的通用函数</li></ul></li></ol><hr><h3 id=限制与编译器行为>限制与编译器行为</h3><ol><li><p><strong>无法内联的情况</strong><br>即使使用 <code>__forceinline__</code>，以下情况仍可能阻止内联：</p><ul><li>函数包含递归调用或虚函数</li><li>使用动态参数列表（Variadic Arguments）</li><li>包含内联汇编（Inline Assembly）或 <code>__declspec(naked)</code> 修饰</li><li>调试模式（如 CUDA 的 <code>-G</code> 编译选项禁用优化）</li></ul></li><li><p><strong>编译器兼容性</strong></p><ul><li><strong>CUDA 工具链</strong>：完全支持 <code>__forceinline__</code>，常用于设备函数优化。</li><li><strong>其他编译器</strong>：非标准关键字，需使用编译器特定扩展（如 GCC 的 <code>__attribute__((always_inline))</code> 或 MSVC 的 <code>__forceinline</code>）。</li></ul></li></ol><hr><h3 id=最佳实践>最佳实践</h3><ol><li><p><strong>优先用于小型设备函数</strong><br>在 CUDA 中，将短小的 <code>__device__</code> 函数标记为 <code>__forceinline__</code>，尤其是在 Warp 级或 Block 级并行操作中：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__forceinline__</span> <span class=n>__device__</span> <span class=kt>float</span> <span class=nf>compute</span><span class=p>(</span><span class=kt>float</span> <span class=n>x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span> <span class=o>*</span> <span class=n>x</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>x</span> <span class=o>+</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></li><li><p><strong>结合性能分析工具</strong><br>使用 <code>nvprof</code> 或 <code>Nsight Compute</code> 验证内联效果，确保强制内联未导致寄存器溢出或缓存命中率下降。</p></li><li><p><strong>替代方案：模板与宏</strong></p><ul><li><strong>模板元编程</strong>：通过编译时展开实现类似内联效果（如 CUDA 的向量化加载操作）。</li><li><strong>宏函数</strong>：适用于极简操作，但缺乏类型安全检查。</li></ul></li></ol><hr><h3 id=代码示例cuda-归约优化>代码示例（CUDA 归约优化）</h3><p>以下展示了 <code>__forceinline__</code> 在 Warp 级归约中的应用：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>// 使用 __forceinline__ 强制内联归约逻辑
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>template</span> <span class=o>&lt;</span><span class=k>typename</span> <span class=n>T</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=n>__forceinline__</span> <span class=n>__device__</span> <span class=n>T</span> <span class=n>warpReduceSum</span><span class=p>(</span><span class=n>T</span> <span class=n>val</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>offset</span> <span class=o>=</span> <span class=mi>16</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>offset</span> <span class=o>&gt;&gt;=</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>val</span> <span class=o>+=</span> <span class=n>__shfl_down_sync</span><span class=p>(</span><span class=mh>0xffffffff</span><span class=p>,</span> <span class=n>val</span><span class=p>,</span> <span class=n>offset</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>val</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>reduceKernel</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span> <span class=n>input</span><span class=p>,</span> <span class=kt>float</span><span class=o>*</span> <span class=n>output</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>sum</span> <span class=o>=</span> <span class=n>input</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>sum</span> <span class=o>=</span> <span class=n>warpReduceSum</span><span class=p>(</span><span class=n>sum</span><span class=p>);</span> <span class=c1>// 内联展开，无函数调用开销
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span> <span class=p>(</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=n>output</span><span class=p>[</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span> <span class=o>=</span> <span class=n>sum</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h3 id=总结>总结</h3><p><code>__forceinline__</code> 是 CUDA 中用于性能调优的利器，但其使用需权衡代码膨胀与执行效率。在设备端高频调用的短函数、Warp 级操作中合理使用，可显著提升并行计算性能，但需结合编译器限制和实际硬件行为进行验证。</p><h2 id=__global__>__global__</h2><p>在 CUDA 编程中，<code>__global__</code> 是一个核心关键字，用于声明 GPU 核函数（Kernel Function）。以下是其关键特性的综合介绍：</p><hr><h3 id=基本定义与核心作用>基本定义与核心作用</h3><p><code>__global__</code> 修饰的函数是 <strong>主机（CPU）调用、设备（GPU）执行</strong> 的并行计算入口点。它通过特殊的 <code>&lt;&lt;&lt;grid_size, block_size>>></code> 语法启动，允许开发者将大规模计算任务分解为多线程并行执行。例如：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>kernel</span><span class=p>()</span> <span class=p>{</span> <span class=cm>/* GPU 执行的代码 */</span> <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=mi>1</span><span class=p>,</span> <span class=mi>256</span><span class=o>&gt;&gt;&gt;</span><span class=p>();</span> <span class=c1>// 启动 256 个线程
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h3 id=核心特性>核心特性</h3><ol><li><p><strong>执行位置与调用关系</strong></p><ul><li>只能在 <strong>GPU 上执行</strong>，但必须由 <strong>CPU 代码显式调用</strong>。</li><li>不能直接调用主机函数（如标准 C 库函数），否则会报错 <code>error: calling a __host__ function from a __global__ function</code>。</li></ul></li><li><p><strong>函数签名限制</strong></p><ul><li>必须返回 <code>void</code> 类型。</li><li>参数传递仅支持 <strong>值传递</strong>，不能使用引用或主机内存指针（需通过设备内存传递）。</li></ul></li><li><p><strong>线程组织方式</strong></p><ul><li>通过 <code>blockIdx</code>（线程块索引）、<code>threadIdx</code>（线程索引）和 <code>gridDim</code>（网格维度）等内置变量定位线程。</li><li>示例计算全局索引：<div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span> <span class=c1>// 一维网格中的线程索引
</span></span></span></code></pre></div></li></ul></li><li><p><strong>内存访问权限</strong></p><ul><li>可直接访问全局内存（如 <code>cudaMalloc</code> 分配的显存）、共享内存、常量内存等 GPU 内存空间。</li></ul></li></ol><hr><h3 id=使用场景>使用场景</h3><ol><li><p><strong>大规模并行计算</strong><br>适用于 <strong>数组运算</strong>（如向量加法）、<strong>矩阵乘法</strong>、<strong>图像处理</strong> 等需要高并发处理的场景。</p></li><li><p><strong>任务分发入口</strong><br>作为 GPU 计算的顶层逻辑，调用 <code>__device__</code> 辅助函数完成具体计算单元。例如：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__device__</span> <span class=kt>float</span> <span class=nf>add</span><span class=p>(</span><span class=kt>float</span> <span class=n>a</span><span class=p>,</span> <span class=kt>float</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span> <span class=k>return</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span><span class=p>;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>vector_add</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span> <span class=n>x</span><span class=p>,</span> <span class=kt>float</span><span class=o>*</span> <span class=n>y</span><span class=p>,</span> <span class=kt>float</span><span class=o>*</span> <span class=n>z</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=p>...;</span> <span class=c1>// 计算索引
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>z</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>add</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>],</span> <span class=n>y</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span> <span class=c1>// 调用设备函数
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div></li></ol><hr><h3 id=与其他关键字的对比>与其他关键字的对比</h3><div class=table-wrapper><table><thead><tr><th>关键字</th><th>调用者</th><th>执行位置</th><th>返回值限制</th><th>典型用途</th></tr></thead><tbody><tr><td><code>__global__</code></td><td>CPU</td><td>GPU</td><td>必须为 <code>void</code></td><td>并行任务入口（核函数）</td></tr><tr><td><code>__device__</code></td><td>GPU</td><td>GPU</td><td>任意类型</td><td>辅助计算（可复用模块）</td></tr><tr><td><code>__host__</code></td><td>CPU</td><td>CPU</td><td>无限制</td><td>普通 CPU 函数</td></tr></tbody></table></div><hr><h3 id=注意事项>注意事项</h3><ol><li><p><strong>动态并行支持</strong><br>从计算能力 3.5 的 GPU 开始，允许在设备代码中调用 <code>__global__</code> 函数（需启用编译选项）。</p></li><li><p><strong>性能优化</strong></p><ul><li>避免在 <code>__global__</code> 函数中频繁调用复杂 <code>__device__</code> 函数，可能导致寄存器溢出，可通过 <code>__launch_bounds__</code> 优化线程配置。</li></ul></li><li><p><strong>错误示例</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>int</span> <span class=nf>error_func</span><span class=p>()</span> <span class=p>{</span> <span class=k>return</span> <span class=mi>1</span><span class=p>;</span> <span class=p>}</span> <span class=c1>// 错误：必须返回 void
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>error_call</span><span class=p>(</span><span class=kt>int</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span> <span class=p>{</span> <span class=p>...</span> <span class=p>}</span> <span class=c1>// 错误：参数不能使用引用
</span></span></span></code></pre></div></li></ol><hr><h3 id=总结-1>总结</h3><p><code>__global__</code> 是 CUDA 并行计算的基石，通过线程网格与块的灵活配置，可实现 GPU 资源的极致利用。开发者需注意其与 <code>__device__</code>、<code>__host__</code> 的协同关系，并遵循内存管理和参数传递规则，才能高效发挥 GPU 的并行计算能力。</p><h2 id=__constant__>__constant__</h2><p>在 CUDA 编程中，<code>__constant__</code> 是一种特殊的内存修饰符，用于声明<strong>常量内存</strong>。以下是其核心特性的综合介绍：</p><hr><h3 id=基本定义与核心作用-1>基本定义与核心作用</h3><p><code>__constant__</code> 用于在 GPU 上声明<strong>只读的全局常量数据</strong>，特点如下：</p><ol><li><strong>主机初始化，设备只读</strong><br>常量内存由主机（CPU）通过 <code>cudaMemcpyToSymbol</code> 或 <code>cudaMemcpy</code> 初始化，设备（GPU）代码只能读取，不可修改。</li><li><strong>静态分配，全局可见</strong><br>必须在全局作用域声明（即核函数外），且对同一编译单元内的所有核函数可见。</li><li><strong>容量限制</strong><br>通常为 <strong>64KB</strong>，超过此限制需使用全局内存或其他存储类型。</li></ol><p>示例代码：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__constant__</span> <span class=kt>float</span> <span class=n>coefficients</span><span class=p>[</span><span class=mi>256</span><span class=p>];</span>  <span class=c1>// 声明常量内存
</span></span></span><span class=line><span class=cl><span class=c1>// 主机端初始化
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>cudaMemcpyToSymbol</span><span class=p>(</span><span class=n>coefficients</span><span class=p>,</span> <span class=n>host_data</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span> <span class=o>*</span> <span class=mi>256</span><span class=p>);</span>
</span></span></code></pre></div><hr><h3 id=核心特性与优化机制>核心特性与优化机制</h3><ol><li><p><strong>常量缓存与广播</strong></p><ul><li><strong>缓存机制</strong>：每个 SM（流式多处理器）有独立的 64KB 常量缓存，加速重复访问。</li><li><strong>广播机制</strong>：当半线程束（16 个线程）访问同一常量内存地址时，GPU 会合并为单次读取操作，并广播数据到所有线程，减少内存带宽消耗。</li></ul></li><li><p><strong>性能优势场景</strong></p><ul><li><strong>线程束内统一访问</strong>：所有线程读取相同地址时性能最佳（如共享的数学系数）。</li><li><strong>分散访问劣势</strong>：若线程访问不同地址，可能导致串行化（性能下降）。</li></ul></li></ol><hr><h3 id=使用场景-1>使用场景</h3><ol><li><strong>高频读取的固定数据</strong><br>如滤波器系数、物理常数、查找表等需频繁访问的只读数据。</li><li><strong>替代全局内存的优化</strong><br>当数据量小且访问模式符合广播特性时，可减少全局内存带宽压力。</li></ol><p>示例：一维卷积核（Stencil）计算，将系数存入常量内存加速访问：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__constant__</span> <span class=kt>float</span> <span class=n>stencil_coeff</span><span class=p>[</span><span class=mi>9</span><span class=p>];</span>  <span class=c1>// 声明卷积核系数
</span></span></span><span class=line><span class=cl><span class=c1>// 主机初始化后，设备端所有线程读取同一系数
</span></span></span></code></pre></div><hr><h3 id=初始化与操作>初始化与操作</h3><ol><li><strong>主机端初始化</strong><br>必须使用 <code>cudaMemcpyToSymbol</code> 或 <code>cudaMemcpy</code>（需先获取符号地址）：<div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>// 方法1：直接拷贝到符号
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>cudaMemcpyToSymbol</span><span class=p>(</span><span class=n>coefficients</span><span class=p>,</span> <span class=n>host_data</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span> <span class=o>*</span> <span class=mi>256</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 方法2：通过地址操作
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>float</span> <span class=o>*</span><span class=n>dev_ptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>cudaGetSymbolAddress</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_ptr</span><span class=p>,</span> <span class=n>coefficients</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>dev_ptr</span><span class=p>,</span> <span class=n>host_data</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span><span class=o>*</span><span class=mi>256</span><span class=p>,</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span>
</span></span></code></pre></div></li><li><strong>设备端访问</strong><br>核函数内直接通过变量名读取，如 <code>float val = coefficients[threadIdx.x];</code>。</li></ol><hr><h3 id=与其他内存类型的对比>与其他内存类型的对比</h3><div class=table-wrapper><table><thead><tr><th>内存类型</th><th>可编程性</th><th>作用域</th><th>访问速度</th><th>典型用途</th></tr></thead><tbody><tr><td><code>__constant__</code></td><td>只读</td><td>全局</td><td>快（缓存）</td><td>高频读取的固定数据</td></tr><tr><td>全局内存</td><td>可读写</td><td>全局</td><td>慢</td><td>通用数据存储</td></tr><tr><td>纹理内存</td><td>只读</td><td>全局</td><td>中等</td><td>空间局部性强的数据</td></tr><tr><td>共享内存</td><td>可读写</td><td>线程块内</td><td>最快</td><td>块内线程协作</td></tr></tbody></table></div><hr><h3 id=注意事项-1>注意事项</h3><ol><li><strong>避免过度使用</strong><br>仅当数据访问模式符合广播特性时使用，否则可能劣于全局内存+只读缓存（如 <code>__ldg</code>）。</li><li><strong>结构体与动态数据</strong><br>支持结构体，但需整体初始化；动态数据需结合全局内存管理。</li><li><strong>架构兼容性</strong><br>常量缓存在所有 NVIDIA GPU 中通用，但 Kepler 架构后的只读缓存（<code>__ldg</code>）在分散访问时更具优势。</li></ol><hr><h3 id=总结-2>总结</h3><p><code>__constant__</code> 内存通过缓存和广播机制优化高频读取场景，是 CUDA 性能调优的重要工具。开发者需结合数据特性和硬件架构，合理选择常量内存、只读缓存或共享内存，以实现 GPU 资源的高效利用。</p><h2 id=存储层次结构>存储层次结构</h2><p>以下是 CUDA 存储层次结构的综合介绍，结合硬件特性和编程模型进行分层解析：</p><hr><h3 id=存储层次概览>存储层次概览</h3><p>CUDA 存储层次由<strong>可编程存储</strong>和<strong>不可编程缓存</strong>组成，设计目标是利用数据局部性优化访问效率。其核心结构按访问速度和范围可分为以下层级：</p><div class=table-wrapper><table><thead><tr><th>存储类型</th><th>作用域</th><th>生命周期</th><th>访问速度</th><th>主要用途</th><th>优化特性</th></tr></thead><tbody><tr><td>寄存器</td><td>线程私有</td><td>线程执行周期</td><td>最快</td><td>存储频繁使用的局部变量</td><td>编译器自动分配，无显式管理</td></tr><tr><td>共享内存</td><td>线程块内共享</td><td>线程块执行周期</td><td>快</td><td>块内线程协作数据交换</td><td>手动控制，低延迟通信</td></tr><tr><td>常量内存</td><td>全局</td><td>应用生命周期</td><td>中等</td><td>存储只读数据（如系数表）</td><td>硬件广播机制优化统一读取</td></tr><tr><td>纹理内存</td><td>全局</td><td>应用生命周期</td><td>中等</td><td>空间局部性强的数据访问</td><td>硬件插值和缓存优化</td></tr><tr><td>全局内存</td><td>全局</td><td>应用生命周期</td><td>慢</td><td>大规模数据存储与交换</td><td>需对齐和合并访问优化</td></tr><tr><td>本地内存</td><td>线程私有</td><td>线程执行周期</td><td>慢</td><td>寄存器溢出时的临时存储</td><td>自动分配，避免寄存器不足</td></tr></tbody></table></div><hr><h3 id=核心存储类型详解>核心存储类型详解</h3><h4 id=寄存器register><strong>寄存器（Register）</strong></h4><ul><li><strong>特性</strong>：每个线程独立拥有，访问速度最快，容量有限（如 Fermi 架构每线程最多 63 个寄存器）。</li><li><strong>使用场景</strong>：存储循环索引、临时变量等高频访问数据。</li><li><strong>优化要点</strong>：减少寄存器使用可提升线程并行度，避免溢出到本地内存。</li></ul><h4 id=共享内存shared-memory><strong>共享内存（Shared Memory）</strong></h4><ul><li><strong>特性</strong>：线程块内共享，类似 CPU 的 L1 缓存，但可编程控制。</li><li><strong>使用场景</strong>：矩阵分块计算、归约操作等需线程协作的任务。</li><li><strong>分配方式</strong>：<ul><li>静态分配：<code>__shared__ int buffer[128];</code></li><li>动态分配：内核启动时指定大小（<code>&lt;&lt;&lt;grid, block, sharedMemSize>>></code>）。</li></ul></li><li><strong>同步机制</strong>：通过 <code>__syncthreads()</code> 确保线程块内数据一致性。</li></ul><h4 id=全局内存global-memory><strong>全局内存（Global Memory）</strong></h4><ul><li><strong>特性</strong>：容量最大（GB 级），但延迟高，需通过 L2 缓存访问。</li><li><strong>优化策略</strong>：<ul><li><strong>对齐访问</strong>：首地址为 32B/128B 的整数倍以减少事务次数。</li><li><strong>合并访问</strong>：线程束内连续访问内存块（如步长为 1）。</li><li>**使用 <code>cudaMallocManaged</code> 实现统一内存管理（UVA）。</li></ul></li></ul><h4 id=常量内存constant-memory><strong>常量内存（Constant Memory）</strong></h4><ul><li><strong>特性</strong>：只读，64KB 容量，通过专用缓存加速。</li><li><strong>使用场景</strong>：存储滤波器系数、物理常数等广播式读取数据。</li><li><strong>初始化方法</strong>：主机端通过 <code>cudaMemcpyToSymbol</code> 写入数据。</li></ul><h4 id=纹理内存texture-memory><strong>纹理内存（Texture Memory）</strong></h4><ul><li><strong>特性</strong>：专为 2D/3D 数据设计，支持硬件插值和边界处理。</li><li><strong>使用场景</strong>：图像处理、空间插值计算。</li><li><strong>优势</strong>：自动缓存空间局部性数据，减少显式内存管理。</li></ul><hr><h3 id=存储访问优化原则>存储访问优化原则</h3><ol><li><strong>时间局部性</strong>：通过共享内存缓存重复访问数据（如矩阵乘法中的子矩阵复用）。</li><li><strong>空间局部性</strong>：组织数据连续存储，利用缓存行预取（如结构体数组 vs 数组结构体）。</li><li><strong>减少主机-设备传输</strong>：<ul><li>使用 <code>cudaMallocHost</code> 分配固定内存（Pinned Memory）提升传输带宽。</li><li>零拷贝内存（Zero-Copy）允许 GPU 直接访问主机内存，避免显式拷贝。</li></ul></li></ol><hr><h3 id=典型应用场景对比>典型应用场景对比</h3><div class=table-wrapper><table><thead><tr><th>场景</th><th>推荐存储类型</th><th>原因</th></tr></thead><tbody><tr><td>线程私有临时变量</td><td>寄存器</td><td>速度快，无竞争</td></tr><tr><td>块内数据共享</td><td>共享内存</td><td>低延迟，支持原子操作和同步</td></tr><tr><td>大规模输入/输出</td><td>全局内存</td><td>容量大，支持异步传输</td></tr><tr><td>高频只读数据</td><td>常量内存</td><td>利用缓存和广播机制减少带宽压力</td></tr><tr><td>图像处理</td><td>纹理内存</td><td>硬件优化空间局部性访问</td></tr></tbody></table></div><hr><h3 id=高级特性与注意事项>高级特性与注意事项</h3><ol><li><strong>统一内存（Unified Memory）</strong>：CUDA 6.0+ 支持自动迁移数据，简化编程（需 UVA 架构）。</li><li><strong>L1/L2 缓存控制</strong>：通过编译选项（如 <code>-Xptxas -dlcm=ca</code>）显式启用/禁用 L1 缓存。</li><li><strong>原子操作</strong>：全局内存支持原子加减（<code>atomicAdd</code>），但需注意性能损耗。</li></ol><hr><p>通过合理选择存储类型和优化访问模式，开发者可显著提升 CUDA 程序性能。例如，矩阵乘法中结合共享内存分块和全局内存合并访问，可实现接近理论峰值的计算效率。</p><h2 id=执行范式>执行范式</h2><p>是的，CUDA内核的执行范式确实是由CPU（主机端）通过指令申请GPU内存并调用<code>__global__</code>内核函数启动计算的。以下是完整的执行流程及关键细节：</p><hr><h3 id=执行范式核心步骤>执行范式核心步骤</h3><ol><li><p><strong>主机端初始化与内存申请</strong></p><ul><li><strong>GPU内存分配</strong>：CPU通过CUDA API（如<code>cudaMalloc</code>）显式申请设备（GPU）内存。例如：<div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>float</span> <span class=o>*</span><span class=n>d_data</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>d_data</span><span class=p>,</span> <span class=n>size</span><span class=p>);</span> <span class=c1>// 由CPU指令分配GPU内存
</span></span></span></code></pre></div></li><li><strong>统一内存管理</strong>（可选）：使用<code>cudaMallocManaged</code>可分配主机与设备共享的统一内存，简化数据传输。</li></ul></li><li><p><strong>数据拷贝</strong></p><ul><li>CPU通过<code>cudaMemcpy</code>将输入数据从主机内存拷贝到设备内存：<div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>d_data</span><span class=p>,</span> <span class=n>h_data</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span> <span class=c1>// 主机→设备传输
</span></span></span></code></pre></div></li></ul></li><li><p><strong>内核调用</strong></p><ul><li>CPU通过<code>&lt;&lt;&lt;grid, block>>></code>语法启动<code>__global__</code>内核函数，指定线程网格（Grid）和线程块（Block）的维度。例如：<div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>myKernel</span><span class=o>&lt;&lt;&lt;</span><span class=mi>128</span><span class=p>,</span> <span class=mi>256</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>d_data</span><span class=p>);</span> <span class=c1>// 启动128个块，每块256线程
</span></span></span></code></pre></div></li><li><strong>异步执行</strong>：内核调用后立即返回，CPU无需等待GPU完成计算。</li></ul></li><li><p><strong>结果同步与回收</strong></p><ul><li><strong>同步机制</strong>：CPU通过<code>cudaDeviceSynchronize()</code>等待GPU完成计算。</li><li><strong>数据回传</strong>：通过<code>cudaMemcpy</code>将结果从设备内存拷贝回主机内存。</li><li><strong>内存释放</strong>：使用<code>cudaFree</code>释放GPU内存。</li></ul></li></ol><hr><h3 id=内核执行特性>内核执行特性</h3><ol><li><p><strong>线程组织模型</strong></p><ul><li>线程按**网格（Grid）→ 块（Block）→ 线程（Thread）**的层级组织。</li><li>通过<code>blockIdx</code>、<code>threadIdx</code>等内置变量定位线程的全局索引。例如：<div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span> <span class=c1>// 一维索引
</span></span></span></code></pre></div></li></ul></li><li><p><strong>硬件执行机制</strong></p><ul><li><strong>SIMT架构</strong>：GPU以**线程束（Warp，32线程）**为调度单位，同一Warp内线程执行相同指令。</li><li><strong>SM调度</strong>：线程块（Block）被分配到流多处理器（SM）上执行，SM通过多级缓存（共享内存、L1/L2）加速数据访问。</li></ul></li><li><p><strong>优化关键点</strong></p><ul><li><strong>内存访问合并</strong>：确保线程束内连续访问全局内存，减少事务次数。</li><li><strong>共享内存复用</strong>：手动缓存重复访问的数据，减少全局内存带宽压力。</li></ul></li></ol><hr><h3 id=与其他编程模型的对比>与其他编程模型的对比</h3><div class=table-wrapper><table><thead><tr><th>阶段</th><th>CPU职责</th><th>GPU职责</th><th>交互方式</th></tr></thead><tbody><tr><td><strong>内存管理</strong></td><td>分配/释放设备内存</td><td>提供显存空间</td><td>通过CUDA API（如<code>cudaMalloc</code>）</td></tr><tr><td><strong>内核执行</strong></td><td>启动内核并指定线程配置</td><td>多线程并行计算</td><td>异步调用（<code>&lt;&lt;&lt;...>>></code>语法）</td></tr><tr><td><strong>数据传输</strong></td><td>主机↔设备数据拷贝</td><td>无直接参与</td><td>显式拷贝或统一内存自动迁移</td></tr><tr><td><strong>同步控制</strong></td><td>显式等待GPU完成（<code>cudaDeviceSynchronize</code>）</td><td>无主动通知机制</td><td>阻塞式同步或流式异步</td></tr></tbody></table></div><hr><h3 id=典型代码示例完整流程>典型代码示例（完整流程）</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>addKernel</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+=</span> <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>N</span> <span class=o>=</span> <span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>20</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>h_a</span><span class=p>,</span> <span class=o>*</span><span class=n>h_b</span><span class=p>,</span> <span class=o>*</span><span class=n>d_a</span><span class=p>,</span> <span class=o>*</span><span class=n>d_b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// 主机内存分配与初始化
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>h_a</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>h_b</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=c1>// ...初始化h_a和h_b...
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=c1>// GPU内存分配
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_a</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_b</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// 数据拷贝至GPU
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>d_a</span><span class=p>,</span> <span class=n>h_a</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>d_b</span><span class=p>,</span> <span class=n>h_b</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// 启动内核（256线程/块）
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>blockSize</span> <span class=o>=</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>numBlocks</span> <span class=o>=</span> <span class=p>(</span><span class=n>N</span> <span class=o>+</span> <span class=n>blockSize</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>blockSize</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>addKernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>numBlocks</span><span class=p>,</span> <span class=n>blockSize</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>d_a</span><span class=p>,</span> <span class=n>d_b</span><span class=p>,</span> <span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// 同步并拷贝结果回主机
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>h_a</span><span class=p>,</span> <span class=n>d_a</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// 释放内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>cudaFree</span><span class=p>(</span><span class=n>d_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>cudaFree</span><span class=p>(</span><span class=n>d_b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>h_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>h_b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h3 id=高级特性扩展>高级特性扩展</h3><ol><li><p><strong>动态并行</strong>（Compute Capability ≥3.5）</p><ul><li>允许GPU内核内部嵌套启动其他内核，减少主机交互开销。</li></ul></li><li><p><strong>多流并发</strong></p><ul><li>使用CUDA流（Stream）实现计算与数据传输重叠，提升吞吐量：<div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>cudaStream_t</span> <span class=n>stream</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>cudaStreamCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stream</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>cudaMemcpyAsync</span><span class=p>(...,</span> <span class=n>stream</span><span class=p>);</span> <span class=c1>// 异步传输
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=p>...,</span> <span class=n>stream</span><span class=o>&gt;&gt;&gt;</span><span class=p>();</span>    <span class=c1>// 流内执行
</span></span></span></code></pre></div></li></ul></li><li><p><strong>统一内存优化</strong></p><ul><li>通过<code>cudaMallocManaged</code>实现自动内存迁移，避免显式拷贝。</li></ul></li></ol><hr><p>综上，CUDA的执行范式确实由CPU主导内存管理与内核调用，而GPU专注于并行计算。这一设计平衡了CPU的控制能力与GPU的并行性能，适用于大规模数据并行任务。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/cuda/>CUDA</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on Jun 15, 2025 19:46 CST</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/mac.db_store-file/><div class=article-image><img src=/covers/cover20.jpg loading=lazy data-key data-hash=/covers/cover20.jpg></div><div class=article-details><h2 class=article-title>【Mac】.DB_Store file</h2></div></a></article><article><a href=/p/cudaconcepts/><div class=article-details><h2 class=article-title>【CUDA】Concepts</h2></div></a></article><article><a href=/p/cudallm-queries/><div class=article-details><h2 class=article-title>【CUDA】LLM Queries</h2></div></a></article><article><a href=/p/cudaprogramming-guide/><div class=article-details><h2 class=article-title>【CUDA】Programming Guide</h2></div></a></article><article><a href=/p/cudafunction/><div class=article-details><h2 class=article-title>【CUDA】Function</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 飞鸿踏雪泥</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>