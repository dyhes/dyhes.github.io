<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CUDA on 飞鸿踏雪泥</title><link>https://dyhes.github.io/tags/cuda/</link><description>Recent content in CUDA on 飞鸿踏雪泥</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 22 Oct 2025 16:27:30 +0800</lastBuildDate><atom:link href="https://dyhes.github.io/tags/cuda/index.xml" rel="self" type="application/rss+xml"/><item><title>【CUDA】Concepts</title><link>https://dyhes.github.io/p/cudaconcepts/</link><pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudaconcepts/</guid><description>&lt;h2 id="thread-block"&gt;Thread Block
&lt;/h2&gt;&lt;p&gt;在CUDA编程中，当一个流多处理器（SM）的目标是运行2048个线程时，线程块（Block）的大小对性能有显著影响。线程块大小的选择不仅关系到硬件资源的利用率，还会影响延迟隐藏能力、内存访问效率等关键因素。以下是详细分析：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-线程块大小与资源分配的权衡"&gt;⚙️ 1. &lt;strong&gt;线程块大小与资源分配的权衡&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;资源限制&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;每个SM的硬件资源（如寄存器、共享内存）是固定的。若线程块过大（如1024线程/块），单个块会消耗更多资源，可能导致SM无法容纳足够的块。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若每个块需占用50KB共享内存，而SM共享内存总量为100KB，则SM仅能驻留2个块（2×1024=2048线程），但此时SM的共享内存利用率已达100%，可能限制其他资源分配。&lt;/li&gt;
&lt;li&gt;相比之下，若使用256线程/块，同样2048线程需8个块。若每个块仅需20KB共享内存，则SM共享内存占用为160KB（假设资源允许），资源压力更小，且能通过多块提升灵活性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;寄存器竞争&lt;/strong&gt;：
大块可能导致单个线程的寄存器分配不足，迫使编译器使用延迟更高的本地内存（Local Memory），显著降低性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-延迟隐藏与并行效率"&gt;⏱️ 2. &lt;strong&gt;延迟隐藏与并行效率&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;线程束调度&lt;/strong&gt;：
SM以线程束（Warp，32线程）为单位调度任务。块越大，单个块内可调度的线程束越多（如1024线程/块 = 32个线程束），理论上更易隐藏内存延迟。但若块数量过少（如仅2个块），当部分线程束因同步（如&lt;code&gt;__syncthreads()&lt;/code&gt;）或内存访问停滞时，SM可能因缺少可切换的线程束而闲置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;小块的并行优势&lt;/strong&gt;：
使用较小块（如128线程/块）时，SM可驻留更多块（16个）。即使部分块因同步停滞，其他块仍可继续执行，提升硬件利用率。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-内存访问模式的影响"&gt;📊 3. &lt;strong&gt;内存访问模式的影响&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;全局内存合并访问&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;p&gt;块大小会影响全局内存的访问效率。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在二维数据计算中，小块（如16×16=256线程）更易实现连续内存访问（合并访问），而大块（如32×32=1024线程）可能因行列跨度导致非连续访问，降低带宽利用率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;共享内存Bank冲突&lt;/strong&gt;：
大块可能加剧共享内存的Bank冲突（多个线程访问同一Bank），而小块通过更精细的数据划分可减少此类冲突。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-4-实际工程经验与优化建议"&gt;🧪 4. &lt;strong&gt;实际工程经验与优化建议&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;经验性取值&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;p&gt;主流实践推荐块大小为&lt;/p&gt;
&lt;p&gt;128–512线程&lt;/p&gt;
&lt;p&gt;（32的倍数），其中256线程是常见起点。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;计算密集型任务：128–256线程/块（减少资源竞争）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;内存密集型任务：256–512线程/块（提升延迟隐藏能力）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;动态调整策略&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;初始设置&lt;/strong&gt;：根据数据量选择256线程/块，网格大小覆盖总线程数（如2048线程需8个块）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源分析&lt;/strong&gt;：使用&lt;code&gt;nsight compute&lt;/code&gt;检测占用率（Occupancy），若低于80%，需调整块大小或减少资源消耗。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;指令级并行（ILP）补偿&lt;/strong&gt;：在低占用率场景下，通过单线程处理多数据（ILP）提升性能（如矩阵转置中单线程计算4个元素）。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-5-1024线程块的适用场景"&gt;⚖️ 5. &lt;strong&gt;1024线程/块的适用场景&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优势场景&lt;/strong&gt;：
当算法需大量线程协作（如矩阵乘法），且共享内存访问模式规则时，大块可减少块间通信开销。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;局限性&lt;/strong&gt;：
在多数场景下，1024线程/块易导致资源碎片化，且需算法高度优化以避免同步瓶颈，非通用选择。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-结论是否应设置为1024"&gt;💎 &lt;strong&gt;结论：是否应设置为1024？&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;否&lt;/strong&gt;：在SM目标为2048线程时，1024线程/块通常&lt;strong&gt;不是最优解&lt;/strong&gt;。它易引发资源竞争、同步停滞及内存访问效率下降。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推荐方案&lt;/strong&gt;：优先选择 &lt;strong&gt;128–512线程/块&lt;/strong&gt;（如256），通过增加块数量（如8–16个块）提升SM的灵活性与资源利用率。最终需结合具体硬件（如A100/V100的SM规格）和算法特性，通过性能分析工具验证。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="线程同步"&gt;线程同步
&lt;/h2&gt;&lt;p&gt;在CUDA编程中，线程同步是协调并行线程执行顺序的关键机制。不同层级的同步（线程块、线程束、子线程束）需要采用不同的技术实现，其效率与适用场景也各有差异。以下是分层级的实现方法与技术细节：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-线程块层级的同步"&gt;⚙️ 1. &lt;strong&gt;线程块层级的同步&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;线程块内的所有线程（最多1024个）通过硬件屏障实现同步。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;核心函数&lt;/strong&gt;：&lt;code&gt;__syncthreads()&lt;/code&gt;
该函数确保线程块内所有线程执行到此位置后，才能继续执行后续代码。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;典型应用场景&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;共享内存数据协作（如矩阵转置前确保数据加载完成）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;规约计算中分阶段汇总结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码示例&lt;/p&gt;
&lt;p&gt;（共享内存初始化同步）：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__global__ void kernel(float *data) {
__shared__ float s_data[1024];
int tid = threadIdx.x;
s_data[tid] = data[tid];
__syncthreads(); // 等待所有线程完成数据写入
// 后续操作（如计算s_data的累加和）
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意事项&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分支一致性&lt;/strong&gt;：若线程块内存在分支（如&lt;code&gt;if&lt;/code&gt;语句），需确保所有线程执行相同分支路径，否则&lt;code&gt;__syncthreads()&lt;/code&gt;会导致死锁。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能开销&lt;/strong&gt;：同步需4个时钟周期以上，频繁使用可能降低并行效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-线程束层级的同步"&gt;⚡ 2. &lt;strong&gt;线程束层级的同步&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;线程束（Warp，32个线程）内的同步通过更轻量级的指令实现。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;核心函数&lt;/strong&gt;：&lt;code&gt;__syncwarp(mask=0xffffffff)&lt;/code&gt;
仅同步掩码指定的线程束内线程，默认掩码&lt;code&gt;0xffffffff&lt;/code&gt;表示全同步。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;性能优势&lt;/strong&gt;：
相比&lt;code&gt;__syncthreads()&lt;/code&gt;，开销显著降低，因无需等待整个线程块。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;典型应用场景&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;规约计算中最后几步（剩余操作在单个线程束内完成）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;避免共享内存访问冲突时的高效同步。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码示例&lt;/p&gt;
&lt;p&gt;（规约优化）：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;for (int offset = 16; offset &amp;gt; 0; offset &amp;gt;&amp;gt;= 1) {
if (threadIdx.x &amp;lt; offset)
s_data[threadIdx.x] += s_data[threadIdx.x + offset];
__syncwarp(); // 仅同步当前线程束
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意事项&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;范围限制&lt;/strong&gt;：仅适用于同一线程束内的线程，跨线程束无效。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;掩码控制&lt;/strong&gt;：可通过掩码排除部分线程（如&lt;code&gt;0xfffffffe&lt;/code&gt;排除0号线程）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-子线程束层级的同步"&gt;🔬 3. &lt;strong&gt;子线程束层级的同步&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;子线程束（Sub-Warp，如16/8/4线程）的同步需结合编程技巧或高级API。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实现方法&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;协作组（Cooperative Groups）
：
支持动态定义线程组（如
```
tiled_partition
```
），并通过
```
sync()
```
同步。
```
#include &amp;lt;cooperative_groups.h&amp;gt;
__global__ void kernel() {
auto tile = cg::tiled_partition&amp;lt;16&amp;gt;(cg::this_thread_block());
float val = ...;
tile.sync(); // 同步16线程的子组
// 组内数据交换
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;线程束洗牌函数（Warp Shuffle）
：
通过寄存器直接交换数据，隐式实现同步（如
```
__shfl_down_sync()
```
）。
```
float val = ...;
for (int offset = 8; offset &amp;gt; 0; offset /= 2)
val += __shfl_down_sync(0xffffffff, val, offset);
```
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;适用场景&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;细粒度数据交换（如规约中相邻线程求和）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;避免共享内存的Bank冲突。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;性能对比&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;同步开销&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;通信方式&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;适用层级&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;协作组&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;显式同步&lt;/td&gt;
&lt;td&gt;任意自定义子组&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;线程束洗牌&lt;/td&gt;
&lt;td&gt;极低&lt;/td&gt;
&lt;td&gt;寄存器隐式同步&lt;/td&gt;
&lt;td&gt;线程束内子组&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-4-关键总结与建议"&gt;💎 4. &lt;strong&gt;关键总结与建议&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;层级选择原则&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;线程块同步&lt;/strong&gt;：需跨线程协作（如共享内存更新）时使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;线程束/子线程束同步&lt;/strong&gt;：操作局限在少数线程时优先选用，减少等待开销。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;性能陷阱&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;避免在分支代码中调用&lt;code&gt;__syncthreads()&lt;/code&gt;，否则可能死锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;子线程束同步需确保设备架构支持（如洗牌指令需Compute Capability ≥ 3.0）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进阶工具&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;协作组&lt;/strong&gt;：适用于复杂线程组（如跨块同步），但需CC 6.0+。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原子操作&lt;/strong&gt;：替代同步实现简单全局更新（如&lt;code&gt;atomicAdd&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过合理选择同步层级与工具，可显著提升GPU程序的并行效率。实际开发中建议结合&lt;code&gt;nsight-compute&lt;/code&gt;分析同步开销，并优先尝试线程束级优化。&lt;/p&gt;
&lt;h2 id="__syncwarp"&gt;__syncwarp
&lt;/h2&gt;&lt;p&gt;在CUDA编程中，&lt;code&gt;__syncwarp&lt;/code&gt; 和 &lt;strong&gt;Cooperative Groups（协作组）&lt;/strong&gt; 均能实现线程同步，但两者在功能粒度、灵活性和适用场景上有显著差异。以下是具体分析：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-__syncwarp"&gt;⚙️ 1. &lt;strong&gt;&lt;code&gt;__syncwarp&lt;/code&gt; 实现 Sub-Warp 同步的可行性&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__syncwarp&lt;/code&gt; 通过 &lt;strong&gt;掩码（mask）&lt;/strong&gt; 参数控制同步范围，理论上可支持16或8线程的子组同步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实现方式&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;p&gt;通过掩码指定需同步的线程（例如&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;0x0000FFFF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同步低16线程，&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;0x000000FF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同步低8线程）：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;unsigned mask_16 = 0x0000FFFF; // 同步低16线程
__syncwarp(mask_16);
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;限制&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;静态指定&lt;/strong&gt;：掩码需在编译时确定，无法动态创建子组。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬性要求&lt;/strong&gt;：掩码包含的所有线程必须执行到 &lt;code&gt;__syncwarp&lt;/code&gt; 位置，否则行为未定义（可能死锁或数据错误）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无分组抽象&lt;/strong&gt;：需手动管理掩码，无法直接操作子组内数据（如广播、规约）。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;✅ &lt;strong&gt;适用场景&lt;/strong&gt;：静态、无分支的简单子组同步（如固定16线程归约）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id="-2-cooperative-groups协作组的优势"&gt;🔧 2. &lt;strong&gt;Cooperative Groups（协作组）的优势&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;协作组提供更灵活的子组同步机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;动态子组创建&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;p&gt;可运行时按需划分任意大小的子组（如16或8线程）：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;#include &amp;lt;cooperative_groups.h&amp;gt;
auto tile = cg::tiled_partition&amp;lt;16&amp;gt;(cg::this_thread_block()); // 创建16线程子组
tile.sync(); // 同步子组内线程
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;安全性与功能性&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分支容忍&lt;/strong&gt;：允许子组内线程存在分支，同步时自动检测未到达线程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内置操作&lt;/strong&gt;：支持子组内数据交换（&lt;code&gt;shuffle&lt;/code&gt;）、规约（&lt;code&gt;reduce&lt;/code&gt;）等原子操作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨层级支持&lt;/strong&gt;：支持线程块、网格级同步，远超 &lt;code&gt;__syncwarp&lt;/code&gt; 范围。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;✅ &lt;strong&gt;适用场景&lt;/strong&gt;：动态子组、存在分支、需子组内数据交互的复杂逻辑。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id="-3-性能与兼容性对比"&gt;⚖️ 3. &lt;strong&gt;性能与兼容性对比&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;code&gt;__syncwarp&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;Cooperative Groups&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;同步开销&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;极低（≈几条指令）&lt;/td&gt;
&lt;td&gt;较高（需创建组对象）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;架构支持&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Compute 3.0+&lt;/td&gt;
&lt;td&gt;Compute 6.0+（需显式启用）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;动态子组&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;不支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;分支容忍性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;低（掩码线程必须全部执行）&lt;/td&gt;
&lt;td&gt;高（自动处理未到达线程）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;代码可维护性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;低（手动管理掩码）&lt;/td&gt;
&lt;td&gt;高（面向对象抽象）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-4-实践建议"&gt;💎 4. &lt;strong&gt;实践建议&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优先使用 Cooperative Groups&lt;/strong&gt;：
尤其是 ​&lt;strong&gt;Volta架构（Compute 7.0+）及以上&lt;/strong&gt;，协作组是官方推荐方式，避免 &lt;code&gt;__syncwarp&lt;/code&gt; 在分支代码中的风险。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;__syncwarp&lt;/code&gt; 的替代场景&lt;/strong&gt;：
若需兼容旧架构（如Pascal），且同步逻辑简单无分支，可用掩码实现子组同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能敏感场景&lt;/strong&gt;：
&lt;code&gt;__syncwarp&lt;/code&gt; 在极端优化场景（如高频调用的轻量操作）可能有轻微优势，但需严格保证线程一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-总结"&gt;📌 &lt;strong&gt;总结&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;__syncwarp&lt;/code&gt; 可静态实现16/8线程同步&lt;/strong&gt;，但需手动管理掩码且不支持动态分组。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cooperative Groups 是更优解&lt;/strong&gt;：提供安全、灵活的子组抽象，适合现代GPU架构。
根据架构和需求选择工具，复杂场景务必用协作组规避同步风险。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="内存延迟"&gt;内存延迟
&lt;/h2&gt;&lt;p&gt;在CUDA编程中，使用8个线程一组的Cooperative Groups（协作组）时，将线程块大小（Thread Block Size）设为1024&lt;strong&gt;理论上可以更好地隐藏内存访问延迟，但实际效果取决于硬件资源利用率和算法设计&lt;/strong&gt;。以下是综合分析：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-内存延迟隐藏的原理"&gt;⚙️ 1. &lt;strong&gt;内存延迟隐藏的原理&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;GPU通过&lt;strong&gt;大规模线程并行&lt;/strong&gt;隐藏全局内存访问的高延迟（通常数百时钟周期）。当线程因内存访问停顿时，SM（流式多处理器）会立即切换到其他可执行的线程束（Warp）。线程块越大，包含的线程束越多（1024线程 = 32个线程束），SM在等待内存时切换的线程束资源越丰富，延迟隐藏能力越强。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-2-1024线程块的优势与风险"&gt;⚖️ 2. &lt;strong&gt;1024线程块的优势与风险&lt;/strong&gt;
&lt;/h3&gt;&lt;h4 id="优势"&gt;&lt;strong&gt;优势：&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;更高的线程束并行度&lt;/strong&gt;：1024线程块提供32个线程束，远高于小线程块（如256线程仅8个线程束）。这增加了SM调度器切换线程束的机会，更易掩盖内存延迟。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;协作组的灵活性&lt;/strong&gt;：8线程的协作组（&lt;code&gt;cg::tiled_partition&amp;lt;8&amp;gt;&lt;/code&gt;）可在1024线程块内创建128个独立子组。每个子组内部同步开销低（如&lt;code&gt;tile.sync()&lt;/code&gt;），且子组间通过大量线程束交错执行，进一步优化延迟隐藏。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="风险"&gt;&lt;strong&gt;风险：&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;资源竞争导致阻塞&lt;/p&gt;
&lt;p&gt;：若1024线程块消耗过多资源（如寄存器、共享内存），SM可能无法驻留足够线程块。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每个线程占用32个寄存器 → 1024线程需32KB寄存器，超过SM上限（如Ampere架构每SM 64KB）时，实际驻留线程块数减少，反而降低并行度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;共享内存不足：若每个线程块需48KB共享内存，SM共享内存总量为128KB时仅能驻留2个块（2048线程），远低于理想状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;子组同步效率问题&lt;/strong&gt;：8线程子组的同步虽快，但若算法依赖跨子组通信（如全局归约），1024线程块可能导致同步点增多，增加整体等待时间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-与较小线程块的性能对比"&gt;📊 3. &lt;strong&gt;与较小线程块的性能对比&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;线程块大小&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;线程束数量&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;延迟隐藏潜力&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;资源压力&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;较低&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;资源密集型任务（如高寄存器使用）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;平衡型任务&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;1024&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;32&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;高&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;高&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;内存密集型 + 资源充足时&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;实验数据支持&lt;/strong&gt;：在立方和计算示例中，1024线程块相比256线程块带宽利用率提升106%（491 MB/s vs. 238 MB/s），但需确保资源不超限。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-4-优化建议平衡资源与并行度"&gt;🛠️ 4. &lt;strong&gt;优化建议：平衡资源与并行度&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;动态调整线程块大小&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优先尝试&lt;strong&gt;512线程块&lt;/strong&gt;（如16个线程束），兼顾并行度与资源占用。&lt;/li&gt;
&lt;li&gt;仅当算法需极多子组且资源充足时选用1024线程块。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;资源占用分析&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用&lt;code&gt;cudaOccupancyMaxActiveBlocksPerMultiprocessor&lt;/code&gt;计算SM实际驻留块数。&lt;/li&gt;
&lt;li&gt;目标占用率建议 ≥80%，否则需减少寄存器使用（&lt;code&gt;__launch_bounds__&lt;/code&gt;）或共享内存。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;子组设计优化&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;8线程子组内使用&lt;strong&gt;寄存器通信&lt;/strong&gt;（如&lt;code&gt;__shfl_sync&lt;/code&gt;）替代共享内存，减少资源争用。&lt;/li&gt;
&lt;li&gt;避免子组间依赖，确保各子组独立工作。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-结论"&gt;💎 &lt;strong&gt;结论&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1024线程块在资源充足时能有效隐藏延迟&lt;/strong&gt;：尤其适合全局内存访问频繁、子组间无依赖的任务（如独立滤波、并行映射）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实际需综合权衡&lt;/strong&gt;：若资源紧张（如共享内存不足），选择512或256线程块更稳健。建议通过&lt;strong&gt;性能分析工具&lt;/strong&gt;（Nsight Compute）实测延迟隐藏效果，动态调整配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="线程块同步"&gt;线程块同步
&lt;/h2&gt;&lt;p&gt;在CUDA编程中，线程块（Thread Block）之间默认是独立执行的，无法直接通过类似&lt;code&gt;__syncthreads()&lt;/code&gt;的块内同步函数实现跨块同步。这是因为CUDA的线程调度模型设计为线程块可乱序执行，且硬件上可能分散在不同流处理器（SM）上。以下是实现跨块同步的几种核心方法及其适用场景：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-一原子操作--全局内存屏障"&gt;⚙️ 一、原子操作 + 全局内存屏障
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：通过全局变量（如计数器）协调线程块状态，结合原子操作确保全局状态更新的原子性。
​&lt;strong&gt;步骤&lt;/strong&gt;​：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;初始化全局变量&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__device__ int block_counter = 0; // 全局计数器
&lt;/code&gt;&lt;/pre&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;线程块完成计算后更新计数器&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;atomicAdd(&amp;amp;block_counter, 1); // 原子递增
&lt;/code&gt;&lt;/pre&gt;&lt;ol start="3"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;等待所有块完成&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;p&gt;每个线程块循环检查计数器是否达到总块数，需配合内存屏障确保全局可见性：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;while (block_counter &amp;lt; gridDim.x) {
__threadfence(); // 确保当前线程写入对其他线程可见
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：兼容性强（支持所有CUDA架构）。
​&lt;strong&gt;缺点&lt;/strong&gt;​：循环等待消耗算力，可能降低性能；需避免死锁（如所有块未完全启动）。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-二协作组cooperative-groups"&gt;🧩 二、协作组（Cooperative Groups）
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：使用CUDA 9+引入的协作组API，支持网格级（Grid-Wide）同步。
​&lt;strong&gt;步骤&lt;/strong&gt;​：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;启动协作内核&lt;/strong&gt;：
使用&lt;code&gt;cudaLaunchCooperativeKernel&lt;/code&gt;启动内核，确保所有块可同时驻留GPU。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;网格内同步&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cooperative_groups::grid_group grid = cooperative_groups::this_grid();
grid.sync(); // 同步所有块
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;硬件要求&lt;/strong&gt;：计算能力≥6.0（Pascal+架构）且GPU支持协作内核。
​&lt;strong&gt;优点&lt;/strong&gt;​：语法简洁，无忙等待开销。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-三流与事件streams-and-events"&gt;⏱️ 三、流与事件（Streams and Events）
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：通过CUDA事件（Event）在主机端协调多个流（Stream）的执行顺序。
​&lt;strong&gt;步骤&lt;/strong&gt;​：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;记录事件&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;p&gt;在第一个内核后记录事件：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cudaEvent_t event;
cudaEventCreate(&amp;amp;event);
kernel1&amp;lt;&amp;lt;&amp;lt;blocks, threads, 0, stream1&amp;gt;&amp;gt;&amp;gt;();
cudaEventRecord(event, stream1);
&lt;/code&gt;&lt;/pre&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;后续内核等待事件&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cudaStreamWaitEvent(stream2, event); // stream2等待event完成
kernel2&amp;lt;&amp;lt;&amp;lt;blocks, threads, 0, stream2&amp;gt;&amp;gt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：需主机介入的粗粒度同步，如多阶段任务。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-四多次内核启动kernel-launch-splitting"&gt;🔁 四、多次内核启动（Kernel Launch Splitting）
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：将任务拆分为多个内核，利用内核启动天然同步的特性。
​&lt;strong&gt;示例&lt;/strong&gt;​：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;// 第一阶段：各块独立计算
phase1_kernel&amp;lt;&amp;lt;&amp;lt;blocks, threads&amp;gt;&amp;gt;&amp;gt;();
cudaDeviceSynchronize(); // 主机同步等待所有块完成
// 第二阶段：处理结果
phase2_kernel&amp;lt;&amp;lt;&amp;lt;blocks, threads&amp;gt;&amp;gt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：简单可靠，无死锁风险。
​&lt;strong&gt;缺点&lt;/strong&gt;​：内核启动延迟较高，频繁拆分影响性能。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-五方法对比与选择建议"&gt;💎 五、方法对比与选择建议
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;实时性&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;复杂度&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;硬件要求&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;原子操作+全局屏障&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;所有架构&lt;/td&gt;
&lt;td&gt;兼容性优先的轻量任务&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;协作组&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;Pascal+架构&lt;/td&gt;
&lt;td&gt;高性能计算，需精细同步&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;流与事件&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;所有架构&lt;/td&gt;
&lt;td&gt;多流任务，主机可协调&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;多次内核启动&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;所有架构&lt;/td&gt;
&lt;td&gt;简单任务，避免死锁&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-注意事项"&gt;⚠️ 注意事项
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;死锁风险&lt;/strong&gt;：原子操作循环等待时，若部分线程块未启动（如资源不足），会导致永久等待。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能权衡&lt;/strong&gt;：协作组性能最优，但需硬件支持；原子操作忙等待可能拖累吞吐量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;上下文隔离&lt;/strong&gt;：多线程主机程序中，确保各线程CUDA上下文互斥操作（如用&lt;code&gt;std::mutex&lt;/code&gt;）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;根据具体场景选择方案：&lt;strong&gt;协作组是未来趋势&lt;/strong&gt;，旧硬件项目可选用&lt;strong&gt;原子操作&lt;/strong&gt;或&lt;strong&gt;内核拆分&lt;/strong&gt;，而依赖主机调度的任务适合&lt;strong&gt;流事件&lt;/strong&gt;机制。&lt;/p&gt;
&lt;h2 id="thread-block-cluster"&gt;Thread Block Cluster
&lt;/h2&gt;&lt;p&gt;Thread Block Cluster（线程块集群）是NVIDIA在Hopper架构中引入的新特性，主要用于优化大规模并行任务的协作效率。以下从技术原理、跨SM能力及性能影响三个方面综合分析：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-thread-block-cluster是否支持跨sm"&gt;⛓️ &lt;strong&gt;1. Thread Block Cluster是否支持跨SM？&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;支持跨SM&lt;/strong&gt;：Thread Block Cluster设计为&lt;strong&gt;跨越多个SM的协作单元&lt;/strong&gt;，最多可包含8个线程块（如Hopper架构）。这些线程块可分布在不同的SM上，通过硬件级同步机制（如张量内存加速器TMA）协调计算任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;技术原理&lt;/strong&gt;：集群通过&lt;strong&gt;硬件互联通道（如NVLink）&lt;/strong&gt; 实现跨SM通信。每个集群内的线程块共享同步对象（如&lt;code&gt;cuda::barrier&lt;/code&gt;），支持设备级（&lt;code&gt;thread_scope_device&lt;/code&gt;）或集群级（新增层级）的同步操作，突破了传统线程块（Block）仅限于单SM的约束。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-跨sm对性能的影响"&gt;📊 &lt;strong&gt;2. 跨SM对性能的影响&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;跨SM协作在提升并行规模的同时，也引入新的性能挑战：&lt;/p&gt;
&lt;h4 id="-1同步延迟显著增加"&gt;⚡ &lt;strong&gt;（1）同步延迟显著增加&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;层级对比&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;单SM内Block同步：延迟约&lt;strong&gt;100–200ns&lt;/strong&gt;（通过共享内存屏障实现）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;跨SM集群同步：延迟介于Block级与Device级之间（约&lt;strong&gt;500ns–1μs&lt;/strong&gt;），因需协调多SM的L2缓存一致性及硬件信号。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;典型案例&lt;/strong&gt;：在3D张量运算中，跨SM集群同步开销比单SM高70%，但通过TMA加速原子操作可部分抵消。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="-2资源竞争与通信带宽瓶颈"&gt;🔄 &lt;strong&gt;（2）资源竞争与通信带宽瓶颈&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;资源竞争&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;集群内线程块共享全局内存带宽，若任务需频繁交换数据，可能受限于HBM带宽（如A100的1.5TB/s）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SM间的寄存器文件独立，跨SM数据依赖需通过全局内存传输，增加延迟。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;通信优化&lt;/strong&gt;：
使用&lt;code&gt;cuda::memcpy_async&lt;/code&gt;异步拷贝或TMA硬件加速，可重叠计算与通信，减少显式等待时间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="-3资源利用率与负载均衡"&gt;⚖️ &lt;strong&gt;（3）资源利用率与负载均衡&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优势场景&lt;/strong&gt;：
任务可分解为独立子问题时（如矩阵分块乘法），跨SM集群能&lt;strong&gt;显著提升吞吐量&lt;/strong&gt;，尤其当单SM资源不足时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;劣势场景&lt;/strong&gt;：
若任务依赖强或数据局部性高，跨SM通信开销可能抵消并行收益，此时单SM内Block协作更高效。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-实际应用中的优化建议"&gt;💡 &lt;strong&gt;3. 实际应用中的优化建议&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;减少跨SM同步频率&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优先在集群内完成数据局部性强的计算，仅必要时同步（如最终结果汇总）。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通信与计算重叠&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结合异步操作（如&lt;code&gt;cuda::pipeline&lt;/code&gt;）隐藏通信延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;动态资源分配&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过&lt;strong&gt;Elastic Block&lt;/strong&gt;机制调整各线程块的寄存器/共享内存占用，避免资源冲突。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="4"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;架构感知设计&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在Hopper及后续架构中，优先使用TMA加速原子操作，降低跨SM同步开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-总结-1"&gt;💎 &lt;strong&gt;总结&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;单SM内Block协作&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;跨SM集群协作&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;同步延迟&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;极低（100–200ns）&lt;/td&gt;
&lt;td&gt;中（500ns–1μs）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;适用任务&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;高数据局部性、强依赖任务&lt;/td&gt;
&lt;td&gt;可分解独立子任务、弱依赖场景&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;资源瓶颈&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;SM内寄存器/共享内存&lt;/td&gt;
&lt;td&gt;全局内存带宽、跨SM通信延迟&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;优化关键&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;减少共享内存冲突&lt;/td&gt;
&lt;td&gt;异步通信+TMA硬件加速&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Thread Block Cluster的跨SM能力为大规模并行任务提供了新可能，但其性能收益&lt;strong&gt;高度依赖任务特征与硬件优化&lt;/strong&gt;。在Hopper架构下，合理设计集群内任务划分并利用硬件加速，可最大化跨SM协作的效能。&lt;/p&gt;
&lt;h2 id="hash-optimization"&gt;Hash Optimization
&lt;/h2&gt;&lt;p&gt;当哈希表的大小（&lt;code&gt;tsize&lt;/code&gt;）是2的幂（如16、32、64）时，取模运算（&lt;code&gt;hash % tsize&lt;/code&gt;）可以替换为位与运算（&lt;code&gt;hash &amp;amp; (tsize - 1)&lt;/code&gt;），这是由&lt;strong&gt;二进制数学特性&lt;/strong&gt;和&lt;strong&gt;计算机运算优化&lt;/strong&gt;共同决定的。以下是详细解释：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="1-数学等价性位运算与取模的等效原理"&gt;1. &lt;strong&gt;数学等价性：位运算与取模的等效原理&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;关键条件&lt;/strong&gt;：若 &lt;code&gt;tsize = 2^n&lt;/code&gt;（例如 &lt;code&gt;16 = 2^4&lt;/code&gt;），则 &lt;code&gt;tsize - 1&lt;/code&gt; 的二进制形式为&lt;strong&gt;全1的低位&lt;/strong&gt;（如 &lt;code&gt;15&lt;/code&gt; 的二进制是 &lt;code&gt;1111&lt;/code&gt;）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;运算等效&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;取模&lt;/strong&gt;：&lt;code&gt;hash % tsize&lt;/code&gt; 的结果是 &lt;code&gt;hash&lt;/code&gt; 除以 &lt;code&gt;tsize&lt;/code&gt; 的余数，其范围在 &lt;code&gt;[0, tsize-1]&lt;/code&gt; 内。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;位与&lt;/strong&gt;：&lt;code&gt;hash &amp;amp; (tsize - 1)&lt;/code&gt; 会保留 &lt;code&gt;hash&lt;/code&gt; 的最低 &lt;code&gt;n&lt;/code&gt; 位（高位归零），结果同样是 &lt;code&gt;[0, tsize-1]&lt;/code&gt; 的整数。
​&lt;strong&gt;示例&lt;/strong&gt;​：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;int hash = 53; // 二进制: 110101
int tsize = 16; // 2^4, tsize-1 = 15 (二进制: 001111)
int mod = 53 % 16; // 结果: 5 (二进制: 0101)
int and = 53 &amp;amp; 15; // 结果: 0101 (保留低4位) → 5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果一致性&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mod
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;和&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;and
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果相同。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="2-性能优势位运算的高效性"&gt;2. &lt;strong&gt;性能优势：位运算的高效性&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;硬件支持&lt;/strong&gt;：位与运算（&lt;code&gt;&amp;amp;&lt;/code&gt;）是CPU的&lt;strong&gt;单指令操作&lt;/strong&gt;，而取模运算（&lt;code&gt;%&lt;/code&gt;）需多次除法/移位操作，效率更低。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化效果&lt;/strong&gt;：在哈希表高频计算索引的场景下（如HashMap的&lt;code&gt;get()&lt;/code&gt;/&lt;code&gt;put()&lt;/code&gt;），位运算显著提升速度。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="3-设计意义减少哈希冲突"&gt;3. &lt;strong&gt;设计意义：减少哈希冲突&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;均匀分布&lt;/strong&gt;：当 &lt;code&gt;tsize-1&lt;/code&gt; 的二进制为全1（如 &lt;code&gt;1111&lt;/code&gt;）时，&lt;code&gt;hash &amp;amp; (tsize-1)&lt;/code&gt; 的结果&lt;strong&gt;完全依赖&lt;code&gt;hash&lt;/code&gt;的低位值&lt;/strong&gt;。若哈希函数质量高，低位均匀性强，数据分布更均衡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;冲突避免&lt;/strong&gt;：若 &lt;code&gt;tsize&lt;/code&gt; 非2的幂（如 &lt;code&gt;10&lt;/code&gt;），&lt;code&gt;tsize-1=9&lt;/code&gt;（二进制 &lt;code&gt;1001&lt;/code&gt;），位与操作会&lt;strong&gt;强制忽略某些比特位&lt;/strong&gt;，导致不同哈希值映射到同一索引（如 &lt;code&gt;5&lt;/code&gt;（&lt;code&gt;0101&lt;/code&gt;）和 &lt;code&gt;13&lt;/code&gt;（&lt;code&gt;1101&lt;/code&gt;）与 &lt;code&gt;9&lt;/code&gt; 位与后均为 &lt;code&gt;1&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="4-实际应用java-hashmap的实现"&gt;4. &lt;strong&gt;实际应用：Java HashMap的实现&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;容量强制为2的幂&lt;/strong&gt;：通过&lt;code&gt;tableSizeFor()&lt;/code&gt;方法将初始容量转换为≥输入值的最小2次幂（如输入 &lt;code&gt;10&lt;/code&gt; → 输出 &lt;code&gt;16&lt;/code&gt;）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;索引计算&lt;/strong&gt;：&lt;code&gt;index = hash &amp;amp; (capacity - 1)&lt;/code&gt; 替代取模（源码&lt;code&gt;indexFor()&lt;/code&gt;方法）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;扩容优化&lt;/p&gt;
&lt;p&gt;：扩容时（&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;resize()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;），元素新位置仅需判断&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;hash &amp;amp; old_capacity
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;的结果：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结果为 &lt;code&gt;0&lt;/code&gt; → 索引不变；&lt;/li&gt;
&lt;li&gt;结果为 &lt;code&gt;1&lt;/code&gt; → 新索引 = 原位置 + 原容量。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="总结"&gt;总结
&lt;/h3&gt;&lt;p&gt;哈希表大小为2的幂时，&lt;strong&gt;位与运算&lt;/strong&gt;在&lt;strong&gt;数学等效性&lt;/strong&gt;、&lt;strong&gt;性能优势&lt;/strong&gt;和&lt;strong&gt;冲突控制&lt;/strong&gt;上全面优于取模运算，是哈希表实现的核心优化手段。Java的HashMap通过&lt;code&gt;tableSizeFor()&lt;/code&gt;和&lt;code&gt;&amp;amp; (capacity-1)&lt;/code&gt;的设计，将这一机制应用于实践。&lt;/p&gt;
&lt;h2 id="cooperative-group"&gt;Cooperative Group
&lt;/h2&gt;&lt;p&gt;在CUDA中将Cooperative Group（协作组）大小设为8，并让每个组访问全局内存的不同部分，这种设计对性能的影响是多方面的，既有潜在优势也可能带来挑战。以下是关键分析：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-内存访问模式的影响"&gt;⚙️ 1. &lt;strong&gt;内存访问模式的影响&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;合并访问的可能性&lt;/strong&gt;：
若组内8个线程访问&lt;strong&gt;连续内存地址&lt;/strong&gt;​（如相邻的8个float），可触发合并访问，减少内存事务次数，提升带宽利用率。
但若组内访问&lt;strong&gt;非连续或跨步过大&lt;/strong&gt;​（如间隔访问），会退化为非合并访问，增加内存事务（可能从1次变为8次），显著降低吞吐量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;组间内存隔离的利弊&lt;/strong&gt;：
✅ ​&lt;strong&gt;优势&lt;/strong&gt;​：各组访问独立内存区域可减少缓存竞争（如L1/L2缓存），避免组间数据冲突。
⚠️ ​&lt;strong&gt;风险&lt;/strong&gt;​：若全局内存访问范围分散，可能降低缓存局部性，增加DRAM访问延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-并行效率与资源占用"&gt;⚡ 2. &lt;strong&gt;并行效率与资源占用&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;线程块资源利用率&lt;/strong&gt;：
Group大小8（小于标准Warp的32线程）可能导致&lt;strong&gt;线程块内Group数量增多&lt;/strong&gt;，但每个Group的线程数较少。若计算负载不均，部分线程可能闲置，降低SM（流多处理器）的占用率（Occupancy）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同步开销优化&lt;/strong&gt;：
小规模Group（如8线程）的同步（&lt;code&gt;sync()&lt;/code&gt;）延迟远低于块级同步（&lt;code&gt;__syncthreads()&lt;/code&gt;），通常在&lt;strong&gt;纳秒级&lt;/strong&gt;​（块级同步约140ns）。适合需要&lt;strong&gt;高频同步&lt;/strong&gt;的算法（如迭代计算）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-数据通信与负载均衡"&gt;🔗 3. &lt;strong&gt;数据通信与负载均衡&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;组间通信需求&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;p&gt;若算法需组间数据交换（如全局结果聚合），需通过原子操作或全局内存中转。此时：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;使用&lt;code&gt;thread_scope_device&lt;/code&gt;级原子操作（延迟3–5μs）可能成为瓶颈。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;建议用共享内存暂存结果，再集中写入全局内存，减少原子操作次数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;负载均衡问题&lt;/strong&gt;：
各组处理不同内存区域时，若数据分布不均（如稀疏矩阵），可能造成部分Group计算量过大，导致延迟[ citation:5]。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-4-与硬件架构的协同性"&gt;⚖️ 4. &lt;strong&gt;与硬件架构的协同性&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SM资源限制&lt;/strong&gt;：
每个SM的寄存器/共享内存总量固定。Group增多可能加剧资源竞争，尤其是共享内存（如每组声明独立共享内存数组时）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;新硬件特性支持&lt;/strong&gt;：
NVIDIA Hopper架构的&lt;strong&gt;线程块集群&lt;/strong&gt;​（Thread Block Cluster）允许8个线程块协作，同步延迟介于块级与设备级之间。若Group设计匹配此结构，可进一步降低通信开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-5-优化策略建议"&gt;🚀 5. &lt;strong&gt;优化策略建议&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;为最大化性能，可结合以下实践：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;强制合并访问&lt;/strong&gt;：
确保组内线程访问连续地址（如&lt;code&gt;group.thread_rank()&lt;/code&gt;映射到连续索引）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共享内存缓存&lt;/strong&gt;：
各组先将全局数据加载到共享内存，组内处理后再写回，避免直接非合并访问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态负载均衡&lt;/strong&gt;：
使用任务队列（如全局计数器分配任务），确保各组负载均匀。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;占用率调优&lt;/strong&gt;：
通过&lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;配置执行参数，平衡Group数量与SM资源。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-性能影响总结"&gt;💎 性能影响总结
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;因素&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;性能优势&lt;/strong&gt; ✅&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;性能挑战&lt;/strong&gt; ⚠️&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;内存访问&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;组内连续访问可合并&lt;/td&gt;
&lt;td&gt;组间分散访问导致缓存命中率下降&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;同步开销&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;小规模组同步延迟低（纳秒级）&lt;/td&gt;
&lt;td&gt;组间通信依赖高延迟原子操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;资源占用&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;灵活适配细粒度任务&lt;/td&gt;
&lt;td&gt;SM占用率可能降低&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;扩展性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;匹配Hopper集群架构可加速&lt;/td&gt;
&lt;td&gt;数据分布不均引发负载失衡&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-结论-1"&gt;💎 &lt;strong&gt;结论&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;将Cooperative Group设为8并分区访问全局内存，在&lt;strong&gt;细粒度同步算法&lt;/strong&gt;（如图遍历、迭代求解器）中可能显著提升性能，尤其适合组内计算密集且需高频同步的场景。然而，若内存访问模式未优化或负载不均衡，性能可能劣于传统Warp级设计。&lt;strong&gt;关键优化点&lt;/strong&gt;在于：
① 强制组内连续内存访问；
② 用共享内存减少全局访问次数；
③ 匹配硬件特性（如集群与TMA加速器）。&lt;/p&gt;
&lt;h2 id="线程规约"&gt;线程规约
&lt;/h2&gt;&lt;p&gt;CUDA线程块规约（Block Reduce）是一种在GPU线程块内高效聚合数据（如求和、求最大值）的关键并行计算技术。其核心在于利用共享内存和线程束（Warp）级指令实现数据的高效合并。以下从实现策略到优化技巧进行详细说明：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-一线程块规约的核心原理"&gt;⚙️ &lt;strong&gt;一、线程块规约的核心原理&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分层规约思想&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt; 步骤1：线程私有计算
每个线程读取多个全局内存数据，进行局部规约（如累加部分和），减少全局内存访问次数。
```
float val = 0.0f;
for (int i = threadIdx.x; i &amp;lt; n; i += blockDim.x) {
val += data[i]; // 局部累加
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;步骤2：共享内存聚合&lt;/strong&gt;
将局部结果存入共享内存（&lt;code&gt;__shared__&lt;/code&gt;），利用块内线程协作进一步规约。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;&lt;strong&gt;线程块内同步&lt;/strong&gt;
使用&lt;code&gt;__syncthreads()&lt;/code&gt;确保所有线程完成数据写入后再进行规约，避免竞态条件。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-二主流规约策略与实现"&gt;🔧 &lt;strong&gt;二、主流规约策略与实现&lt;/strong&gt;
&lt;/h3&gt;&lt;h4 id="1-交错规约interleaved-reduction"&gt;&lt;strong&gt;1. 交错规约（Interleaved Reduction）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;操作方式&lt;/strong&gt;：线程每次处理间隔为步长的一半（折半合并）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码示例&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__shared__ float sdata[1024];
sdata[threadIdx.x] = val;
__syncthreads();
for (int stride = blockDim.x / 2; stride &amp;gt; 0; stride &amp;gt;&amp;gt;= 1) {
if (threadIdx.x &amp;lt; stride) {
sdata[threadIdx.x] += sdata[threadIdx.x + stride];
}
__syncthreads();
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：内存访问连续，合并度高（Coalesced Access），性能较好。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="2-交叉规约sequential-reduction"&gt;&lt;strong&gt;2. 交叉规约（Sequential Reduction）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;操作方式&lt;/strong&gt;：相邻线程两两合并（如线程0与1、2与3）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：内存访问不连续，易导致Bank Conflict，效率较低。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="3-warp级规约warp-shuffle"&gt;&lt;strong&gt;3. Warp级规约（Warp Shuffle）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：利用&lt;code&gt;__shfl_down_sync&lt;/code&gt;指令在Warp内直接交换寄存器数据，无需共享内存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码示例&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;float warp_reduce(float val) {
for (int offset = 16; offset &amp;gt; 0; offset /= 2)
val += __shfl_down_sync(0xffffffff, val, offset);
return val;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：延迟低（寄存器访问仅1周期），适合Warp内聚合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="4-块内规约结合warp-shuffle"&gt;&lt;strong&gt;4. 块内规约（结合Warp Shuffle）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;步骤&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个Warp内先规约到1个值。&lt;/li&gt;
&lt;li&gt;将各Warp结果存入共享内存。&lt;/li&gt;
&lt;li&gt;第一个Warp再次规约这些值。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__shared__ float warp_results[32];
float warp_val = warp_reduce(val); // Warp内规约
if (lane_id == 0) warp_results[warp_id] = warp_val;
__syncthreads();
if (threadIdx.x &amp;lt; 32) {
float block_val = warp_reduce(warp_results[threadIdx.x]);
if (threadIdx.x == 0) result = block_val;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：处理大规模数据时效率高。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="5-使用cub库"&gt;&lt;strong&gt;5. 使用CUB库&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;简化开发&lt;/p&gt;
&lt;p&gt;：直接调用&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cub::BlockReduce
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;模板类。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;#include &amp;lt;cub/block/block_reduce.cuh&amp;gt;
__shared__ cub::BlockReduce&amp;lt;float&amp;gt;::TempStorage temp;
float block_sum = cub::BlockReduce(temp).Sum(val);
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：自动优化底层实现，支持多种规约操作（如Sum/Max）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-三性能优化关键技巧"&gt;⚡ &lt;strong&gt;三、性能优化关键技巧&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;避免共享内存Bank Conflict&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交错规约优于交叉规约，因步长访问更连续。&lt;/li&gt;
&lt;li&gt;调整共享内存布局（如使用偏移量）分散Bank访问。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;向量化内存访问&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;float4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;/&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;int4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;类型单次读写4个元素，提升带宽利用率。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;float4* data_vec = (float4*)data;
float4 tmp = data_vec[id];
val += tmp.x + tmp.y + tmp.z + tmp.w;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;线程块配置原则&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Block Size&lt;/strong&gt;：设为32的倍数（如256/512），适配Warp调度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grid Size&lt;/strong&gt;：覆盖总数据量，公式：
&lt;code&gt;grid_size = (n + block_size - 1) / block_size&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;双规约融合&lt;/strong&gt;
在Softmax等场景中，可同时计算最大值和求和：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;struct { float max_val; float sum_val; } md;
md.max_val = max(a, b);
md.sum_val = exp(a - md.max_val) + exp(b - md.max_val); // 数值稳定
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过自定义规约算子一次性完成。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-四应用场景"&gt;💻 &lt;strong&gt;四、应用场景&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;科学计算&lt;/strong&gt;：大规模向量求和/求极值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;深度学习&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Softmax中的最大值/求和规约。&lt;/li&gt;
&lt;li&gt;损失函数计算（如交叉熵）。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;strong&gt;图像处理&lt;/strong&gt;：像素级统计（平均亮度、方差）。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-五不同策略性能对比"&gt;📊 &lt;strong&gt;五、不同策略性能对比&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;规约策略&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;延迟&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;共享内存使用&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;交叉规约&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;简单教学示例&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;交错规约&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;通用需求&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Warp Shuffle&lt;/td&gt;
&lt;td&gt;极低&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;Warp内聚合（≤32线程）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUB库&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;自动优化&lt;/td&gt;
&lt;td&gt;生产环境首选&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-总结-2"&gt;💎 &lt;strong&gt;总结&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;线程块规约的核心是通过&lt;strong&gt;分层合并&lt;/strong&gt;（线程→Warp→块）和&lt;strong&gt;硬件特性利用&lt;/strong&gt;（共享内存/Warp指令）实现高效聚合。&lt;strong&gt;交错规约&lt;/strong&gt;和&lt;strong&gt;Warp Shuffle&lt;/strong&gt;是性能最优策略，而&lt;strong&gt;CUB库&lt;/strong&gt;可简化开发并自动优化。实际开发需结合数据规模（如Warp级处理小矩阵行、块级处理大行）和硬件特性（如Bank Conflict规避）精细调整参数。&lt;/p&gt;</description></item><item><title>【CUDA】LLM Queries</title><link>https://dyhes.github.io/p/cudallm-queries/</link><pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudallm-queries/</guid><description>&lt;h2 id="协作组"&gt;协作组
&lt;/h2&gt;&lt;p&gt;线程协作组（Cooperative Groups）是 &lt;strong&gt;CUDA 9.0 引入的编程模型扩展&lt;/strong&gt;，旨在提供更灵活、安全且高效的线程同步与协作机制。它允许开发者动态定义不同粒度的线程组（如线程块、warp 或自定义子集），并支持显式同步和集体操作，从而优化并行计算的设计。以下是其核心要点：&lt;/p&gt;
&lt;h3 id="-核心概念与背景"&gt;⚙️ 核心概念与背景
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;传统同步的局限&lt;/strong&gt; ：早期 CUDA 仅支持线程块级同步（__syncthreads()），无法灵活处理更细粒度（如单个 warp）或跨线程块协作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;协作组的解决方案&lt;/strong&gt; ：将线程组抽象为&lt;strong&gt;一级程序对象&lt;/strong&gt; （first-class object），开发者可显式创建、操作和同步任意规模的线程组，避免临时性同步代码的脆弱性。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-核心组件与功能"&gt;🧩 核心组件与功能
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;组类型&lt;/strong&gt; ：
* &lt;strong&gt;隐式组&lt;/strong&gt; ：由 CUDA 自动定义（如 thread_block 表示整个线程块）。
* &lt;strong&gt;显式子组&lt;/strong&gt; ：通过分区操作生成（如 tiled_partition 划分 warp 或自定义大小组）。
* &lt;strong&gt;网格级组&lt;/strong&gt; ：跨线程块同步（需 CUDA 11.0+，性能优化 30%）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;同步操作&lt;/strong&gt; ：
* 组内同步：g.sync() 或 cg::synchronize(g) 替代传统 __syncthreads()。
* 支持细粒度控制（如仅同步 warp 内线程）。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;集体算法&lt;/strong&gt; （需 C++11）：
* &lt;strong&gt;数据搬运&lt;/strong&gt; ：memcpy_async() 实现异步内存拷贝。
* &lt;strong&gt;规约与扫描&lt;/strong&gt; ：reduce()、inclusive_scan() 等高效集合计算。
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;硬件加速支持&lt;/strong&gt; ：
* 针对特定组类型（如 thread_block_tile）优化，编译时生成高效指令。
⠀&lt;/p&gt;
&lt;h3 id="-编程模型优势"&gt;🚀 编程模型优势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt; ：支持动态线程组划分（如 64/128 线程的 tile），适应复杂算法需求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;安全性&lt;/strong&gt; ：显式组对象强制同步约束，减少竞态条件和死锁风险。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能提升&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;细粒度同步减少无效等待（如仅同步必要线程子集）。&lt;/li&gt;
&lt;li&gt;集体算法利用硬件特性（如 Tensor Core 加速规约）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可维护性&lt;/strong&gt; ：组对象作为函数参数传递，明确协作边界，提升代码可读性。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-典型应用场景"&gt;⚡ 典型应用场景
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;生产者-消费者模型&lt;/strong&gt; ：不同线程组分别负责数据生成与处理，通过显式同步协调流程。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;跨线程块规约&lt;/strong&gt; ：使用网格级组（grid_group）实现全局求和或扫描。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;异步数据传输&lt;/strong&gt; ：### memcpy_async() 在计算同时预取数据，隐藏内存延迟。
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;动态负载均衡&lt;/strong&gt; ：机会并行（opportunistic parallelism）按需分配线程任务。
⠀&lt;/p&gt;
&lt;h3 id="-注意事项"&gt;⚠️ 注意事项
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;版本依赖&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;网格级组需 CUDA 11.0+，集体算法需 C++11 编译（&amp;ndash;std=c++11）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件限制&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;大于 32 线程的 tile 需 Compute Capability 8.0+（如 A100/RTX 30 系列）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能权衡&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;过度细分组可能导致同步开销增加，需结合算法特性设计。
⠀线程协作组通过&lt;strong&gt;显式线程管理&lt;/strong&gt;和&lt;strong&gt;硬件加速集合操作&lt;/strong&gt;，显著提升了 CUDA 并行程序的灵活性与效率，尤其适合复杂协作逻辑（如科学计算、AI 推理）的开发。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="warp"&gt;Warp
&lt;/h2&gt;&lt;p&gt;在CUDA编程中， &lt;strong&gt;Warp（线程束）是GPU执行指令的最小调度单元&lt;/strong&gt;，其大小是固定的硬件设计。以下是关键信息总结：&lt;/p&gt;
&lt;h3 id="-warp-的标准大小"&gt;⚙️ Warp 的标准大小
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;固定为32线程&lt;/strong&gt;
* 所有NVIDIA GPU架构（从早期Tesla到最新Ampere/Ada Lovelace）均采用 &lt;strong&gt;32线程&lt;/strong&gt; 作为Warp的基本单位。
* 这一设计由硬件层固化，开发者无法修改。
⠀🔧 硬件实现机制&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SIMT（单指令多线程）执行模型&lt;/strong&gt; ：Warp内的32个线程&lt;strong&gt;同步执行相同指令&lt;/strong&gt;，但可处理不同数据（即单指令作用于多个数据路径）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分支发散（Divergence）处理&lt;/strong&gt; ：若Warp内线程因条件分支走向不同路径（如if-else），GPU会&lt;strong&gt;串行执行所有分支路径&lt;/strong&gt;，显著降低效率。需避免此类设计。
⠀📊 不同架构下的Warp特性
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;GPU架构&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Warp大小&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;关键特性&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Tesla/Fermi/Kepler&lt;/td&gt;
&lt;td style="text-align: center"&gt;32线程&lt;/td&gt;
&lt;td style="text-align: center"&gt;基础SIMT模型，无独立线程调度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Maxwell/Pascal&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;32线程&lt;/td&gt;
&lt;td style="text-align: center"&gt;引入动态并行，Warp调度优化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Volta/Ampere&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;32线程&lt;/td&gt;
&lt;td style="text-align: center"&gt;支持&lt;strong&gt;独立线程调度（ISA）&lt;/strong&gt; ，减少分支发散代价&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Hopper/Ada Lovelace&lt;/td&gt;
&lt;td style="text-align: center"&gt;32线程&lt;/td&gt;
&lt;td style="text-align: center"&gt;增强线程块集群协作，Warp级操作更高效&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-编程注意事项"&gt;💡 编程注意事项
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;性能优化核心&lt;/strong&gt; ：
* &lt;strong&gt;内存访问对齐&lt;/strong&gt; ：确保Warp内线程访问连续内存地址（如threadIdx.x对应相邻数据），避免全局内存碎片。
* &lt;strong&gt;减少分支发散&lt;/strong&gt; ：通过重组数据或使用__syncwarp()显式同步（Volta+架构）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;资源分配影响&lt;/strong&gt; ：
* 每个SM（流多处理器）的Warp数量受限于寄存器文件（Register File）和共享内存（Shared Memory）容量。
* 例如：Kepler架构SM最多驻留64个活跃Warp（即2048线程）。
⠀🌰 示例场景
若一个线程块（Block）包含256线程 → 将被拆分为 &lt;strong&gt;8个Warp&lt;/strong&gt; （256/32）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;理想情况&lt;/strong&gt; ：所有线程执行相同指令，无分支发散 → 硬件利用率100%。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最差情况&lt;/strong&gt; ：32线程分别执行32个不同分支 → 实际并行度降为1/32。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-总结"&gt;💎 总结
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;固定大小&lt;/strong&gt; ：Warp恒为&lt;strong&gt;32线程&lt;/strong&gt;，是GPU调度的原子单元。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化关键&lt;/strong&gt; ：避免分支发散、确保内存连续访问，以最大化Warp执行效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;架构演进&lt;/strong&gt; ：新一代GPU（Volta+）通过独立线程调度降低分支代价，但32线程基础结构不变。
⠀📌 &lt;strong&gt;实践建议&lt;/strong&gt; ：使用cudaDeviceProp.warpSize获取当前设备的Warp大小（始终为32），并在内核设计中显式对齐32的倍数（如线程块尺寸设为32×N）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="warp-divergence"&gt;Warp Divergence
&lt;/h2&gt;&lt;p&gt;在CUDA编程中，“串行执行所有分支路径”是GPU处理&lt;strong&gt;分支发散（Warp Divergence）&lt;/strong&gt; 的核心机制，指当同一个Warp（32线程）内的线程因条件分支（如if-else）走向不同执行路径时，GPU硬件被迫&lt;strong&gt;按分支路径顺序逐条执行所有路径&lt;/strong&gt;，而非并行处理。其具体含义和原理如下：&lt;/p&gt;
&lt;h3 id="-硬件背景simt执行模型"&gt;⚙️ 硬件背景：SIMT执行模型
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Warp是调度单元&lt;/strong&gt; ：GPU以Warp（32线程）为单位调度指令，同一Warp内所有线程&lt;strong&gt;必须同步执行相同指令&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分支冲突的代价&lt;/strong&gt; ：若Warp内部分线程满足条件A，另一部分满足条件B，硬件无法同时执行两条路径。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-串行执行所有分支路径的流程"&gt;🔄 “串行执行所有分支路径”的流程
&lt;/h3&gt;&lt;p&gt;当Warp内出现分支发散时，GPU按以下步骤处理：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;路径分离&lt;/strong&gt; ：识别Warp内线程的不同分支路径（如if分支和else分支）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;掩码激活与屏蔽&lt;/strong&gt; ：
* 先激活执行&lt;strong&gt;第一条路径的线程&lt;/strong&gt; （如满足if的线程），同时&lt;strong&gt;屏蔽其他线程&lt;/strong&gt; （如else线程）。
* 再激活执行&lt;strong&gt;第二条路径的线程&lt;/strong&gt; （如else线程），屏蔽已执行完的线程。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;路径合并&lt;/strong&gt; ：所有路径执行完毕后，线程重新汇合到同一执行点继续后续指令。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;理想情况&lt;/strong&gt; ：所有32线程走同一路径 → 1次执行完成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分支发散&lt;/strong&gt; ：16线程走路径A，16线程走路径B → 硬件需&lt;strong&gt;先执行路径A（屏蔽路径B线程）&lt;/strong&gt; ， &lt;strong&gt;再执行路径B（屏蔽路径A线程）&lt;/strong&gt; → &lt;strong&gt;实际耗时翻倍&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-性能影响"&gt;⚠️ 性能影响
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;并行度骤降&lt;/strong&gt; ：Warp的并行能力从32线程降至实际有效线程数（如仅16线程活跃）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源闲置&lt;/strong&gt; ：被屏蔽的线程占用寄存器/内存资源，但无法执行指令，造成硬件资源浪费。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;极端案例&lt;/strong&gt; ：若32线程走向32条不同路径，GPU需&lt;strong&gt;串行执行32次&lt;/strong&gt;，性能下降32倍。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-与cpu分支处理的区别"&gt;🧩 与CPU分支处理的区别
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;GPU（SIMT模型）&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;CPU（超标量/乱序执行）&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;分支处理&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;串行化所有路径&lt;/td&gt;
&lt;td style="text-align: center"&gt;分支预测 + 推测执行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;并行粒度&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;Warp（32线程）为单位&lt;/td&gt;
&lt;td style="text-align: center"&gt;单线程指令级并行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;代价&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;路径数越多，性能损失越大&lt;/td&gt;
&lt;td style="text-align: center"&gt;预测失败时需刷新流水线&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;💡 关键差异：CPU通过预测减少分支代价，而GPU无分支预测能力，只能硬性串行化。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-优化策略"&gt;⚡ 优化策略
&lt;/h3&gt;&lt;p&gt;为减少串行执行的开销，可采取以下方法：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;重构分支逻辑&lt;/strong&gt;
* 用&lt;strong&gt;三元运算符&lt;/strong&gt;替代if-else：// 原分支
* if (idx % 2 == 0) data[idx] = 1.0f;&lt;br&gt;
* else data[idx] = -1.0f;
* // 优化为
* data[idx] = (idx % 2 == 0) ? 1.0f : -1.0f;
* 使用&lt;strong&gt;位运算或掩码&lt;/strong&gt;避免分支：float mask = (idx &amp;amp; 1) ^ 1; // 偶数为1，奇数为0
* data[idx] = mask * 1.0f + (1 - mask) * (-1.0f);
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;数据布局调整&lt;/strong&gt;
* 将&lt;strong&gt;相同分支行为的线程分组&lt;/strong&gt;到同一Warp（如按数据奇偶性重排输入）。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;Warp级原语&lt;/strong&gt;
* 使用__shfl_xor()、__ballot()等指令在Warp内交换数据，避免显式分支。
⠀&lt;/p&gt;
&lt;h3 id="-总结-1"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;“串行执行所有分支路径”是GPU应对&lt;strong&gt;Warp Divergence的底层硬件行为&lt;/strong&gt;，本质是SIMT架构为统一指令流的妥协。其代价是&lt;strong&gt;并行效率的显著下降&lt;/strong&gt;，尤其在分支路径多、分布随机时。优化需聚焦：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;减少分支数量&lt;/strong&gt; （如数学等价转换）
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;对齐线程行为&lt;/strong&gt; （数据重排）
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;利用硬件特性&lt;/strong&gt; （Warp级指令）。理解这一机制是写出高性能CUDA代码的关键前提。&lt;/p&gt;
&lt;h2 id="warp-part"&gt;Warp-Part
&lt;/h2&gt;&lt;p&gt;是的， &lt;strong&gt;线程协作组（Cooperative Groups）可以划分得比32线程更小&lt;/strong&gt;。这是其核心设计目标之一——提供比传统 Warp（固定32线程）更灵活的线程组织粒度。以下是关键说明：&lt;/p&gt;
&lt;h3 id="-协作组支持细粒度划分"&gt;⚙️ 协作组支持细粒度划分
&lt;/h3&gt;&lt;p&gt;线程协作组允许开发者动态创建&lt;strong&gt;任意规模&lt;/strong&gt;的线程子集，包括小于 Warp 的组：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;最小可划分至单线程&lt;/strong&gt; ：通过 tiled_partition 或 coalesced_threads() 可创建 1~31 线程的子组。例如：auto tile16 = cg::tiled_partition&amp;lt;16&amp;gt;(block); // 划分16线程子组&lt;/li&gt;
&lt;li&gt;auto tile8 = cg::tiled_partition&amp;lt;8&amp;gt;(block); // 划分8线程子组&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件支持&lt;/strong&gt; ：在 Volta 架构（Compute Capability 7.0+）及更新 GPU 上， &lt;strong&gt;独立线程调度（ISA）&lt;/strong&gt; 允许子组内线程独立执行分支，避免传统 Warp 的分发散问题。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-典型应用场景-1"&gt;🧩 典型应用场景
&lt;/h3&gt;&lt;p&gt;小于 Warp 的组在以下场景中尤为重要：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据分块处理&lt;/strong&gt; ：当每行数据宽度小于 32（如处理 16 通道图像），用 16 线程子组可避免资源浪费。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;细粒度同步&lt;/strong&gt; ：组内仅需同步必要线程（如生产者-消费者模型），减少无效等待。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高效集合操作&lt;/strong&gt; ：小规模规约（Reduce）或扫描（Scan）在子组内完成，减少共享内存争用。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-性能与限制"&gt;⚠️ 性能与限制
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;优势&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;灵活性&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;适应不规则计算模式（如稀疏数据处理）&lt;/td&gt;
&lt;td style="text-align: center"&gt;过小组（&amp;lt;8线程）可能导致并行度不足&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;分支发散处理&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;子组内分支发散代价更低（Volta+架构）&lt;/td&gt;
&lt;td style="text-align: center"&gt;旧架构（Maxwell/Pascal）仍需串行执行所有路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;资源开销&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;减少寄存器/共享内存占用（组规模小）&lt;/td&gt;
&lt;td style="text-align: center"&gt;频繁划分子组可能增加调度开销&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;💡 &lt;strong&gt;最佳实践&lt;/strong&gt; ：&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;优先在 &lt;strong&gt;Volta/Turing/Ampere 架构&lt;/strong&gt; 使用小规模组（充分利用 ISA）。&lt;/li&gt;
&lt;li&gt;避免在计算密集型任务中划分过小组（如 &amp;lt;8 线程），确保硬件利用率。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-代码示例"&gt;💻 代码示例
&lt;/h3&gt;&lt;h3 id="global-void-processsmalldatafloat-data-"&gt;&lt;strong&gt;global&lt;/strong&gt; void processSmallData(float* data) {
&lt;/h3&gt;&lt;h3 id="auto-block--cgthis_thread_block"&gt;auto block = cg::this_thread_block();
&lt;/h3&gt;&lt;h3 id="auto-tile16--cgtiled_partition16block--创建16线程子组"&gt;auto tile16 = cg::tiled_partition&amp;lt;16&amp;gt;(block); // 创建16线程子组
&lt;/h3&gt;&lt;h3 id="if-tilethread_rank--8-"&gt;if (tilethread_rank() &amp;lt; 8) {
&lt;/h3&gt;&lt;h3 id="-前8线程处理任务a"&gt;// 前8线程处理任务A
&lt;/h3&gt;&lt;h3 id="float-val--datatilethread_rank"&gt;float val = data[tilethread_rank()];
&lt;/h3&gt;&lt;h3 id="val--tileshflval-0--子组内数据交换"&gt;val = tileshfl(val, 0); // 子组内数据交换
&lt;/h3&gt;&lt;h3 id="-else-"&gt;} else {
&lt;/h3&gt;&lt;h3 id="-后8线程处理任务b"&gt;// 后8线程处理任务B
&lt;/h3&gt;&lt;h3 id="-"&gt;// &amp;hellip;
&lt;/h3&gt;&lt;h3 id="heading"&gt;}
&lt;/h3&gt;&lt;h3 id="tilesync--仅同步16线程子组"&gt;tilesync(); // 仅同步16线程子组
&lt;/h3&gt;&lt;h3 id="heading-1"&gt;}
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;关键点&lt;/strong&gt; ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tile16.shfl() 实现组内数据广播（硬件加速）。&lt;/li&gt;
&lt;li&gt;tile16.sync() 仅同步子组，无需等待整个 Warp。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-总结-2"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;线程协作组&lt;strong&gt;支持任意小于 Warp 的划分&lt;/strong&gt; （最小至单线程），通过以下方式实现高效协作：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;动态子组创建&lt;/strong&gt; （tiled_partition）
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;细粒度同步&lt;/strong&gt; （group.sync()）
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;硬件加速集合操作&lt;/strong&gt; （如 shfl()、reduce()）需结合硬件架构（Volta+）和任务特性权衡组规模，以最大化并行效率。
比Warp（32线程）更小的协作组（如16、8线程）在GPU物理结构上实现并行，主要依赖以下硬件与软件协同机制：&lt;/p&gt;
&lt;h3 id="-独立线程调度isa硬件级支持"&gt;⚙️ 独立线程调度（ISA）——硬件级支持
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Volta架构（2017）及更新GPU&lt;/strong&gt; （如Turing/Ampere/Hopper）引入&lt;strong&gt;独立线程调度（ISA）&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;每个线程拥有独立的&lt;strong&gt;程序计数器（PC）&lt;/strong&gt; 和&lt;strong&gt;执行状态寄存器&lt;/strong&gt;，打破传统Warp必须锁步执行（SIMT）的限制。&lt;/li&gt;
&lt;li&gt;硬件可为子组（如16线程）分配独立指令流，实现&lt;strong&gt;真正细粒度并行&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行原理&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;当协作组（如16线程）被划分后，GPU调度器将子组视为独立执行单元。&lt;/li&gt;
&lt;li&gt;若子组内无分支发散，硬件仍按SIMT模式广播指令；若存在分支，硬件自动为不同路径线程分配独立资源， &lt;strong&gt;避免串行执行所有路径&lt;/strong&gt;。
⠀✅ &lt;strong&gt;示例&lt;/strong&gt; ：8线程子组中，4线程走路径A、4线程走路径B → 硬件并行执行两条路径，而非传统Warp的串行化。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-动态子组划分与资源隔离软件层协作"&gt;🧩 动态子组划分与资源隔离——软件层协作
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;协作组API（如&lt;/strong&gt; tiled_partition**）** ：auto tile16 = cg::tiled_partition&amp;lt;16&amp;gt;(block); // 划分16线程子组
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;逻辑划分&lt;/strong&gt; ：API将Warp拆分为更小线程子集，每个子组拥有&lt;strong&gt;独立同步原语&lt;/strong&gt; （如 tile16.sync()）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件资源映射&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;寄存器文件&lt;/strong&gt; ：每个线程独占物理寄存器，子组共享寄存器访问权限。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共享内存&lt;/strong&gt; ：子组通过共享内存（Shared Memory）交换数据，硬件提供低延迟访问通道。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-细粒度内存访问优化"&gt;🚀 细粒度内存访问优化
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内存合并访问&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;小规模组（如8线程）更易实现&lt;strong&gt;连续内存访问&lt;/strong&gt;，硬件自动合并全局内存请求，提升带宽利用率。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共享内存局部性&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;子组将热点数据缓存至共享内存（如矩阵分块计算），减少全局内存延迟。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-分支发散代价的规避"&gt;⚡ 分支发散代价的规避
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;局部发散控制&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;分支发散被限制在子组内部（如16线程），而非整个Warp（32线程）， &lt;strong&gt;最大发散路径数减半&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;硬件只需为子组内少数路径分配资源，降低串行化开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;谓词掩码优化&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;子组内使用&lt;strong&gt;组内投票指令&lt;/strong&gt; （如 ballot()、shfl()）替代条件分支，保持指令一致性。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-专用硬件加速集合操作"&gt;🧪 专用硬件加速集合操作
&lt;/h3&gt;&lt;p&gt;协作组支持高效集合操作，由硬件直接加速：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;规约（Reduce）&lt;/strong&gt; ：子组内并行求和（cg::reduce()），利用Warp级原语（如 __shfl_down()）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据交换（Shuffle）&lt;/strong&gt; ：tile16.shfl(val, src_lane) 实现组内线程数据广播。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt; ：小规模组减少共享内存争用，提升集合操作吞吐量。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-架构依赖性与限制"&gt;⚠️ 架构依赖性与限制
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;架构&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;支持能力&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Volta+&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;完整ISA支持，子组并行效率高&lt;/td&gt;
&lt;td style="text-align: center"&gt;需Compute Capability ≥7.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Maxwell/Pascal&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;无ISA，子组内分支仍串行执行&lt;/td&gt;
&lt;td style="text-align: center"&gt;需重构算法避免分支发散&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;过小组（&amp;lt;8线程）&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;并行度不足，可能降低SM利用率&lt;/td&gt;
&lt;td style="text-align: center"&gt;建议与计算密集型任务搭配使用&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-总结-3"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;小于Warp的协作组通过 &lt;strong&gt;“硬件独立调度（ISA）+ 软件动态划分 + 内存局部性优化”&lt;/strong&gt; 三重机制实现高效并行：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;硬件突破&lt;/strong&gt; ：Volta+架构的ISA解除线程锁步限制。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;软件抽象&lt;/strong&gt; ：协作组API逻辑划分线程，隔离资源与同步。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;局部性利用&lt;/strong&gt; ：小规模组更易优化内存访问与规避分支代价。&lt;strong&gt;实践建议&lt;/strong&gt; ：在Ampere/Hopper架构上优先使用8-16线程子组，结合共享内存与集合操作，最大化并行效率。&lt;/p&gt;
&lt;h2 id="sm-利用率"&gt;SM 利用率
&lt;/h2&gt;&lt;p&gt;过小的线程组（如小于32线程的协作组或线程块）会显著降低流多处理器（SM）的利用率，主要源于以下硬件资源分配和调度机制的限制：&lt;/p&gt;
&lt;h3 id="-资源分配以线程块为最小单位"&gt;⚙️ 资源分配以线程块为最小单位
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;固定开销占用&lt;/strong&gt; ：SM的资源（寄存器、共享内存、线程槽位）按线程块分配。每个线程块无论包含多少线程，都会占用固定的管理资源（如共享内存槽位、寄存器文件入口）。&lt;strong&gt;问题&lt;/strong&gt; ：若一个线程块仅含32线程（1个Warp），但其占用的共享内存和寄存器量与128线程的块相同 → 导致SM实际可运行的线程数大幅减少。&lt;strong&gt;示例&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;Tesla M6 SM支持最多2048个并发线程。&lt;/li&gt;
&lt;li&gt;若每个块仅32线程 → SM最多运行64个块（32×64=2048线程） &lt;strong&gt;理论可行&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;但实际受限于共享内存：若每个块占用48KB共享内存，SM总共享内存96KB → &lt;strong&gt;仅能运行2个块&lt;/strong&gt; → 实际线程数仅64（32×2），利用率骤降至3.1%。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-warp调度器闲置"&gt;⚡ Warp调度器闲置
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Warp是调度单元&lt;/strong&gt; ：SM通过Warp调度器管理指令发射，每个调度器需持续接收Warp指令流以隐藏延迟（如内存访问）。&lt;strong&gt;问题&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;过小组导致&lt;strong&gt;活跃Warp数量不足&lt;/strong&gt; ：若一个SM仅运行少量Warp（如2个Warp），调度器无法切换足够任务掩盖延迟 → 硬件空闲周期增加。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;极端案例&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;SM最多支持64个活跃Warp（Tesla M6）。&lt;/li&gt;
&lt;li&gt;若每个线程块仅含1个Warp（32线程），且SM运行2个块 → 仅2个活跃Warp → &lt;strong&gt;Warp槽位利用率仅3.1%&lt;/strong&gt; 。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-寄存器与共享内存的碎片化"&gt;📉 寄存器与共享内存的碎片化
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;寄存器分配粒度&lt;/strong&gt; ：寄存器以Warp为单位分配（分配粒度为4）。&lt;strong&gt;问题&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;若线程组非32的整数倍（如16线程），仍需分配完整Warp的寄存器资源 → 剩余寄存器闲置。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共享内存分配&lt;/strong&gt; ：共享内存按块分配，若组规模小但共享内存需求固定（如48KB/块），则SM可容纳的块数受限于总共享内存容量。&lt;strong&gt;公式&lt;/strong&gt; ：\text{SM利用率} = \frac{\text{实际运行线程数}}{\text{SM最大线程数}} \times 100%当线程组过小时，分子因资源限制显著缩小。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-并行度不足与负载不均衡"&gt;🔄 并行度不足与负载不均衡
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;网格级并行缺陷&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;GPU依赖网格（Grid）中大量线程块覆盖所有SM。若每个块线程数过少（如32线程），需极多块才能填满SM → 但算法可能无法生成足够块。&lt;strong&gt;案例&lt;/strong&gt; ：处理200×768矩阵的行规约时：&lt;/li&gt;
&lt;li&gt;若每行分配1线程 → 仅200线程 → 至多2个块 → 仅占用1-2个SM。&lt;/li&gt;
&lt;li&gt;优化后：每行分配1个Warp（32线程） → 200个Warp → 50个块（按4 Warp/块） → 充分利用50个SM。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分支发散放大&lt;/strong&gt; ：小组内分支发散可能更频繁，进一步降低有效指令吞吐量。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-总结过小组降低利用率的本质"&gt;💎 总结：过小组降低利用率的本质
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;因素&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;影响机制&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;优化方向&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;资源分配粒度&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;固定开销挤占可用线程数&lt;/td&gt;
&lt;td style="text-align: center"&gt;增大组规模（≥128线程/块）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Warp调度需求&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;活跃Warp不足导致调度器闲置&lt;/td&gt;
&lt;td style="text-align: center"&gt;确保每SM活跃Warp数接近上限（如64）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;内存碎片化&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;非整Warp组造成寄存器/共享内存浪费&lt;/td&gt;
&lt;td style="text-align: center"&gt;组规模设为32的倍数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;网格级负载均衡&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;少量线程块无法覆盖所有SM&lt;/td&gt;
&lt;td style="text-align: center"&gt;动态调整块数量，匹配SM总数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;📌 &lt;strong&gt;实践建议&lt;/strong&gt; ：&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;基准测试&lt;/strong&gt; ：用 &amp;ndash;ptxas-options=-v 编译查看寄存器/共享内存占用。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;组规模&lt;/strong&gt; ：线程块至少128线程（4 Warp），协作组不小于8线程。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;资源监控&lt;/strong&gt; ：通过 nvidia-smi 或 DCGM 跟踪 &lt;strong&gt;SM效率&lt;/strong&gt; （活跃SM占比）而非仅GPU利用率。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="launch_"&gt;&lt;strong&gt;launch_bounds&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;launch_bounds&lt;/strong&gt; 是 CUDA 编程中的核心修饰符，用于优化内核（Kernel）在 GPU 上的执行效率，通过控制资源分配和线程调度来提升性能。其主要作用如下：&lt;/p&gt;
&lt;h3 id="-资源优化限制寄存器与共享内存使用"&gt;⚙️ 资源优化：限制寄存器与共享内存使用
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;避免寄存器溢出（Register Spilling）&lt;/strong&gt; 通过 maxThreadsPerBlock 指定线程块的最大线程数，编译器会据此计算寄存器使用上限 L。若内核初始寄存器需求超过 L，编译器会主动减少寄存器用量（可能增加本地内存访问或指令数），防止溢出到低速显存。
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;示例&lt;/em&gt;：若指定 &lt;strong&gt;launch_bounds&lt;/strong&gt;(256)，编译器确保每个线程寄存器用量不超过硬件限制（如 Fermi 架构单线程最多 63 寄存器）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共享内存争用控制&lt;/strong&gt; 结合线程块大小限制，可避免因共享内存超额分配导致 SM 上活跃线程块减少。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-性能提升最大化-sm-利用率"&gt;🚀 性能提升：最大化 SM 利用率
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;保障最小常驻块数&lt;/strong&gt; 通过 minBlocksPerMultiprocessor 指定每个 SM 需驻留的最小线程块数，确保足够多的线程块并行执行，隐藏指令与内存延迟。
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;效果&lt;/em&gt;：若 SM 有 48KB 共享内存，每个块需 16KB，则 minBlocksPerMultiprocessor=3 强制编译器优化至至少 3 个块/SM（而非默认 2 个）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;平衡指令与寄存器&lt;/strong&gt; 当寄存器初始用量低于 L 时，编译器可能主动 &lt;strong&gt;增加寄存器用量&lt;/strong&gt; 至 L，减少指令数并优化单线程延迟（尤其同时指定 maxThreadsPerBlock 和 minBlocksPerMultiprocessor 时）。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-规避运行时错误"&gt;⚠️ 规避运行时错误
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;强制线程块规模限制&lt;/strong&gt; 内核若以超过 maxThreadsPerBlock 的线程数启动，将直接失败（避免资源超限导致的未定义行为）。
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;错误示例&lt;/em&gt;：指定 maxThreadsPerBlock=128 却以 &amp;laquo;&amp;lt;&amp;hellip;, 256&amp;raquo;&amp;gt; 启动 → 内核崩溃。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;未来硬件兼容性&lt;/strong&gt; 显式声明线程块上限可确保代码在新型 GPU 上仍能运行（如 Ampere 的 SM 资源分配策略变化）。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-使用示例与技巧"&gt;🛠️ 使用示例与技巧
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;🔧 基本语法&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__launch_bounds__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxThreadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;minBlocksPerMultiprocessor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="cm"&gt;/*参数*/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 内核代码
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;参数说明&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;maxThreadsPerBlock：线程块最大线程数（必选）。&lt;/li&gt;
&lt;li&gt;minBlocksPerMultiprocessor：SM 最小常驻块数（可选）。
⠀&lt;strong&gt;🌐 架构适配方案&lt;/strong&gt;
不同 GPU 架构需不同优化参数，可通过 &lt;strong&gt;CUDA_ARCH&lt;/strong&gt; 动态调整：&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#define THREADS_PER_BLOCK 256
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#if __CUDA_ARCH__ &amp;gt;= 200 &lt;/span&gt;&lt;span class="c1"&gt;// Ampere+ 架构
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MAX_THREADS (2 * THREADS_PER_BLOCK)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MIN_BLOCKS 3
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#else &lt;/span&gt;&lt;span class="c1"&gt;// 旧架构
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MAX_THREADS THREADS_PER_BLOCK
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MIN_BLOCKS 2
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#endif
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__launch_bounds__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MY_KERNEL_MAX_THREADS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MY_KERNEL_MIN_BLOCKS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;📊 调试与验证&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;寄存器用量&lt;/strong&gt; ：编译时添加 &amp;ndash;ptxas-options=-v 查看实际寄存器分配。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SM 占用率&lt;/strong&gt; ：使用 NVIDIA Profiler 分析常驻块数量与执行效率。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-总结-4"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;launch_bounds&lt;/strong&gt; 的核心价值是通过 &lt;strong&gt;资源约束+执行保障&lt;/strong&gt; 提升内核性能：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;资源优化&lt;/strong&gt; ：避免寄存器/共享内存溢出，减少低速内存访问。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;并行度保障&lt;/strong&gt; ：强制最小常驻块数，最大化 SM 利用率。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;错误预防&lt;/strong&gt; ：显式声明线程块限制，增强代码健壮性。
⠀⚠️ &lt;strong&gt;注意&lt;/strong&gt; ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;过小的 maxThreadsPerBlock 或过高的 minBlocksPerMultiprocessor 可能导致寄存器压缩过度，反增指令开销。&lt;/li&gt;
&lt;li&gt;优先通过性能分析（如 nvprof）确定最佳参数，而非盲目设置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cudamallochost"&gt;cudaMallocHost
&lt;/h2&gt;&lt;p&gt;cudaMallocHost 是 NVIDIA CUDA 编程中用于在&lt;strong&gt;主机（CPU）上分配页锁定内存（Pinned Memory）&lt;/strong&gt; 的核心函数。其核心作用是提升主机与设备（GPU）间数据传输效率，减少内存复制开销。以下是详细解析：&lt;/p&gt;
&lt;h3 id="-核心功能与原理"&gt;🔧 核心功能与原理
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;页锁定内存（Pinned Memory）&lt;/strong&gt;
* &lt;strong&gt;定义&lt;/strong&gt; ：通过 cudaMallocHost 分配的内存由操作系统固定（锁定）在物理地址， &lt;strong&gt;不可被换出到磁盘&lt;/strong&gt;，确保物理地址始终有效。
* &lt;strong&gt;优势&lt;/strong&gt; ：
* &lt;strong&gt;避免额外拷贝&lt;/strong&gt; ：传统可分页内存（Pageable Memory）需先拷贝到临时页锁定缓冲区，再传输至设备；而 cudaMallocHost 分配的内存可直接与设备交互。
* &lt;strong&gt;带宽提升&lt;/strong&gt; ：减少一次主机内存拷贝，显著提升 PCIe 传输效率（实测带宽可提升 50% 以上）。
* &lt;strong&gt;支持异步传输&lt;/strong&gt; ：可与 cudaMemcpyAsync 结合，实现数据传输与计算重叠。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;函数原型&lt;/strong&gt; cudaError_t cudaMallocHost(void **ptr, size_t size);
* ptr：指向分配内存地址的指针。
* size：需分配的字节数。
* &lt;strong&gt;返回值&lt;/strong&gt; ：cudaSuccess 表示成功，否则返回错误码（如 cudaErrorMemoryAllocation）。
⠀&lt;/p&gt;
&lt;h3 id="-适用场景"&gt;⚡ 适用场景
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;高频主机-设备数据传输&lt;/strong&gt;
* 需频繁拷贝大数据（如图像处理、科学计算），页锁定内存减少传输延迟。
* &lt;strong&gt;示例&lt;/strong&gt; ：float &lt;em&gt;h_pinned;
* cudaMallocHost((void&lt;/em&gt;*)&amp;amp;h_pinned, size); // 分配页锁定内存
* cudaMemcpyAsync(d_data, h_pinned, size, cudaMemcpyHostToDevice, stream); // 异步传输
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;零拷贝内存（Unified Memory 前身）&lt;/strong&gt;
* 通过 cudaHostAlloc 的 cudaHostAllocMapped 标志，可创建主机与设备共享的零拷贝内存，GPU 直接访问主机内存（需 UVA 支持）。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;GPU 直接访问主机数据&lt;/strong&gt;
* 结合 cudaHostGetDevicePointer 获取设备端指针，实现 GPU 内核直接读写主机内存（避免显式拷贝）。
⠀&lt;/p&gt;
&lt;h3 id="-注意事项与限制"&gt;⚠️ 注意事项与限制
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;资源消耗&lt;/strong&gt;
* 页锁定内存占用物理内存且不可交换，过量分配可能导致系统内存碎片或耗尽。
* &lt;strong&gt;建议&lt;/strong&gt; ：仅对高频传输数据使用，释放需调用 cudaFreeHost（非 free）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;错误处理&lt;/strong&gt; cudaError_t err = cudaMallocHost(&amp;amp;h_ptr, size);
3 if (err != cudaSuccess) {
4 printf(&amp;ldquo;Error: %s\n&amp;rdquo;, cudaGetErrorString(err));
5 }
&lt;strong&gt;6&lt;/strong&gt; &lt;strong&gt;与可分页内存对比&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;7&lt;/strong&gt; &lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;8&lt;/strong&gt; &lt;strong&gt;可分页内存&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;9&lt;/strong&gt; &lt;strong&gt;页锁定内存&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;10&lt;/strong&gt; &lt;strong&gt;分配函数&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;11 malloc / new&lt;/td&gt;
&lt;td style="text-align: center"&gt;12 cudaMallocHost&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;13&lt;/strong&gt; &lt;strong&gt;传输路径&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;14 主机→临时缓冲区→设备&lt;/td&gt;
&lt;td style="text-align: center"&gt;15 主机→设备（直接）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;16&lt;/strong&gt; &lt;strong&gt;带宽效率&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;17 低（多一次拷贝）&lt;/td&gt;
&lt;td style="text-align: center"&gt;18 高（节省 30%~50% 时间）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;19&lt;/strong&gt; &lt;strong&gt;适用场景&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;20 低频小数据&lt;/td&gt;
&lt;td style="text-align: center"&gt;21 高频大数据传输&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;22&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;⠀&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-代码示例-1"&gt;💻 代码示例
&lt;/h3&gt;&lt;p&gt;#include &amp;lt;cuda_runtime.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;&lt;/p&gt;
&lt;p&gt;int main() {
const size_t N = 1024 * 1024;
float &lt;em&gt;h_pinned, &lt;em&gt;d_data;
// 分配页锁定内存
cudaMallocHost((void&lt;/em&gt;&lt;/em&gt;)&amp;amp;h_pinned, N * sizeof(float));
// 分配设备内存
cudaMalloc(&amp;amp;d_data, N * sizeof(float));
// 初始化主机数据
for (int i = 0; i &amp;lt; N; i++) h_pinned[i] = i;
// 主机→设备传输
cudaMemcpy(d_data, h_pinned, N * sizeof(float), cudaMemcpyHostToDevice);
// 释放资源
cudaFree(d_data);
cudaFreeHost(h_pinned);
return 0;
}&lt;/p&gt;
&lt;h3 id="-总结-5"&gt;✅ 总结
&lt;/h3&gt;&lt;p&gt;cudaMallocHost 的核心价值在于：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;高性能传输&lt;/strong&gt; ：通过物理地址固定，实现主机-设备间&lt;strong&gt;直接数据传输&lt;/strong&gt;，避免中间拷贝。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;异步支持&lt;/strong&gt; ：与 cudaStream 结合， &lt;strong&gt;重叠计算与数据传输&lt;/strong&gt;，最大化 GPU 利用率。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;适用性广&lt;/strong&gt; ：适用于需高频交互的场景（如深度学习训练、实时图像处理），但需注意内存分配平衡。
⠀⚠️ 注：CUDA 6.0 后推出的&lt;strong&gt;统一内存（Unified Memory）&lt;/strong&gt; 可进一步简化编程（自动迁移数据），但 cudaMallocHost 在精细控制场景仍不可替代。&lt;/p&gt;
&lt;h2 id="gpu-共享"&gt;GPU 共享
&lt;/h2&gt;&lt;p&gt;不同程序在GPU上的并行执行能力取决于GPU硬件架构、操作系统调度策略及具体实现技术。以下是关键机制分析：&lt;/p&gt;
&lt;h3 id="-硬件架构与调度机制"&gt;⚙️ 硬件架构与调度机制
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;GPU核心设计&lt;/strong&gt; GPU拥有数千个小型计算核心（如NVIDIA的CUDA核心），理论上支持大规模并行计算。但这些核心由统一调度器管理， &lt;strong&gt;单个程序可独占所有核心并行处理数据&lt;/strong&gt; （如矩阵运算）。&lt;strong&gt;不同程序之间&lt;/strong&gt;无法直接共享核心，需通过系统级调度分配资源。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;时间片轮转（Time-Slicing）&lt;/strong&gt; 默认情况下，GPU通过&lt;strong&gt;时分复用&lt;/strong&gt;实现多程序“并发”：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个程序分配固定时间片（如毫秒级），轮流使用GPU计算资源。&lt;/li&gt;
&lt;li&gt;上下文切换涉及状态保存/恢复，可能产生10%~20%性能开销。&lt;em&gt;示例&lt;/em&gt;：程序A运行2ms后暂停，程序B运行2ms，循环交替。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;空间分区（MPS/MIG）&lt;/strong&gt; 高端GPU支持物理资源分割：&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多进程服务（MPS）&lt;/strong&gt; ：允许多进程共享GPU，但仍依赖时间片调度，适合轻量级任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多实例GPU（MIG）&lt;/strong&gt; ：将GPU硬件分割为独立实例（如NVIDIA A100可拆7个实例）， &lt;strong&gt;每个实例可独立运行不同程序，实现真正并行&lt;/strong&gt;，但资源分配固定。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-实现并行的技术方案"&gt;⠀🔧 实现并行的技术方案
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;技术&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;原理&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;限制&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Time-Slicing&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;操作系统自动分配时间片&lt;/td&gt;
&lt;td style="text-align: center"&gt;通用程序，无特殊配置需求&lt;/td&gt;
&lt;td style="text-align: center"&gt;上下文切换延迟，性能波动&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;MPS&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;进程级共享SM资源&lt;/td&gt;
&lt;td style="text-align: center"&gt;轻量级多任务（如推理服务）&lt;/td&gt;
&lt;td style="text-align: center"&gt;兼容性问题，资源竞争&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;MIG&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;物理分割GPU为独立实例&lt;/td&gt;
&lt;td style="text-align: center"&gt;关键任务需强隔离（如云服务）&lt;/td&gt;
&lt;td style="text-align: center"&gt;仅支持特定架构（Ampere+）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-关键性能影响因素"&gt;⚠️ 关键性能影响因素
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;资源争用&lt;/strong&gt;
* &lt;strong&gt;显存瓶颈&lt;/strong&gt; ：多程序共享显存带宽，频繁数据交换可能降低效率。
* &lt;strong&gt;计算冲突&lt;/strong&gt; ：高优先级任务可能抢占资源（如实时推理中断训练任务）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;通信开销&lt;/strong&gt; 跨GPU或CPU-GPU数据传输（如PCIe总线）可能成为瓶颈，尤其多程序频繁交换数据时。&lt;/p&gt;
&lt;h3 id="-最佳实践建议"&gt;💡 最佳实践建议
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;独立GPU实例&lt;/strong&gt; ：对延迟敏感型程序（如自动驾驶感知），优先使用MIG物理隔离。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容器化部署&lt;/strong&gt; ：通过Kubernetes设备插件管理GPU资源，自动调度Time-Slicing。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;混合并行策略&lt;/strong&gt; ：结合数据并行（单程序多GPU）与模型并行（大模型拆分），最大化利用率。
⠀📌 &lt;strong&gt;总结&lt;/strong&gt; ：不同程序可通过时间片轮转实现&lt;strong&gt;逻辑并行&lt;/strong&gt;，但受限于调度开销；物理并行需依赖MIG等高级技术。优化方向需平衡资源隔离需求与系统利用率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="多设备kernel"&gt;多设备Kernel
&lt;/h2&gt;&lt;p&gt;从CUDA编程模型的角度来看， &lt;strong&gt;一个CUDA Kernel的单个启动调用（通过&lt;/strong&gt;&amp;laquo;&amp;lt;&amp;raquo;&amp;gt;&lt;strong&gt;语法启动的那个实例）本身不能同时在多个物理设备上执行。&lt;/strong&gt; CUDA的设计核心思想是单个Kernel启动针对单个Device进行优化调度。
以下是关键要点和原因：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;设备选择 (&lt;strong&gt;cudaSetDevice&lt;/strong&gt;)&lt;/strong&gt; :
在执行Kernel之前，你必须在你的主机代码中明确调用cudaSetDevice(device_id)来选择希望在其上启动Kernel的GPU设备。例如：cudaSetDevice(0); // 选择第一个GPU&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 选择第一个GPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(...);&lt;/span&gt; &lt;span class="c1"&gt;// 在 GPU 0 上启动 kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 选择第二个GPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(...);&lt;/span&gt; &lt;span class="c1"&gt;// 在 GPU 1 上启动（同一个kernel的另一个实例）
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一个特定的&amp;laquo;&amp;lt;&amp;raquo;&amp;gt;语法启动的Kernel只会在当前设置的设备上运行。该Kernel内部的线程块只会在这个特定设备的SM上调度执行。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;Kernel启动的语境&lt;/strong&gt;:
当你写kernel&amp;laquo;&amp;lt;grid_size, block_size, shared_mem_size, stream&amp;raquo;&amp;gt;(arguments);时，grid_size、block_size、shared_mem_size、stream以及传递给Kernel的参数，所有这些信息都是针对&lt;strong&gt;当前&lt;/strong&gt;cudaSetDevice&lt;strong&gt;设置的特定设备上下文&lt;/strong&gt;的。它定义了这个Kernel实例将在哪个设备的资源上运行。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;内存隔离&lt;/strong&gt;:
每个设备（GPU）拥有自己独立的全局内存、常量内存、纹理内存和本地内存（L1/SMEM等）。
启动一个Kernel需要将其指向的内存参数（如设备指针）存在于同一个设备的显存中。一个Kernel无法直接访问另一台设备上的内存（除非通过显式通信如PCIe P2P或NVLink）。
让一个Kernel“同时”运行在设备A和设备B上，意味着它需要访问并操作两个设备上的资源，而CUDA的基础编程模型并没有为单个Kernel实例提供这种跨设备的透明内存访问机制。
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;调度单元&lt;/strong&gt;:
在CUDA的执行模型中，调度单元是线程块。硬件调度器根据设备资源（如SM数量、资源可用性）在设备的SM上调度这些线程块。调度器无法将同一个Kernel启动中的一个线程块分配到另一个物理设备上去执行。
&lt;strong&gt;那么，如何利用多个设备运行同一个Kernel呢？&lt;/strong&gt;
答案是： &lt;strong&gt;多次启动同一个Kernel函数，并在每次启动前设置目标设备。&lt;/strong&gt; 这是最直接和最常用的方法。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 假设有 num_devices 个可用的 GPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_devices&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 设置目标设备
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 为这个设备分配输入/输出内存（通常在初始化时完成）
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// ... (e.g., cudaMalloc, cudaMemcpyAsync for this device)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 启动Kernel在这个设备上执行。注意grid/block配置、stream等可以按需设置，甚至不同设备可以不同。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;myKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;gridDim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharedMemSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev_input_ptr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;dev_output_ptr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;...);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 可以在这个设备的流上进行异步操作
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 在所有设备上异步启动后，主机线程可以等待它们完成
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_devices&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaDeviceSynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 或等待该设备上的特定流
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;关键点：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多个实例：&lt;/strong&gt; 这样做会在每个设备上启动一个&lt;strong&gt;独立&lt;/strong&gt;的Kernel实例（执行），每个实例运行在自己设备的资源和内存上。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并行执行：&lt;/strong&gt; 只要硬件支持（多个PCIe根节点/NVSwitch等）并且主机线程管理得当（通常使用异步API和多个CUDA Stream），这些在不同设备上启动的Kernel实例可以&lt;strong&gt;并行运行&lt;/strong&gt;。这是多GPU/分布式CUDA编程的核心模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据分发/归约：&lt;/strong&gt; 你需要手动将整体任务数据分割到各个设备上（例如通过device_id索引部分数据），并在所有设备上的Kernel运行完毕后，将结果收集（归约）起来。这通常需要使用cudaMemcpy（或更好的，cudaMemcpyPeerAsync用于P2P）和主机端的同步操作。
⠀&lt;strong&gt;现代高级抽象框架（简化多设备管理）：&lt;/strong&gt;
框架如NCCL（用于通信）、多进程库（如torch.distributed, Horovod）以及更高层次的异构编程模型（如SYCL, DPC++）封装了底层的多设备逻辑：&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨设备通信：&lt;/strong&gt; 它们提供高效（如基于NVLink/GPUDirect RDMA）的点对点通信、广播、规约、All-Gather等集合操作原语，大大简化了多设备间的数据交换。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;任务分发：&lt;/strong&gt; 它们能自动或更方便地在多个设备（节点）上创建Kernel任务实例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;单程序多数据 (SPMD)：&lt;/strong&gt; 在深度学习等场景中，模型并行（将模型层分散到设备）、数据并行（将数据批次分散到设备）通常都遵循SPMD模式：每个设备上的进程/线程运行相同的程序代码（相同的Kernel），但处理输入数据的不同部分。
&lt;ul&gt;
&lt;li&gt;在CUDA层面，每个设备上的进程/线程&lt;strong&gt;各自调用&lt;/strong&gt;cudaSetDevice&lt;strong&gt;然后启动所需的Kernel&lt;/strong&gt;。对于框架的使用者来说，框架的API调用看起来像是“一次调用运行在所有设备上”，但在底层框架实现中，它仍然是按照cudaSetDevice + 多次Kernel启动的模式在工作，只不过框架自动完成了设备管理、流管理和通信工作。
⠀&lt;strong&gt;总结:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一个CUDA Kernel的&lt;strong&gt;单个启动调用&lt;/strong&gt; (&amp;laquo;&amp;lt;&amp;raquo;&amp;gt;) 只能在一个指定的CUDA Device上执行。&lt;/li&gt;
&lt;li&gt;为了让同一个Kernel函数运行在多个设备上，你需要在你的主机程序中：
1 多次调用该Kernel函数。
2 在每次调用前，使用cudaSetDevice(device_id)将目标设备设置为期望的GPU。
3 确保每个设备上的Kernel操作的数据都在该设备的内存中。
4 管理好多个设备之间的通信（分发输入、收集输出、同步结果），这通常需要额外的通信库(如NCCL)或者手动实现的同步/通信代码。&lt;/li&gt;
&lt;li&gt;高级框架（如NCCL配合的多进程库、深度学习框架的分布式模块）封装了这些细节，使得在多个设备/节点上运行同一个模型/算法更加方便，但其底层实现仍然依赖于每个设备上的多次独立Kernel启动和设备间的显式通信。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="nvlink"&gt;NVLink
&lt;/h2&gt;&lt;p&gt;NVLink是由NVIDIA开发的高速互连技术，旨在解决多GPU系统及GPU与CPU间通信的带宽和延迟瓶颈，尤其适用于高性能计算（HPC）和人工智能（AI）领域。以下是其核心特性和技术解析：&lt;/p&gt;
&lt;h3 id="-技术定义与核心目标"&gt;⚙️ 技术定义与核心目标
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;基本架构&lt;/strong&gt; NVLink采用&lt;strong&gt;点对点直连结构&lt;/strong&gt; （Peer-to-Peer），支持GPU-GPU、GPU-CPU间直接通信。与传统的树状PCIe拓扑不同，NVLink通过网状互联（如NVSwitch）实现多设备高效协同，避免CPU中转造成的延迟。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;设计目标&lt;/strong&gt; 替代PCIe在多GPU场景的局限性，提供更高带宽、更低延迟的通信通道，满足大规模并行计算需求（如大模型训练、科学模拟）。
⠀&lt;/p&gt;
&lt;h3 id="-关键性能优势对比pcie"&gt;⚡️ 关键性能优势（对比PCIe）
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;维度&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;NVLink 4.0&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCIe 5.0 x16&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;提升倍数&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;带宽&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;900 GB/s（双向）&lt;/td&gt;
&lt;td style="text-align: center"&gt;128 GB/s（双向）&lt;/td&gt;
&lt;td style="text-align: center"&gt;7倍&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;延迟&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;1.5微秒&lt;/td&gt;
&lt;td style="text-align: center"&gt;5-10微秒&lt;/td&gt;
&lt;td style="text-align: center"&gt;降低5-10倍&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;能效&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;1.3皮焦/字节&lt;/td&gt;
&lt;td style="text-align: center"&gt;6.5皮焦/字节&lt;/td&gt;
&lt;td style="text-align: center"&gt;5倍&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;扩展性&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;支持8+ GPU全互联&lt;/td&gt;
&lt;td style="text-align: center"&gt;多设备共享带宽&lt;/td&gt;
&lt;td style="text-align: center"&gt;更优拓扑&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;💡 &lt;strong&gt;示例&lt;/strong&gt; ：在训练175B参数的GPT-3模型时，NVLink使8xA100的扩展效率达92%，而PCIe仅60%。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-技术演进与核心特性"&gt;🔧 技术演进与核心特性
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;代际升级&lt;/strong&gt;
* &lt;strong&gt;NVLink 1.0&lt;/strong&gt; （2016）：Pascal架构，单链路20GB/s，总带宽160GB/s（Tesla P100）。
* &lt;strong&gt;NVLink 4.0&lt;/strong&gt; （2022）：Hopper架构，单链路100GB/s，总带宽900GB/s（H100），支持1.8TB/s聚合带宽。
* &lt;strong&gt;NVLink 5.0&lt;/strong&gt; （2024）：带宽达1.8TB/s，较前代翻倍。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;创新技术&lt;/strong&gt;
* &lt;strong&gt;NVSwitch芯片&lt;/strong&gt; ：实现多GPU全互联拓扑（如DGX系统中的8卡直连），消除通信阻塞。
* &lt;strong&gt;缓存一致性&lt;/strong&gt; （NVLink 2.0+）：支持CPU与GPU内存统一寻址，原子操作和直接加载/存储。
* &lt;strong&gt;NVLink-C2C&lt;/strong&gt; ：芯片级互连（如Grace Hopper超级芯片），能效比PCIe Gen5高25倍。
⠀&lt;/p&gt;
&lt;h3 id="-应用场景与性能影响"&gt;🖥️ 应用场景与性能影响
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AI训练&lt;/strong&gt; ：ResNet-50多卡效率提升至1.8倍（PCIe为1.5倍）；BERT-Large训练加速30%。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;科学计算&lt;/strong&gt; ：CFD仿真中通信时间占比从30%降至5%；分子动力学软件AMBER性能翻倍。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;超算系统&lt;/strong&gt; ：Summit/Sierra超算通过NVLink连接IBM POWER9 CPU与Volta GPU，实现百亿亿次计算。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-硬件支持与限制"&gt;⚠️ 硬件支持与限制
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;支持设备&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;专业卡：Tesla P100/V100/A100/H100（带宽80GB/s→900GB/s）。&lt;/li&gt;
&lt;li&gt;消费级：RTX 3090支持NVLink 3.0（但被软件限制），RTX 4090不支持。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;部署要求&lt;/strong&gt; ：需专用主板、NVLink桥接器及SXM接口，成本高于PCIe方案。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-总结-6"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;NVLink通过&lt;strong&gt;超高带宽、超低延迟、点对点直连&lt;/strong&gt;重塑了多GPU系统的通信范式，成为AI超算（如DGX系统）的核心基石。尽管其生态目前局限于NVIDIA硬件，但在大模型训练和HPC场景中，性能优势远超PCIe，是追求极致算效用户的必选技术。未来，随着C2C封装和光子通信技术的发展，NVLink或将进一步突破物理限制。&lt;/p&gt;
&lt;h2 id="nvlink-结构"&gt;NVLink 结构
&lt;/h2&gt;&lt;p&gt;NVLink 是一种&lt;strong&gt;融合硬件实体与软件协议的综合技术体系&lt;/strong&gt;，既包含物理结构（硬件），也依赖软件协议实现功能调度。以下是具体解析：&lt;/p&gt;
&lt;h3 id="-物理结构硬件层面"&gt;⚙️ 物理结构（硬件层面）
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;专用硬件接口与链路&lt;/strong&gt;
* NVLink 的物理层（Physical Layer）由多组差分信号对（如8对差分对构成32条物理线路）组成，采用直流耦合技术，支持高速串行传输。
* 例如，在 Tesla P100（NVLink 1.0）中，每个 GPU 集成4条物理链路，每条链路提供双向40 GB/s带宽。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;桥接器与交换芯片&lt;/strong&gt;
* &lt;strong&gt;NVLink 桥接器&lt;/strong&gt; ：用于连接 GPU 与 CPU 或其他设备，如 IBM POWER9 处理器通过桥接器与 GPU 直连。
* &lt;strong&gt;NVSwitch&lt;/strong&gt; ：多端口交换芯片（如 DGX 系统中的 NVSwitch），支持全连接拓扑。例如 H100 GPU 通过18条 NVLink 4.0 链路连接 NVSwitch，总带宽达 900 GB/s。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;封装级集成（NVLink-C2C）&lt;/strong&gt;
* 在 Grace Hopper 超级芯片中，NVLink-C2C 通过先进封装（如硅中介层）将 CPU 和 GPU 裸片直接互连，带宽达 900 GB/s，能效比 PCIe 高 25 倍。
⠀&lt;/p&gt;
&lt;h3 id="-软件协议功能实现层"&gt;💻 软件协议（功能实现层）
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;通信协议栈&lt;/strong&gt;
* NVLink 协议栈分为三层：
* &lt;strong&gt;物理层（PL）&lt;/strong&gt; ：管理信号传输与电气特性；
* &lt;strong&gt;数据链路层（DL）&lt;/strong&gt; ：负责错误检测（25位 CRC 校验）、流量控制与数据包重传；
* &lt;strong&gt;传输层（TL）&lt;/strong&gt; ：处理数据分组、路由与缓存一致性（如原子操作支持）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;软件驱动与 API&lt;/strong&gt;
* CUDA 提供 cudaMemcpyPeer 等 API，支持 GPU 间直接内存拷贝；
* NCCL（NVIDIA Collective Communications Library）优化多 GPU 通信（如 All-Reduce 操作），显著提升分布式训练效率。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;缓存一致性协议&lt;/strong&gt;
* NVLink 2.0+ 通过硬件级缓存一致性协议，实现 CPU 与 GPU 共享统一内存空间，减少数据复制开销。例如 IBM Power9 可直接访问 GPU 显存。
⠀&lt;/p&gt;
&lt;h3 id="-协同机制硬件与软件的深度耦合"&gt;🔄 协同机制：硬件与软件的深度耦合
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;动态资源分配&lt;/strong&gt; ：软件协议根据负载调整链路使用（如捆绑多条链路提升带宽）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;错误恢复&lt;/strong&gt; ：硬件检测传输错误（如 CRC 校验），软件层触发数据重传。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;拓扑管理&lt;/strong&gt; ：NVSwitch 由软件配置路由策略，实现 GPU 间全连接通信。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-与传统-pcie-的对比"&gt;🆚 与传统 PCIe 的对比
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;NVLink&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCIe&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;物理结构&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;专用差分对、直连链路&lt;/td&gt;
&lt;td style="text-align: center"&gt;通用串行总线&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;带宽&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;1.8 TB/s (NVLink 5.0)&lt;/td&gt;
&lt;td style="text-align: center"&gt;126 GB/s (PCIe 5.0 x16)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;延迟&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;微秒级（1.5 μs）&lt;/td&gt;
&lt;td style="text-align: center"&gt;5-10 μs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;软件依赖&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;定制协议栈 + CUDA/NCCL&lt;/td&gt;
&lt;td style="text-align: center"&gt;操作系统级驱动&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-总结-7"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;NVLink 是 &lt;strong&gt;硬件实体（物理链路、交换芯片）与软件协议（通信栈、API）的深度融合&lt;/strong&gt; ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;物理结构&lt;/strong&gt; 提供高带宽、低延迟的传输通道；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;软件协议&lt;/strong&gt; 实现功能调度、错误控制与系统优化。这种协同设计使其在 AI 训练（如千卡集群）、科学计算等场景中远超 PCIe，成为高性能计算的基石。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="pcie"&gt;PCIe
&lt;/h2&gt;&lt;p&gt;PCIe（Peripheral Component Interconnect Express）是一种&lt;strong&gt;高速串行计算机扩展总线标准&lt;/strong&gt;，由英特尔于2001年提出，旨在取代传统的PCI、PCI-X和AGP总线，现已成为计算机硬件中主流的互连技术。以下从核心特性、技术演进、架构设计及应用场景等方面全面解析：&lt;/p&gt;
&lt;h3 id="-核心特性与设计原理"&gt;⚙️ 核心特性与设计原理
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;点对点串行架构&lt;/strong&gt;
* PCIe采用&lt;strong&gt;点对点直连&lt;/strong&gt; （非共享总线），每个设备独享带宽，避免传统PCI总线的资源争用问题。
* &lt;strong&gt;双单工通信&lt;/strong&gt; ：支持双向同步数据传输（类似全双工），显著提升吞吐效率。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;通道配置（Lane Scaling）&lt;/strong&gt;
* 通道数灵活配置：支持x1、x4、x8、x16等模式，其中：
* &lt;strong&gt;x1&lt;/strong&gt; ：带宽250 MB/s（PCIe 1.0），用于声卡、网卡等低带宽设备。
* &lt;strong&gt;x16&lt;/strong&gt; ：主流显卡接口，提供单向4 GB/s（PCIe 3.0）至16 GB/s（PCIe 5.0）带宽。
* 物理兼容性：短插槽设备可插入长插槽（如x1卡插入x16槽）。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;分层协议栈&lt;/strong&gt;
* &lt;strong&gt;事务层&lt;/strong&gt; ：处理数据包（TLP）的封装与路由，支持读写、配置、中断等操作。
* &lt;strong&gt;数据链路层&lt;/strong&gt; ：通过CRC校验、序列号重传（ACK/NAK机制）确保传输可靠性。
* &lt;strong&gt;物理层&lt;/strong&gt; ：采用差分信号（LVDS）和内嵌时钟技术，支持8b/10b（PCIe 2.0）或128b/130b编码（PCIe 3.0+），减少信号干扰。
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;高级功能支持&lt;/strong&gt;
* 热插拔、电源管理、服务质量（QoS）、错误报告（AER）及I/O虚拟化。
⠀&lt;/p&gt;
&lt;h3 id="-技术演进与性能升级"&gt;📈 技术演进与性能升级
&lt;/h3&gt;&lt;p&gt;PCIe版本迭代持续提升传输速率与效率：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;版本&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;传输速率&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;编码效率&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;单向带宽（x16）&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;发布时间&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 1.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;2.5 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;8b/10b (80%)&lt;/td&gt;
&lt;td style="text-align: center"&gt;4 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2003年&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 2.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;5 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;8b/10b (80%)&lt;/td&gt;
&lt;td style="text-align: center"&gt;8 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2007年&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 3.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;8 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;128b/130b (98.5%)&lt;/td&gt;
&lt;td style="text-align: center"&gt;16 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2010年&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 4.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;16 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;128b/130b&lt;/td&gt;
&lt;td style="text-align: center"&gt;32 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2017年&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 5.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;32 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;128b/130b&lt;/td&gt;
&lt;td style="text-align: center"&gt;64 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2019年&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 6.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;64 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;PAM4调制&lt;/td&gt;
&lt;td style="text-align: center"&gt;128 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2022年&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 7.0（开发中）&lt;/td&gt;
&lt;td style="text-align: center"&gt;128 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;PAM4调制&lt;/td&gt;
&lt;td style="text-align: center"&gt;256 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2025年（预计）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;💡 &lt;strong&gt;关键升级&lt;/strong&gt; ：&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PCIe 3.0&lt;/strong&gt; ：引入128b/130b编码，带宽利用率提升至98.5%。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PCIe 6.0+&lt;/strong&gt; ：采用PAM4（四电平脉冲调制）技术，单通道速率翻倍。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-系统架构与关键组件"&gt;🧩 系统架构与关键组件
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;硬件拓扑结构&lt;/strong&gt;
* &lt;strong&gt;Root Complex（根复合体）&lt;/strong&gt; ：集成于CPU或芯片组，负责发起事务和连接内存/处理器。
* &lt;strong&gt;Switch（交换机）&lt;/strong&gt; ：扩展多设备连接，支持复杂拓扑（如服务器多GPU互连）。
* &lt;strong&gt;Endpoint（端点设备）&lt;/strong&gt; ：终端设备（如显卡、SSD），直接处理数据。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;配置空间与地址映射&lt;/strong&gt;
* 每个设备拥有&lt;strong&gt;256B配置空间&lt;/strong&gt; （含Vendor ID、Class Code等），支持即插即用和资源分配。
* 通过&lt;strong&gt;BAR（基址寄存器）&lt;/strong&gt; 映射设备内存到系统地址空间，实现主机直接访问。
⠀&lt;/p&gt;
&lt;h3 id="-应用场景与性能影响-1"&gt;🖥️ 应用场景与性能影响
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;图形处理&lt;/strong&gt;
* &lt;strong&gt;x16接口&lt;/strong&gt;成为显卡标配，PCIe 5.0 x16带宽达128 GB/s，满足8K游戏与AI渲染需求。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;高速存储&lt;/strong&gt;
* NVMe SSD通过PCIe 4.0 x4实现7 GB/s读写速度（如三星990 Pro），比SATA SSD快12倍。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;网络与加速卡&lt;/strong&gt;
* 100G网卡（如Mellanox ConnectX-6）依赖PCIe 4.0 x16，降低数据中心延迟。
* AI训练卡（如NVIDIA A100）利用PCIe 5.0提升CPU-GPU数据交换效率。
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;扩展性与兼容性&lt;/strong&gt;
* 支持外部GPU（eGPU）、Thunderbolt 4扩展坞等场景。
* 向下兼容：PCIe 5.0设备可在PCIe 3.0插槽降速运行。
⠀&lt;/p&gt;
&lt;h3 id="-对比传统总线技术"&gt;⚖️ 对比传统总线技术
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCIe&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCI&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;AGP&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;架构&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;点对点串行&lt;/td&gt;
&lt;td style="text-align: center"&gt;共享并行总线&lt;/td&gt;
&lt;td style="text-align: center"&gt;专用图形并行接口&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;带宽（峰值）&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;256 GB/s（PCIe 7.0 x16）&lt;/td&gt;
&lt;td style="text-align: center"&gt;533 MB/s（64位/66MHz）&lt;/td&gt;
&lt;td style="text-align: center"&gt;2.1 GB/s（AGP 8X）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;扩展性&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;高（多通道灵活配置）&lt;/td&gt;
&lt;td style="text-align: center"&gt;低（总线争用）&lt;/td&gt;
&lt;td style="text-align: center"&gt;仅支持单显卡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;主流应用&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;GPU/SSD/网卡&lt;/td&gt;
&lt;td style="text-align: center"&gt;声卡/低速网卡&lt;/td&gt;
&lt;td style="text-align: center"&gt;旧式显卡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;🔍 PCIe取代AGP的关键原因：带宽不足（AGP 8X仅2.1GB/s）且无法支持多设备并行。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-总结-8"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;PCIe通过&lt;strong&gt;点对点串行架构&lt;/strong&gt;、&lt;strong&gt;分层协议栈&lt;/strong&gt;和&lt;strong&gt;持续带宽升级&lt;/strong&gt;，解决了传统总线的带宽瓶颈与扩展限制。其技术优势体现在：✅ &lt;strong&gt;超高带宽&lt;/strong&gt; ：PCIe 7.0将达256 GB/s（x16），满足AI/超算需求；✅ &lt;strong&gt;低延迟高可靠&lt;/strong&gt; ：数据链路层重传机制保障传输完整性；✅ &lt;strong&gt;生态兼容&lt;/strong&gt; ：软硬件向下兼容，支持热插拔与虚拟化。
随着PCIe 7.0规范于2025年落地，其128 GT/s速率将进一步推动数据中心、AI及6G通信技术的革新。&lt;/p&gt;
&lt;h2 id="__threadfence"&gt;__threadFence
&lt;/h2&gt;&lt;p&gt;__threadfence() 是 CUDA 编程中的一种&lt;strong&gt;内存栅栏（Memory Fence）函数&lt;/strong&gt;，用于确保线程对内存的写入操作在执行顺序和可见性上满足特定约束。它与线程同步函数（如 __syncthreads()）有本质区别： &lt;strong&gt;__threadfence()不阻塞线程执行，而是强制完成当前线程的写操作并使其对其他线程可见&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id="-核心功能内存可见性保障"&gt;⚙️ 核心功能：内存可见性保障
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;作用范围&lt;/strong&gt;
* __threadfence()：确保调用线程在 &lt;strong&gt;全局内存（Global Memory）&lt;/strong&gt; 和 &lt;strong&gt;共享内存（Shared Memory）&lt;/strong&gt; 的写操作，对 &lt;strong&gt;整个 Grid 的所有线程可见&lt;/strong&gt; 。
* __threadfence_block()：仅保证写操作对 &lt;strong&gt;同一 Block 内的线程可见&lt;/strong&gt; 。
* __threadfence_system()（较少用）：扩展至 CPU 和其他 GPU 设备。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;非执行屏障&lt;/strong&gt;
* &lt;strong&gt;不要求线程同步到同一位置&lt;/strong&gt;，仅保证调用前线程的写操作完成后，结果才能被其他线程读取 。例如：// 线程 A 写入数据
* data[threadIdx.x] = value;
* __threadfence(); // 确保 data 写入完成且全局可见
* flag = 1; // 设置完成标志其他线程读取 flag 前，必须先看到 data 的更新值 。
⠀&lt;/p&gt;
&lt;h3 id="-与同步函数的区别"&gt;⚖️ 与同步函数的区别
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;函数&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;作用域&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;行为&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;典型用途&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;__syncthreads()&lt;/td&gt;
&lt;td style="text-align: center"&gt;同一 Block 内&lt;/td&gt;
&lt;td style="text-align: center"&gt;阻塞线程直至所有线程到达此处&lt;/td&gt;
&lt;td style="text-align: center"&gt;Block 内线程协作（如规约）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;__threadfence()&lt;/td&gt;
&lt;td style="text-align: center"&gt;整个 Grid&lt;/td&gt;
&lt;td style="text-align: center"&gt;仅保证内存操作可见性，不阻塞&lt;/td&gt;
&lt;td style="text-align: center"&gt;跨 Block 数据传递（如标志位更新）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;__threadfence_block()&lt;/td&gt;
&lt;td style="text-align: center"&gt;同一 Block 内&lt;/td&gt;
&lt;td style="text-align: center"&gt;保证 Block 内内存可见性&lt;/td&gt;
&lt;td style="text-align: center"&gt;替代 __syncthreads() 的特殊分支场景&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;⚠️ &lt;strong&gt;关键区别&lt;/strong&gt; ：&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;__syncthreads() 是 &lt;strong&gt;执行屏障&lt;/strong&gt; （线程等待），而 __threadfence() 是 &lt;strong&gt;内存屏障&lt;/strong&gt; （写操作可见性）。&lt;/li&gt;
&lt;li&gt;跨 Block 同步必须用 __threadfence()，因 __syncthreads() 无法同步不同 Block 。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-典型应用场景-2"&gt;🧩 典型应用场景
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;跨 Block 数据协作&lt;/strong&gt; 多 Block 协作任务（如分阶段求和）中，需确保一个 Block 完成数据写入后，其他 Block 才能读取：&lt;strong&gt;global&lt;/strong&gt; void sum_kernel(float* data, float* result) {
2 // 步骤1：计算局部和并写入全局内存
3 float partial_sum = &amp;hellip;;
4 result[blockIdx.x] = partial_sum;
5 &lt;br&gt;
6 // 确保 result 写入完成且全局可见
7 __threadfence();
8 &lt;br&gt;
9 // 步骤2：原子操作标记完成
10 if (threadIdx.x == 0) {
11 int count = atomicAdd(&amp;amp;counter, 1);
12 is_last_block = (count == gridDim.x - 1);
13 }
14 &lt;br&gt;
15 // 步骤3：最后一个 Block 汇总结果
16 if (is_last_block) {
17 float total = 0;
18 for (int i = 0; i &amp;lt; gridDim.x; i++) total += result[i];
19 *result = total;
20 }
21 }此处 __threadfence() 保证 result 写入先于 atomicAdd 生效，避免其他 Block 读取未完成的数据 。
&lt;strong&gt;22&lt;/strong&gt; &lt;strong&gt;避免写操作乱序&lt;/strong&gt; CUDA 默认允许内存操作乱序执行。以下代码可能出错：data[threadIdx.x] = value; // 写操作1
23 flag = 1; // 写操作2若无栅栏，其他线程可能先看到 flag=1 但 data 未更新。添加 __threadfence() 强制顺序：data[threadIdx.x] = value;
24 __threadfence(); // 确保 data 写入先完成
25 flag = 1;
⠀&lt;/p&gt;
&lt;h3 id="-注意事项-1"&gt;⚠️ 注意事项
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;与原子操作协同&lt;/strong&gt; __threadfence() 常与原子操作（如 atomicAdd）配合，确保“写入完成”的标志位（如 is_last_block）被安全设置 。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;性能开销&lt;/strong&gt; 频繁调用 __threadfence() 会暴露内存延迟，降低并行效率。建议仅在必要时使用 。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;不替代同步函数&lt;/strong&gt; Block 内线程协作仍需 __syncthreads()；__threadfence() 仅解决内存可见性问题 。
⠀&lt;/p&gt;
&lt;h3 id="-总结-9"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;__threadfence() 是 CUDA 中&lt;strong&gt;保障内存操作可见性的关键工具&lt;/strong&gt;，尤其适用于跨 Block 数据传递的场景：✅ &lt;strong&gt;核心作用&lt;/strong&gt; ：强制当前线程的写操作完成后，结果对所有线程可见。✅ &lt;strong&gt;使用场景&lt;/strong&gt; ：跨 Block 协作（如标志位更新、分阶段规约）。✅ &lt;strong&gt;编程实践&lt;/strong&gt; ：与原子操作组合（写数据 → __threadfence() → 原子标记），避免数据竞争 。⚠️ &lt;strong&gt;误区&lt;/strong&gt; ：它不是线程同步原语，不阻塞执行流，需与 __syncthreads() 区分应用场景 。&lt;/p&gt;
&lt;h2 id="tensor-core"&gt;Tensor Core
&lt;/h2&gt;&lt;p&gt;CUDA Core 和 Tensor Core 是 NVIDIA GPU 中两类功能定位截然不同的计算核心，它们在设计目标、架构特点和应用场景上存在显著差异。以下是基于最新技术的综合对比分析：&lt;/p&gt;
&lt;h3 id="-核心定位与设计目标"&gt;⚙️ 核心定位与设计目标
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;CUDA Core&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Tensor Core&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;本质&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;通用并行计算单元&lt;/strong&gt;，处理各类标量和简单矩阵运算&lt;/td&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;专用加速单元&lt;/strong&gt;，专注矩阵乘累加（GEMM）等张量运算&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;设计目标&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;灵活支持图形渲染、科学计算等多样化任务&lt;/td&gt;
&lt;td style="text-align: center"&gt;极致优化深度学习中的矩阵计算，提升AI训练/推理效率&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;架构演进&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;自 Fermi 架构（2010年）成为基础单元，持续增强&lt;/td&gt;
&lt;td style="text-align: center"&gt;Volta 架构（2017年）首次引入，迭代至 Blackwell（2024）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-架构与计算原理"&gt;🔧 架构与计算原理
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;CUDA Core：通用性与灵活性&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;计算单元&lt;/strong&gt; ：每个核心包含独立的浮点(FPU)和整数(ALU)运算单元，支持 FP32/FP64/INT32 等精度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行模式&lt;/strong&gt; ：基于 SIMD（单指令多数据）架构，单周期完成一次乘加运算（如 y = a*x + b）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;任务类型&lt;/strong&gt; ：适合处理分支逻辑、数据预处理等非规则计算。
⠀&lt;strong&gt;Tensor Core：专用性与高效性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算单元&lt;/strong&gt; ：以矩阵块（如 4×4）为单位处理运算，单周期完成 64 次混合精度乘累加。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;混合精度支持&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;输入/权重&lt;/strong&gt; ：FP16、BF16、INT8、FP8（节省内存带宽）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;累加/输出&lt;/strong&gt; ：FP32（保障精度）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件优化&lt;/strong&gt; ：融合乘加（FMA）流水线设计，避免数据反复搬运。
⠀💡 &lt;strong&gt;性能对比示例&lt;/strong&gt; ：NVIDIA A100 GPU 中，Tensor Core 的 TF32 算力（312 TFLOPS）是 CUDA Core FP32 算力（19.5 TFLOPS）的 &lt;strong&gt;16倍&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-性能与应用场景"&gt;🚀 性能与应用场景
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;CUDA Core 主导场景&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图形渲染&lt;/strong&gt; ：游戏光影计算、抗锯齿（如 RTX 4090 含 16384 CUDA Core）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通用计算&lt;/strong&gt; ：科学模拟（流体力学、分子动力学）、视频编解码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI 辅助任务&lt;/strong&gt; ：数据加载、激活函数计算等非矩阵操作。
⠀&lt;strong&gt;Tensor Core 主导场景&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;深度学习训练&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;混合精度训练（FP16+FP32），加速 Transformer/GPT 等大模型&lt;/li&gt;
&lt;li&gt;Blackwell 架构支持 FP4 精度，推理性能提升 30倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推理优化&lt;/strong&gt; ：INT8/FP8 量化降低延迟（如 TensorRT 部署）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HPC 加速&lt;/strong&gt; ：稀疏矩阵计算（气象模拟、量子化学）。
⠀⚡ &lt;strong&gt;协作示例&lt;/strong&gt; ：Stable Diffusion 生成图像时：&lt;/li&gt;
&lt;li&gt;Tensor Core 执行扩散模型推理&lt;/li&gt;
&lt;li&gt;CUDA Core 处理后处理渲染。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-协同工作模式"&gt;🔄 协同工作模式
&lt;/h3&gt;&lt;p&gt;现代 GPU（如 Hopper H100）通过 &lt;strong&gt;SM（流式多处理器）&lt;/strong&gt; 整合两类核心：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务分配&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;CUDA Core 处理控制流和标量运算&lt;/li&gt;
&lt;li&gt;Tensor Core 专注矩阵乘法。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源调度&lt;/strong&gt; ：SM 内的 Warp 调度器动态分配任务至两类核心。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内存协作&lt;/strong&gt; ：共享寄存器文件与缓存，减少数据搬运开销。
⠀&lt;strong&gt;硬件实例&lt;/strong&gt; ：NVIDIA H100 GPU 包含 18432 个 CUDA Core + 576 个 Tensor Core，SM 内比例约 32:1。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-技术演进趋势"&gt;📈 技术演进趋势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tensor Core 持续增强&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;精度扩展&lt;/strong&gt; ：Hopper 支持 FP8，Blackwell 引入 FP4 及微缩放格式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;领域定制&lt;/strong&gt; ：Transformer 引擎优化大语言模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUDA Core 通用性升级&lt;/strong&gt; ：Ampere 架构支持 FP32+INT 并行执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;异构计算融合&lt;/strong&gt; ：CPU-GPU-NPU 分工（如 Grace Hopper 超级芯片）。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-总结核心差异全景"&gt;💎 总结：核心差异全景
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;维度&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;CUDA Core&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Tensor Core&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;核心能力&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;通用标量/矢量计算&lt;/td&gt;
&lt;td style="text-align: center"&gt;专用矩阵加速（GEMM）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;关键优势&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;灵活性高，支持复杂逻辑&lt;/td&gt;
&lt;td style="text-align: center"&gt;吞吐量极高，能效比优化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;精度支持&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;FP32/FP64/INT32&lt;/td&gt;
&lt;td style="text-align: center"&gt;FP16/TF32/INT8/FP8/FP4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;适用负载&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;图形渲染、科学计算&lt;/td&gt;
&lt;td style="text-align: center"&gt;深度学习训练/推理、科学矩阵运算&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;硬件占比&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;数量多（千至万级）&lt;/td&gt;
&lt;td style="text-align: center"&gt;数量少（百级），但算力占比高&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;🤝 &lt;strong&gt;协作价值&lt;/strong&gt; ：CUDA Core 如“瑞士军刀”应对多样化任务，Tensor Core 如“激光切割机”专攻深度学习——二者协同构成 NVIDIA GPU 在 AI 与 HPC 领域的统治力基石。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="wmma"&gt;WMMA
&lt;/h2&gt;&lt;p&gt;WMMA（Warp-level Matrix Multiply-Accumulate）是 NVIDIA 为 &lt;strong&gt;Tensor Core&lt;/strong&gt; 设计的专用编程接口，两者是软件抽象与硬件实体的关系。WMMA 通过 Warp 级协作模型，让开发者能够高效调用 Tensor Core 的矩阵加速能力。以下是两者的核心关联及协作机制：&lt;/p&gt;
&lt;h3 id="-核心关系软件抽象层与硬件加速器的绑定"&gt;⚙️ 核心关系：软件抽象层与硬件加速器的绑定
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;Tensor Core 的硬件本质&lt;/strong&gt;
* &lt;strong&gt;专用计算单元&lt;/strong&gt; ：Tensor Core 是 GPU SM（流式多处理器）内的专用硬件，专注于矩阵乘累加（GEMM）操作，如 D = A × B + C。
* &lt;strong&gt;高性能特性&lt;/strong&gt; ：单周期完成子矩阵运算（如 Volta 架构的 4×4×4 矩阵），吞吐量远超 CUDA Core（如 A100 的 Tensor Core FP16 算力是 FP32 CUDA Core 的 16 倍）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;WMMA 的软件角色&lt;/strong&gt;
* &lt;strong&gt;编程接口&lt;/strong&gt; ：WMMA 是 CUDA 提供的 C++ API 及 PTX 指令集，封装了 Tensor Core 的调用逻辑。
* &lt;strong&gt;Warp 级协作&lt;/strong&gt; ：以 Warp（32 线程）为调度单元，协同加载数据、执行计算、存储结果。
⠀✅ &lt;strong&gt;关系本质&lt;/strong&gt; ：WMMA 是开发者访问 Tensor Core 能力的&lt;strong&gt;唯一官方途径&lt;/strong&gt;，Tensor Core 是 WMMA 的&lt;strong&gt;硬件执行引擎&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id="-wmma-如何驱动-tensor-core"&gt;🔧 WMMA 如何驱动 Tensor Core
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;工作流程四步曲
1&lt;/strong&gt; &lt;strong&gt;数据分块与加载&lt;/strong&gt;
* 使用 load_matrix_sync 将全局内存或共享内存中的矩阵子块（Tile）加载到 &lt;strong&gt;Fragment（片段）&lt;/strong&gt; 中。
* Fragment 是存储在寄存器中的数据结构，每个线程持有子块的一部分（如 16×16 矩阵分给 32 线程，每线程存 8 个元素）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;矩阵乘累加计算&lt;/strong&gt;
* 调用 mma_sync 触发 Tensor Core 硬件执行：
* 输入两个 Fragment（A、B）和累加器 Fragment（C）；
* 输出结果 Fragment（D = A × B + C）。
* &lt;strong&gt;硬件优化&lt;/strong&gt; ：Tensor Core 以流水线方式并行处理多个子矩阵，避免寄存器瓶颈。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;结果存储&lt;/strong&gt;
* 通过 store_matrix_sync 将 Fragment 数据写回全局内存，完成计算闭环。
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;隐式同步机制&lt;/strong&gt;
* WMMA 函数（如 mma_sync）隐含 Warp 内线程同步，确保数据就绪性。
⠀&lt;strong&gt;关键设计特点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;混合精度支持&lt;/strong&gt; ：WMMA 支持 FP16→FP32、BF16→FP32、TF32→FP32 等混合精度模式，由 Tensor Core 硬件实现无损精度累积。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;固定计算尺寸&lt;/strong&gt; ：早期仅支持 16×16×16 子矩阵（M×N×K），后续架构扩展至更大尺寸。
⠀&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-tensor-core-的架构演进与-wmma-的适配"&gt;⚡️ Tensor Core 的架构演进与 WMMA 的适配
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;架构&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Tensor Core 升级&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;WMMA 支持增强&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Volta&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;第一代，支持 FP16→FP32&lt;/td&gt;
&lt;td style="text-align: center"&gt;CUDA 9.0 引入基础 API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Turing&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;扩展至 INT8/INT4 推理&lt;/td&gt;
&lt;td style="text-align: center"&gt;支持整数精度加载/存储&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Ampere&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;新增 TF32（19位浮点）&lt;/td&gt;
&lt;td style="text-align: center"&gt;新增 tf32 片段类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Hopper&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;支持 FP8 精度&lt;/td&gt;
&lt;td style="text-align: center"&gt;扩展 FP8 矩阵操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Blackwell&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;支持 FP4/FP6 及微缩放格式&lt;/td&gt;
&lt;td style="text-align: center"&gt;未来预计扩展超低精度 API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;💡 &lt;strong&gt;精度与性能权衡&lt;/strong&gt; ：WMMA 通过精度类型参数（如 wmma::precision::fp16）匹配 Tensor Core 的硬件能力，实现性能最大化。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-开发实践中的关键约束"&gt;⚠️ 开发实践中的关键约束
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;硬件依赖&lt;/strong&gt;
* 仅支持计算能力 ≥ 7.0 的 GPU（Volta 及后续架构）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;数据对齐要求&lt;/strong&gt;
* 全局内存地址需对齐至 128 字节，否则需使用共享内存中转。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;动态形状限制&lt;/strong&gt;
* WMMA 子矩阵尺寸需编译期确定，不支持运行时动态调整。
⠀&lt;/p&gt;
&lt;h3 id="-总结wmma-与-tensor-core-的协作价值"&gt;💎 总结：WMMA 与 Tensor Core 的协作价值
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;性能层面&lt;/strong&gt; ：WMMA 将 Tensor Core 的硬件加速潜力转化为实际算力，实现 10-30 倍于 CUDA Core 的吞吐量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;编程层面&lt;/strong&gt; ：封装了跨代硬件差异，开发者无需重写代码即可适配新一代 Tensor Core。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生态层面&lt;/strong&gt; ：作为 cuBLAS/cuDNN 的底层基础，支撑 PyTorch/TensorFlow 等框架的混合精度训练。
⠀开发者应优先通过 WMMA 调用 Tensor Core，而非直接操作 CUDA Core，尤其在深度学习、科学计算等矩阵密集型场景中。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="host-与-device-异步数据传输"&gt;Host 与 Device 异步数据传输
&lt;/h2&gt;&lt;p&gt;在GPU编程中，主机（Host）和设备（Device）之间的异步数据传输是优化计算性能的关键技术，主要通过以下机制实现：&lt;/p&gt;
&lt;h3 id="-异步传输函数cudamemcpyasync"&gt;⚙️ &lt;strong&gt;异步传输函数：cudaMemcpyAsync&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt; ：允许数据传输操作在GPU执行其他任务（如内核计算）时并行进行，避免阻塞主机线程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用场景&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;主机到设备（cudaMemcpyHostToDevice）&lt;/li&gt;
&lt;li&gt;设备到主机（cudaMemcpyDeviceToHost）&lt;/li&gt;
&lt;li&gt;设备内部传输（需设备支持）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码示例&lt;/strong&gt; ：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-锁页内存page-locked-memory"&gt;📍 锁页内存（Page-Locked Memory）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;必要性&lt;/strong&gt; ：异步传输要求主机内存不能被操作系统换页（即物理地址固定），否则驱动需额外复制到临时锁页内存，降低效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分配方式&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;cudaMallocHost(void** ptr, size_t size)：分配锁页内存。&lt;/li&gt;
&lt;li&gt;cudaHostAlloc(void** pHost, size_t size, unsigned int flags)：支持更多控制（如cudaHostAllocMapped映射到设备地址空间）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-cuda流stream管理"&gt;🔁 CUDA流（Stream）管理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用&lt;/strong&gt; ：流是异步操作的执行序列，同一流内操作顺序执行，不同流可并行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关键步骤&lt;/strong&gt; ：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;创建流&lt;/strong&gt; ：cudaStream_t stream;
2 cudaStreamCreate(&amp;amp;stream);
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;在流中执行操作&lt;/strong&gt; ：// 异步数据传输
4 cudaMemcpyAsync(&amp;hellip;, stream);
5 // 内核启动（指定流）
6 kernel&amp;laquo;&amp;lt;grid, block, 0, stream&amp;raquo;&amp;gt;(&amp;hellip;);
&lt;strong&gt;7&lt;/strong&gt; &lt;strong&gt;同步与销毁&lt;/strong&gt; ：cudaStreamSynchronize(stream); // 等待流内操作完成
8 cudaStreamDestroy(stream);&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-事件event同步"&gt;⏱️ 事件（Event）同步
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt; ：标记流中的特定点，用于跨流依赖控制或性能分析。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;跨流同步&lt;/strong&gt; ：使流B等待流A中的事件完成：cudaEvent_t event;&lt;/li&gt;
&lt;li&gt;cudaEventCreate(&amp;amp;event);&lt;/li&gt;
&lt;li&gt;cudaEventRecord(event, streamA);&lt;/li&gt;
&lt;li&gt;cudaStreamWaitEvent(streamB, event); // 流B等待事件&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计时&lt;/strong&gt; ：cudaEventRecord(start, stream);&lt;/li&gt;
&lt;li&gt;kernel&amp;laquo;&amp;lt;&amp;hellip;, stream&amp;raquo;&amp;gt;();&lt;/li&gt;
&lt;li&gt;cudaEventRecord(stop, stream);&lt;/li&gt;
&lt;li&gt;cudaEventElapsedTime(&amp;amp;time, start, stop);&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-设备能力检测与优化"&gt;🔧 设备能力检测与优化
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;硬件支持检查&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;asyncEngineCount：&amp;gt;0 表示支持数据传输与计算并行（如PCIe双向传输）。&lt;/li&gt;
&lt;li&gt;concurrentKernels：&amp;gt;0 表示支持多内核并发执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;示例代码&lt;/strong&gt; ：cudaDeviceProp prop;&lt;/li&gt;
&lt;li&gt;cudaGetDeviceProperties(&amp;amp;prop, 0);&lt;/li&gt;
&lt;li&gt;if (prop.asyncEngineCount &amp;gt; 0) {&lt;/li&gt;
&lt;li&gt;// 支持异步引擎&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-性能优化策略"&gt;🚀 性能优化策略
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;重叠计算与传输&lt;/strong&gt; ：使用多流将数据分块，交替执行传输和计算：for (int i = 0; i &amp;lt; nStreams; i++) {&lt;/li&gt;
&lt;li&gt;int offset = i * chunkSize;&lt;/li&gt;
&lt;li&gt;cudaMemcpyAsync(&amp;hellip;, stream[i]);&lt;/li&gt;
&lt;li&gt;kernel&amp;laquo;&amp;lt;&amp;hellip;, stream[i]&amp;raquo;&amp;gt;(&amp;hellip;, offset);&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;统一内存（Unified Memory）&lt;/strong&gt; ：简化内存管理（cudaMallocManaged），但需注意隐式同步的开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-注意事项-2"&gt;⚠️ 注意事项
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;错误检查&lt;/strong&gt; ：所有CUDA API调用后需检查返回值（如cudaGetLastError()）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同步点&lt;/strong&gt; ：避免隐式同步操作（如锁页内存分配、cudaMemcpy）破坏异步性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源竞争&lt;/strong&gt; ：多流并发时需确保内存访问无冲突（如不同流操作不同内存区域）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-总结-10"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;异步数据传输的核心是 &lt;strong&gt;锁页内存 + CUDA流 + 异步函数&lt;/strong&gt;。通过流间并行和事件同步，最大化重叠数据传输与计算，显著提升GPU利用率。实际应用中需结合设备能力（如asyncEngineCount）设计分块策略，并利用事件监控性能瓶颈。&lt;/p&gt;
&lt;h2 id="global-memorytexture-memory-constant-memory"&gt;Global Memory，Texture Memory, Constant Memory
&lt;/h2&gt;&lt;p&gt;在NVIDIA GPU架构中，Constant Memory（常量内存）、Texture Memory（纹理内存）和Global Memory（全局内存）是三种不同的内存类型，它们在物理位置、访问特性、性能优化场景及编程模型上存在显著差异。以下是综合对比分析：&lt;/p&gt;
&lt;h3 id="-物理位置与硬件支持"&gt;⚙️ 物理位置与硬件支持
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;位置&lt;/strong&gt; ：片外（Off-chip）DRAM（如HBM或GDDR），容量最大（如H100达80GB）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件支持&lt;/strong&gt; ：无专用缓存，但可通过L2缓存加速访问（延迟400-600周期）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;访问权限&lt;/strong&gt; ：所有线程可读写，是数据存储的核心区域。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;位置&lt;/strong&gt; ：实际数据存储在Global Memory中，但每个SM（流式多处理器）有专用的&lt;strong&gt;常量缓存&lt;/strong&gt; （Constant Cache，通常64KB）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件支持&lt;/strong&gt; ：只读，针对同一warp内所有线程访问同一常量时优化为广播机制（单次访问服务全warp）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;位置&lt;/strong&gt; ：数据同样位于Global Memory，但每个SM/TPC（线程处理集群）有专用的&lt;strong&gt;纹理缓存&lt;/strong&gt; （Texture Cache）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件支持&lt;/strong&gt; ：只读，缓存针对空间局部性优化（如2D图像相邻像素访问），支持硬件插值和过滤。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-访问特性与性能"&gt;⚡️ 访问特性与性能
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;访问延迟&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;高（400-600周期）&lt;/td&gt;
&lt;td style="text-align: center"&gt;低（通过常量缓存，延迟≈L1）&lt;/td&gt;
&lt;td style="text-align: center"&gt;中低（通过纹理缓存）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;带宽利用率&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;依赖合并访问（Coalesced Access）&lt;/td&gt;
&lt;td style="text-align: center"&gt;高（广播机制减少重复访问）&lt;/td&gt;
&lt;td style="text-align: center"&gt;高（空间局部性优化）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;适用访问模式&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;随机/分散访问&lt;/td&gt;
&lt;td style="text-align: center"&gt;所有线程访问相同常量&lt;/td&gt;
&lt;td style="text-align: center"&gt;空间局部性访问（如图像纹理）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;读写权限&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;可读写&lt;/td&gt;
&lt;td style="text-align: center"&gt;只读（主机初始化）&lt;/td&gt;
&lt;td style="text-align: center"&gt;只读（支持动态更新纹理）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-编程模型与使用场景"&gt;🧩 编程模型与使用场景
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;声明方式&lt;/strong&gt; ：&lt;strong&gt;device&lt;/strong&gt; 或动态分配（cudaMalloc）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;典型场景&lt;/strong&gt; ：存储输入/输出数据、中间计算结果，需显式管理数据传输（如cudaMemcpy）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化关键&lt;/strong&gt; ：需对齐（Aligned）和合并（Coalesced）访问以提升带宽。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;声明方式&lt;/strong&gt; ：&lt;strong&gt;constant&lt;/strong&gt; 静态声明，主机通过cudaMemcpyToSymbol初始化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;典型场景&lt;/strong&gt; ：存储算法参数（如卷积核权重）、数学常量等不变数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt; ：避免重复加载，适合频繁访问的全局常量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;声明方式&lt;/strong&gt; ：通过纹理引用（Texture Reference）或对象（Texture Object）绑定到Global Memory。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;典型场景&lt;/strong&gt; ：图像处理、科学计算中的插值计算、空间滤波等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特殊功能&lt;/strong&gt; ：支持自动插值（如双线性滤波）、坐标归一化、边界处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-性能对比与适用性总结"&gt;📊 **性能对比与适用性总结
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;维度&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;容量&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;超大（GB级）&lt;/td&gt;
&lt;td style="text-align: center"&gt;极小（64KB）&lt;/td&gt;
&lt;td style="text-align: center"&gt;中（依赖缓存大小）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;速度&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;慢&lt;/td&gt;
&lt;td style="text-align: center"&gt;快（缓存命中时）&lt;/td&gt;
&lt;td style="text-align: center"&gt;中快（缓存命中时）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;访问模式优化&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;需合并访问&lt;/td&gt;
&lt;td style="text-align: center"&gt;单值广播&lt;/td&gt;
&lt;td style="text-align: center"&gt;空间局部性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;通用数据存储、读写操作&lt;/td&gt;
&lt;td style="text-align: center"&gt;高频访问的全局常量&lt;/td&gt;
&lt;td style="text-align: center"&gt;图像/空间数据、只读采样&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-总结与建议"&gt;💎 总结与建议
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优先用Constant Memory&lt;/strong&gt; ：当所有线程需频繁读取&lt;strong&gt;相同常量&lt;/strong&gt; （如算法参数），利用其广播机制降低延迟。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优先用Texture Memory&lt;/strong&gt; ：处理&lt;strong&gt;空间局部性数据&lt;/strong&gt; （如图像、地图），利用硬件插值和缓存优化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化Global Memory&lt;/strong&gt; ：对读写型数据，需通过&lt;strong&gt;合并访问&lt;/strong&gt;、利用共享内存（Shared Memory）缓存数据减少全局访问次数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀💡 &lt;strong&gt;提示&lt;/strong&gt; ：现代GPU（如Hopper架构）通过TMA（张量内存加速器）优化Global Memory与Shared Memory的数据传输，进一步平衡三者使用可最大化性能。&lt;/p&gt;
&lt;h2 id="alignment--padding"&gt;Alignment &amp;amp; Padding
&lt;/h2&gt;&lt;p&gt;Padding（填充）和 Alignment（对齐）是计算机内存管理中的核心概念，主要用于优化数据访问效率、保障硬件兼容性及避免程序错误。它们的必要性源于硬件架构的设计特性和编程语言的内存管理机制。以下从概念、原理和应用角度综合解析：&lt;/p&gt;
&lt;h3 id="-核心概念"&gt;📌 核心概念
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;Alignment（对齐）&lt;/strong&gt;
* &lt;strong&gt;定义&lt;/strong&gt; ：数据对象的起始内存地址必须满足其数据类型大小的整数倍。例如：
* int（4字节）需地址能被4整除（如地址0x1000）。
* double（8字节）需地址能被8整除。
* &lt;strong&gt;对齐值&lt;/strong&gt; ：通过 alignof(T) 获取（C11标准），默认对齐值通常等于类型大小（自然对齐）。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;Padding（填充）&lt;/strong&gt;
* &lt;strong&gt;定义&lt;/strong&gt; ：编译器为满足对齐要求，在结构体成员之间或末尾插入的“无用字节”。例如：struct Example {
* char a; // 1字节
* // 编译器插入3字节填充（假设int需4字节对齐）
* int b; // 4字节
* };
* 结构体大小从理论值5字节变为实际8字节。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-为何需要对齐与填充"&gt;⚙️ 为何需要对齐与填充？
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. 硬件性能优化&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPU访存机制&lt;/strong&gt; ：CPU以固定字长（如4/8字节）读取内存。若数据未对齐：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对齐访问&lt;/strong&gt; ：单次访存即可完成（如读取4字节int，地址0x1000）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;未对齐访问&lt;/strong&gt; ：需多次访存并拼接数据（如读取跨越两个4字节块的int地址0x1003），导致性能显著下降（ARM/MIPS架构尤为严重）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SIMD指令要求&lt;/strong&gt; ：SSE/AVX等向量指令强制要求数据对齐，否则触发未定义行为。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. 原子性与稳定性&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;原子操作保障&lt;/strong&gt; ：对齐访问在多数架构中是原子的（如64位系统下的8字节对齐数据）。未对齐访问可能破坏原子性，引发并发问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件兼容性&lt;/strong&gt; ：部分架构（如ARM v5、MIPS）不支持未对齐访问，直接触发对齐异常（Alignment Fault）导致程序崩溃。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;3. 编程语言与编译器实现&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;结构体内存布局&lt;/strong&gt; ：C标准允许编译器插入填充（§6.7.2.1），确保成员地址对齐。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨平台一致性&lt;/strong&gt; ：不同编译器/架构的对齐规则可能不同（如32位与64位系统），填充机制避免代码移植时的手动调整。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;4. 内存空间与性能的权衡&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;填充的代价&lt;/strong&gt; ：结构体填充可能导致内存浪费（如44%空间浪费案例）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能优先&lt;/strong&gt; ：牺牲少量空间换取访问速度，符合“空间换时间”原则。例如：
&lt;ul&gt;
&lt;li&gt;频繁访问的数组对齐后，性能可提升数倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-实际应用与问题规避"&gt;💻 实际应用与问题规避
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. 结构体优化设计&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;成员排序策略&lt;/strong&gt; ：按对齐值降序排列成员（如double → int → char），最小化填充。// 优化前：12字节（1+3填充+4+1+3填充）&lt;/li&gt;
&lt;li&gt;struct Bad { char a; int b; char c; };&lt;/li&gt;
&lt;li&gt;// 优化后：8字节（4+1+1+2填充）&lt;/li&gt;
&lt;li&gt;struct Good { int b; char a; char c; };&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;手动控制填充&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;编译器指令（如#pragma pack(1)或GCC的__attribute__((packed))）禁用填充，但需承担性能损失和移植风险。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. 跨平台数据交换&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;避免直接传递结构体&lt;/strong&gt; ：网络传输或文件存储时，序列化为字节流（手动处理对齐），而非直接memcpy结构体。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;初始化清零&lt;/strong&gt; ：memset(&amp;amp;obj, 0, sizeof(obj)) 避免未初始化填充位残留脏数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;3. 指针与类型转换的陷阱&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;未对齐访问风险&lt;/strong&gt; ：char data[10];&lt;/li&gt;
&lt;li&gt;int &lt;em&gt;p = (int&lt;/em&gt;)&amp;amp;data[1]; // 地址未对齐&lt;/li&gt;
&lt;li&gt;*p = 10; // ARM/MIPS下崩溃，x86性能下降
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;替代方案&lt;/strong&gt; ：用memcpy复制数据而非指针转换。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-不同架构下的对齐支持对比"&gt;📊 不同架构下的对齐支持对比
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;架构&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;未对齐访问支持&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;性能影响&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;典型场景&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;x86/x64&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;✅ 硬件自动处理&lt;/td&gt;
&lt;td style="text-align: center"&gt;⚠️ 损失10%~30%&lt;/td&gt;
&lt;td style="text-align: center"&gt;桌面/服务器应用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ARM v8+&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;✅ 部分支持&lt;/td&gt;
&lt;td style="text-align: center"&gt;⚠️ 损失显著（SIMD除外）&lt;/td&gt;
&lt;td style="text-align: center"&gt;移动/嵌入式设备&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ARM v5/MIPS&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;❌ 触发Alignment Fault&lt;/td&gt;
&lt;td style="text-align: center"&gt;🔥 程序崩溃&lt;/td&gt;
&lt;td style="text-align: center"&gt;旧嵌入式系统&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-总结-11"&gt;💎 总结
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对齐（Alignment）&lt;/strong&gt; ：硬件高效访问内存的基础要求，避免性能损失和程序异常。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;填充（Padding）&lt;/strong&gt; ：编译器为实现对齐的自动优化手段，以空间换取时间效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;必要性核心&lt;/strong&gt; ：💡 &lt;strong&gt;硬件效率&lt;/strong&gt; ：对齐减少CPU访存次数，提速关键操作；💡 &lt;strong&gt;稳定保障&lt;/strong&gt; ：避免架构相关的崩溃（如ARM的Alignment Fault）；💡 &lt;strong&gt;开发友好&lt;/strong&gt; ：编译器自动填充简化代码，但需警惕跨平台差异。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀实际开发中，应善用sizeof和offsetof获取内存布局，优先通过成员排序减少填充，仅在必要时（如嵌入式内存紧缺场景）手动控制对齐，并严格测试性能与稳定性。&lt;/p&gt;
&lt;h4 id="__restrict__"&gt;__restrict__
&lt;/h4&gt;&lt;p&gt;程序员向编译器承诺&lt;strong&gt;指针无别名&lt;/strong&gt;，换取更激进的优化&lt;/p&gt;
&lt;h2 id="warp-sync"&gt;warp sync
&lt;/h2&gt;&lt;p&gt;在 CUDA 编程中，__syncwarp() 与 Cooperative Groups（协作组）中定义为 Warp 大小的线程组再调用 .sync()虽然都用于 Warp 级别的线程同步，但两者在&lt;strong&gt;设计理念、使用方式、安全性和适用范围&lt;/strong&gt;上存在显著差异。以下从多个维度分析它们的区别：&lt;/p&gt;
&lt;h3 id="-设计理念与编程模型"&gt;🧩 设计理念与编程模型
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; __syncwarp()&lt;strong&gt;：底层显式同步原语&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定位&lt;/strong&gt; ：CUDA 早期引入的 Warp 级同步指令，需开发者&lt;strong&gt;手动指定参与同步的线程掩码（Mask）&lt;/strong&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同步粒度&lt;/strong&gt; ：通过掩码（如 0xFFFFFFFF 表示整个 Warp）控制哪些线程需同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内存栅栏&lt;/strong&gt; ：隐含内存屏障（Memory Fence），确保同步点前后内存操作对其他线程可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. Cooperative Groups：面向对象的安全抽象&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定位&lt;/strong&gt; ：CUDA 9+ 引入的现代线程组模型，将线程组视为&lt;strong&gt;一级对象（First-class Object）&lt;/strong&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同步方式&lt;/strong&gt; ：通过线程组对象（如 cooperative_groups::thread_block_tile&amp;lt;32&amp;gt;）调用 .sync() 方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐式关系&lt;/strong&gt; ：组内线程关系在对象创建时确定，无需手动管理掩码。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-使用方式与代码安全"&gt;⚙️ 使用方式与代码安全
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; __syncwarp() &lt;strong&gt;的陷阱与限制&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;掩码错误风险&lt;/strong&gt; ：需开发者确保掩码与活跃线程匹配，否则导致&lt;strong&gt;未定义行为&lt;/strong&gt; （如部分线程未调用同步）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分支发散问题&lt;/strong&gt; ：在分支代码中直接使用 __activemask() 生成的掩码可能不完整（非所有分支线程都参与）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;示例问题&lt;/strong&gt; ：以下代码在分支内使用 __activemask() 可能导致部分线程未同步：if (threadIdx.x &amp;lt; 16) {&lt;/li&gt;
&lt;li&gt;unsigned mask = __activemask(); // 错误！分支内掩码可能缺失&lt;/li&gt;
&lt;li&gt;val = __shfl_sync(mask, val, 0); // 部分线程未参与&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. Cooperative Groups 的显式安全&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;自动掩码管理&lt;/strong&gt; ：创建线程组时自动绑定活跃线程，.sync() 时隐含正确掩码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分支兼容性&lt;/strong&gt; ：支持在发散分支中安全同步（组对象在分支前创建）：auto tile = cg::tiled_partition&amp;lt;32&amp;gt;(cg::this_thread_block());&lt;/li&gt;
&lt;li&gt;if (condition) {&lt;/li&gt;
&lt;li&gt;// 组内所有线程（包括未进分支的）均通过 tile.sync() 同步&lt;/li&gt;
&lt;li&gt;tile.sync();&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-功能扩展性与硬件支持"&gt;🛡️ 功能扩展性与硬件支持
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; __syncwarp() &lt;strong&gt;的局限性&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;仅限同步&lt;/strong&gt; ：仅提供同步功能，不包含集体操作（如规约、扫描）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;依赖架构&lt;/strong&gt; ：在 Volta 架构前，Warp 是严格同步的（SIMT），但 Volta 后支持&lt;strong&gt;独立线程调度&lt;/strong&gt; （Independent Thread Scheduling），需显式同步避免竞争。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. Cooperative Groups 的丰富集体操作&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内置算法&lt;/strong&gt; ：支持 reduce()、scan()、memcpy_async() 等集体操作，可直接调用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨粒度支持&lt;/strong&gt; ：不仅支持 Warp，还可定义 &lt;strong&gt;Block、Grid 甚至多 GPU 的线程组同步&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件加速&lt;/strong&gt; ：如 Hopper 架构的 wgmma.mma_async 指令需配合协作组实现异步矩阵乘。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-性能与兼容性"&gt;⚖️ 性能与兼容性
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;维度&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;__syncwarp()&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Cooperative Groups&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;代码安全性&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;低（需手动管理掩码，易出错）&lt;/td&gt;
&lt;td style="text-align: center"&gt;高（对象化管理，避免掩码错误）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;可维护性&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;低（逻辑分散，难适配新架构）&lt;/td&gt;
&lt;td style="text-align: center"&gt;高（接口统一，向前兼容）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;功能丰富度&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;仅同步&lt;/td&gt;
&lt;td style="text-align: center"&gt;同步 + 集体算法 + 跨粒度组操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;适用架构&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;全架构支持（但 Volta+ 需更谨慎）&lt;/td&gt;
&lt;td style="text-align: center"&gt;CUDA 9.0+（需 Compute Capability 6.0+）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-总结如何选择"&gt;💎 总结：如何选择？
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;优先 Cooperative Groups 的场景&lt;/strong&gt; ：
* 需要安全同步（如分支代码、库函数开发）。
* 需集体操作（如 Warp 级规约/扫描）。
* 跨架构兼容性要求高（如支持 Volta/Ampere/Hopper）。
2 &lt;strong&gt;__syncwarp() 的适用场景&lt;/strong&gt; ：
* 对旧架构（Maxwell/Pascal）的兼容性维护。
* 极高性能敏感场景（需手动优化掩码减少开销）。
* 简单同步且能保证掩码正确性（如非分支代码）。&lt;/p&gt;
&lt;p&gt;⠀&lt;strong&gt;迁移建议&lt;/strong&gt; ：旧代码中大量使用 __syncwarp() 时，可逐步替换为协作组对象（如 cg::thread_block_tile&amp;lt;32&amp;gt;），提升安全性与可读性。在异步操作（如 WGMMA）中，协作组与 TMA（Tensor Memory Accelerator）的结合更能发挥新一代 GPU 性能。&lt;/p&gt;
&lt;h2 id="cache-hint"&gt;Cache Hint
&lt;/h2&gt;&lt;p&gt;Cache Hints（缓存提示）是NVIDIA GPU中用于显式指导缓存行为的编程技术，通过__ldg()、nvvm_prefetch等指令或限定符（如const &lt;strong&gt;restrict&lt;/strong&gt;）实现，旨在优化内存访问模式，提升并行效率。其核心在于根据数据访问特性适配缓存策略，减少冗余数据缓存和延迟。以下是三类Cache Hints的详细解析：&lt;/p&gt;
&lt;h3 id="-load-hints加载提示"&gt;⚙️ Load Hints（加载提示）
&lt;/h3&gt;&lt;p&gt;用于优化&lt;strong&gt;数据读取&lt;/strong&gt;阶段的缓存行为，主要包含两种策略：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;流式加载（Streaming Load）&lt;/strong&gt;
* &lt;strong&gt;作用&lt;/strong&gt; ：标记数据为&lt;strong&gt;短期使用&lt;/strong&gt;，加载后不保留在缓存中，避免污染缓存空间。
* &lt;strong&gt;适用场景&lt;/strong&gt; ：大规模顺序访问数据（如科学计算的流式处理），后续无重复访问需求。
* &lt;strong&gt;实现方式&lt;/strong&gt; ：// 使用PTX指令显式声明流式加载
* asm volatile(&amp;ldquo;prefetch.global.L2 [%0];&amp;rdquo; :: &amp;ldquo;l&amp;rdquo;(ptr));
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;缓存保留加载（Cached Load）&lt;/strong&gt;
* &lt;strong&gt;作用&lt;/strong&gt; ：提示GPU将数据保留在L1/L2缓存， &lt;strong&gt;加速后续重复访问&lt;/strong&gt;。
* &lt;strong&gt;适用场景&lt;/strong&gt; ：频繁访问的查找表（LUT）、共享系数矩阵等。
* &lt;strong&gt;实现方式&lt;/strong&gt; ：// 使用__ldg()函数强制通过纹理缓存（只读）
* float val = __ldg(&amp;amp;data[index]); // 触发L1缓存保留&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-store-hints存储提示"&gt;💾 Store Hints（存储提示）
&lt;/h3&gt;&lt;p&gt;用于优化&lt;strong&gt;数据写入&lt;/strong&gt;阶段的缓存行为，减少不必要的缓存占用：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;流式存储（Streaming Store）&lt;/strong&gt;
* &lt;strong&gt;作用&lt;/strong&gt; ：数据写入后&lt;strong&gt;立即刷出缓存&lt;/strong&gt;，不占用缓存空间。
* &lt;strong&gt;适用场景&lt;/strong&gt; ：一次性写入结果（如渲染输出到帧缓冲区），无需后续读取。
* &lt;strong&gt;实现方式&lt;/strong&gt; ：// 使用__stwt指令（Ampere+架构）
* __stwt(&amp;amp;output[addr], value); // 绕过L1，直写L2/显存
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;写合并（Write-Combining）&lt;/strong&gt;
* &lt;strong&gt;作用&lt;/strong&gt; ：合并多个线程的写入操作，减少缓存行访问次数。
* &lt;strong&gt;适用场景&lt;/strong&gt; ：原子操作（Atomic）或规约（Reduction）中的临时结果写入。
* &lt;strong&gt;硬件支持&lt;/strong&gt; ：NVIDIA GPU的L2缓存自动合并部分写入请求。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-read-only-hints只读提示"&gt;📖 Read-Only Hints（只读提示）
&lt;/h3&gt;&lt;p&gt;专为&lt;strong&gt;常量数据&lt;/strong&gt;设计，通过只读缓存路径提升性能：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;纹理/常量缓存路径&lt;/strong&gt;
* &lt;strong&gt;作用&lt;/strong&gt; ：将数据标记为只读，触发纹理缓存（Texture Cache）或常量缓存（Constant Cache）机制。
* &lt;strong&gt;优势&lt;/strong&gt; ：
* 纹理缓存针对2D空间局部性优化，适合图像/矩阵数据。
* 常量缓存广播机制：单地址读取可广播到整个Warp，减少访问次数。
* &lt;strong&gt;实现方式&lt;/strong&gt; ：// 使用const __restrict__限定符
* void kernel(const float* &lt;strong&gt;restrict&lt;/strong&gt; data) {
* // 编译器自动使用__ldg()或纹理路径
* }
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;统一内存只读优化&lt;/strong&gt;
* 在Unified Memory（UM）中，只读提示可避免数据回迁至CPU，减少PCIe传输。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-技术原理与性能影响"&gt;⚖️ 技术原理与性能影响
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;机制&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;硬件行为&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;性能收益&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;缓存层级选择&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;Hints指导数据缓存于L1（高重用）或跳过L1（流式数据），减少L1污染&lt;/td&gt;
&lt;td style="text-align: center"&gt;提升缓存命中率，降低平均延迟&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;带宽优化&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;流式操作减少缓存占用，释放带宽给其他任务&lt;/td&gt;
&lt;td style="text-align: center"&gt;高吞吐场景下提升并行度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;资源竞争缓解&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;避免只读数据与读写数据共用缓存行，减少伪共享（False Sharing）&lt;/td&gt;
&lt;td style="text-align: center"&gt;提升多线程稳定性&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-使用注意事项"&gt;⚠️ 使用注意事项
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;架构差异性&lt;/strong&gt;
* Pascal及更早架构：__ldg()对全局内存无效，需依赖const &lt;strong&gt;restrict&lt;/strong&gt;。
* Volta+：引入独立的&lt;strong&gt;只读数据缓存&lt;/strong&gt; （Read-Only Data Cache），显式提示效果更显著。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;过度使用的风险&lt;/strong&gt;
* 错误标记流式加载可能导致重复访问数据时反复从显存加载，性能反降。
* 只读提示误用于可变数据会引发未定义行为（如数据不一致）。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;调试工具依赖&lt;/strong&gt;
* 需通过nvprof或Nsight Compute分析缓存命中率（l1tex__t_sectors_per_request指标）验证优化效果。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-总结-12"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;Cache Hints是NVIDIA GPU中&lt;strong&gt;精细化控制内存子系统&lt;/strong&gt;的关键技术，其价值在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;精准适配场景&lt;/strong&gt; ：流式数据避缓存、只读数据走高速路径、写入操作减污染。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;释放硬件潜力&lt;/strong&gt; ：结合GPU缓存层级（L1/L2/纹理）和访问特性（如广播、合并），最大化并行吞吐。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;编程可控性&lt;/strong&gt; ：从编译器限定符到汇编指令，提供多层次控制接口。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀开发者应在性能分析驱动下，针对性使用Hints优化热点内存访问，避免盲目应用。对延迟敏感型内核（如光线追踪G-Buffer读取），合理配置只读提示可获显著加速；而对流式处理（如粒子模拟），显式流式加载能缓解缓存抖动。&lt;/p&gt;
&lt;h2 id="barrier"&gt;Barrier
&lt;/h2&gt;&lt;p&gt;Barrier（屏障）在CUDA编程中是一种&lt;strong&gt;关键同步机制&lt;/strong&gt;，用于协调同一线程块（Block）内多个线程的执行顺序，确保所有线程在特定点达到一致状态后再继续执行。其核心作用是解决并行计算中的数据竞争和顺序依赖问题。下面从原理、类型、实现及注意事项展开说明：&lt;/p&gt;
&lt;h3 id="-barrier的核心原理"&gt;⚙️ Barrier的核心原理
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;同步逻辑&lt;/strong&gt; 当线程调用Barrier时，会暂停执行并等待同线程块内的所有其他线程也到达该Barrier点。只有当所有线程都抵达后，才能继续执行后续代码。&lt;strong&gt;类比&lt;/strong&gt; ：类似于多人协作任务中的“集合点”，所有人必须到齐后才能进行下一步。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;解决什么问题？&lt;/strong&gt;
* &lt;strong&gt;数据竞争&lt;/strong&gt; ：防止线程A在写入共享内存时，线程B提前读取未完成计算的数据。
* &lt;strong&gt;顺序依赖&lt;/strong&gt; ：确保前序操作（如数据加载、计算）完成后再执行后续操作（如汇总结果）。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-cuda中的barrier类型"&gt;🧩 CUDA中的Barrier类型
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. ****__syncthreads()&lt;/strong&gt;（显式屏障） ****&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用范围&lt;/strong&gt; ：仅同步同一线程块（Block）内的线程，无法跨Block同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;典型场景&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;共享内存操作（如规约求和）前确保数据加载完成。&lt;/li&gt;
&lt;li&gt;避免读写冲突（例如先读后写同一共享变量）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码示例&lt;/strong&gt; ：&lt;strong&gt;shared&lt;/strong&gt; float s_data[128];&lt;/li&gt;
&lt;li&gt;s_data[threadIdx.x] = input_data; // 写入共享内存&lt;/li&gt;
&lt;li&gt;__syncthreads(); // 等待所有线程写入完成&lt;/li&gt;
&lt;li&gt;// 安全读取其他线程写入的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. 异步Barrier（CUDA 11+）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;实现方式&lt;/strong&gt; ：通过__mbarrier_*系列函数（如__mbarrier_arrive）控制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;支持更细粒度的同步（如分阶段计数、线程动态退出）。&lt;/li&gt;
&lt;li&gt;可减少阻塞等待时间，提升并行效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适用场景&lt;/strong&gt; ：生产者-消费者模型、动态任务分配。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;3. 全局同步（隐式屏障）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;机制&lt;/strong&gt; ：通过cudaDeviceSynchronize()强制CPU等待所有GPU线程完成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;注意&lt;/strong&gt; ：频繁使用会显著降低性能，应尽量通过内核拆分替代。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-关键注意事项"&gt;⚠️ 关键注意事项
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;条件分支中的风险&lt;/strong&gt; 在条件分支内使用Barrier需确保&lt;strong&gt;所有线程均执行相同分支&lt;/strong&gt;，否则会导致死锁（部分线程永久等待）。&lt;strong&gt;错误示例&lt;/strong&gt; ：### if (threadIdx.x % 2 == 0) {&lt;/p&gt;
&lt;h3 id="2-----__syncthreads--偶线程等待"&gt;2 __syncthreads(); // 偶线程等待
&lt;/h3&gt;&lt;p&gt;3 } else {
4 __syncthreads(); // 奇线程等待，但实际无法保证同步点一致
5 }
&lt;strong&gt;6&lt;/strong&gt; &lt;strong&gt;跨线程块同步不可行&lt;/strong&gt; CUDA的线程块独立执行，若需跨Block同步，需拆分内核或使用多级同步策略。
&lt;strong&gt;7&lt;/strong&gt; &lt;strong&gt;性能优化&lt;/strong&gt;
* 减少Barrier调用次数（每次同步均有开销）。
* 优先使用共享内存+__syncthreads()替代全局同步。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-总结-13"&gt;💎 总结
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;基础场景&lt;/strong&gt; ：线程块内同步首选__syncthreads()，确保共享内存操作安全。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高级需求&lt;/strong&gt; ：动态或分阶段同步使用异步Barrier（_&lt;em&gt;mbarrier&lt;/em&gt;*）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全局同步&lt;/strong&gt; ：谨慎使用cudaDeviceSynchronize()，避免性能瓶颈。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀Barrier是CUDA并行正确性的基石，理解其适用场景和限制，方能高效规避竞态条件并优化计算效率。&lt;/p&gt;
&lt;h2 id="cudapipeline"&gt;cuda::pipeline
&lt;/h2&gt;&lt;p&gt;以下是对 CUDA 中 cuda::pipeline 的详细介绍，结合其设计原理、核心组件、使用场景及优化策略展开说明：&lt;/p&gt;
&lt;h3 id="-cudapipeline-的核心设计目标"&gt;⚙️ cuda::pipeline 的核心设计目标
&lt;/h3&gt;&lt;p&gt;cuda::pipeline 是 CUDA 提供的一种&lt;strong&gt;异步数据拷贝与计算重叠&lt;/strong&gt;的同步机制，旨在解决 GPU 计算中内存访问延迟与计算资源利用率不足的问题。其核心目标包括：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;隐藏内存延迟&lt;/strong&gt; ：通过异步拷贝（如 memcpy_async）将数据从全局内存预取到共享内存，与计算任务并行执行。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;资源高效利用&lt;/strong&gt; ：利用流水线（Pipeline）的多阶段缓冲，实现计算与数据传输的深度重叠。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;线程级协作&lt;/strong&gt; ：基于线程块（Thread Block）范围内的同步，确保数据依赖正确性。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-核心组件与工作流程"&gt;🧩 核心组件与工作流程
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. 流水线对象（Pipeline Object）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;结构&lt;/strong&gt; ：一个 FIFO（先进先出）队列，包含多个&lt;strong&gt;阶段（Stage）&lt;/strong&gt; ，每个阶段存储一组异步操作（如数据拷贝）。
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;函数&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;作用&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;producer_acquire()&lt;/td&gt;
&lt;td&gt;获取一个空闲的流水线阶段，用于提交新操作。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;producer_commit()&lt;/td&gt;
&lt;td&gt;提交当前阶段的所有异步操作（如 memcpy_async），将其加入流水线队列。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consumer_wait()&lt;/td&gt;
&lt;td&gt;等待流水线中最旧阶段的操作完成。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consumer_release()&lt;/td&gt;
&lt;td&gt;释放最旧阶段，使其可被生产者重新获取。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. 异步拷贝操作（&lt;strong&gt;memcpy_async&lt;/strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将数据从全局内存（Global Memory）异步复制到共享内存（Shared Memory），无需阻塞线程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件加速&lt;/strong&gt; ：在 Compute Capability ≥ 8.0（如 Ampere、Hopper架构）的设备上，直接绕过寄存器，提升拷贝效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;3. 工作流程示例（单阶段流水线）&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cuda/pipeline&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;global_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;global_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;block&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;extern&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;[];&lt;/span&gt; &lt;span class="c1"&gt;// 共享内存缓冲区
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;pipeline_shared_state&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;thread_scope&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_pipeline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;batch_sz&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 生产者：获取阶段并提交异步拷贝
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;producer_acquire&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;memcpy_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_in&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;producer_commit&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 消费者：等待上一阶段拷贝完成
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;consumer_wait&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;compute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;global_out&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 计算任务
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;consumer_release&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 释放阶段
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;流程解析&lt;/strong&gt; ：
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;生产者提交任务&lt;/strong&gt; ：获取阶段 → 提交异步拷贝 → 提交阶段。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;消费者处理任务&lt;/strong&gt; ：等待拷贝完成 → 执行计算 → 释放阶段。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;重叠实现&lt;/strong&gt; ：当计算任务（compute）处理当前数据时，异步拷贝已开始预取下一批数据。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-多阶段流水线与性能优化"&gt;⚡ 多阶段流水线与性能优化
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. 多阶段设计（如双缓冲）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;原理&lt;/strong&gt; ：使用多个缓冲区（如 Stage=2），实现“计算-拷贝”的深度重叠。constexpr size_t stages_count = 2; // 双阶段流水线&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;shared&lt;/strong&gt; cuda::pipeline_shared_state&amp;lt;cuda::thread_scope::block, stages_count&amp;gt; state;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;计算与拷贝完全重叠&lt;/strong&gt; ：一个阶段用于计算时，另一个阶段同时进行数据预取。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;减少线程空闲&lt;/strong&gt; ：避免因等待数据拷贝而阻塞。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;2. 与硬件特性结合&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hopper 架构的增强&lt;/strong&gt; ：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TMA（Tensor Memory Accelerator）&lt;/strong&gt; ：支持大块数据的高效异步传输，减少线程开销。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WGMMA（Warp Group Matrix Multiply-Accumulate）&lt;/strong&gt; ：流水线为张量核心（Tensor Core）持续供应数据，避免计算单元闲置。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;strong&gt;3. 性能优化策略&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;共享内存分配&lt;/strong&gt; ：确保每个阶段的数据块大小适配共享内存容量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;线程块配置&lt;/strong&gt; ：线程数设为 32 的倍数（Warp 对齐），避免 Bank Conflict。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;流水线深度&lt;/strong&gt; ：根据计算与拷贝的耗时比例，调整阶段数量（通常 2-4 阶段）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-应用场景"&gt;🚀 应用场景
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;高性能计算（HPC）&lt;/strong&gt;
* 在矩阵乘法（GEMM）、卷积等计算密集型任务中，通过流水线隐藏全局内存访问延迟。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;深度学习训练/推理&lt;/strong&gt;
* 加速神经网络层的数据加载与计算重叠，尤其适用于大模型（如 Transformer）。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;流式数据处理&lt;/strong&gt;
* 实时处理传感器数据流（如自动驾驶），确保计算单元持续工作。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-注意事项与限制-1"&gt;⚠️ 注意事项与限制
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;作用域限制&lt;/strong&gt; ### cuda::pipeline 仅支持线程块（thread_scope::block）内的同步，无法跨块协作。
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;资源开销&lt;/strong&gt;
* 多阶段流水线需额外共享内存，可能减少可用计算资源。
* 阶段过多可能导致调度复杂度上升。
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;兼容性要求&lt;/strong&gt;
* 异步拷贝硬件加速需 Compute Capability ≥ 8.0（Ampere+）。
* 旧架构需通过线程束专业化（Warp Specialization）模拟类似效果。&lt;/p&gt;
&lt;p&gt;⠀&lt;/p&gt;
&lt;h3 id="-总结-14"&gt;💎 总结
&lt;/h3&gt;&lt;p&gt;cuda::pipeline 是 CUDA 中实现&lt;strong&gt;计算-通信重叠&lt;/strong&gt;的核心工具，通过多阶段流水线机制显著提升 GPU 利用率。其设计要点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;生产者-消费者模型&lt;/strong&gt; ：通过 producer_acquire/commit 和 consumer_wait/release 实现精细同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件协作&lt;/strong&gt; ：结合 memcpy_async 和 TMA 等特性，最大化数据传输效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适用场景&lt;/strong&gt; ：适用于需高吞吐、低延迟的并行任务（如深度学习、科学计算）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⠀开发者可通过调整流水线阶段数、优化内存访问模式及适配新一代 GPU 架构（如 Hopper），进一步释放性能潜力。&lt;/p&gt;</description></item><item><title>【CUDA】Programming Guide</title><link>https://dyhes.github.io/p/cudaprogramming-guide/</link><pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudaprogramming-guide/</guid><description>&lt;h2 id="introduction"&gt;Introduction
&lt;/h2&gt;&lt;p&gt;In general, an application has a mix of parallel parts and sequential parts, so systems are designed with a mix of GPUs and CPUs in order to maximize overall performance. 
&lt;img src="https://i.ibb.co/7xgqKH7d/image.png"
loading="lazy"
&gt;
The challenge is to develop application software that transparently scales its parallelism to leverage the increasing number of processor cores.
At its core are three key abstractions — a hierarchy of &lt;strong&gt;thread groups&lt;/strong&gt;, &lt;strong&gt;shared memories&lt;/strong&gt;, and &lt;strong&gt;barrier synchronization&lt;/strong&gt; — that are simply exposed to the programmer as a minimal set of language extensions.
Each block of threads can be scheduled on any of the available multiprocessors within a GPU, in any order, concurrently or sequentially, so that a compiled CUDA program can execute on any number of multiprocessors.
&lt;img src="https://i.ibb.co/hxDXmRFY/image-2.png"
loading="lazy"
&gt;&lt;/p&gt;
&lt;h2 id="programming-model"&gt;Programming Model
&lt;/h2&gt;&lt;h3 id="kernel"&gt;Kernel
&lt;/h3&gt;&lt;p&gt;CUDA C++ extends C++ by allowing the programmer to define C++ functions, called &lt;em&gt;kernels&lt;/em&gt;, that, when called, are executed N times in parallel by N different &lt;em&gt;CUDA threads&lt;/em&gt;, as opposed to only once like regular C++ functions.
A kernel is defined using the &lt;strong&gt;global&lt;/strong&gt; declaration specifier and the number of CUDA threads that execute that kernel for a given kernel call is specified using a new &amp;laquo;&amp;lt;&amp;hellip;&amp;raquo;&amp;gt;&lt;em&gt;execution configuration&lt;/em&gt; syntax (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;). Each thread that executes the kernel is given a &lt;strong&gt;unique &lt;em&gt;thread ID&lt;/em&gt;&lt;/strong&gt; that is accessible within the kernel through built-in variables.&lt;/p&gt;
&lt;h3 id="thread-hierarchy"&gt;Thread Hierarchy
&lt;/h3&gt;&lt;p&gt;For convenience, threadIdx is a &lt;strong&gt;3-component vector&lt;/strong&gt;, so that threads can be identified using a one-dimensional, two-dimensional, or three-dimensional &lt;em&gt;thread index&lt;/em&gt;, forming a one-dimensional, two-dimensional, or three-dimensional block of threads, called a &lt;em&gt;thread block&lt;/em&gt;.
The index of a thread and its thread ID relate to each other in a straightforward way: For a one-dimensional block, they are the &lt;strong&gt;same&lt;/strong&gt;; for a two-dimensional block of size &lt;em&gt;(Dx, Dy)&lt;/em&gt;, the thread ID of a thread of index &lt;em&gt;(x, y)&lt;/em&gt; is &lt;em&gt;(&lt;strong&gt;x + y Dx&lt;/strong&gt;)&lt;/em&gt;; for a three-dimensional block of size &lt;em&gt;(Dx, Dy, Dz)&lt;/em&gt;, the thread ID of a thread of index &lt;em&gt;(x, y, z)&lt;/em&gt; is &lt;em&gt;(&lt;strong&gt;x + y Dx + z Dx Dy&lt;/strong&gt;)&lt;/em&gt;.
There is a limit to the number of threads per block, since all threads of a block are expected to &lt;strong&gt;reside&lt;/strong&gt; on the same streaming multiprocessor core and must &lt;strong&gt;share&lt;/strong&gt; the limited memory resources of that core. On current GPUs, a thread block may contain &lt;strong&gt;up to 1024&lt;/strong&gt; threads.
Blocks are organized into a one-dimensional, two-dimensional, or three-dimensional &lt;em&gt;grid&lt;/em&gt; of thread blocks.
&lt;img src="https://i.ibb.co/tpTsSt42/image-3.png"
loading="lazy"
&gt;
The number of threads per block and the number of blocks per grid specified in the &amp;laquo;&amp;lt;&amp;hellip;&amp;raquo;&amp;gt; syntax can be of type int or dim3.
Each block within the grid can be identified by a one-dimensional, two-dimensional, or three-dimensional unique index accessible within the kernel through the built-in blockIdx variable. The dimension of the thread block is accessible within the kernel through the built-in blockDim variable.
A thread block size of 16x16 (256 threads), although arbitrary in this case, is a common choice. 
Thread blocks are required to execute &lt;strong&gt;independently&lt;/strong&gt;. It must be possible to execute blocks in any order, &lt;strong&gt;in parallel or in series&lt;/strong&gt;. This independence requirement allows thread blocks to be scheduled in any order and across any number of cores.
Threads within a block can &lt;strong&gt;cooperate&lt;/strong&gt; by sharing data through some &lt;em&gt;shared memory&lt;/em&gt; and by synchronizing their execution to coordinate memory accesses. More precisely, one can specify synchronization points in the kernel by calling the &lt;strong&gt;__syncthreads()&lt;/strong&gt; intrinsic function; __syncthreads() acts as a barrier at which all threads in the block must wait before any is allowed to proceed. &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory" target="_blank" rel="noopener"
&gt;Shared Memory&lt;/a&gt; gives an example of using shared memory. In addition to __syncthreads(), the &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cooperative-groups" target="_blank" rel="noopener"
&gt;Cooperative Groups API&lt;/a&gt; provides a rich set of thread-synchronization primitives.
With the introduction of NVIDIA &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-9-0" target="_blank" rel="noopener"
&gt;Compute Capability 9.0&lt;/a&gt;, the CUDA programming model introduces an &lt;strong&gt;optional&lt;/strong&gt; level of hierarchy called Thread Block Clusters that are made up of thread blocks. Similar to how threads in a thread block are guaranteed to be co-scheduled on a streaming multiprocessor, thread blocks in a cluster are also guaranteed to be co-scheduled on a GPU Processing Cluster (GPC) in the GPU.
Similar to thread blocks, clusters are also organized into a one-dimension, two-dimension, or three-dimension grid of thread block clusters. The number of thread blocks in a cluster can be user-defined, and &lt;strong&gt;a maximum of 8 thread blocks&lt;/strong&gt; in a cluster is supported as a portable cluster size in CUDA. Note that on GPU hardware or MIG configurations which are too small to support 8 multiprocessors the maximum cluster size will be reduced accordingly. Identification of these smaller configurations, as well as of larger configurations supporting a thread block cluster size beyond 8, is &lt;strong&gt;architecture-specific&lt;/strong&gt; and can be queried using the &lt;strong&gt;&lt;code&gt;cudaOccupancyMaxPotentialClusterSize&lt;/code&gt;&lt;/strong&gt; API.
&lt;img src="https://i.ibb.co/G3HT4zGK/image-4.png"
loading="lazy"
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In a kernel launched using cluster support, the gridDim variable still denotes the size in terms of number of thread blocks, for &lt;strong&gt;compatibility&lt;/strong&gt; purposes. The rank of a block in a cluster can be found using the &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg" target="_blank" rel="noopener"
&gt;Cluster Group&lt;/a&gt; API.
A thread block cluster can be enabled in a kernel either using a &lt;strong&gt;compile-time&lt;/strong&gt; kernel attribute using &lt;strong&gt;cluster_dims&lt;/strong&gt;(X,Y,Z) or using the CUDA kernel launch API &lt;code&gt;cudaLaunchKernelEx&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Kernel definition
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Compile time cluster size 2 in X-dimension and 1 in Y and Z dimension
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__cluster_dims__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;cluster_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Kernel invocation with compile time cluster size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// The grid dimension is not affected by cluster launch, and is still enumerated
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// using number of blocks.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// The grid dimension must be a multiple of cluster size.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cluster_kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Kernel definition
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// No compile time attribute attached to the kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;cluster_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Kernel invocation with runtime cluster size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaLaunchConfig_t&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// The grid dimension is not affected by cluster launch, and is still enumerated
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// using number of blocks.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// The grid dimension should be a multiple of cluster size.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gridDim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;blockDim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaLaunchAttribute&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cudaLaunchAttributeClusterDimension&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusterDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// Cluster size in X-dimension
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusterDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusterDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numAttrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaLaunchKernelEx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cluster_kernel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In GPUs with compute capability &lt;strong&gt;9.0&lt;/strong&gt;, all the thread blocks in the cluster are guaranteed to be co-scheduled on a single &lt;strong&gt;GPU Processing Cluster (GPC)&lt;/strong&gt; and allow thread blocks in the cluster to perform &lt;strong&gt;hardware-supported synchronization&lt;/strong&gt; using the &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg" target="_blank" rel="noopener"
&gt;Cluster Group&lt;/a&gt; API &lt;code&gt;cluster.sync()&lt;/code&gt;. Cluster group also provides member functions to query cluster group size in terms of number of threads or number of blocks using &lt;code&gt;num_threads()&lt;/code&gt; and &lt;code&gt;num_blocks()&lt;/code&gt; API respectively. The rank of a thread or block in the cluster group can be queried using &lt;code&gt;dim_threads()&lt;/code&gt; and &lt;code&gt;dim_blocks()&lt;/code&gt; API respectively.
Thread blocks that belong to a cluster have access to the &lt;strong&gt;Distributed Shared Memory&lt;/strong&gt;. Thread blocks in a cluster have the ability to read, write, and perform atomics to any address in the distributed shared memory.&lt;/p&gt;
&lt;h3 id="memory-hierarchy"&gt;Memory Hierarchy
&lt;/h3&gt;&lt;p&gt;&lt;img src="https://i.ibb.co/qMRxr4DF/image-5.png"
loading="lazy"
&gt;
There are also two additional read-only memory spaces accessible by all threads: the constant and texture memory spaces. The global, constant, and texture memory spaces are &lt;strong&gt;optimized for different memory usages&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="heterogeneous-programming"&gt;Heterogeneous Programming
&lt;/h3&gt;&lt;p&gt;The CUDA programming model also assumes that both the host and the device maintain their &lt;strong&gt;own&lt;/strong&gt; separate memory spaces in DRAM, referred to as &lt;em&gt;host memory&lt;/em&gt; and &lt;em&gt;device memory&lt;/em&gt;, respectively. Therefore, a program manages the global, constant, and texture memory spaces visible to kernels through calls to the CUDA runtime (described in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-interface" target="_blank" rel="noopener"
&gt;Programming Interface&lt;/a&gt;). This includes device memory &lt;strong&gt;allocation&lt;/strong&gt; and &lt;strong&gt;deallocation&lt;/strong&gt; as well as data &lt;strong&gt;transfer&lt;/strong&gt; between host and device memory.
Unified Memory provides &lt;em&gt;managed memory&lt;/em&gt; to &lt;strong&gt;bridge&lt;/strong&gt; the host and device memory spaces. Managed memory is accessible from all CPUs and GPUs in the system as a single, coherent memory image with a common address space. This capability enables &lt;strong&gt;oversubscription&lt;/strong&gt; of device memory and can greatly simplify the task of porting applications by eliminating the need to explicitly mirror data on host and device.&lt;/p&gt;
&lt;h3 id="asynchronous-simt-programming-model"&gt;Asynchronous SIMT Programming Model
&lt;/h3&gt;&lt;p&gt;In the CUDA programming model a thread is the lowest level of abstraction for doing a computation or a memory operation. Starting with devices based on the &lt;strong&gt;NVIDIA Ampere GPU Architecture&lt;/strong&gt;, the CUDA programming model provides acceleration to memory operations via the asynchronous programming model. The asynchronous programming model defines the behavior of asynchronous operations with respect to CUDA threads.
The asynchronous programming model defines the behavior of &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#aw-barrier" target="_blank" rel="noopener"
&gt;Asynchronous Barrier&lt;/a&gt; for synchronization between CUDA threads. The model also explains and defines how &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-data-copies" target="_blank" rel="noopener"
&gt;cuda::memcpy_async&lt;/a&gt; can be used to move data asynchronously from global memory while computing in the GPU.
An asynchronous operation is defined as an operation that is &lt;strong&gt;initiated by a&lt;/strong&gt; CUDA thread and is &lt;strong&gt;executed asynchronously as-if by another&lt;/strong&gt; thread. In a well formed program one or more CUDA threads synchronize with the &lt;strong&gt;asynchronous operation&lt;/strong&gt;. The CUDA thread that initiated the asynchronous operation is not required to be among the synchronizing threads.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;发起异步操作的CUDA线程无需参与该操作的同步等待过程，其他线程可以代替它完成同步
Such an asynchronous thread (an as-if thread) is always associated with the CUDA thread that initiated the asynchronous operation. An asynchronous operation uses a synchronization object to synchronize the completion of the operation. Such a synchronization object can be explicitly managed by a user (e.g., cuda::memcpy_async) or implicitly managed within a library (e.g., cooperative_groups::memcpy_async).
A synchronization object could be a cuda::barrier or a cuda::pipeline. These objects are explained in detail in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#aw-barrier" target="_blank" rel="noopener"
&gt;Asynchronous Barrier&lt;/a&gt; and &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-data-copies" target="_blank" rel="noopener"
&gt;Asynchronous Data Copies using cuda::pipeline&lt;/a&gt;.
These synchronization objects can be used at &lt;strong&gt;different thread scopes&lt;/strong&gt;. A scope defines the set of threads that may use the synchronization object to synchronize with the asynchronous operation. The following table defines the thread scopes available in CUDA C++ and the threads that can be synchronized with each.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Thread Scope&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_thread&lt;/td&gt;
&lt;td&gt;Only the CUDA thread which initiated asynchronous operations synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_block&lt;/td&gt;
&lt;td&gt;All or any CUDA threads within the same thread block as the initiating thread synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_device&lt;/td&gt;
&lt;td&gt;All or any CUDA threads in the same GPU device as the initiating thread synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_system&lt;/td&gt;
&lt;td&gt;All or any CUDA or CPU threads in the same system as the initiating thread synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;These thread scopes are implemented as extensions to standard C++ in the &lt;a class="link" href="https://nvidia.github.io/libcudacxx/extended_api/memory_model.html#thread-scopes" target="_blank" rel="noopener"
&gt;CUDA Standard C++&lt;/a&gt; library.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;
&lt;h2 id="programming-interface"&gt;Programming Interface
&lt;/h2&gt;&lt;p&gt;CUDA C++ provides a simple path for users familiar with the C++ programming language to easily write programs for execution by the device.
It consists of a &lt;strong&gt;minimal set of extensions&lt;/strong&gt; to the C++ language and a &lt;strong&gt;runtime&lt;/strong&gt; library.
Any source file that contains some of these extensions must be compiled with &lt;code&gt;nvcc&lt;/code&gt;.
The runtime provides C and C++ functions that execute on the host to allocate and deallocate device memory, transfer data between host memory and device memory, manage systems with multiple devices, etc. 
The runtime is built on top of &lt;strong&gt;a lower-level C API, the CUDA driver API&lt;/strong&gt;, which is also accessible by the application. The driver API provides an additional level of control by exposing lower-level concepts such as &lt;strong&gt;CUDA contexts&lt;/strong&gt; - the analogue of host processes for the device - and &lt;strong&gt;CUDA modules&lt;/strong&gt; - the analogue of dynamically loaded libraries for the device. Most applications do not use the driver API as they do not need this &lt;strong&gt;additional&lt;/strong&gt; level of control and when using the runtime, context and module management are &lt;strong&gt;implicit&lt;/strong&gt;, resulting in more concise code. As the runtime is interoperable with the driver API, most applications that need some driver API features can default to use the runtime API and only use the driver API where &lt;strong&gt;needed&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="nvcc"&gt;NVCC
&lt;/h3&gt;&lt;p&gt;Kernels can be written using the CUDA instruction set architecture, called &lt;em&gt;&lt;strong&gt;PTX&lt;/strong&gt;&lt;/em&gt;, which is described in the PTX reference manual. It is however usually &lt;strong&gt;more effective&lt;/strong&gt; to use a high-level programming language such as C++. In both cases, kernels must be compiled into binary code by nvcc to execute on the device.
nvcc is a compiler driver that simplifies the process of compiling &lt;em&gt;C++&lt;/em&gt; or &lt;em&gt;PTX&lt;/em&gt; code: It provides simple and familiar command line options and executes them by invoking the collection of tools that implement the different compilation stages. 
Only a subset of C++ is fully supported for the device code.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CUDA设备代码（device code）仅支持部分C++语法，这是由GPU硬件架构、执行模型和编译器设计的本质差异决定的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="offline-compilation"&gt;Offline Compilation
&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;Source files compiled with nvcc can include a mix of host code (i.e., code that executes on the host) and device code (i.e., code that executes on the device). nvcc’s basic workflow consists in **separating** device code from host code and then:
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;compiling the device code into an &lt;strong&gt;assembly form&lt;/strong&gt; (&lt;em&gt;PTX&lt;/em&gt; code) and/or &lt;strong&gt;binary form&lt;/strong&gt; (&lt;em&gt;cubin&lt;/em&gt; object),&lt;/li&gt;
&lt;li&gt;and modifying the host code by &lt;strong&gt;replacing&lt;/strong&gt; the &amp;laquo;&amp;lt;&amp;hellip;&amp;raquo;&amp;gt; syntax introduced in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#kernels" target="_blank" rel="noopener"
&gt;Kernels&lt;/a&gt; (and described in more details in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;) by the necessary CUDA runtime function calls to load and launch each compiled kernel &lt;strong&gt;from&lt;/strong&gt; the &lt;em&gt;PTX&lt;/em&gt; code and/or &lt;em&gt;cubin&lt;/em&gt; object.
The modified host code is output either as C++ code that is left to be compiled using another tool or as object code directly by letting nvcc invoke the host compiler during the last compilation stage.
Applications can then:&lt;/li&gt;
&lt;li&gt;Either link to the compiled host code (this is the most common case),&lt;/li&gt;
&lt;li&gt;Or &lt;strong&gt;ignore&lt;/strong&gt; the modified host code (if any) and use the CUDA driver API (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#driver-api" target="_blank" rel="noopener"
&gt;Driver API&lt;/a&gt;) to load and execute the &lt;em&gt;PTX&lt;/em&gt; code or &lt;em&gt;cubin&lt;/em&gt; object.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="just-in-time-compilation"&gt;Just-in-Time Compilation
&lt;/h4&gt;&lt;p&gt;Any &lt;em&gt;PTX&lt;/em&gt; code loaded by an application at runtime is &lt;strong&gt;compiled further to binary code&lt;/strong&gt; by the device driver. This is called &lt;em&gt;just-in-time compilation&lt;/em&gt;. Just-in-time compilation increases application load time, but allows the application to &lt;strong&gt;benefit&lt;/strong&gt; from any new compiler improvements coming with each new device driver. It is also the only way for applications to run on devices that &lt;strong&gt;did not exist&lt;/strong&gt; at the time the application was compiled.
As an alternative to using &lt;code&gt;nvcc&lt;/code&gt; to compile CUDA C++ device code, &lt;strong&gt;NVRTC&lt;/strong&gt; can be used to compile CUDA C++ device code to PTX at runtime.&lt;/p&gt;
&lt;h4 id="compatibility"&gt;Compatibility
&lt;/h4&gt;&lt;p&gt;Binary code is &lt;strong&gt;architecture-specific.&lt;/strong&gt; A &lt;em&gt;cubin&lt;/em&gt; object is generated using the compiler option &lt;code&gt;-code&lt;/code&gt; that specifies the targeted architecture: For example, compiling with &lt;code&gt;-code=sm_80&lt;/code&gt; produces binary code for devices of &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability" target="_blank" rel="noopener"
&gt;compute capability&lt;/a&gt; 8.0. Binary compatibility is guaranteed from one minor revision to the next one, but not from one minor revision to the previous one or across major revisions. In other words, a &lt;em&gt;cubin&lt;/em&gt; object generated for compute capability &lt;em&gt;X.y&lt;/em&gt; will only execute on devices of compute capability &lt;em&gt;X.z&lt;/em&gt; where &lt;em&gt;z≥y&lt;/em&gt;.
Some &lt;em&gt;PTX&lt;/em&gt; instructions are &lt;strong&gt;only supported on devices of higher compute capabilities&lt;/strong&gt;. For example, &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-shuffle-functions" target="_blank" rel="noopener"
&gt;Warp Shuffle Functions&lt;/a&gt; are only supported on devices of compute capability 5.0 and above. The &lt;code&gt;-arch&lt;/code&gt; compiler option &lt;strong&gt;specifies the compute capability that is assumed when compiling C++ to &lt;em&gt;PTX&lt;/em&gt; code&lt;/strong&gt;. So, code that contains warp shuffle, for example, must be compiled with -arch=compute_50 (or higher).
&lt;em&gt;PTX&lt;/em&gt; code produced for some specific compute capability can always be compiled to binary code of &lt;strong&gt;greater or equal&lt;/strong&gt; compute capability. Note that a binary compiled from an earlier PTX version &lt;strong&gt;may not&lt;/strong&gt; make use of some hardware features. For example, a binary targeting devices of compute capability 7.0 (Volta) compiled from PTX generated for compute capability 6.0 (Pascal) will not make use of Tensor Core instructions, since these were not available on Pascal. As a result, the final binary may &lt;strong&gt;perform worse&lt;/strong&gt; than would be possible if the binary were generated using the latest version of PTX.
&lt;em&gt;PTX&lt;/em&gt; code compiled to target &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#architecture-specific-features" target="_blank" rel="noopener"
&gt;Architecture-Specific Features&lt;/a&gt; only runs on &lt;strong&gt;the exact same&lt;/strong&gt; physical architecture and nowhere else. Architecture-specific &lt;em&gt;PTX&lt;/em&gt; code is not forward and backward compatible. Example code compiled with sm_90a or compute_90a only runs on devices with compute capability 9.0 and is not backward or forward compatible.
&lt;em&gt;PTX&lt;/em&gt; code compiled to target &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#family-specific-features" target="_blank" rel="noopener"
&gt;Family-Specific Features&lt;/a&gt; only runs on the exact same physical architecture and other architectures in the same family. Family-specific &lt;em&gt;PTX&lt;/em&gt; code is &lt;strong&gt;forward&lt;/strong&gt; compatible with other devices in the same family, and is not backward compatible. Example code compiled with sm_100f or compute_100f only runs on devices with compute capability 10.0 and 10.3.
Which &lt;em&gt;PTX&lt;/em&gt; and binary code gets embedded in a CUDA C++ application is controlled by the -arch and -code compiler options or the -gencode compiler option.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;nvcc x.cu -gencode &lt;span class="nv"&gt;arch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;compute_50,code&lt;span class="o"&gt;=&lt;/span&gt;sm_50
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Applications using the driver API &lt;strong&gt;must&lt;/strong&gt; compile code to separate files and explicitly load and execute the most appropriate file at runtime.&lt;/p&gt;
&lt;h3 id="runtime"&gt;Runtime
&lt;/h3&gt;&lt;p&gt;The runtime is implemented in the cudart library, which is linked to the application, either &lt;strong&gt;statically&lt;/strong&gt; via &lt;code&gt;cudart.lib&lt;/code&gt; or &lt;code&gt;libcudart.a&lt;/code&gt;, or dynamically via &lt;code&gt;cudart.dll&lt;/code&gt; or &lt;code&gt;libcudart.so&lt;/code&gt;. Applications that require cudart.dll and/or cudart.so for dynamic linking typically include them as part of the application installation package. It is only safe to pass the address of CUDA runtime symbols between components that link to the same instance of the CUDA runtime.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;cudart.lib 和 libcudart.a 都是 &lt;strong&gt;CUDA Runtime 库的静态链接版本&lt;/strong&gt;，核心区别在于 &lt;strong&gt;操作系统平台和编译工具链的兼容性&lt;/strong&gt;。
&lt;strong&gt;cudart.lib&lt;/strong&gt; / &lt;strong&gt;cudart.dll&lt;/strong&gt;: windows
&lt;strong&gt;libcudart.a&lt;/strong&gt; / cudart.so : Linux / macos
All its entry points are &lt;strong&gt;prefixed with cuda&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="initialization"&gt;Initialization
&lt;/h4&gt;&lt;p&gt;CUDA 12.0&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心变化&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cudaInitDevice() 与 cudaSetDevice() &lt;strong&gt;在CUDA 12.0中成为&lt;/strong&gt;显式初始化入口&lt;/strong&gt;。调用二者之一会立即：✅ 初始化CUDA运行时库✅ 创建指定设备的Primary Context（主上下文）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;未调用时的默认行为&lt;/strong&gt; ：运行时自动选择device 0，并在首次需要时隐式初始化（如调用cudaMalloc或内核启动）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工程意义&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;性能分析&lt;/strong&gt; ：显式初始化将耗时集中在可控阶段，避免首次API调用的延迟干扰计时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;错误处理&lt;/strong&gt; ：必须检查cudaSetDevice()的返回值（如cudaError_t），因其可能返回设备初始化错误（如cudaErrorInvalidDevice）
历史行为（CUDA 11.x及更早）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaSetDevice()的局限性 &lt;strong&gt;：仅设置当前设备，&lt;/strong&gt; 不触发运行时初始化&lt;/strong&gt;。运行时需通过其他API调用被动初始化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaFree(0)的妙用 &lt;strong&gt;：开发者调用此&amp;quot;空操作&amp;quot;函数（释放空指针）作为&lt;/strong&gt;显式初始化触发器&lt;/strong&gt;，目的包括：✅ 隔离初始化耗时（方便性能分析）✅ 提前捕获初始化错误（避免首次业务API调用失败）&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 设置设备（不初始化运行时）
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 强制初始化运行时并检查错误
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaError_t&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cudaGetLastError&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 验证初始化状态
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The runtime creates a CUDA context for each device in the system (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#context" target="_blank" rel="noopener"
&gt;Context&lt;/a&gt; for more details on CUDA contexts). This context is the &lt;strong&gt;primary context&lt;/strong&gt; for this device and is initialized at &lt;strong&gt;the first runtime&lt;/strong&gt; function which requires an active context on this device. It is &lt;strong&gt;shared among all the host threads&lt;/strong&gt; of the application. As part of this context creation, the device code is just-in-time compiled if necessary (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#just-in-time-compilation" target="_blank" rel="noopener"
&gt;Just-in-Time Compilation&lt;/a&gt;) and loaded into device memory. This all happens transparently.&lt;/p&gt;
&lt;h4 id="device-memory"&gt;Device Memory
&lt;/h4&gt;&lt;p&gt;Device memory can be allocated either as &lt;em&gt;&lt;strong&gt;linear memory&lt;/strong&gt;&lt;/em&gt; or as &lt;em&gt;&lt;strong&gt;CUDA arrays&lt;/strong&gt;&lt;/em&gt;.
CUDA arrays are opaque memory layouts optimized for texture fetching. They are described in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#texture-and-surface-memory" target="_blank" rel="noopener"
&gt;Texture and Surface Memory&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;不透明内存布局（Opaque Memory Layout）&lt;/strong&gt; ：CUDA数组的物理存储结构对开发者完全隐藏，无法通过指针直接访问内部数据。其布局由GPU驱动动态优化，专为&lt;strong&gt;纹理拾取（Texture Fetching）&lt;/strong&gt; 场景设计。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;纹理/表面内存优化&lt;/strong&gt; ：数据以适合纹理缓存的格式存储，支持硬件加速的&lt;strong&gt;坐标寻址、滤波（如双线性插值）和边界处理&lt;/strong&gt; （钳位/循环模式）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多维数据结构&lt;/strong&gt; ：天然支持&lt;strong&gt;一维、二维或三维&lt;/strong&gt;数据（如图像、体渲染数据），无需手动计算内存步长（Pitch）。
Linear memory is allocated in a single unified address space, which means that separately allocated entities can reference one another via pointers, for example, in a binary tree or linked list. 
支持任意数据结构，但&lt;strong&gt;多维数据需对齐&lt;/strong&gt; （用cudaMallocPitch/cudaMalloc3D避免Bank Conflict）
Linear memory is typically allocated using &lt;code&gt;cudaMalloc()&lt;/code&gt; and freed using &lt;code&gt;cudaFree()&lt;/code&gt; and data transfer between host memory and device memory are typically done using &lt;code&gt;cudaMemcpy()&lt;/code&gt;.
Linear memory can also be allocated through &lt;code&gt;cudaMallocPitch()&lt;/code&gt; and &lt;code&gt;cudaMalloc3D()&lt;/code&gt;. These functions are recommended for allocations of 2D or 3D arrays as it makes sure that the allocation is &lt;strong&gt;appropriately padded&lt;/strong&gt; to meet the alignment requirements described in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses" target="_blank" rel="noopener"
&gt;Device Memory Accesses&lt;/a&gt;, therefore &lt;strong&gt;ensuring best performance&lt;/strong&gt; when accessing the row addresses or performing copies between 2D arrays and other regions of device memory (using the &lt;code&gt;cudaMemcpy2D()&lt;/code&gt; and &lt;code&gt;cudaMemcpy3D()&lt;/code&gt; functions). The returned pitch (or stride) must be used to access array elements. &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Host code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaMallocPitch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Device code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MyKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)((&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;devPtr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Pitch: &lt;strong&gt;每行实际分配的字节数&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="shared-memory"&gt;Shared Memory
&lt;/h4&gt;&lt;p&gt;&lt;img src="https://i.ibb.co/jNV47KT/image-6.png"
loading="lazy"
&gt;
Thread Block 中的每个 Thread 合力进行数据加载，一次加载一块&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrices are stored in row-major order:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// M(row, col) = *(M.elements + row * M.stride + col)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;typedef&lt;/span&gt; &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Get a matrix element
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;GetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Set a matrix element
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;SetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Get the BLOCK_SIZExBLOCK_SIZE sub-matrix Asub of A that is
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// located col sub-matrices to the right and row sub-matrices down
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// from the upper-left corner of A
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="nf"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Thread block size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#define BLOCK_SIZE 16
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Forward declaration of the matrix multiplication kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MatMulKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrix multiplication - Host code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrix dimensions are assumed to be multiples of BLOCK_SIZE
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MatMul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Load A and B to device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Allocate C in device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Invoke kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;dimGrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;MatMulKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dimGrid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Read C from device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Free device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrix multiplication kernel called by MatMul()
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MatMulKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Block row and column
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;blockRow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;blockCol&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Each thread block computes one sub-matrix Csub of C
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Csub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockRow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockCol&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Each thread computes one element of Csub
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// by accumulating results into Cvalue
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;Cvalue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Thread row and column within Csub
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Loop over all the sub-matrices of A and B that are
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// required to compute Csub
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Multiply each pair of sub-matrices together
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// and accumulate the results
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Get sub-matrix Asub of A
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Asub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockRow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Get sub-matrix Bsub of B
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Bsub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockCol&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Shared memory used to store Asub and Bsub respectively
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;As&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;Bs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Load Asub and Bsub from device memory to shared memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Each thread loads one element of each sub-matrix
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;As&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Bs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Bsub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Synchronize to make sure the sub-matrices are loaded
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// before starting the computation
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__syncthreads&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Multiply Asub and Bsub together
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Cvalue&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;As&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Bs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Synchronize to make sure that the preceding
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// computation is done before loading two new
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// sub-matrices of A and B in the next iteration
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__syncthreads&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Write Csub to device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Each thread writes one element
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;SetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Csub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Cvalue&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id="distributed-shared-memory"&gt;Distributed Shared Memory
&lt;/h4&gt;&lt;p&gt;Accessing data in distributed shared memory requires all the thread blocks to exist. A user can &lt;strong&gt;guarantee&lt;/strong&gt; that all thread blocks have started executing using &lt;code&gt;cluster.sync()&lt;/code&gt; from &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg" target="_blank" rel="noopener"
&gt;Cluster Group&lt;/a&gt; API. The user also needs to ensure that all distributed shared memory operations happen &lt;strong&gt;before the exit&lt;/strong&gt; of a thread block, e.g., if a remote thread block is trying to read a given thread block’s shared memory, user needs to ensure that the shared memory read by remote thread block is completed before it can exit.&lt;/p&gt;
&lt;h4 id="page-locked-host-memory"&gt;Page-Locked Host Memory
&lt;/h4&gt;&lt;p&gt;Page-locked host memory（页锁定主机内存，也称为 “固定内存” 或 “ pinned memory”）是一种特殊的主机内存分配方式，在 CUDA 编程中具有重要性能优化作用。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;普通内存（pageable memory）&lt;/strong&gt;：由操作系统动态管理，可被换出到虚拟内存，CPU 访问时需通过页表映射。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;页锁定内存&lt;/strong&gt;：通过cudaHostAlloc或cudaHostRegister等 API 分配，其物理地址在内存中保持固定，&lt;strong&gt;不会被操作系统换出&lt;/strong&gt;，且 CPU 和 GPU 可直接访问其物理地址。
页锁定内存绕过了操作系统的虚拟内存管理机制，直接映射到物理内存，避免了页面调度（page fault）的开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="memory-synchronization"&gt;Memory Synchronization
&lt;/h4&gt;&lt;p&gt;As the GPU cannot know at the time of execution which writes have been guaranteed at the source level to be visible and which are visible only by chance timing, it must cast a conservatively wide net for in-flight memory operations.
This sometimes leads to interference: because the GPU is waiting on memory operations it is not required to at the source level, the fence/flush may take longer than necessary.&lt;/p&gt;
&lt;h3 id="asynchronous-concurrent-execution"&gt;Asynchronous Concurrent Execution
&lt;/h3&gt;&lt;p&gt;CUDA exposes the following operations as independent tasks that can operate concurrently with one another:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computation on the host;&lt;/li&gt;
&lt;li&gt;Computation on the device;&lt;/li&gt;
&lt;li&gt;Memory transfers from the host to the device;&lt;/li&gt;
&lt;li&gt;Memory transfers from the device to the host;&lt;/li&gt;
&lt;li&gt;Memory transfers within the memory of a given device;&lt;/li&gt;
&lt;li&gt;Memory transfers among devices.
The level of concurrency achieved between these operations will depend on the feature set and compute capability of the device
Using asynchronous calls, many device operations can be queued up together to be executed by the CUDA driver when appropriate device resources are available. This relieves the host thread of much of the responsibility to manage the device, leaving it free for other tasks.
Kernel launches are &lt;strong&gt;synchronous&lt;/strong&gt; if hardware counters are collected via a &lt;strong&gt;profiler&lt;/strong&gt; (Nsight, Visual Profiler) unless concurrent kernel profiling is enabled. Async memory copies might also be synchronous if they involve host memory that is &lt;strong&gt;not page-locked&lt;/strong&gt;.
Concurrent host execution is facilitated through asynchronous library functions that &lt;strong&gt;return control to the host thread before the device completes the requested task&lt;/strong&gt;. Using asynchronous calls, many device operations can be queued up together to be executed by the CUDA driver when appropriate device resources are available. 
Programmers can globally disable asynchronicity of kernel launches for all CUDA applications running on a system by setting the &lt;strong&gt;CUDA_LAUNCH_BLOCKING&lt;/strong&gt; environment variable to 1. This feature is provided for &lt;strong&gt;debugging purposes only&lt;/strong&gt; and should not be used as a way to make production software run reliably.
A kernel from one CUDA context cannot execute concurrently with a kernel from another CUDA context. The GPU may time slice to provide forward progress to each context. If a user wants to run kernels from multiple process simultaneously on the SM, one must &lt;strong&gt;enable MPS&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="stream"&gt;Stream
&lt;/h3&gt;&lt;p&gt;Applications manage the concurrent operations described above through &lt;em&gt;&lt;strong&gt;streams&lt;/strong&gt;&lt;/em&gt;. A stream is &lt;strong&gt;a sequence of commands&lt;/strong&gt; (possibly issued by &lt;strong&gt;different&lt;/strong&gt; host threads) that execute in order. Different streams, on the other hand, may execute their commands out of order with respect to one another or concurrently; this behavior is not guaranteed and should therefore not be relied upon for correctness (for example, inter-kernel communication is undefined). The commands issued on a stream may execute &lt;strong&gt;when all the dependencies of the command are met&lt;/strong&gt;. The dependencies could be previously launched commands on &lt;strong&gt;same&lt;/strong&gt; stream or dependencies from &lt;strong&gt;other&lt;/strong&gt; streams. The successful completion of &lt;strong&gt;synchronize&lt;/strong&gt; call guarantees that all the commands launched are completed.&lt;/p&gt;
&lt;h4 id="default-stream"&gt;default stream
&lt;/h4&gt;&lt;p&gt;Kernel launches and host device memory copies that &lt;strong&gt;do not specify&lt;/strong&gt; any stream parameter, or equivalently that set the stream parameter to &lt;strong&gt;zero&lt;/strong&gt;, are issued to the &lt;strong&gt;default&lt;/strong&gt; stream. They are therefore executed in order.
For code that is compiled using the &lt;code&gt;--default-stream per-thread&lt;/code&gt; compilation flag (or that defines the &lt;code&gt;CUDA_API_PER_THREAD_DEFAULT_STREAM&lt;/code&gt; macro before including CUDA headers (cuda.h and cuda_runtime.h)), the default stream is a regular stream and each host thread has its own default stream.
For code that is compiled using the &lt;code&gt;—default-stream legacy&lt;/code&gt; compilation flag, the default stream is a special stream called the &lt;em&gt;&lt;strong&gt;NULL stream&lt;/strong&gt;&lt;/em&gt; and each device has a single NULL stream used for all host threads. The NULL stream is special as it causes implicit synchronization.
For code that is compiled without specifying a &lt;code&gt;—default-stream compilation&lt;/code&gt; flag, &lt;code&gt;—default-stream legacy&lt;/code&gt; is assumed as the &lt;strong&gt;default&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id="explicit-synchronization"&gt;explicit synchronization
&lt;/h4&gt;&lt;p&gt;There are various ways to explicitly synchronize streams with each other.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cudaDeviceSynchronize&lt;/strong&gt;() waits until all preceding commands in all streams of all host threads have completed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaStreamSynchronize&lt;/strong&gt;()takes a stream as a parameter and waits until all preceding commands in the given stream have completed. It can be used to synchronize the host with a specific stream, allowing other streams to continue executing on the device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaStreamWaitEvent&lt;/strong&gt;()takes a stream and an event as parameters (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#events" target="_blank" rel="noopener"
&gt;Events&lt;/a&gt; for a description of events)and makes all the commands added to the given stream after the call to cudaStreamWaitEvent()delay their execution until the given event has completed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaStreamQuery&lt;/strong&gt;()provides applications with a way to know if all preceding commands in a stream have completed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="implicit-synchronization"&gt;implicit synchronization
&lt;/h4&gt;&lt;p&gt;Two operations from different streams cannot run concurrently if any CUDA operation on the &lt;strong&gt;NULL stream is submitted in-between&lt;/strong&gt; them, &lt;strong&gt;unless&lt;/strong&gt; the streams are &lt;strong&gt;non-blocking streams&lt;/strong&gt; (created with the cudaStreamNonBlocking flag).
Applications should follow these guidelines to improve their potential for concurrent kernel execution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All independent operations should be issued before dependent operations,&lt;/li&gt;
&lt;li&gt;Synchronization of any kind should be delayed as long as possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;默认流（NULL流）的阻塞性&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NULL流的特性&lt;/strong&gt; ：默认流（未显式指定流时使用的流）具有&lt;strong&gt;隐式同步作用&lt;/strong&gt;。当主机向NULL流提交操作（如cudaMemcpy或核函数）时，它会强制等待&lt;strong&gt;所有先前提交到任何流中的操作完成&lt;/strong&gt;，自身执行结束后又会阻塞后续其他流的操作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并发中断原因&lt;/strong&gt; ：若在两个不同流的操作之间插入NULL流操作（例如：StreamA操作 → NULL流操作 → StreamB操作），则：
&lt;ul&gt;
&lt;li&gt;NULL流操作会等待StreamA操作完成才开始；&lt;/li&gt;
&lt;li&gt;StreamB操作必须等待NULL流操作完成后才能启动。&lt;em&gt;结果&lt;/em&gt;：StreamA和StreamB的操作被&lt;strong&gt;强制串行化&lt;/strong&gt;，无法并发执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;非阻塞流的例外&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;创建方式&lt;/strong&gt; ：使用cudaStreamCreateWithFlags(&amp;amp;stream, cudaStreamNonBlocking)创建的流称为&lt;strong&gt;非阻塞流&lt;/strong&gt; （Non-Blocking Stream）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;规避阻塞&lt;/strong&gt; ：非阻塞流&lt;strong&gt;不与NULL流同步&lt;/strong&gt;，因此：
&lt;ul&gt;
&lt;li&gt;即使NULL流操作插入在非阻塞流的操作之间（如NonBlockingStreamA操作 → NULL流操作 → NonBlockingStreamB操作），NonBlockingStreamA和NonBlockingStreamB的操作仍可&lt;strong&gt;并发执行&lt;/strong&gt; 。&lt;/li&gt;
&lt;li&gt;NULL流操作仅阻塞自身，不影响非阻塞流的独立性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="host-functions"&gt;&lt;strong&gt;Host Functions&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;The runtime provides a way to insert a CPU function call at any point into a stream via &lt;strong&gt;cudaLaunchHostFunc&lt;/strong&gt;(). The provided function is executed on the host once all commands issued to the stream before the callback have completed.
A host function enqueued into a stream must not make CUDA API calls (directly or indirectly), as it might end up waiting on itself if it makes such a call leading to a deadlock.&lt;/p&gt;
&lt;h4 id="priority"&gt;Priority
&lt;/h4&gt;&lt;p&gt;The relative priorities of streams can be specified at creation using cudaStreamCreateWithPriority(). The range of allowable priorities, ordered as [ greatest priority, least priority ] can be obtained using the cudaDeviceGetStreamPriorityRange() function.
These priorities serve as hints rather than guarantees.&lt;/p&gt;
&lt;h4 id="dependent-launch"&gt;Dependent Launch
&lt;/h4&gt;&lt;p&gt;The &lt;em&gt;Programmatic Dependent Launch&lt;/em&gt; mechanism allows for a dependent &lt;em&gt;secondary&lt;/em&gt; kernel to launch &lt;strong&gt;before&lt;/strong&gt; the &lt;em&gt;primary&lt;/em&gt; kernel it depends on in the same CUDA stream has finished executing. Available starting with devices of &lt;strong&gt;compute capability 9.0&lt;/strong&gt;, this technique can provide performance benefits when the &lt;em&gt;secondary&lt;/em&gt; kernel can complete &lt;strong&gt;significant&lt;/strong&gt; work that does not depend on the results of the &lt;em&gt;primary&lt;/em&gt; kernel.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;primary_kernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Initial work that should finish before starting secondary kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Trigger the secondary kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaTriggerProgrammaticLaunchCompletion&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Work that can coincide with the secondary kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;secondary_kernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Independent work
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Will block until all primary kernels the secondary kernel is dependent on have completed and flushed results to global memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaGridDependencySynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Dependent work
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaLaunchAttribute&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cudaLaunchAttributeProgrammaticStreamSerialization&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;programmaticStreamSerializationAllowed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;configSecondary&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;configSecondary&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numAttrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;primary_kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;grid_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;block_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaLaunchKernelEx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;configSecondary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;secondary_kernel&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="events"&gt;Events
&lt;/h3&gt;&lt;p&gt;The runtime also provides a way to closely monitor the device’s progress, as well as perform accurate timing, by letting the application asynchronously record &lt;em&gt;&lt;strong&gt;events&lt;/strong&gt;&lt;/em&gt; at any point in the program, and query when these events are completed. An event has completed when all tasks - or optionally, all commands in a given stream - preceding the event have completed. Events in &lt;strong&gt;stream zero&lt;/strong&gt; are completed after all preceding tasks and commands in &lt;strong&gt;all streams&lt;/strong&gt; are completed.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEvent_t&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventCreate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventCreate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventDestroy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventDestroy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Timing&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventRecord&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputHost&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputHost&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;outputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventRecord&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventSynchronize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;elapsedTime&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventElapsedTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;elapsedTime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="error-checking"&gt;Error Checking
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;All runtime functions return an error code&lt;/strong&gt;, but for an asynchronous function (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-concurrent-execution" target="_blank" rel="noopener"
&gt;Asynchronous Concurrent Execution&lt;/a&gt;), this error code cannot possibly report any of the asynchronous errors that could occur on the device since the function returns before the device has completed the task; the error code only reports errors that occur on the host prior to executing the task, typically related to parameter validation; if an asynchronous error occurs, it will be reported by some subsequent unrelated runtime function call.
The only way to check for asynchronous errors just after some asynchronous function call is therefore to &lt;strong&gt;synchronize just after the call&lt;/strong&gt; by calling cudaDeviceSynchronize() (or by using any other synchronization mechanisms described in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-concurrent-execution" target="_blank" rel="noopener"
&gt;Asynchronous Concurrent Execution&lt;/a&gt;) and checking the error code returned by cudaDeviceSynchronize().
The runtime maintains an error variable for each host thread that is initialized to cudaSuccess and is overwritten by the error code every time an error occurs (be it a parameter validation error or an asynchronous error). &lt;strong&gt;cudaPeekAtLastError&lt;/strong&gt;() returns this variable. &lt;strong&gt;cudaGetLastError&lt;/strong&gt;() returns this variable and &lt;strong&gt;resets&lt;/strong&gt; it to cudaSuccess.
Kernel launches do not return any error code, so cudaPeekAtLastError() or cudaGetLastError() &lt;strong&gt;must be called just after the kernel launch to retrieve any pre-launch errors&lt;/strong&gt;. To ensure that any error returned by cudaPeekAtLastError() or cudaGetLastError() does not originate from calls prior to the kernel launch, one has to make sure that the runtime error variable is set to cudaSuccess just before the kernel launch, for example, by calling cudaGetLastError() just before the kernel launch. Kernel launches are asynchronous, so to check for asynchronous errors, the application must &lt;strong&gt;synchronize in-between&lt;/strong&gt; the kernel launch and the call to cudaPeekAtLastError() or cudaGetLastError().
Note that cudaErrorNotReady that may be returned by cudaStreamQuery() and cudaEventQuery() is not considered an error and is therefore not reported by cudaPeekAtLastError() or cudaGetLastError().&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;设计逻辑&lt;/strong&gt; ：cudaErrorNotReady 是正常状态（表示“进行中”），而非错误&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="compute-mode"&gt;Compute Mode
&lt;/h3&gt;&lt;p&gt;On Tesla solutions running Windows Server 2008 and later or Linux, one can set any device in a system in one of the three following modes using &lt;strong&gt;NVIDIA’s System Management Interface (nvidia-smi)&lt;/strong&gt;, which is a tool distributed as part of the driver:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Default&lt;/em&gt; compute mode&lt;/strong&gt;: Multiple host threads can use the device (by calling cudaSetDevice() on this device, when using the runtime API, or by making current a context associated to the device, when using the driver API) at the same time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Exclusive-process&lt;/em&gt; compute mode&lt;/strong&gt;: Only one CUDA context may be created on the device across all processes in the system. The context may be current to as many threads as desired within the process that created that context.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Prohibited&lt;/em&gt; compute mode&lt;/strong&gt;: No CUDA context can be created on the device.
⠀This means, in particular, that a host thread using the runtime API without explicitly calling cudaSetDevice() might be associated with a device &lt;strong&gt;other than device 0&lt;/strong&gt; if device 0 turns out to be in prohibited mode or in exclusive-process mode and used by another process. cudaSetValidDevices() can be used to set a device from a prioritized list of devices.
Note also that, for devices featuring the Pascal architecture onwards (compute capability with major revision number 6 and higher), there exists support for &lt;strong&gt;Compute Preemption&lt;/strong&gt;. This allows compute tasks to be preempted at instruction-level granularity, rather than thread block granularity as in prior Maxwell and Kepler GPU architecture, with the benefit that applications with long-running kernels can be prevented from either monopolizing the system or timing out. However, there will be &lt;strong&gt;context switch overheads&lt;/strong&gt; associated with Compute Preemption, which is &lt;strong&gt;automatically enabled&lt;/strong&gt; on those devices for which support exists. The individual attribute query function cudaDeviceGetAttribute() with the attribute &lt;strong&gt;cudaDevAttrComputePreemptionSupported&lt;/strong&gt; can be used to determine if the device in use supports Compute Preemption. Users wishing to avoid context switch overheads associated with different processes can ensure that only one process is active on the GPU by &lt;strong&gt;selecting exclusive-process mode&lt;/strong&gt;.
Applications may query the compute mode of a device by checking the computeMode device property (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-enumeration" target="_blank" rel="noopener"
&gt;Device Enumeration&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="hardware-implementation"&gt;Hardware Implementation
&lt;/h2&gt;&lt;p&gt;The NVIDIA GPU architecture is built around a &lt;strong&gt;scalable&lt;/strong&gt; array of &lt;strong&gt;multithreaded &lt;em&gt;Streaming Multiprocessors&lt;/em&gt;&lt;/strong&gt; (&lt;em&gt;SMs&lt;/em&gt;). When a CUDA program on the host CPU invokes a kernel grid, the blocks of the grid are enumerated and distributed to multiprocessors with available execution capacity. The threads of a thread block execute concurrently on one multiprocessor, and multiple thread blocks can execute concurrently on one multiprocessor. As thread blocks terminate, new blocks are launched on the vacated multiprocessors.
A multiprocessor is designed to execute hundreds of threads concurrently. To manage such a large number of threads, it employs a unique architecture called &lt;em&gt;&lt;strong&gt;SIMT&lt;/strong&gt;&lt;/em&gt; (&lt;em&gt;Single-Instruction, Multiple-Thread&lt;/em&gt;) that is described in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture" target="_blank" rel="noopener"
&gt;SIMT Architecture&lt;/a&gt;. The instructions are pipelined, leveraging instruction-level parallelism within a single thread, as well as extensive thread-level parallelism through simultaneous hardware multithreading as detailed in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading" target="_blank" rel="noopener"
&gt;Hardware Multithreading&lt;/a&gt;. Unlike CPU cores, they are issued in order and there is no branch prediction or speculative execution.
The NVIDIA GPU architecture uses a &lt;strong&gt;little-endian&lt;/strong&gt; representation.&lt;/p&gt;
&lt;h3 id="simt"&gt;SIMT
&lt;/h3&gt;&lt;p&gt;The multiprocessor creates, manages, schedules, and executes threads in &lt;strong&gt;groups of 32 parallel threads&lt;/strong&gt; called &lt;em&gt;warps&lt;/em&gt;. Individual threads composing a warp start together at the same program address, but they have their own instruction address counter and register state and are therefore free to branch and execute independently. The term &lt;em&gt;warp&lt;/em&gt; originates from &lt;strong&gt;weaving&lt;/strong&gt;, the first parallel thread technology. A &lt;em&gt;half-warp&lt;/em&gt; is either the first or second half of a warp. A &lt;em&gt;quarter-warp&lt;/em&gt; is either the first, second, third, or fourth quarter of a warp.
When a multiprocessor is &lt;strong&gt;given one or more thread blocks&lt;/strong&gt; to execute, it partitions them into warps and each warp gets scheduled by a &lt;em&gt;&lt;strong&gt;warp scheduler&lt;/strong&gt;&lt;/em&gt; for execution. The way a block is partitioned into warps is always the same; each warp contains threads of consecutive, increasing thread IDs with the first warp containing thread 0. &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy" target="_blank" rel="noopener"
&gt;Thread Hierarchy&lt;/a&gt; describes how thread IDs relate to thread indices in the block.
A warp executes one common instruction at a time, so &lt;strong&gt;full&lt;/strong&gt; efficiency is realized when all 32 threads of a warp &lt;strong&gt;agree&lt;/strong&gt; on their execution path. If threads of a warp diverge via a data-dependent conditional branch, the warp &lt;strong&gt;executes each&lt;/strong&gt; branch path taken, disabling threads that are not on that path. Branch divergence occurs only within a warp; different warps execute independently regardless of whether they are executing common or disjoint code paths.
The SIMT architecture is &lt;strong&gt;akin&lt;/strong&gt; to SIMD (Single Instruction, Multiple Data) vector organizations in that a single instruction controls multiple processing elements. A key difference is that SIMD vector organizations expose the SIMD width to the software, whereas SIMT instructions specify the execution and branching behavior of a single thread. In contrast with SIMD vector machines, SIMT enables programmers to write &lt;strong&gt;thread-level parallel&lt;/strong&gt; code for independent, scalar threads, as well as data-parallel code for coordinated threads. For the purposes of correctness, the programmer can essentially ignore the SIMT behavior; however, substantial performance improvements can be realized by taking care that the code seldom requires threads in a warp to diverge. In practice, this is analogous to the role of cache lines in traditional code: Cache line size can be safely ignored when designing for correctness but must be considered in the code structure when designing for peak performance. Vector architectures, on the other hand, require the software to coalesce loads into vectors and manage divergence manually.
&lt;strong&gt;Prior to NVIDIA Volta, warps used a single program counter shared amongst all 32 threads in the warp together with an active mask specifying the active threads of the warp&lt;/strong&gt;. As a result, threads from the same warp in divergent regions or different states of execution cannot signal each other or exchange data, and algorithms requiring fine-grained sharing of data guarded by locks or mutexes can easily lead to deadlock, depending on which warp the contending threads come from.
Starting with the NVIDIA Volta architecture, &lt;em&gt;&lt;strong&gt;Independent Thread Scheduling&lt;/strong&gt;&lt;/em&gt; allows full concurrency between threads, regardless of warp. With Independent Thread Scheduling, the GPU maintains execution state per thread, including a program counter and call stack, and can yield execution at a per-thread granularity, either to make better use of execution resources or to allow one thread to wait for data to be produced by another. &lt;strong&gt;A schedule optimizer determines how to group active threads from the same warp together into SIMT units&lt;/strong&gt;. This retains the high throughput of SIMT execution as in prior NVIDIA GPUs, but with much more flexibility: threads can now diverge and reconverge at sub-warp granularity.
Independent Thread Scheduling can lead to a rather different set of threads participating in the executed code than intended if the developer made assumptions about warp-synchronicity&lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#fn2" target="_blank" rel="noopener"
&gt;2&lt;/a&gt; of previous hardware architectures. In particular, any warp-synchronous code (such as synchronization-free, intra-warp reductions) should be &lt;strong&gt;revisited&lt;/strong&gt; to ensure compatibility with NVIDIA Volta and beyond. See &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x" target="_blank" rel="noopener"
&gt;Compute Capability 7.x&lt;/a&gt; for further details.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The threads of a warp that are participating in the current instruction are called the &lt;em&gt;&lt;strong&gt;active&lt;/strong&gt;&lt;/em&gt; threads, whereas threads not on the current instruction are &lt;em&gt;inactive&lt;/em&gt; (disabled). Threads can be inactive for a variety of reasons including having exited earlier than other threads of their warp, having taken a different branch path than the branch path currently executed by the warp, or being the last threads of a block whose number of threads is not a multiple of the warp size.
If a &lt;strong&gt;non-atomic&lt;/strong&gt; instruction executed by a warp writes to the same location in global or shared memory for more than one of the threads of the warp, the number of serialized writes that occur to that location varies depending on the compute capability of the device (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-5-x" target="_blank" rel="noopener"
&gt;Compute Capability 5.x&lt;/a&gt;, &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-6-x" target="_blank" rel="noopener"
&gt;Compute Capability 6.x&lt;/a&gt;, and &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x" target="_blank" rel="noopener"
&gt;Compute Capability 7.x&lt;/a&gt;), and which thread performs the final write is undefined.
If an &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions" target="_blank" rel="noopener"
&gt;atomic&lt;/a&gt; instruction executed by a warp reads, modifies, and writes to the same location in global memory for more than one of the threads of the warp, each read/modify/write to that location occurs and they are all serialized, but the order in which they occur is undefined.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="hardware-multithreading"&gt;Hardware Multithreading
&lt;/h3&gt;&lt;p&gt;The execution &lt;strong&gt;context&lt;/strong&gt; (program counters, registers, and so on) for each warp processed by a multiprocessor is maintained on-chip during the entire lifetime of the warp. Therefore, switching from one execution context to another has &lt;strong&gt;no&lt;/strong&gt; &lt;strong&gt;cost&lt;/strong&gt;, and at every instruction issue time, a warp scheduler &lt;strong&gt;selects&lt;/strong&gt; a warp that has threads ready to execute its next instruction (the &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture-notes" target="_blank" rel="noopener"
&gt;active threads&lt;/a&gt; of the warp) and issues the instruction to those threads.
In particular, each multiprocessor has a set of 32-bit registers that are partitioned among the warps, and a &lt;em&gt;parallel data cache&lt;/em&gt; or &lt;em&gt;&lt;strong&gt;shared memory&lt;/strong&gt;&lt;/em&gt; that is partitioned among the thread blocks.
The number of blocks and warps that can reside and be processed together on the multiprocessor for a given kernel depends on the amount of registers and shared memory used by the kernel and the amount of registers and shared memory available on the multiprocessor. There are also a &lt;strong&gt;maximum number&lt;/strong&gt; of resident blocks and a maximum number of resident warps per multiprocessor. These limits as well the amount of registers and shared memory available on the multiprocessor are a function of the compute capability of the device and are given in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities" target="_blank" rel="noopener"
&gt;Compute Capabilities&lt;/a&gt;. If there are not enough registers or shared memory available per multiprocessor to process &lt;strong&gt;at least one block&lt;/strong&gt;, the kernel will fail to launch.&lt;/p&gt;
&lt;h2 id="cooperative-groups"&gt;Cooperative Groups
&lt;/h2&gt;&lt;p&gt;Cooperative Groups is an extension to the CUDA programming model, introduced in &lt;strong&gt;CUDA 9&lt;/strong&gt;, for organizing groups of communicating threads. Cooperative Groups allows developers to express the granularity at which threads are communicating, helping them to express richer, more efficient parallel decompositions.
Historically, the CUDA programming model has provided a single, simple construct for synchronizing cooperating threads: a barrier across all threads of a thread &lt;strong&gt;block&lt;/strong&gt;, as implemented with the &lt;strong&gt;__syncthreads()&lt;/strong&gt; intrinsic function. However, programmers would like to define and synchronize groups of threads at other granularities to enable greater performance, design flexibility, and software reuse in the form of “collective” group-wide function interfaces. In an effort to express broader patterns of parallel interaction, many performance-oriented programmers have resorted to writing their own ad hoc and unsafe primitives for synchronizing threads within a single warp, or across sets of thread blocks running on a single GPU. Whilst the performance improvements achieved have often been valuable, this has resulted in an ever-growing collection of brittle code that is expensive to write, tune, and maintain over time and across GPU generations. Cooperative Groups addresses this by providing a &lt;strong&gt;safe&lt;/strong&gt; and &lt;strong&gt;future-proof&lt;/strong&gt; mechanism to enable performant code.
header.h&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Primary header is compatible with pre-C++11, collective algorithm headers require C++11
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Optionally include for memcpy_async() collective
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Optionally include for reduce() collective
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/reduce.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Optionally include for inclusive_scan() and exclusive_scan() collectives
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/scan.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;namespace&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Alternatively use an alias to avoid polluting the namespace with collective algorithms
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;cg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="group-type"&gt;Group Type
&lt;/h3&gt;&lt;h4 id="implicit-groups"&gt;Implicit Groups
&lt;/h4&gt;&lt;p&gt;Implicit groups represent the &lt;strong&gt;launch configuration&lt;/strong&gt; of the kernel. Regardless of how your kernel is written, it always has a set number of threads, blocks and block dimensions, a single grid and grid dimensions. In addition, if the &lt;strong&gt;multi-device cooperative launch API&lt;/strong&gt; is used, it can have multiple grids (single grid per device). These groups provide a starting point for decomposition into finer grained groups which are typically HW accelerated and are more specialized for the problem the developer is solving.
Although you can create an implicit group anywhere in the code, it is &lt;strong&gt;dangerous&lt;/strong&gt; to do so. Creating a handle for an implicit group is a collective operation—&lt;strong&gt;all&lt;/strong&gt; threads in the group must participate. If the group was created in a conditional branch that not all threads reach, this can lead to deadlocks or data corruption. For this reason, it is recommended that you create a handle for the implicit group &lt;strong&gt;upfront&lt;/strong&gt; (as early as possible, before any branching has occurred) and use that handle throughout the kernel. Group handles must be initialized at declaration time (there is no default constructor) for the same reason and copy-constructing them is discouraged.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thread Block Group
Any CUDA programmer is already familiar with a certain group of threads: the thread block. The Cooperative Groups extension introduces a new datatype, &lt;strong&gt;thread_block&lt;/strong&gt;, to explicitly represent this concept within the kernel.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_block&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Cluster Group
This group object represents all the threads launched in a single cluster. Refer to &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-block-clusters" target="_blank" rel="noopener"
&gt;Thread Block Clusters&lt;/a&gt;. The APIs are available on all hardware with Compute &lt;strong&gt;Capability 9.0+&lt;/strong&gt;. In such cases, when a non-cluster grid is launched, the APIs assume a &lt;strong&gt;1x1x1&lt;/strong&gt; cluster.&lt;/li&gt;
&lt;li&gt;Grid Group
This group object represents all the threads launched in a single grid. APIs other than sync() are available at all times, but to be able to synchronize across the grid, you need to use the &lt;strong&gt;cooperative launch API&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;grid_group&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_grid&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id="explicit-groups"&gt;Explicit Groups
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Thread Block Tile
A templated version of a tiled group, where a &lt;strong&gt;template parameter&lt;/strong&gt; is used to specify the size of the tile - with this known at compile time there is the potential for more optimal execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;cooperative_kernel&lt;/span&gt;&lt;span class="p"&gt;(...)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// obtain default &amp;#34;current thread block&amp;#34; group
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;thread_block&lt;/span&gt; &lt;span class="n"&gt;my_block&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// subdivide into 32-thread, tiled subgroups
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Tiled subgroups evenly partition a parent group into
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// adjacent sets of threads - in this case each one warp in size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;my_tile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tiled_partition&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_block&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// This operation will be performed by only the
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// first 32-thread tile of each block
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_tile&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;meta_group_rank&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// ...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;my_tile&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sync&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Single Thread Group&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;memcpy_async&lt;/strong&gt; API uses a thread_group, to copy an int element from source to destination:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;memcpy_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Coalesced Groups
In CUDA’s SIMT architecture, at the hardware level the multiprocessor executes threads in groups of 32 called warps. If there exists a data-dependent conditional branch in the application code such that threads within a warp diverge, then the warp serially executes each branch disabling threads not on that path. &lt;strong&gt;The threads that remain active on the path are referred to as coalesced&lt;/strong&gt;. Cooperative Groups has functionality to discover, and create, a group containing all coalesced threads.
Constructing the group handle via &lt;strong&gt;coalesced_threads&lt;/strong&gt;() is opportunistic. It returns the set of active threads at that point in time, and makes no guarantee about which threads are returned (as long as they are active) or that they will stay coalesced throughout execution (they will be brought back together for the execution of a collective but can diverge again afterwards).&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;active&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coalesced_threads&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="group-partitioning"&gt;Group Partitioning
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;ParentT&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ParentT&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;tiled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;ParentT&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_group&lt;/span&gt; &lt;span class="nf"&gt;tiled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;thread_group&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;parent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;tilesz&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;strong&gt;tiled_partition&lt;/strong&gt; method is a collective operation that partitions the parent group into a one-dimensional, row-major, tiling of subgroups. A total of ((size(parent)/tilesz) subgroups will be created, therefore the parent group size &lt;strong&gt;must be evenly divisible&lt;/strong&gt; by the Size. The allowed parent groups are thread_block or thread_block_tile.
The implementation may cause the calling thread to &lt;strong&gt;wait&lt;/strong&gt; until all the members of the parent group have invoked the operation before resuming execution. Functionality is limited to native hardware sizes, 1/2/4/8/16/32 and the cg::size(parent) must be greater than the Size parameter. The templated version of tiled_partition supports 64/128/256/512 sizes as well, but some additional steps are required on Compute Capability 7.5 or lower.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;labeled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;coalesced_group&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;labeled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Label&lt;/strong&gt; can be any integral type.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="nf"&gt;binary_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;coalesced_group&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;binary_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is a specialized form of &lt;strong&gt;labeled_partition&lt;/strong&gt;(), where the label can only be 0 or 1.&lt;/p&gt;
&lt;h3 id="group-collectives"&gt;Group Collectives
&lt;/h3&gt;&lt;p&gt;Cooperative Groups library provides a set of &lt;strong&gt;collective operations&lt;/strong&gt; that can be performed by a group of threads. These operations require &lt;strong&gt;participation of all threads&lt;/strong&gt; in the specified group in order to complete the operation. All threads in the group need to pass the &lt;strong&gt;same&lt;/strong&gt; values for corresponding arguments to each collective call, unless different values are explicitly allowed in the argument description. Otherwise the behavior of the call is undefined.&lt;/p&gt;
&lt;h4 id="memcpy_async"&gt;memcpy_async
&lt;/h4&gt;&lt;p&gt;memcpy_async is a &lt;strong&gt;group-wide&lt;/strong&gt; collective memcpy that utilizes hardware accelerated support for non-blocking memory transactions &lt;strong&gt;from global to shared memory&lt;/strong&gt;. Given a set of threads named in the group, memcpy_async will move specified amount of bytes or elements of the input type through a single pipeline stage. Additionally for achieving best performance when using the memcpy_async API, &lt;strong&gt;an alignment of 16 bytes&lt;/strong&gt; for both shared memory and global memory is required. It is important to note that while this is a memcpy in the general case, it is only asynchronous if the source is global memory and the destination is shared memory and both &lt;strong&gt;can be addressed with 16, 8, or 4 byte alignments&lt;/strong&gt;. Asynchronously copied data should only be read following a call to wait or wait_prior which signals that the corresponding stage has completed moving data to shared memory.
Having to wait on all outstanding requests can lose some flexibility (but gain simplicity). In order to efficiently overlap data transfer and execution, its important to be able to kick off an &lt;strong&gt;N+1&lt;/strong&gt;memcpy_async request while waiting on and operating on request &lt;strong&gt;N&lt;/strong&gt;. To do so, use memcpy_async and wait on it using the collective stage-based wait_prior API. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;/// This example streams elementsPerThreadBlock worth of data from global memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;/// into a limited sized shared memory (elementsInShared) block to operate on.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;cg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;global_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;thread_block&lt;/span&gt; &lt;span class="n"&gt;tb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;elementsInShared&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;local_smem&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elementsInShared&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;copy_count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;memcpy_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tb&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;local_smem&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elementsInShared&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_data&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;copy_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;elementsInShared&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tb&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Work with local_smem
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;copy_count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="multi-device"&gt;Multi-Device
&lt;/h3&gt;&lt;p&gt;In order to enable synchronization across multiple devices with Cooperative Groups, use of the &lt;strong&gt;cudaLaunchCooperativeKernelMultiDevice&lt;/strong&gt; CUDA API is required. This, a significant departure from existing CUDA APIs, will allow a single host thread to launch a kernel across multiple devices.
Deprecation Notice: &lt;strong&gt;cudaLaunchCooperativeKernelMultiDevice&lt;/strong&gt; has been deprecated in CUDA 11.3 for all devices. Example of an alternative approach can be found in the multi device conjugate gradient sample.
Optimal performance in multi-device synchronization is achieved by enabling peer access via &lt;strong&gt;cuCtxEnablePeerAccess&lt;/strong&gt; or &lt;strong&gt;cudaDeviceEnablePeerAccess&lt;/strong&gt; for all participating devices.&lt;/p&gt;
&lt;h2 id="c-language-extensions"&gt;C++ Language Extensions
&lt;/h2&gt;&lt;h3 id="function-execution-space-specifier"&gt;Function Execution Space Specifier
&lt;/h3&gt;&lt;h4 id="__global__"&gt;__global__
&lt;/h4&gt;&lt;p&gt;The __global__ execution space specifier declares a function as &lt;strong&gt;being a kernel&lt;/strong&gt;. Such a function is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executed on the device,&lt;/li&gt;
&lt;li&gt;Callable from the host,&lt;/li&gt;
&lt;li&gt;Callable from the device for devices of compute capability 5.0 or higher 
A __global__ function must have &lt;strong&gt;void&lt;/strong&gt; return type, and cannot be a member of a class.
Any call to a __global__ function must specify its &lt;strong&gt;execution configuration&lt;/strong&gt; as described in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;.
A call to a __global__ function is &lt;strong&gt;asynchronous&lt;/strong&gt;, meaning it returns before the device has completed its execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="__device__"&gt;__device__
&lt;/h4&gt;&lt;p&gt;The __device__ execution space specifier declares a function that is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executed on the device,&lt;/li&gt;
&lt;li&gt;Callable from the &lt;strong&gt;device only&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="__host__"&gt;__host__ 
&lt;/h4&gt;&lt;p&gt;⠀The __host__ execution space specifier declares a function that is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executed on the host,&lt;/li&gt;
&lt;li&gt;Callable from the &lt;strong&gt;host only.&lt;/strong&gt;
It is equivalent to declare a function &lt;strong&gt;with only&lt;/strong&gt; the __host__ execution space specifier or to declare it &lt;strong&gt;without&lt;/strong&gt; any of the __host__, __device__, or __global__ execution space specifier; in either case the function is compiled for the host only.
The __device__ and __host__ execution space specifiers can be used together however, in which case the function is &lt;strong&gt;compiled for both&lt;/strong&gt; the host and the device. The __CUDA_ARCH__ macro introduced in &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#application-compatibility" target="_blank" rel="noopener"
&gt;Application Compatibility&lt;/a&gt; can be used to differentiate code paths between host and device:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="nf"&gt;func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#if __CUDA_ARCH__ &amp;gt;= 800
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 8.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif __CUDA_ARCH__ &amp;gt;= 700
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 7.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif __CUDA_ARCH__ &amp;gt;= 600
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 6.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif __CUDA_ARCH__ &amp;gt;= 500
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 5.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif !defined(__CUDA_ARCH__)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Host code path
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#endif
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id="inline"&gt;inline
&lt;/h4&gt;&lt;p&gt;The compiler inlines any __device__ function when &lt;strong&gt;deemed&lt;/strong&gt; appropriate.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The __noinline__ function qualifier can be used as a hint for the compiler &lt;strong&gt;not to inline&lt;/strong&gt; the function if possible.&lt;/li&gt;
&lt;li&gt;The __forceinline__ function qualifier can be used to &lt;strong&gt;force&lt;/strong&gt; the compiler to inline the function.&lt;/li&gt;
&lt;li&gt;The __inline_hint__ qualifier enables more &lt;strong&gt;aggressive&lt;/strong&gt; inlining in the compiler. Unlike __forceinline__, it does not imply that the function is inline. It can be used to improve inlining across modules when using LTO.
The __noinline__ and __forceinline__ function qualifiers cannot be used together, and neither function qualifier can be applied to an inline function.
Neither the __noinline__ nor the __forceinline__ function qualifier can be used with the __inline_hint__ function qualifier.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="variable-memory-space-specifier"&gt;Variable Memory Space Specifier
&lt;/h3&gt;&lt;h4 id="__device__-1"&gt;__device__
&lt;/h4&gt;&lt;p&gt;The __device__ memory space specifier declares a variable that &lt;strong&gt;resides on the device&lt;/strong&gt;.
At most one of __constant__, __managed__ and __shared__ may be used together with __device__ to further denote which memory space the variable belongs to. If none of them is present, the variable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resides in &lt;strong&gt;global&lt;/strong&gt; memory space,&lt;/li&gt;
&lt;li&gt;Has the lifetime of the CUDA context in which it is created,&lt;/li&gt;
&lt;li&gt;Has a distinct object per device,&lt;/li&gt;
&lt;li&gt;Is accessible from all the threads within the grid and from the host through the runtime library (cudaGetSymbolAddress() / cudaGetSymbolSize() / cudaMemcpyToSymbol() / cudaMemcpyFromSymbol()).&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;GPU 上的线程可直接读写该变量；主机（CPU）需通过 CUDA Runtime API 间接访问&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="__shared__"&gt;__shared__
&lt;/h4&gt;&lt;p&gt;The __shared__ memory space specifier, optionally used together with __device__, declares a variable that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resides in the shared memory space of a thread block,&lt;/li&gt;
&lt;li&gt;Has the lifetime of the block,&lt;/li&gt;
&lt;li&gt;Has a &lt;strong&gt;distinct object per block&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;Is only accessible from all the threads within the block,&lt;/li&gt;
&lt;li&gt;Does not have a &lt;strong&gt;constant address&lt;/strong&gt;.
⠀When declaring a variable in shared memory as an external array such as&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;extern&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;[];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;the size of the array is &lt;strong&gt;determined at launch time&lt;/strong&gt; (see &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;). All variables declared in this fashion, start at the same address in memory, so that the layout of the variables in the array must be &lt;strong&gt;explicitly managed&lt;/strong&gt; through offsets.&lt;/p&gt;
&lt;h3 id="dim3"&gt;dim3
&lt;/h3&gt;&lt;p&gt;This type is an integer vector type based on &lt;strong&gt;uint3&lt;/strong&gt; that is used to specify dimensions. When defining a variable of type dim3, any component left unspecified is &lt;strong&gt;initialized to 1&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="built-in-variables"&gt;Built-in Variables
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;gridDim(dim3)&lt;/li&gt;
&lt;li&gt;BlockDim(dim3)&lt;/li&gt;
&lt;li&gt;blockIdx(uint3)&lt;/li&gt;
&lt;li&gt;threadIdx(uint3)&lt;/li&gt;
&lt;li&gt;warpSize(int)&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>【CUDA】Notes</title><link>https://dyhes.github.io/p/cudanotes/</link><pubDate>Mon, 19 May 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudanotes/</guid><description>&lt;h2 id="__forceinline__"&gt;__forceinline__
&lt;/h2&gt;&lt;p&gt;在 CUDA 编程中，&lt;code&gt;__forceinline__&lt;/code&gt; 是一个编译器指令，用于强制将函数内联（Inline）到调用位置，即使编译器自身的优化策略不建议内联。以下是对其核心机制和应用场景的综合解析：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="核心作用与语义"&gt;核心作用与语义
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;强制内联的意图&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;__forceinline__&lt;/code&gt; 通过覆盖编译器的默认优化策略，&lt;strong&gt;强制将函数体直接嵌入调用处&lt;/strong&gt;，以消除函数调用的开销（如参数传递、栈帧管理）。这种机制常用于高频调用的短小函数（如数学运算、内存操作）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;与 &lt;code&gt;inline&lt;/code&gt; 的区别&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;inline&lt;/code&gt;：仅向编译器发出建议，最终是否内联由编译器决定（可能因函数复杂度或优化级别被忽略）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__forceinline__&lt;/code&gt;：绕过编译器的启发式分析，&lt;strong&gt;强制内联&lt;/strong&gt;（除非遇到硬件或语法限制）。例如在 CUDA 的归约操作中，高频调用的辅助函数常使用此关键字。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CUDA 设备函数的特殊支持&lt;/strong&gt;&lt;br&gt;
CUDA 允许在 &lt;code&gt;__device__&lt;/code&gt; 或 &lt;code&gt;__global__&lt;/code&gt; 函数前使用 &lt;code&gt;__forceinline__&lt;/code&gt;，以优化 GPU 线程的执行效率。例如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="适用场景与性能影响"&gt;适用场景与性能影响
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;高频短函数优化&lt;/strong&gt;&lt;br&gt;
适用于循环内部或线程级高频调用的简单操作（如向量加法、比较运算）。例如在 Warp 级归约（Warp Reduce）中，通过强制内联减少指令延迟：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;warpReduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;__shfl_down_sync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0xffffffff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;避免函数调用开销&lt;/strong&gt;&lt;br&gt;
在 GPU 核函数中，每个线程的独立执行路径若频繁调用外部函数，内联可减少上下文切换成本。例如将共享内存的归约逻辑直接嵌入主核函数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;代码膨胀的权衡&lt;/strong&gt;&lt;br&gt;
强制内联可能导致&lt;strong&gt;代码体积增大&lt;/strong&gt;，影响指令缓存效率。需在以下场景谨慎使用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;函数体较大（如包含复杂分支或循环）&lt;/li&gt;
&lt;li&gt;被多处调用的通用函数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="限制与编译器行为"&gt;限制与编译器行为
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;无法内联的情况&lt;/strong&gt;&lt;br&gt;
即使使用 &lt;code&gt;__forceinline__&lt;/code&gt;，以下情况仍可能阻止内联：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;函数包含递归调用或虚函数&lt;/li&gt;
&lt;li&gt;使用动态参数列表（Variadic Arguments）&lt;/li&gt;
&lt;li&gt;包含内联汇编（Inline Assembly）或 &lt;code&gt;__declspec(naked)&lt;/code&gt; 修饰&lt;/li&gt;
&lt;li&gt;调试模式（如 CUDA 的 &lt;code&gt;-G&lt;/code&gt; 编译选项禁用优化）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;编译器兼容性&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CUDA 工具链&lt;/strong&gt;：完全支持 &lt;code&gt;__forceinline__&lt;/code&gt;，常用于设备函数优化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;其他编译器&lt;/strong&gt;：非标准关键字，需使用编译器特定扩展（如 GCC 的 &lt;code&gt;__attribute__((always_inline))&lt;/code&gt; 或 MSVC 的 &lt;code&gt;__forceinline&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="最佳实践"&gt;最佳实践
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;优先用于小型设备函数&lt;/strong&gt;&lt;br&gt;
在 CUDA 中，将短小的 &lt;code&gt;__device__&lt;/code&gt; 函数标记为 &lt;code&gt;__forceinline__&lt;/code&gt;，尤其是在 Warp 级或 Block 级并行操作中：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;compute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;结合性能分析工具&lt;/strong&gt;&lt;br&gt;
使用 &lt;code&gt;nvprof&lt;/code&gt; 或 &lt;code&gt;Nsight Compute&lt;/code&gt; 验证内联效果，确保强制内联未导致寄存器溢出或缓存命中率下降。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;替代方案：模板与宏&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模板元编程&lt;/strong&gt;：通过编译时展开实现类似内联效果（如 CUDA 的向量化加载操作）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;宏函数&lt;/strong&gt;：适用于极简操作，但缺乏类型安全检查。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="代码示例cuda-归约优化"&gt;代码示例（CUDA 归约优化）
&lt;/h3&gt;&lt;p&gt;以下展示了 &lt;code&gt;__forceinline__&lt;/code&gt; 在 Warp 级归约中的应用：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 使用 __forceinline__ 强制内联归约逻辑
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;warpReduceSum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;__shfl_down_sync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0xffffffff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;reduceKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;warpReduceSum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 内联展开，无函数调用开销
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="总结"&gt;总结
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__forceinline__&lt;/code&gt; 是 CUDA 中用于性能调优的利器，但其使用需权衡代码膨胀与执行效率。在设备端高频调用的短函数、Warp 级操作中合理使用，可显著提升并行计算性能，但需结合编译器限制和实际硬件行为进行验证。&lt;/p&gt;
&lt;h2 id="__global__"&gt;__global__
&lt;/h2&gt;&lt;p&gt;在 CUDA 编程中，&lt;code&gt;__global__&lt;/code&gt; 是一个核心关键字，用于声明 GPU 核函数（Kernel Function）。以下是其关键特性的综合介绍：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="基本定义与核心作用"&gt;基本定义与核心作用
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__global__&lt;/code&gt; 修饰的函数是 &lt;strong&gt;主机（CPU）调用、设备（GPU）执行&lt;/strong&gt; 的并行计算入口点。它通过特殊的 &lt;code&gt;&amp;lt;&amp;lt;&amp;lt;grid_size, block_size&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; 语法启动，允许开发者将大规模计算任务分解为多线程并行执行。例如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="cm"&gt;/* GPU 执行的代码 */&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 启动 256 个线程
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaDeviceSynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="核心特性"&gt;核心特性
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;执行位置与调用关系&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只能在 &lt;strong&gt;GPU 上执行&lt;/strong&gt;，但必须由 &lt;strong&gt;CPU 代码显式调用&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;不能直接调用主机函数（如标准 C 库函数），否则会报错 &lt;code&gt;error: calling a __host__ function from a __global__ function&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;函数签名限制&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;必须返回 &lt;code&gt;void&lt;/code&gt; 类型。&lt;/li&gt;
&lt;li&gt;参数传递仅支持 &lt;strong&gt;值传递&lt;/strong&gt;，不能使用引用或主机内存指针（需通过设备内存传递）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;线程组织方式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过 &lt;code&gt;blockIdx&lt;/code&gt;（线程块索引）、&lt;code&gt;threadIdx&lt;/code&gt;（线程索引）和 &lt;code&gt;gridDim&lt;/code&gt;（网格维度）等内置变量定位线程。&lt;/li&gt;
&lt;li&gt;示例计算全局索引：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// 一维网格中的线程索引
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;内存访问权限&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可直接访问全局内存（如 &lt;code&gt;cudaMalloc&lt;/code&gt; 分配的显存）、共享内存、常量内存等 GPU 内存空间。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="使用场景"&gt;使用场景
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;大规模并行计算&lt;/strong&gt;&lt;br&gt;
适用于 &lt;strong&gt;数组运算&lt;/strong&gt;（如向量加法）、&lt;strong&gt;矩阵乘法&lt;/strong&gt;、&lt;strong&gt;图像处理&lt;/strong&gt; 等需要高并发处理的场景。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;任务分发入口&lt;/strong&gt;&lt;br&gt;
作为 GPU 计算的顶层逻辑，调用 &lt;code&gt;__device__&lt;/code&gt; 辅助函数完成具体计算单元。例如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;vector_add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;...;&lt;/span&gt; &lt;span class="c1"&gt;// 计算索引
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt; &lt;span class="c1"&gt;// 调用设备函数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="与其他关键字的对比"&gt;与其他关键字的对比
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;关键字&lt;/th&gt;
&lt;th&gt;调用者&lt;/th&gt;
&lt;th&gt;执行位置&lt;/th&gt;
&lt;th&gt;返回值限制&lt;/th&gt;
&lt;th&gt;典型用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__global__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;必须为 &lt;code&gt;void&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;并行任务入口（核函数）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__device__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;任意类型&lt;/td&gt;
&lt;td&gt;辅助计算（可复用模块）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__host__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;无限制&lt;/td&gt;
&lt;td&gt;普通 CPU 函数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="注意事项"&gt;注意事项
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;动态并行支持&lt;/strong&gt;&lt;br&gt;
从计算能力 3.5 的 GPU 开始，允许在设备代码中调用 &lt;code&gt;__global__&lt;/code&gt; 函数（需启用编译选项）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;性能优化&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;避免在 &lt;code&gt;__global__&lt;/code&gt; 函数中频繁调用复杂 &lt;code&gt;__device__&lt;/code&gt; 函数，可能导致寄存器溢出，可通过 &lt;code&gt;__launch_bounds__&lt;/code&gt; 优化线程配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;错误示例&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;error_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;// 错误：必须返回 void
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;error_call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;// 错误：参数不能使用引用
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="总结-1"&gt;总结
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__global__&lt;/code&gt; 是 CUDA 并行计算的基石，通过线程网格与块的灵活配置，可实现 GPU 资源的极致利用。开发者需注意其与 &lt;code&gt;__device__&lt;/code&gt;、&lt;code&gt;__host__&lt;/code&gt; 的协同关系，并遵循内存管理和参数传递规则，才能高效发挥 GPU 的并行计算能力。&lt;/p&gt;
&lt;h2 id="__constant__"&gt;__constant__
&lt;/h2&gt;&lt;p&gt;在 CUDA 编程中，&lt;code&gt;__constant__&lt;/code&gt; 是一种特殊的内存修饰符，用于声明&lt;strong&gt;常量内存&lt;/strong&gt;。以下是其核心特性的综合介绍：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="基本定义与核心作用-1"&gt;基本定义与核心作用
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__constant__&lt;/code&gt; 用于在 GPU 上声明&lt;strong&gt;只读的全局常量数据&lt;/strong&gt;，特点如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;主机初始化，设备只读&lt;/strong&gt;&lt;br&gt;
常量内存由主机（CPU）通过 &lt;code&gt;cudaMemcpyToSymbol&lt;/code&gt; 或 &lt;code&gt;cudaMemcpy&lt;/code&gt; 初始化，设备（GPU）代码只能读取，不可修改。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;静态分配，全局可见&lt;/strong&gt;&lt;br&gt;
必须在全局作用域声明（即核函数外），且对同一编译单元内的所有核函数可见。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容量限制&lt;/strong&gt;&lt;br&gt;
通常为 &lt;strong&gt;64KB&lt;/strong&gt;，超过此限制需使用全局内存或其他存储类型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;示例代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__constant__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt; &lt;span class="c1"&gt;// 声明常量内存
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 主机端初始化
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaMemcpyToSymbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="核心特性与优化机制"&gt;核心特性与优化机制
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;常量缓存与广播&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;缓存机制&lt;/strong&gt;：每个 SM（流式多处理器）有独立的 64KB 常量缓存，加速重复访问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;广播机制&lt;/strong&gt;：当半线程束（16 个线程）访问同一常量内存地址时，GPU 会合并为单次读取操作，并广播数据到所有线程，减少内存带宽消耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;性能优势场景&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;线程束内统一访问&lt;/strong&gt;：所有线程读取相同地址时性能最佳（如共享的数学系数）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分散访问劣势&lt;/strong&gt;：若线程访问不同地址，可能导致串行化（性能下降）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="使用场景-1"&gt;使用场景
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;高频读取的固定数据&lt;/strong&gt;&lt;br&gt;
如滤波器系数、物理常数、查找表等需频繁访问的只读数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;替代全局内存的优化&lt;/strong&gt;&lt;br&gt;
当数据量小且访问模式符合广播特性时，可减少全局内存带宽压力。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;示例：一维卷积核（Stencil）计算，将系数存入常量内存加速访问：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__constant__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;stencil_coeff&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt; &lt;span class="c1"&gt;// 声明卷积核系数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 主机初始化后，设备端所有线程读取同一系数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="初始化与操作"&gt;初始化与操作
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;主机端初始化&lt;/strong&gt;&lt;br&gt;
必须使用 &lt;code&gt;cudaMemcpyToSymbol&lt;/code&gt; 或 &lt;code&gt;cudaMemcpy&lt;/code&gt;（需先获取符号地址）：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 方法1：直接拷贝到符号
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaMemcpyToSymbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 方法2：通过地址操作
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;dev_ptr&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaGetSymbolAddress&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;dev_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;设备端访问&lt;/strong&gt;&lt;br&gt;
核函数内直接通过变量名读取，如 &lt;code&gt;float val = coefficients[threadIdx.x];&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="与其他内存类型的对比"&gt;与其他内存类型的对比
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内存类型&lt;/th&gt;
&lt;th&gt;可编程性&lt;/th&gt;
&lt;th&gt;作用域&lt;/th&gt;
&lt;th&gt;访问速度&lt;/th&gt;
&lt;th&gt;典型用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__constant__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;只读&lt;/td&gt;
&lt;td&gt;全局&lt;/td&gt;
&lt;td&gt;快（缓存）&lt;/td&gt;
&lt;td&gt;高频读取的固定数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;全局内存&lt;/td&gt;
&lt;td&gt;可读写&lt;/td&gt;
&lt;td&gt;全局&lt;/td&gt;
&lt;td&gt;慢&lt;/td&gt;
&lt;td&gt;通用数据存储&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;纹理内存&lt;/td&gt;
&lt;td&gt;只读&lt;/td&gt;
&lt;td&gt;全局&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;空间局部性强的数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;共享内存&lt;/td&gt;
&lt;td&gt;可读写&lt;/td&gt;
&lt;td&gt;线程块内&lt;/td&gt;
&lt;td&gt;最快&lt;/td&gt;
&lt;td&gt;块内线程协作&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="注意事项-1"&gt;注意事项
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;避免过度使用&lt;/strong&gt;&lt;br&gt;
仅当数据访问模式符合广播特性时使用，否则可能劣于全局内存+只读缓存（如 &lt;code&gt;__ldg&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结构体与动态数据&lt;/strong&gt;&lt;br&gt;
支持结构体，但需整体初始化；动态数据需结合全局内存管理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;架构兼容性&lt;/strong&gt;&lt;br&gt;
常量缓存在所有 NVIDIA GPU 中通用，但 Kepler 架构后的只读缓存（&lt;code&gt;__ldg&lt;/code&gt;）在分散访问时更具优势。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="总结-2"&gt;总结
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__constant__&lt;/code&gt; 内存通过缓存和广播机制优化高频读取场景，是 CUDA 性能调优的重要工具。开发者需结合数据特性和硬件架构，合理选择常量内存、只读缓存或共享内存，以实现 GPU 资源的高效利用。&lt;/p&gt;
&lt;h2 id="存储层次结构"&gt;存储层次结构
&lt;/h2&gt;&lt;p&gt;以下是 CUDA 存储层次结构的综合介绍，结合硬件特性和编程模型进行分层解析：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="存储层次概览"&gt;存储层次概览
&lt;/h3&gt;&lt;p&gt;CUDA 存储层次由&lt;strong&gt;可编程存储&lt;/strong&gt;和&lt;strong&gt;不可编程缓存&lt;/strong&gt;组成，设计目标是利用数据局部性优化访问效率。其核心结构按访问速度和范围可分为以下层级：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;存储类型&lt;/th&gt;
&lt;th&gt;作用域&lt;/th&gt;
&lt;th&gt;生命周期&lt;/th&gt;
&lt;th&gt;访问速度&lt;/th&gt;
&lt;th&gt;主要用途&lt;/th&gt;
&lt;th&gt;优化特性&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;寄存器&lt;/td&gt;
&lt;td&gt;线程私有&lt;/td&gt;
&lt;td&gt;线程执行周期&lt;/td&gt;
&lt;td&gt;最快&lt;/td&gt;
&lt;td&gt;存储频繁使用的局部变量&lt;/td&gt;
&lt;td&gt;编译器自动分配，无显式管理&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;共享内存&lt;/td&gt;
&lt;td&gt;线程块内共享&lt;/td&gt;
&lt;td&gt;线程块执行周期&lt;/td&gt;
&lt;td&gt;快&lt;/td&gt;
&lt;td&gt;块内线程协作数据交换&lt;/td&gt;
&lt;td&gt;手动控制，低延迟通信&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;常量内存&lt;/td&gt;
&lt;td&gt;全局&lt;/td&gt;
&lt;td&gt;应用生命周期&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;存储只读数据（如系数表）&lt;/td&gt;
&lt;td&gt;硬件广播机制优化统一读取&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;纹理内存&lt;/td&gt;
&lt;td&gt;全局&lt;/td&gt;
&lt;td&gt;应用生命周期&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;空间局部性强的数据访问&lt;/td&gt;
&lt;td&gt;硬件插值和缓存优化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;全局内存&lt;/td&gt;
&lt;td&gt;全局&lt;/td&gt;
&lt;td&gt;应用生命周期&lt;/td&gt;
&lt;td&gt;慢&lt;/td&gt;
&lt;td&gt;大规模数据存储与交换&lt;/td&gt;
&lt;td&gt;需对齐和合并访问优化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;本地内存&lt;/td&gt;
&lt;td&gt;线程私有&lt;/td&gt;
&lt;td&gt;线程执行周期&lt;/td&gt;
&lt;td&gt;慢&lt;/td&gt;
&lt;td&gt;寄存器溢出时的临时存储&lt;/td&gt;
&lt;td&gt;自动分配，避免寄存器不足&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="核心存储类型详解"&gt;核心存储类型详解
&lt;/h3&gt;&lt;h4 id="寄存器register"&gt;&lt;strong&gt;寄存器（Register）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特性&lt;/strong&gt;：每个线程独立拥有，访问速度最快，容量有限（如 Fermi 架构每线程最多 63 个寄存器）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用场景&lt;/strong&gt;：存储循环索引、临时变量等高频访问数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化要点&lt;/strong&gt;：减少寄存器使用可提升线程并行度，避免溢出到本地内存。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="共享内存shared-memory"&gt;&lt;strong&gt;共享内存（Shared Memory）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特性&lt;/strong&gt;：线程块内共享，类似 CPU 的 L1 缓存，但可编程控制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用场景&lt;/strong&gt;：矩阵分块计算、归约操作等需线程协作的任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分配方式&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;静态分配：&lt;code&gt;__shared__ int buffer[128];&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;动态分配：内核启动时指定大小（&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;grid, block, sharedMemSize&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同步机制&lt;/strong&gt;：通过 &lt;code&gt;__syncthreads()&lt;/code&gt; 确保线程块内数据一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="全局内存global-memory"&gt;&lt;strong&gt;全局内存（Global Memory）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特性&lt;/strong&gt;：容量最大（GB 级），但延迟高，需通过 L2 缓存访问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化策略&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对齐访问&lt;/strong&gt;：首地址为 32B/128B 的整数倍以减少事务次数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合并访问&lt;/strong&gt;：线程束内连续访问内存块（如步长为 1）。&lt;/li&gt;
&lt;li&gt;**使用 &lt;code&gt;cudaMallocManaged&lt;/code&gt; 实现统一内存管理（UVA）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="常量内存constant-memory"&gt;&lt;strong&gt;常量内存（Constant Memory）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特性&lt;/strong&gt;：只读，64KB 容量，通过专用缓存加速。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用场景&lt;/strong&gt;：存储滤波器系数、物理常数等广播式读取数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;初始化方法&lt;/strong&gt;：主机端通过 &lt;code&gt;cudaMemcpyToSymbol&lt;/code&gt; 写入数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="纹理内存texture-memory"&gt;&lt;strong&gt;纹理内存（Texture Memory）&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特性&lt;/strong&gt;：专为 2D/3D 数据设计，支持硬件插值和边界处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用场景&lt;/strong&gt;：图像处理、空间插值计算。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：自动缓存空间局部性数据，减少显式内存管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="存储访问优化原则"&gt;存储访问优化原则
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;时间局部性&lt;/strong&gt;：通过共享内存缓存重复访问数据（如矩阵乘法中的子矩阵复用）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;空间局部性&lt;/strong&gt;：组织数据连续存储，利用缓存行预取（如结构体数组 vs 数组结构体）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;减少主机-设备传输&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;cudaMallocHost&lt;/code&gt; 分配固定内存（Pinned Memory）提升传输带宽。&lt;/li&gt;
&lt;li&gt;零拷贝内存（Zero-Copy）允许 GPU 直接访问主机内存，避免显式拷贝。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="典型应用场景对比"&gt;典型应用场景对比
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;场景&lt;/th&gt;
&lt;th&gt;推荐存储类型&lt;/th&gt;
&lt;th&gt;原因&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;线程私有临时变量&lt;/td&gt;
&lt;td&gt;寄存器&lt;/td&gt;
&lt;td&gt;速度快，无竞争&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;块内数据共享&lt;/td&gt;
&lt;td&gt;共享内存&lt;/td&gt;
&lt;td&gt;低延迟，支持原子操作和同步&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;大规模输入/输出&lt;/td&gt;
&lt;td&gt;全局内存&lt;/td&gt;
&lt;td&gt;容量大，支持异步传输&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;高频只读数据&lt;/td&gt;
&lt;td&gt;常量内存&lt;/td&gt;
&lt;td&gt;利用缓存和广播机制减少带宽压力&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;图像处理&lt;/td&gt;
&lt;td&gt;纹理内存&lt;/td&gt;
&lt;td&gt;硬件优化空间局部性访问&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="高级特性与注意事项"&gt;高级特性与注意事项
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;统一内存（Unified Memory）&lt;/strong&gt;：CUDA 6.0+ 支持自动迁移数据，简化编程（需 UVA 架构）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;L1/L2 缓存控制&lt;/strong&gt;：通过编译选项（如 &lt;code&gt;-Xptxas -dlcm=ca&lt;/code&gt;）显式启用/禁用 L1 缓存。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原子操作&lt;/strong&gt;：全局内存支持原子加减（&lt;code&gt;atomicAdd&lt;/code&gt;），但需注意性能损耗。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;通过合理选择存储类型和优化访问模式，开发者可显著提升 CUDA 程序性能。例如，矩阵乘法中结合共享内存分块和全局内存合并访问，可实现接近理论峰值的计算效率。&lt;/p&gt;
&lt;h2 id="执行范式"&gt;执行范式
&lt;/h2&gt;&lt;p&gt;是的，CUDA内核的执行范式确实是由CPU（主机端）通过指令申请GPU内存并调用&lt;code&gt;__global__&lt;/code&gt;内核函数启动计算的。以下是完整的执行流程及关键细节：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="执行范式核心步骤"&gt;执行范式核心步骤
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;主机端初始化与内存申请&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GPU内存分配&lt;/strong&gt;：CPU通过CUDA API（如&lt;code&gt;cudaMalloc&lt;/code&gt;）显式申请设备（GPU）内存。例如：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 由CPU指令分配GPU内存
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;统一内存管理&lt;/strong&gt;（可选）：使用&lt;code&gt;cudaMallocManaged&lt;/code&gt;可分配主机与设备共享的统一内存，简化数据传输。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据拷贝&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU通过&lt;code&gt;cudaMemcpy&lt;/code&gt;将输入数据从主机内存拷贝到设备内存：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 主机→设备传输
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;内核调用&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU通过&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;grid, block&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;语法启动&lt;code&gt;__global__&lt;/code&gt;内核函数，指定线程网格（Grid）和线程块（Block）的维度。例如：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;myKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 启动128个块，每块256线程
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;异步执行&lt;/strong&gt;：内核调用后立即返回，CPU无需等待GPU完成计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;结果同步与回收&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;同步机制&lt;/strong&gt;：CPU通过&lt;code&gt;cudaDeviceSynchronize()&lt;/code&gt;等待GPU完成计算。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据回传&lt;/strong&gt;：通过&lt;code&gt;cudaMemcpy&lt;/code&gt;将结果从设备内存拷贝回主机内存。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内存释放&lt;/strong&gt;：使用&lt;code&gt;cudaFree&lt;/code&gt;释放GPU内存。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="内核执行特性"&gt;内核执行特性
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;线程组织模型&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程按**网格（Grid）→ 块（Block）→ 线程（Thread）**的层级组织。&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;blockIdx&lt;/code&gt;、&lt;code&gt;threadIdx&lt;/code&gt;等内置变量定位线程的全局索引。例如：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// 一维索引
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;硬件执行机制&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SIMT架构&lt;/strong&gt;：GPU以**线程束（Warp，32线程）**为调度单位，同一Warp内线程执行相同指令。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SM调度&lt;/strong&gt;：线程块（Block）被分配到流多处理器（SM）上执行，SM通过多级缓存（共享内存、L1/L2）加速数据访问。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;优化关键点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内存访问合并&lt;/strong&gt;：确保线程束内连续访问全局内存，减少事务次数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共享内存复用&lt;/strong&gt;：手动缓存重复访问的数据，减少全局内存带宽压力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="与其他编程模型的对比"&gt;与其他编程模型的对比
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;阶段&lt;/th&gt;
&lt;th&gt;CPU职责&lt;/th&gt;
&lt;th&gt;GPU职责&lt;/th&gt;
&lt;th&gt;交互方式&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;内存管理&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;分配/释放设备内存&lt;/td&gt;
&lt;td&gt;提供显存空间&lt;/td&gt;
&lt;td&gt;通过CUDA API（如&lt;code&gt;cudaMalloc&lt;/code&gt;）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;内核执行&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;启动内核并指定线程配置&lt;/td&gt;
&lt;td&gt;多线程并行计算&lt;/td&gt;
&lt;td&gt;异步调用（&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;...&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;语法）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;数据传输&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;主机↔设备数据拷贝&lt;/td&gt;
&lt;td&gt;无直接参与&lt;/td&gt;
&lt;td&gt;显式拷贝或统一内存自动迁移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;同步控制&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;显式等待GPU完成（&lt;code&gt;cudaDeviceSynchronize&lt;/code&gt;）&lt;/td&gt;
&lt;td&gt;无主动通知机制&lt;/td&gt;
&lt;td&gt;阻塞式同步或流式异步&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="典型代码示例完整流程"&gt;典型代码示例（完整流程）
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;addKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;h_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 主机内存分配与初始化
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;h_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="nf"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;h_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="nf"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// ...初始化h_a和h_b...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// GPU内存分配
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 数据拷贝至GPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 启动内核（256线程/块）
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;addKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 同步并拷贝结果回主机
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaDeviceSynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// 释放内存
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="高级特性扩展"&gt;高级特性扩展
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;动态并行&lt;/strong&gt;（Compute Capability ≥3.5）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;允许GPU内核内部嵌套启动其他内核，减少主机交互开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多流并发&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用CUDA流（Stream）实现计算与数据传输重叠，提升吞吐量：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;cudaStream_t&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaStreamCreate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(...,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 异步传输
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;...,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 流内执行
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;统一内存优化&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过&lt;code&gt;cudaMallocManaged&lt;/code&gt;实现自动内存迁移，避免显式拷贝。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;综上，CUDA的执行范式确实由CPU主导内存管理与内核调用，而GPU专注于并行计算。这一设计平衡了CPU的控制能力与GPU的并行性能，适用于大规模数据并行任务。&lt;/p&gt;</description></item><item><title>【CUDA】Function</title><link>https://dyhes.github.io/p/cudafunction/</link><pubDate>Tue, 22 Apr 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudafunction/</guid><description>&lt;p&gt;在CUDA编程中，错误信息 &lt;code&gt;&amp;quot;calling a __host__ function from a __host__ __device__ function is not allowed&amp;quot;&lt;/code&gt; 表示你尝试在 &lt;strong&gt;同时支持主机（CPU）和设备（GPU）调用的函数&lt;/strong&gt; 中，调用了一个 &lt;strong&gt;仅支持主机端执行&lt;/strong&gt; 的函数。以下是具体解析和解决方案：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="错误原因解析"&gt;错误原因解析
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;函数修饰符的作用&lt;/strong&gt; ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;__host__&lt;/code&gt;：函数仅在CPU上执行，只能被CPU调用（默认修饰符，可省略）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__device__&lt;/code&gt;：函数仅在GPU上执行，只能被GPU线程调用。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__host__ __device__&lt;/code&gt;：函数可以同时在CPU和GPU上编译和执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;冲突场景&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当一个被标记为 &lt;code&gt;__host__ __device__&lt;/code&gt; 的函数（例如 &lt;code&gt;__host__ __device__ void foo()&lt;/code&gt;）在其内部调用了另一个仅标记为 &lt;code&gt;__host__&lt;/code&gt; 的函数（例如 &lt;code&gt;void bar()&lt;/code&gt;）时，会导致此错误。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;核心矛盾&lt;/strong&gt;：在GPU执行路径中（即 &lt;code&gt;__device__&lt;/code&gt; 分支），&lt;code&gt;bar()&lt;/code&gt; 作为纯主机函数无法在设备端被调用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="典型示例"&gt;典型示例
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 纯主机函数（默认 __host__）
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;host_only_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="cm"&gt;/* CPU逻辑 */&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// 混合修饰符函数：支持CPU和GPU调用
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;hybrid_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;host_only_func&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 错误！若在GPU执行路径中调用纯主机函数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="解决方案"&gt;解决方案
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;检查被调用函数的修饰符&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若 &lt;code&gt;host_only_func()&lt;/code&gt; 需要在GPU中被调用，需添加 &lt;code&gt;__device__&lt;/code&gt; 修饰符：
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;host_device_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="cm"&gt;/* 兼容逻辑 */&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;若该函数无法修改（如第三方库函数），需重构代码逻辑，避免在设备端路径中调用它。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;利用条件编译隔离逻辑&lt;/strong&gt; ：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;hybrid_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#ifdef __CUDA_ARCH__ &lt;/span&gt;&lt;span class="c1"&gt;// 仅在GPU编译时生效
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;device_logic&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 设备端专用代码
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#else
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="n"&gt;host_only_func&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// 主机端专用代码
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#endif
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;统一函数的设备端兼容性&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若需跨设备通用，确保所有内部调用的函数也支持 &lt;code&gt;__device__&lt;/code&gt;，例如使用 &lt;code&gt;__host__ __device__&lt;/code&gt; 修饰符或仅依赖CUDA支持的数学函数。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="扩展建议"&gt;扩展建议
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;调试工具&lt;/strong&gt;：使用 &lt;code&gt;cuda-gdb&lt;/code&gt; 或 &lt;code&gt;cuda-memcheck&lt;/code&gt; 定位具体报错位置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码规范&lt;/strong&gt;：避免在混合修饰符函数中直接调用非CUDA兼容的库函数（如STL容器），这类函数通常仅支持主机端。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此错误本质是 &lt;strong&gt;作用域隔离问题&lt;/strong&gt;，通过合理使用修饰符和条件编译可有效解决。&lt;/p&gt;</description></item></channel></rss>