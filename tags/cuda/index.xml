<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CUDA on é£é¸¿è¸é›ªæ³¥</title><link>https://dyhes.github.io/tags/cuda/</link><description>Recent content in CUDA on é£é¸¿è¸é›ªæ³¥</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 22 Oct 2025 16:27:30 +0800</lastBuildDate><atom:link href="https://dyhes.github.io/tags/cuda/index.xml" rel="self" type="application/rss+xml"/><item><title>ã€CUDAã€‘Concepts</title><link>https://dyhes.github.io/p/cudaconcepts/</link><pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudaconcepts/</guid><description>&lt;h2 id="thread-block"&gt;Thread Block
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œå½“ä¸€ä¸ªæµå¤šå¤„ç†å™¨ï¼ˆSMï¼‰çš„ç›®æ ‡æ˜¯è¿è¡Œ2048ä¸ªçº¿ç¨‹æ—¶ï¼Œçº¿ç¨‹å—ï¼ˆBlockï¼‰çš„å¤§å°å¯¹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚çº¿ç¨‹å—å¤§å°çš„é€‰æ‹©ä¸ä»…å…³ç³»åˆ°ç¡¬ä»¶èµ„æºçš„åˆ©ç”¨ç‡ï¼Œè¿˜ä¼šå½±å“å»¶è¿Ÿéšè—èƒ½åŠ›ã€å†…å­˜è®¿é—®æ•ˆç‡ç­‰å…³é”®å› ç´ ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†åˆ†æï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-çº¿ç¨‹å—å¤§å°ä¸èµ„æºåˆ†é…çš„æƒè¡¡"&gt;âš™ï¸ 1. &lt;strong&gt;çº¿ç¨‹å—å¤§å°ä¸èµ„æºåˆ†é…çš„æƒè¡¡&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;èµ„æºé™åˆ¶&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;p&gt;æ¯ä¸ªSMçš„ç¡¬ä»¶èµ„æºï¼ˆå¦‚å¯„å­˜å™¨ã€å…±äº«å†…å­˜ï¼‰æ˜¯å›ºå®šçš„ã€‚è‹¥çº¿ç¨‹å—è¿‡å¤§ï¼ˆå¦‚1024çº¿ç¨‹/å—ï¼‰ï¼Œå•ä¸ªå—ä¼šæ¶ˆè€—æ›´å¤šèµ„æºï¼Œå¯èƒ½å¯¼è‡´SMæ— æ³•å®¹çº³è¶³å¤Ÿçš„å—ã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è‹¥æ¯ä¸ªå—éœ€å ç”¨50KBå…±äº«å†…å­˜ï¼Œè€ŒSMå…±äº«å†…å­˜æ€»é‡ä¸º100KBï¼Œåˆ™SMä»…èƒ½é©»ç•™2ä¸ªå—ï¼ˆ2Ã—1024=2048çº¿ç¨‹ï¼‰ï¼Œä½†æ­¤æ—¶SMçš„å…±äº«å†…å­˜åˆ©ç”¨ç‡å·²è¾¾100%ï¼Œå¯èƒ½é™åˆ¶å…¶ä»–èµ„æºåˆ†é…ã€‚&lt;/li&gt;
&lt;li&gt;ç›¸æ¯”ä¹‹ä¸‹ï¼Œè‹¥ä½¿ç”¨256çº¿ç¨‹/å—ï¼ŒåŒæ ·2048çº¿ç¨‹éœ€8ä¸ªå—ã€‚è‹¥æ¯ä¸ªå—ä»…éœ€20KBå…±äº«å†…å­˜ï¼Œåˆ™SMå…±äº«å†…å­˜å ç”¨ä¸º160KBï¼ˆå‡è®¾èµ„æºå…è®¸ï¼‰ï¼Œèµ„æºå‹åŠ›æ›´å°ï¼Œä¸”èƒ½é€šè¿‡å¤šå—æå‡çµæ´»æ€§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å¯„å­˜å™¨ç«äº‰&lt;/strong&gt;ï¼š
å¤§å—å¯èƒ½å¯¼è‡´å•ä¸ªçº¿ç¨‹çš„å¯„å­˜å™¨åˆ†é…ä¸è¶³ï¼Œè¿«ä½¿ç¼–è¯‘å™¨ä½¿ç”¨å»¶è¿Ÿæ›´é«˜çš„æœ¬åœ°å†…å­˜ï¼ˆLocal Memoryï¼‰ï¼Œæ˜¾è‘—é™ä½æ€§èƒ½ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-å»¶è¿Ÿéšè—ä¸å¹¶è¡Œæ•ˆç‡"&gt;â±ï¸ 2. &lt;strong&gt;å»¶è¿Ÿéšè—ä¸å¹¶è¡Œæ•ˆç‡&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;çº¿ç¨‹æŸè°ƒåº¦&lt;/strong&gt;ï¼š
SMä»¥çº¿ç¨‹æŸï¼ˆWarpï¼Œ32çº¿ç¨‹ï¼‰ä¸ºå•ä½è°ƒåº¦ä»»åŠ¡ã€‚å—è¶Šå¤§ï¼Œå•ä¸ªå—å†…å¯è°ƒåº¦çš„çº¿ç¨‹æŸè¶Šå¤šï¼ˆå¦‚1024çº¿ç¨‹/å— = 32ä¸ªçº¿ç¨‹æŸï¼‰ï¼Œç†è®ºä¸Šæ›´æ˜“éšè—å†…å­˜å»¶è¿Ÿã€‚ä½†è‹¥å—æ•°é‡è¿‡å°‘ï¼ˆå¦‚ä»…2ä¸ªå—ï¼‰ï¼Œå½“éƒ¨åˆ†çº¿ç¨‹æŸå› åŒæ­¥ï¼ˆå¦‚&lt;code&gt;__syncthreads()&lt;/code&gt;ï¼‰æˆ–å†…å­˜è®¿é—®åœæ»æ—¶ï¼ŒSMå¯èƒ½å› ç¼ºå°‘å¯åˆ‡æ¢çš„çº¿ç¨‹æŸè€Œé—²ç½®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å°å—çš„å¹¶è¡Œä¼˜åŠ¿&lt;/strong&gt;ï¼š
ä½¿ç”¨è¾ƒå°å—ï¼ˆå¦‚128çº¿ç¨‹/å—ï¼‰æ—¶ï¼ŒSMå¯é©»ç•™æ›´å¤šå—ï¼ˆ16ä¸ªï¼‰ã€‚å³ä½¿éƒ¨åˆ†å—å› åŒæ­¥åœæ»ï¼Œå…¶ä»–å—ä»å¯ç»§ç»­æ‰§è¡Œï¼Œæå‡ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-å†…å­˜è®¿é—®æ¨¡å¼çš„å½±å“"&gt;ğŸ“Š 3. &lt;strong&gt;å†…å­˜è®¿é—®æ¨¡å¼çš„å½±å“&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å…¨å±€å†…å­˜åˆå¹¶è®¿é—®&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;p&gt;å—å¤§å°ä¼šå½±å“å…¨å±€å†…å­˜çš„è®¿é—®æ•ˆç‡ã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;åœ¨äºŒç»´æ•°æ®è®¡ç®—ä¸­ï¼Œå°å—ï¼ˆå¦‚16Ã—16=256çº¿ç¨‹ï¼‰æ›´æ˜“å®ç°è¿ç»­å†…å­˜è®¿é—®ï¼ˆåˆå¹¶è®¿é—®ï¼‰ï¼Œè€Œå¤§å—ï¼ˆå¦‚32Ã—32=1024çº¿ç¨‹ï¼‰å¯èƒ½å› è¡Œåˆ—è·¨åº¦å¯¼è‡´éè¿ç»­è®¿é—®ï¼Œé™ä½å¸¦å®½åˆ©ç”¨ç‡ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å…±äº«å†…å­˜Bankå†²çª&lt;/strong&gt;ï¼š
å¤§å—å¯èƒ½åŠ å‰§å…±äº«å†…å­˜çš„Bankå†²çªï¼ˆå¤šä¸ªçº¿ç¨‹è®¿é—®åŒä¸€Bankï¼‰ï¼Œè€Œå°å—é€šè¿‡æ›´ç²¾ç»†çš„æ•°æ®åˆ’åˆ†å¯å‡å°‘æ­¤ç±»å†²çªã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-4-å®é™…å·¥ç¨‹ç»éªŒä¸ä¼˜åŒ–å»ºè®®"&gt;ğŸ§ª 4. &lt;strong&gt;å®é™…å·¥ç¨‹ç»éªŒä¸ä¼˜åŒ–å»ºè®®&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ç»éªŒæ€§å–å€¼&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;p&gt;ä¸»æµå®è·µæ¨èå—å¤§å°ä¸º&lt;/p&gt;
&lt;p&gt;128â€“512çº¿ç¨‹&lt;/p&gt;
&lt;p&gt;ï¼ˆ32çš„å€æ•°ï¼‰ï¼Œå…¶ä¸­256çº¿ç¨‹æ˜¯å¸¸è§èµ·ç‚¹ã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;è®¡ç®—å¯†é›†å‹ä»»åŠ¡ï¼š128â€“256çº¿ç¨‹/å—ï¼ˆå‡å°‘èµ„æºç«äº‰ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;å†…å­˜å¯†é›†å‹ä»»åŠ¡ï¼š256â€“512çº¿ç¨‹/å—ï¼ˆæå‡å»¶è¿Ÿéšè—èƒ½åŠ›ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åŠ¨æ€è°ƒæ•´ç­–ç•¥&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;åˆå§‹è®¾ç½®&lt;/strong&gt;ï¼šæ ¹æ®æ•°æ®é‡é€‰æ‹©256çº¿ç¨‹/å—ï¼Œç½‘æ ¼å¤§å°è¦†ç›–æ€»çº¿ç¨‹æ•°ï¼ˆå¦‚2048çº¿ç¨‹éœ€8ä¸ªå—ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;èµ„æºåˆ†æ&lt;/strong&gt;ï¼šä½¿ç”¨&lt;code&gt;nsight compute&lt;/code&gt;æ£€æµ‹å ç”¨ç‡ï¼ˆOccupancyï¼‰ï¼Œè‹¥ä½äº80%ï¼Œéœ€è°ƒæ•´å—å¤§å°æˆ–å‡å°‘èµ„æºæ¶ˆè€—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æŒ‡ä»¤çº§å¹¶è¡Œï¼ˆILPï¼‰è¡¥å¿&lt;/strong&gt;ï¼šåœ¨ä½å ç”¨ç‡åœºæ™¯ä¸‹ï¼Œé€šè¿‡å•çº¿ç¨‹å¤„ç†å¤šæ•°æ®ï¼ˆILPï¼‰æå‡æ€§èƒ½ï¼ˆå¦‚çŸ©é˜µè½¬ç½®ä¸­å•çº¿ç¨‹è®¡ç®—4ä¸ªå…ƒç´ ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-5-1024çº¿ç¨‹å—çš„é€‚ç”¨åœºæ™¯"&gt;âš–ï¸ 5. &lt;strong&gt;1024çº¿ç¨‹/å—çš„é€‚ç”¨åœºæ™¯&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿åœºæ™¯&lt;/strong&gt;ï¼š
å½“ç®—æ³•éœ€å¤§é‡çº¿ç¨‹åä½œï¼ˆå¦‚çŸ©é˜µä¹˜æ³•ï¼‰ï¼Œä¸”å…±äº«å†…å­˜è®¿é—®æ¨¡å¼è§„åˆ™æ—¶ï¼Œå¤§å—å¯å‡å°‘å—é—´é€šä¿¡å¼€é”€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å±€é™æ€§&lt;/strong&gt;ï¼š
åœ¨å¤šæ•°åœºæ™¯ä¸‹ï¼Œ1024çº¿ç¨‹/å—æ˜“å¯¼è‡´èµ„æºç¢ç‰‡åŒ–ï¼Œä¸”éœ€ç®—æ³•é«˜åº¦ä¼˜åŒ–ä»¥é¿å…åŒæ­¥ç“¶é¢ˆï¼Œéé€šç”¨é€‰æ‹©ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-ç»“è®ºæ˜¯å¦åº”è®¾ç½®ä¸º1024"&gt;ğŸ’ &lt;strong&gt;ç»“è®ºï¼šæ˜¯å¦åº”è®¾ç½®ä¸º1024ï¼Ÿ&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¦&lt;/strong&gt;ï¼šåœ¨SMç›®æ ‡ä¸º2048çº¿ç¨‹æ—¶ï¼Œ1024çº¿ç¨‹/å—é€šå¸¸&lt;strong&gt;ä¸æ˜¯æœ€ä¼˜è§£&lt;/strong&gt;ã€‚å®ƒæ˜“å¼•å‘èµ„æºç«äº‰ã€åŒæ­¥åœæ»åŠå†…å­˜è®¿é—®æ•ˆç‡ä¸‹é™ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨èæ–¹æ¡ˆ&lt;/strong&gt;ï¼šä¼˜å…ˆé€‰æ‹© &lt;strong&gt;128â€“512çº¿ç¨‹/å—&lt;/strong&gt;ï¼ˆå¦‚256ï¼‰ï¼Œé€šè¿‡å¢åŠ å—æ•°é‡ï¼ˆå¦‚8â€“16ä¸ªå—ï¼‰æå‡SMçš„çµæ´»æ€§ä¸èµ„æºåˆ©ç”¨ç‡ã€‚æœ€ç»ˆéœ€ç»“åˆå…·ä½“ç¡¬ä»¶ï¼ˆå¦‚A100/V100çš„SMè§„æ ¼ï¼‰å’Œç®—æ³•ç‰¹æ€§ï¼Œé€šè¿‡æ€§èƒ½åˆ†æå·¥å…·éªŒè¯ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="çº¿ç¨‹åŒæ­¥"&gt;çº¿ç¨‹åŒæ­¥
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œçº¿ç¨‹åŒæ­¥æ˜¯åè°ƒå¹¶è¡Œçº¿ç¨‹æ‰§è¡Œé¡ºåºçš„å…³é”®æœºåˆ¶ã€‚ä¸åŒå±‚çº§çš„åŒæ­¥ï¼ˆçº¿ç¨‹å—ã€çº¿ç¨‹æŸã€å­çº¿ç¨‹æŸï¼‰éœ€è¦é‡‡ç”¨ä¸åŒçš„æŠ€æœ¯å®ç°ï¼Œå…¶æ•ˆç‡ä¸é€‚ç”¨åœºæ™¯ä¹Ÿå„æœ‰å·®å¼‚ã€‚ä»¥ä¸‹æ˜¯åˆ†å±‚çº§çš„å®ç°æ–¹æ³•ä¸æŠ€æœ¯ç»†èŠ‚ï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-çº¿ç¨‹å—å±‚çº§çš„åŒæ­¥"&gt;âš™ï¸ 1. &lt;strong&gt;çº¿ç¨‹å—å±‚çº§çš„åŒæ­¥&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;çº¿ç¨‹å—å†…çš„æ‰€æœ‰çº¿ç¨‹ï¼ˆæœ€å¤š1024ä¸ªï¼‰é€šè¿‡ç¡¬ä»¶å±éšœå®ç°åŒæ­¥ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ ¸å¿ƒå‡½æ•°&lt;/strong&gt;ï¼š&lt;code&gt;__syncthreads()&lt;/code&gt;
è¯¥å‡½æ•°ç¡®ä¿çº¿ç¨‹å—å†…æ‰€æœ‰çº¿ç¨‹æ‰§è¡Œåˆ°æ­¤ä½ç½®åï¼Œæ‰èƒ½ç»§ç»­æ‰§è¡Œåç»­ä»£ç ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å…¸å‹åº”ç”¨åœºæ™¯&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;å…±äº«å†…å­˜æ•°æ®åä½œï¼ˆå¦‚çŸ©é˜µè½¬ç½®å‰ç¡®ä¿æ•°æ®åŠ è½½å®Œæˆï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;è§„çº¦è®¡ç®—ä¸­åˆ†é˜¶æ®µæ±‡æ€»ç»“æœã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä»£ç ç¤ºä¾‹&lt;/p&gt;
&lt;p&gt;ï¼ˆå…±äº«å†…å­˜åˆå§‹åŒ–åŒæ­¥ï¼‰ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__global__ void kernel(float *data) {
__shared__ float s_data[1024];
int tid = threadIdx.x;
s_data[tid] = data[tid];
__syncthreads(); // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆæ•°æ®å†™å…¥
// åç»­æ“ä½œï¼ˆå¦‚è®¡ç®—s_dataçš„ç´¯åŠ å’Œï¼‰
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ³¨æ„äº‹é¡¹&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯ä¸€è‡´æ€§&lt;/strong&gt;ï¼šè‹¥çº¿ç¨‹å—å†…å­˜åœ¨åˆ†æ”¯ï¼ˆå¦‚&lt;code&gt;if&lt;/code&gt;è¯­å¥ï¼‰ï¼Œéœ€ç¡®ä¿æ‰€æœ‰çº¿ç¨‹æ‰§è¡Œç›¸åŒåˆ†æ”¯è·¯å¾„ï¼Œå¦åˆ™&lt;code&gt;__syncthreads()&lt;/code&gt;ä¼šå¯¼è‡´æ­»é”ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½å¼€é”€&lt;/strong&gt;ï¼šåŒæ­¥éœ€4ä¸ªæ—¶é’Ÿå‘¨æœŸä»¥ä¸Šï¼Œé¢‘ç¹ä½¿ç”¨å¯èƒ½é™ä½å¹¶è¡Œæ•ˆç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-çº¿ç¨‹æŸå±‚çº§çš„åŒæ­¥"&gt;âš¡ 2. &lt;strong&gt;çº¿ç¨‹æŸå±‚çº§çš„åŒæ­¥&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;çº¿ç¨‹æŸï¼ˆWarpï¼Œ32ä¸ªçº¿ç¨‹ï¼‰å†…çš„åŒæ­¥é€šè¿‡æ›´è½»é‡çº§çš„æŒ‡ä»¤å®ç°ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ ¸å¿ƒå‡½æ•°&lt;/strong&gt;ï¼š&lt;code&gt;__syncwarp(mask=0xffffffff)&lt;/code&gt;
ä»…åŒæ­¥æ©ç æŒ‡å®šçš„çº¿ç¨‹æŸå†…çº¿ç¨‹ï¼Œé»˜è®¤æ©ç &lt;code&gt;0xffffffff&lt;/code&gt;è¡¨ç¤ºå…¨åŒæ­¥ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ€§èƒ½ä¼˜åŠ¿&lt;/strong&gt;ï¼š
ç›¸æ¯”&lt;code&gt;__syncthreads()&lt;/code&gt;ï¼Œå¼€é”€æ˜¾è‘—é™ä½ï¼Œå› æ— éœ€ç­‰å¾…æ•´ä¸ªçº¿ç¨‹å—ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å…¸å‹åº”ç”¨åœºæ™¯&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;è§„çº¦è®¡ç®—ä¸­æœ€åå‡ æ­¥ï¼ˆå‰©ä½™æ“ä½œåœ¨å•ä¸ªçº¿ç¨‹æŸå†…å®Œæˆï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;é¿å…å…±äº«å†…å­˜è®¿é—®å†²çªæ—¶çš„é«˜æ•ˆåŒæ­¥ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä»£ç ç¤ºä¾‹&lt;/p&gt;
&lt;p&gt;ï¼ˆè§„çº¦ä¼˜åŒ–ï¼‰ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;for (int offset = 16; offset &amp;gt; 0; offset &amp;gt;&amp;gt;= 1) {
if (threadIdx.x &amp;lt; offset)
s_data[threadIdx.x] += s_data[threadIdx.x + offset];
__syncwarp(); // ä»…åŒæ­¥å½“å‰çº¿ç¨‹æŸ
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ³¨æ„äº‹é¡¹&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;èŒƒå›´é™åˆ¶&lt;/strong&gt;ï¼šä»…é€‚ç”¨äºåŒä¸€çº¿ç¨‹æŸå†…çš„çº¿ç¨‹ï¼Œè·¨çº¿ç¨‹æŸæ— æ•ˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ©ç æ§åˆ¶&lt;/strong&gt;ï¼šå¯é€šè¿‡æ©ç æ’é™¤éƒ¨åˆ†çº¿ç¨‹ï¼ˆå¦‚&lt;code&gt;0xfffffffe&lt;/code&gt;æ’é™¤0å·çº¿ç¨‹ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-å­çº¿ç¨‹æŸå±‚çº§çš„åŒæ­¥"&gt;ğŸ”¬ 3. &lt;strong&gt;å­çº¿ç¨‹æŸå±‚çº§çš„åŒæ­¥&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;å­çº¿ç¨‹æŸï¼ˆSub-Warpï¼Œå¦‚16/8/4çº¿ç¨‹ï¼‰çš„åŒæ­¥éœ€ç»“åˆç¼–ç¨‹æŠ€å·§æˆ–é«˜çº§APIã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å®ç°æ–¹æ³•&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;åä½œç»„ï¼ˆCooperative Groupsï¼‰
ï¼š
æ”¯æŒåŠ¨æ€å®šä¹‰çº¿ç¨‹ç»„ï¼ˆå¦‚
```
tiled_partition
```
ï¼‰ï¼Œå¹¶é€šè¿‡
```
sync()
```
åŒæ­¥ã€‚
```
#include &amp;lt;cooperative_groups.h&amp;gt;
__global__ void kernel() {
auto tile = cg::tiled_partition&amp;lt;16&amp;gt;(cg::this_thread_block());
float val = ...;
tile.sync(); // åŒæ­¥16çº¿ç¨‹çš„å­ç»„
// ç»„å†…æ•°æ®äº¤æ¢
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;çº¿ç¨‹æŸæ´—ç‰Œå‡½æ•°ï¼ˆWarp Shuffleï¼‰
ï¼š
é€šè¿‡å¯„å­˜å™¨ç›´æ¥äº¤æ¢æ•°æ®ï¼Œéšå¼å®ç°åŒæ­¥ï¼ˆå¦‚
```
__shfl_down_sync()
```
ï¼‰ã€‚
```
float val = ...;
for (int offset = 8; offset &amp;gt; 0; offset /= 2)
val += __shfl_down_sync(0xffffffff, val, offset);
```
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é€‚ç”¨åœºæ™¯&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ç»†ç²’åº¦æ•°æ®äº¤æ¢ï¼ˆå¦‚è§„çº¦ä¸­ç›¸é‚»çº¿ç¨‹æ±‚å’Œï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;é¿å…å…±äº«å†…å­˜çš„Bankå†²çªã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ€§èƒ½å¯¹æ¯”&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;æ–¹æ³•&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;åŒæ­¥å¼€é”€&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;é€šä¿¡æ–¹å¼&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;é€‚ç”¨å±‚çº§&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;åä½œç»„&lt;/td&gt;
&lt;td&gt;ä¸­ç­‰&lt;/td&gt;
&lt;td&gt;æ˜¾å¼åŒæ­¥&lt;/td&gt;
&lt;td&gt;ä»»æ„è‡ªå®šä¹‰å­ç»„&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;çº¿ç¨‹æŸæ´—ç‰Œ&lt;/td&gt;
&lt;td&gt;æä½&lt;/td&gt;
&lt;td&gt;å¯„å­˜å™¨éšå¼åŒæ­¥&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹æŸå†…å­ç»„&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-4-å…³é”®æ€»ç»“ä¸å»ºè®®"&gt;ğŸ’ 4. &lt;strong&gt;å…³é”®æ€»ç»“ä¸å»ºè®®&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å±‚çº§é€‰æ‹©åŸåˆ™&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;çº¿ç¨‹å—åŒæ­¥&lt;/strong&gt;ï¼šéœ€è·¨çº¿ç¨‹åä½œï¼ˆå¦‚å…±äº«å†…å­˜æ›´æ–°ï¼‰æ—¶ä½¿ç”¨ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;çº¿ç¨‹æŸ/å­çº¿ç¨‹æŸåŒæ­¥&lt;/strong&gt;ï¼šæ“ä½œå±€é™åœ¨å°‘æ•°çº¿ç¨‹æ—¶ä¼˜å…ˆé€‰ç”¨ï¼Œå‡å°‘ç­‰å¾…å¼€é”€ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ€§èƒ½é™·é˜±&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;é¿å…åœ¨åˆ†æ”¯ä»£ç ä¸­è°ƒç”¨&lt;code&gt;__syncthreads()&lt;/code&gt;ï¼Œå¦åˆ™å¯èƒ½æ­»é”ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;å­çº¿ç¨‹æŸåŒæ­¥éœ€ç¡®ä¿è®¾å¤‡æ¶æ„æ”¯æŒï¼ˆå¦‚æ´—ç‰ŒæŒ‡ä»¤éœ€Compute Capability â‰¥ 3.0ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿›é˜¶å·¥å…·&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åä½œç»„&lt;/strong&gt;ï¼šé€‚ç”¨äºå¤æ‚çº¿ç¨‹ç»„ï¼ˆå¦‚è·¨å—åŒæ­¥ï¼‰ï¼Œä½†éœ€CC 6.0+ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŸå­æ“ä½œ&lt;/strong&gt;ï¼šæ›¿ä»£åŒæ­¥å®ç°ç®€å•å…¨å±€æ›´æ–°ï¼ˆå¦‚&lt;code&gt;atomicAdd&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é€šè¿‡åˆç†é€‰æ‹©åŒæ­¥å±‚çº§ä¸å·¥å…·ï¼Œå¯æ˜¾è‘—æå‡GPUç¨‹åºçš„å¹¶è¡Œæ•ˆç‡ã€‚å®é™…å¼€å‘ä¸­å»ºè®®ç»“åˆ&lt;code&gt;nsight-compute&lt;/code&gt;åˆ†æåŒæ­¥å¼€é”€ï¼Œå¹¶ä¼˜å…ˆå°è¯•çº¿ç¨‹æŸçº§ä¼˜åŒ–ã€‚&lt;/p&gt;
&lt;h2 id="__syncwarp"&gt;__syncwarp
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œ&lt;code&gt;__syncwarp&lt;/code&gt; å’Œ &lt;strong&gt;Cooperative Groupsï¼ˆåä½œç»„ï¼‰&lt;/strong&gt; å‡èƒ½å®ç°çº¿ç¨‹åŒæ­¥ï¼Œä½†ä¸¤è€…åœ¨åŠŸèƒ½ç²’åº¦ã€çµæ´»æ€§å’Œé€‚ç”¨åœºæ™¯ä¸Šæœ‰æ˜¾è‘—å·®å¼‚ã€‚ä»¥ä¸‹æ˜¯å…·ä½“åˆ†æï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-__syncwarp"&gt;âš™ï¸ 1. &lt;strong&gt;&lt;code&gt;__syncwarp&lt;/code&gt; å®ç° Sub-Warp åŒæ­¥çš„å¯è¡Œæ€§&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__syncwarp&lt;/code&gt; é€šè¿‡ &lt;strong&gt;æ©ç ï¼ˆmaskï¼‰&lt;/strong&gt; å‚æ•°æ§åˆ¶åŒæ­¥èŒƒå›´ï¼Œç†è®ºä¸Šå¯æ”¯æŒ16æˆ–8çº¿ç¨‹çš„å­ç»„åŒæ­¥ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å®ç°æ–¹å¼&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;p&gt;é€šè¿‡æ©ç æŒ‡å®šéœ€åŒæ­¥çš„çº¿ç¨‹ï¼ˆä¾‹å¦‚&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;0x0000FFFF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;åŒæ­¥ä½16çº¿ç¨‹ï¼Œ&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;0x000000FF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;åŒæ­¥ä½8çº¿ç¨‹ï¼‰ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;unsigned mask_16 = 0x0000FFFF; // åŒæ­¥ä½16çº¿ç¨‹
__syncwarp(mask_16);
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é™åˆ¶&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é™æ€æŒ‡å®š&lt;/strong&gt;ï¼šæ©ç éœ€åœ¨ç¼–è¯‘æ—¶ç¡®å®šï¼Œæ— æ³•åŠ¨æ€åˆ›å»ºå­ç»„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬æ€§è¦æ±‚&lt;/strong&gt;ï¼šæ©ç åŒ…å«çš„æ‰€æœ‰çº¿ç¨‹å¿…é¡»æ‰§è¡Œåˆ° &lt;code&gt;__syncwarp&lt;/code&gt; ä½ç½®ï¼Œå¦åˆ™è¡Œä¸ºæœªå®šä¹‰ï¼ˆå¯èƒ½æ­»é”æˆ–æ•°æ®é”™è¯¯ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ— åˆ†ç»„æŠ½è±¡&lt;/strong&gt;ï¼šéœ€æ‰‹åŠ¨ç®¡ç†æ©ç ï¼Œæ— æ³•ç›´æ¥æ“ä½œå­ç»„å†…æ•°æ®ï¼ˆå¦‚å¹¿æ’­ã€è§„çº¦ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;âœ… &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;ï¼šé™æ€ã€æ— åˆ†æ”¯çš„ç®€å•å­ç»„åŒæ­¥ï¼ˆå¦‚å›ºå®š16çº¿ç¨‹å½’çº¦ï¼‰ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id="-2-cooperative-groupsåä½œç»„çš„ä¼˜åŠ¿"&gt;ğŸ”§ 2. &lt;strong&gt;Cooperative Groupsï¼ˆåä½œç»„ï¼‰çš„ä¼˜åŠ¿&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;åä½œç»„æä¾›æ›´çµæ´»çš„å­ç»„åŒæ­¥æœºåˆ¶ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åŠ¨æ€å­ç»„åˆ›å»º&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;p&gt;å¯è¿è¡Œæ—¶æŒ‰éœ€åˆ’åˆ†ä»»æ„å¤§å°çš„å­ç»„ï¼ˆå¦‚16æˆ–8çº¿ç¨‹ï¼‰ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;#include &amp;lt;cooperative_groups.h&amp;gt;
auto tile = cg::tiled_partition&amp;lt;16&amp;gt;(cg::this_thread_block()); // åˆ›å»º16çº¿ç¨‹å­ç»„
tile.sync(); // åŒæ­¥å­ç»„å†…çº¿ç¨‹
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å®‰å…¨æ€§ä¸åŠŸèƒ½æ€§&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯å®¹å¿&lt;/strong&gt;ï¼šå…è®¸å­ç»„å†…çº¿ç¨‹å­˜åœ¨åˆ†æ”¯ï¼ŒåŒæ­¥æ—¶è‡ªåŠ¨æ£€æµ‹æœªåˆ°è¾¾çº¿ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å†…ç½®æ“ä½œ&lt;/strong&gt;ï¼šæ”¯æŒå­ç»„å†…æ•°æ®äº¤æ¢ï¼ˆ&lt;code&gt;shuffle&lt;/code&gt;ï¼‰ã€è§„çº¦ï¼ˆ&lt;code&gt;reduce&lt;/code&gt;ï¼‰ç­‰åŸå­æ“ä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è·¨å±‚çº§æ”¯æŒ&lt;/strong&gt;ï¼šæ”¯æŒçº¿ç¨‹å—ã€ç½‘æ ¼çº§åŒæ­¥ï¼Œè¿œè¶… &lt;code&gt;__syncwarp&lt;/code&gt; èŒƒå›´ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;âœ… &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;ï¼šåŠ¨æ€å­ç»„ã€å­˜åœ¨åˆ†æ”¯ã€éœ€å­ç»„å†…æ•°æ®äº¤äº’çš„å¤æ‚é€»è¾‘ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id="-3-æ€§èƒ½ä¸å…¼å®¹æ€§å¯¹æ¯”"&gt;âš–ï¸ 3. &lt;strong&gt;æ€§èƒ½ä¸å…¼å®¹æ€§å¯¹æ¯”&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;code&gt;__syncwarp&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;Cooperative Groups&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;åŒæ­¥å¼€é”€&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;æä½ï¼ˆâ‰ˆå‡ æ¡æŒ‡ä»¤ï¼‰&lt;/td&gt;
&lt;td&gt;è¾ƒé«˜ï¼ˆéœ€åˆ›å»ºç»„å¯¹è±¡ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;æ¶æ„æ”¯æŒ&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Compute 3.0+&lt;/td&gt;
&lt;td&gt;Compute 6.0+ï¼ˆéœ€æ˜¾å¼å¯ç”¨ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;åŠ¨æ€å­ç»„&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;ä¸æ”¯æŒ&lt;/td&gt;
&lt;td&gt;æ”¯æŒ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;åˆ†æ”¯å®¹å¿æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;ä½ï¼ˆæ©ç çº¿ç¨‹å¿…é¡»å…¨éƒ¨æ‰§è¡Œï¼‰&lt;/td&gt;
&lt;td&gt;é«˜ï¼ˆè‡ªåŠ¨å¤„ç†æœªåˆ°è¾¾çº¿ç¨‹ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;ä»£ç å¯ç»´æŠ¤æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;ä½ï¼ˆæ‰‹åŠ¨ç®¡ç†æ©ç ï¼‰&lt;/td&gt;
&lt;td&gt;é«˜ï¼ˆé¢å‘å¯¹è±¡æŠ½è±¡ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-4-å®è·µå»ºè®®"&gt;ğŸ’ 4. &lt;strong&gt;å®è·µå»ºè®®&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜å…ˆä½¿ç”¨ Cooperative Groups&lt;/strong&gt;ï¼š
å°¤å…¶æ˜¯ â€‹&lt;strong&gt;Voltaæ¶æ„ï¼ˆCompute 7.0+ï¼‰åŠä»¥ä¸Š&lt;/strong&gt;ï¼Œåä½œç»„æ˜¯å®˜æ–¹æ¨èæ–¹å¼ï¼Œé¿å… &lt;code&gt;__syncwarp&lt;/code&gt; åœ¨åˆ†æ”¯ä»£ç ä¸­çš„é£é™©ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;__syncwarp&lt;/code&gt; çš„æ›¿ä»£åœºæ™¯&lt;/strong&gt;ï¼š
è‹¥éœ€å…¼å®¹æ—§æ¶æ„ï¼ˆå¦‚Pascalï¼‰ï¼Œä¸”åŒæ­¥é€»è¾‘ç®€å•æ— åˆ†æ”¯ï¼Œå¯ç”¨æ©ç å®ç°å­ç»„åŒæ­¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½æ•æ„Ÿåœºæ™¯&lt;/strong&gt;ï¼š
&lt;code&gt;__syncwarp&lt;/code&gt; åœ¨æç«¯ä¼˜åŒ–åœºæ™¯ï¼ˆå¦‚é«˜é¢‘è°ƒç”¨çš„è½»é‡æ“ä½œï¼‰å¯èƒ½æœ‰è½»å¾®ä¼˜åŠ¿ï¼Œä½†éœ€ä¸¥æ ¼ä¿è¯çº¿ç¨‹ä¸€è‡´æ€§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-æ€»ç»“"&gt;ğŸ“Œ &lt;strong&gt;æ€»ç»“&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;__syncwarp&lt;/code&gt; å¯é™æ€å®ç°16/8çº¿ç¨‹åŒæ­¥&lt;/strong&gt;ï¼Œä½†éœ€æ‰‹åŠ¨ç®¡ç†æ©ç ä¸”ä¸æ”¯æŒåŠ¨æ€åˆ†ç»„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cooperative Groups æ˜¯æ›´ä¼˜è§£&lt;/strong&gt;ï¼šæä¾›å®‰å…¨ã€çµæ´»çš„å­ç»„æŠ½è±¡ï¼Œé€‚åˆç°ä»£GPUæ¶æ„ã€‚
æ ¹æ®æ¶æ„å’Œéœ€æ±‚é€‰æ‹©å·¥å…·ï¼Œå¤æ‚åœºæ™¯åŠ¡å¿…ç”¨åä½œç»„è§„é¿åŒæ­¥é£é™©ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="å†…å­˜å»¶è¿Ÿ"&gt;å†…å­˜å»¶è¿Ÿ
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œä½¿ç”¨8ä¸ªçº¿ç¨‹ä¸€ç»„çš„Cooperative Groupsï¼ˆåä½œç»„ï¼‰æ—¶ï¼Œå°†çº¿ç¨‹å—å¤§å°ï¼ˆThread Block Sizeï¼‰è®¾ä¸º1024&lt;strong&gt;ç†è®ºä¸Šå¯ä»¥æ›´å¥½åœ°éšè—å†…å­˜è®¿é—®å»¶è¿Ÿï¼Œä½†å®é™…æ•ˆæœå–å†³äºç¡¬ä»¶èµ„æºåˆ©ç”¨ç‡å’Œç®—æ³•è®¾è®¡&lt;/strong&gt;ã€‚ä»¥ä¸‹æ˜¯ç»¼åˆåˆ†æï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-å†…å­˜å»¶è¿Ÿéšè—çš„åŸç†"&gt;âš™ï¸ 1. &lt;strong&gt;å†…å­˜å»¶è¿Ÿéšè—çš„åŸç†&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;GPUé€šè¿‡&lt;strong&gt;å¤§è§„æ¨¡çº¿ç¨‹å¹¶è¡Œ&lt;/strong&gt;éšè—å…¨å±€å†…å­˜è®¿é—®çš„é«˜å»¶è¿Ÿï¼ˆé€šå¸¸æ•°ç™¾æ—¶é’Ÿå‘¨æœŸï¼‰ã€‚å½“çº¿ç¨‹å› å†…å­˜è®¿é—®åœé¡¿æ—¶ï¼ŒSMï¼ˆæµå¼å¤šå¤„ç†å™¨ï¼‰ä¼šç«‹å³åˆ‡æ¢åˆ°å…¶ä»–å¯æ‰§è¡Œçš„çº¿ç¨‹æŸï¼ˆWarpï¼‰ã€‚çº¿ç¨‹å—è¶Šå¤§ï¼ŒåŒ…å«çš„çº¿ç¨‹æŸè¶Šå¤šï¼ˆ1024çº¿ç¨‹ = 32ä¸ªçº¿ç¨‹æŸï¼‰ï¼ŒSMåœ¨ç­‰å¾…å†…å­˜æ—¶åˆ‡æ¢çš„çº¿ç¨‹æŸèµ„æºè¶Šä¸°å¯Œï¼Œå»¶è¿Ÿéšè—èƒ½åŠ›è¶Šå¼ºã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-2-1024çº¿ç¨‹å—çš„ä¼˜åŠ¿ä¸é£é™©"&gt;âš–ï¸ 2. &lt;strong&gt;1024çº¿ç¨‹å—çš„ä¼˜åŠ¿ä¸é£é™©&lt;/strong&gt;
&lt;/h3&gt;&lt;h4 id="ä¼˜åŠ¿"&gt;&lt;strong&gt;ä¼˜åŠ¿ï¼š&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ›´é«˜çš„çº¿ç¨‹æŸå¹¶è¡Œåº¦&lt;/strong&gt;ï¼š1024çº¿ç¨‹å—æä¾›32ä¸ªçº¿ç¨‹æŸï¼Œè¿œé«˜äºå°çº¿ç¨‹å—ï¼ˆå¦‚256çº¿ç¨‹ä»…8ä¸ªçº¿ç¨‹æŸï¼‰ã€‚è¿™å¢åŠ äº†SMè°ƒåº¦å™¨åˆ‡æ¢çº¿ç¨‹æŸçš„æœºä¼šï¼Œæ›´æ˜“æ©ç›–å†…å­˜å»¶è¿Ÿã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åä½œç»„çš„çµæ´»æ€§&lt;/strong&gt;ï¼š8çº¿ç¨‹çš„åä½œç»„ï¼ˆ&lt;code&gt;cg::tiled_partition&amp;lt;8&amp;gt;&lt;/code&gt;ï¼‰å¯åœ¨1024çº¿ç¨‹å—å†…åˆ›å»º128ä¸ªç‹¬ç«‹å­ç»„ã€‚æ¯ä¸ªå­ç»„å†…éƒ¨åŒæ­¥å¼€é”€ä½ï¼ˆå¦‚&lt;code&gt;tile.sync()&lt;/code&gt;ï¼‰ï¼Œä¸”å­ç»„é—´é€šè¿‡å¤§é‡çº¿ç¨‹æŸäº¤é”™æ‰§è¡Œï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–å»¶è¿Ÿéšè—ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="é£é™©"&gt;&lt;strong&gt;é£é™©ï¼š&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;èµ„æºç«äº‰å¯¼è‡´é˜»å¡&lt;/p&gt;
&lt;p&gt;ï¼šè‹¥1024çº¿ç¨‹å—æ¶ˆè€—è¿‡å¤šèµ„æºï¼ˆå¦‚å¯„å­˜å™¨ã€å…±äº«å†…å­˜ï¼‰ï¼ŒSMå¯èƒ½æ— æ³•é©»ç•™è¶³å¤Ÿçº¿ç¨‹å—ã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;æ¯ä¸ªçº¿ç¨‹å ç”¨32ä¸ªå¯„å­˜å™¨ â†’ 1024çº¿ç¨‹éœ€32KBå¯„å­˜å™¨ï¼Œè¶…è¿‡SMä¸Šé™ï¼ˆå¦‚Ampereæ¶æ„æ¯SM 64KBï¼‰æ—¶ï¼Œå®é™…é©»ç•™çº¿ç¨‹å—æ•°å‡å°‘ï¼Œåè€Œé™ä½å¹¶è¡Œåº¦ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;å…±äº«å†…å­˜ä¸è¶³ï¼šè‹¥æ¯ä¸ªçº¿ç¨‹å—éœ€48KBå…±äº«å†…å­˜ï¼ŒSMå…±äº«å†…å­˜æ€»é‡ä¸º128KBæ—¶ä»…èƒ½é©»ç•™2ä¸ªå—ï¼ˆ2048çº¿ç¨‹ï¼‰ï¼Œè¿œä½äºç†æƒ³çŠ¶æ€ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å­ç»„åŒæ­¥æ•ˆç‡é—®é¢˜&lt;/strong&gt;ï¼š8çº¿ç¨‹å­ç»„çš„åŒæ­¥è™½å¿«ï¼Œä½†è‹¥ç®—æ³•ä¾èµ–è·¨å­ç»„é€šä¿¡ï¼ˆå¦‚å…¨å±€å½’çº¦ï¼‰ï¼Œ1024çº¿ç¨‹å—å¯èƒ½å¯¼è‡´åŒæ­¥ç‚¹å¢å¤šï¼Œå¢åŠ æ•´ä½“ç­‰å¾…æ—¶é—´ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-ä¸è¾ƒå°çº¿ç¨‹å—çš„æ€§èƒ½å¯¹æ¯”"&gt;ğŸ“Š 3. &lt;strong&gt;ä¸è¾ƒå°çº¿ç¨‹å—çš„æ€§èƒ½å¯¹æ¯”&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;çº¿ç¨‹å—å¤§å°&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;çº¿ç¨‹æŸæ•°é‡&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;å»¶è¿Ÿéšè—æ½œåŠ›&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;èµ„æºå‹åŠ›&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;è¾ƒä½&lt;/td&gt;
&lt;td&gt;ä½&lt;/td&gt;
&lt;td&gt;èµ„æºå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚é«˜å¯„å­˜å™¨ä½¿ç”¨ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;ä¸­ç­‰&lt;/td&gt;
&lt;td&gt;ä¸­ç­‰&lt;/td&gt;
&lt;td&gt;å¹³è¡¡å‹ä»»åŠ¡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;1024&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;32&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;é«˜&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;é«˜&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;å†…å­˜å¯†é›†å‹ + èµ„æºå……è¶³æ—¶&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;å®éªŒæ•°æ®æ”¯æŒ&lt;/strong&gt;ï¼šåœ¨ç«‹æ–¹å’Œè®¡ç®—ç¤ºä¾‹ä¸­ï¼Œ1024çº¿ç¨‹å—ç›¸æ¯”256çº¿ç¨‹å—å¸¦å®½åˆ©ç”¨ç‡æå‡106%ï¼ˆ491 MB/s vs. 238 MB/sï¼‰ï¼Œä½†éœ€ç¡®ä¿èµ„æºä¸è¶…é™ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-4-ä¼˜åŒ–å»ºè®®å¹³è¡¡èµ„æºä¸å¹¶è¡Œåº¦"&gt;ğŸ› ï¸ 4. &lt;strong&gt;ä¼˜åŒ–å»ºè®®ï¼šå¹³è¡¡èµ„æºä¸å¹¶è¡Œåº¦&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;åŠ¨æ€è°ƒæ•´çº¿ç¨‹å—å¤§å°&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä¼˜å…ˆå°è¯•&lt;strong&gt;512çº¿ç¨‹å—&lt;/strong&gt;ï¼ˆå¦‚16ä¸ªçº¿ç¨‹æŸï¼‰ï¼Œå…¼é¡¾å¹¶è¡Œåº¦ä¸èµ„æºå ç”¨ã€‚&lt;/li&gt;
&lt;li&gt;ä»…å½“ç®—æ³•éœ€æå¤šå­ç»„ä¸”èµ„æºå……è¶³æ—¶é€‰ç”¨1024çº¿ç¨‹å—ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;èµ„æºå ç”¨åˆ†æ&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä½¿ç”¨&lt;code&gt;cudaOccupancyMaxActiveBlocksPerMultiprocessor&lt;/code&gt;è®¡ç®—SMå®é™…é©»ç•™å—æ•°ã€‚&lt;/li&gt;
&lt;li&gt;ç›®æ ‡å ç”¨ç‡å»ºè®® â‰¥80%ï¼Œå¦åˆ™éœ€å‡å°‘å¯„å­˜å™¨ä½¿ç”¨ï¼ˆ&lt;code&gt;__launch_bounds__&lt;/code&gt;ï¼‰æˆ–å…±äº«å†…å­˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å­ç»„è®¾è®¡ä¼˜åŒ–&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;8çº¿ç¨‹å­ç»„å†…ä½¿ç”¨&lt;strong&gt;å¯„å­˜å™¨é€šä¿¡&lt;/strong&gt;ï¼ˆå¦‚&lt;code&gt;__shfl_sync&lt;/code&gt;ï¼‰æ›¿ä»£å…±äº«å†…å­˜ï¼Œå‡å°‘èµ„æºäº‰ç”¨ã€‚&lt;/li&gt;
&lt;li&gt;é¿å…å­ç»„é—´ä¾èµ–ï¼Œç¡®ä¿å„å­ç»„ç‹¬ç«‹å·¥ä½œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-ç»“è®º"&gt;ğŸ’ &lt;strong&gt;ç»“è®º&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1024çº¿ç¨‹å—åœ¨èµ„æºå……è¶³æ—¶èƒ½æœ‰æ•ˆéšè—å»¶è¿Ÿ&lt;/strong&gt;ï¼šå°¤å…¶é€‚åˆå…¨å±€å†…å­˜è®¿é—®é¢‘ç¹ã€å­ç»„é—´æ— ä¾èµ–çš„ä»»åŠ¡ï¼ˆå¦‚ç‹¬ç«‹æ»¤æ³¢ã€å¹¶è¡Œæ˜ å°„ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å®é™…éœ€ç»¼åˆæƒè¡¡&lt;/strong&gt;ï¼šè‹¥èµ„æºç´§å¼ ï¼ˆå¦‚å…±äº«å†…å­˜ä¸è¶³ï¼‰ï¼Œé€‰æ‹©512æˆ–256çº¿ç¨‹å—æ›´ç¨³å¥ã€‚å»ºè®®é€šè¿‡&lt;strong&gt;æ€§èƒ½åˆ†æå·¥å…·&lt;/strong&gt;ï¼ˆNsight Computeï¼‰å®æµ‹å»¶è¿Ÿéšè—æ•ˆæœï¼ŒåŠ¨æ€è°ƒæ•´é…ç½®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="çº¿ç¨‹å—åŒæ­¥"&gt;çº¿ç¨‹å—åŒæ­¥
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œçº¿ç¨‹å—ï¼ˆThread Blockï¼‰ä¹‹é—´é»˜è®¤æ˜¯ç‹¬ç«‹æ‰§è¡Œçš„ï¼Œæ— æ³•ç›´æ¥é€šè¿‡ç±»ä¼¼&lt;code&gt;__syncthreads()&lt;/code&gt;çš„å—å†…åŒæ­¥å‡½æ•°å®ç°è·¨å—åŒæ­¥ã€‚è¿™æ˜¯å› ä¸ºCUDAçš„çº¿ç¨‹è°ƒåº¦æ¨¡å‹è®¾è®¡ä¸ºçº¿ç¨‹å—å¯ä¹±åºæ‰§è¡Œï¼Œä¸”ç¡¬ä»¶ä¸Šå¯èƒ½åˆ†æ•£åœ¨ä¸åŒæµå¤„ç†å™¨ï¼ˆSMï¼‰ä¸Šã€‚ä»¥ä¸‹æ˜¯å®ç°è·¨å—åŒæ­¥çš„å‡ ç§æ ¸å¿ƒæ–¹æ³•åŠå…¶é€‚ç”¨åœºæ™¯ï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-ä¸€åŸå­æ“ä½œ--å…¨å±€å†…å­˜å±éšœ"&gt;âš™ï¸ ä¸€ã€åŸå­æ“ä½œ + å…¨å±€å†…å­˜å±éšœ
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;åŸç†&lt;/strong&gt;ï¼šé€šè¿‡å…¨å±€å˜é‡ï¼ˆå¦‚è®¡æ•°å™¨ï¼‰åè°ƒçº¿ç¨‹å—çŠ¶æ€ï¼Œç»“åˆåŸå­æ“ä½œç¡®ä¿å…¨å±€çŠ¶æ€æ›´æ–°çš„åŸå­æ€§ã€‚
â€‹&lt;strong&gt;æ­¥éª¤&lt;/strong&gt;â€‹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;åˆå§‹åŒ–å…¨å±€å˜é‡&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__device__ int block_counter = 0; // å…¨å±€è®¡æ•°å™¨
&lt;/code&gt;&lt;/pre&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;çº¿ç¨‹å—å®Œæˆè®¡ç®—åæ›´æ–°è®¡æ•°å™¨&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;atomicAdd(&amp;amp;block_counter, 1); // åŸå­é€’å¢
&lt;/code&gt;&lt;/pre&gt;&lt;ol start="3"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ç­‰å¾…æ‰€æœ‰å—å®Œæˆ&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;p&gt;æ¯ä¸ªçº¿ç¨‹å—å¾ªç¯æ£€æŸ¥è®¡æ•°å™¨æ˜¯å¦è¾¾åˆ°æ€»å—æ•°ï¼Œéœ€é…åˆå†…å­˜å±éšœç¡®ä¿å…¨å±€å¯è§æ€§ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;while (block_counter &amp;lt; gridDim.x) {
__threadfence(); // ç¡®ä¿å½“å‰çº¿ç¨‹å†™å…¥å¯¹å…¶ä»–çº¿ç¨‹å¯è§
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå…¼å®¹æ€§å¼ºï¼ˆæ”¯æŒæ‰€æœ‰CUDAæ¶æ„ï¼‰ã€‚
â€‹&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;â€‹ï¼šå¾ªç¯ç­‰å¾…æ¶ˆè€—ç®—åŠ›ï¼Œå¯èƒ½é™ä½æ€§èƒ½ï¼›éœ€é¿å…æ­»é”ï¼ˆå¦‚æ‰€æœ‰å—æœªå®Œå…¨å¯åŠ¨ï¼‰ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-äºŒåä½œç»„cooperative-groups"&gt;ğŸ§© äºŒã€åä½œç»„ï¼ˆCooperative Groupsï¼‰
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;åŸç†&lt;/strong&gt;ï¼šä½¿ç”¨CUDA 9+å¼•å…¥çš„åä½œç»„APIï¼Œæ”¯æŒç½‘æ ¼çº§ï¼ˆGrid-Wideï¼‰åŒæ­¥ã€‚
â€‹&lt;strong&gt;æ­¥éª¤&lt;/strong&gt;â€‹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å¯åŠ¨åä½œå†…æ ¸&lt;/strong&gt;ï¼š
ä½¿ç”¨&lt;code&gt;cudaLaunchCooperativeKernel&lt;/code&gt;å¯åŠ¨å†…æ ¸ï¼Œç¡®ä¿æ‰€æœ‰å—å¯åŒæ—¶é©»ç•™GPUã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ç½‘æ ¼å†…åŒæ­¥&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cooperative_groups::grid_group grid = cooperative_groups::this_grid();
grid.sync(); // åŒæ­¥æ‰€æœ‰å—
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;ç¡¬ä»¶è¦æ±‚&lt;/strong&gt;ï¼šè®¡ç®—èƒ½åŠ›â‰¥6.0ï¼ˆPascal+æ¶æ„ï¼‰ä¸”GPUæ”¯æŒåä½œå†…æ ¸ã€‚
â€‹&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;â€‹ï¼šè¯­æ³•ç®€æ´ï¼Œæ— å¿™ç­‰å¾…å¼€é”€ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-ä¸‰æµä¸äº‹ä»¶streams-and-events"&gt;â±ï¸ ä¸‰ã€æµä¸äº‹ä»¶ï¼ˆStreams and Eventsï¼‰
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;åŸç†&lt;/strong&gt;ï¼šé€šè¿‡CUDAäº‹ä»¶ï¼ˆEventï¼‰åœ¨ä¸»æœºç«¯åè°ƒå¤šä¸ªæµï¼ˆStreamï¼‰çš„æ‰§è¡Œé¡ºåºã€‚
â€‹&lt;strong&gt;æ­¥éª¤&lt;/strong&gt;â€‹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;è®°å½•äº‹ä»¶&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;p&gt;åœ¨ç¬¬ä¸€ä¸ªå†…æ ¸åè®°å½•äº‹ä»¶ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cudaEvent_t event;
cudaEventCreate(&amp;amp;event);
kernel1&amp;lt;&amp;lt;&amp;lt;blocks, threads, 0, stream1&amp;gt;&amp;gt;&amp;gt;();
cudaEventRecord(event, stream1);
&lt;/code&gt;&lt;/pre&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;åç»­å†…æ ¸ç­‰å¾…äº‹ä»¶&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cudaStreamWaitEvent(stream2, event); // stream2ç­‰å¾…eventå®Œæˆ
kernel2&amp;lt;&amp;lt;&amp;lt;blocks, threads, 0, stream2&amp;gt;&amp;gt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;ï¼šéœ€ä¸»æœºä»‹å…¥çš„ç²—ç²’åº¦åŒæ­¥ï¼Œå¦‚å¤šé˜¶æ®µä»»åŠ¡ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-å››å¤šæ¬¡å†…æ ¸å¯åŠ¨kernel-launch-splitting"&gt;ğŸ” å››ã€å¤šæ¬¡å†…æ ¸å¯åŠ¨ï¼ˆKernel Launch Splittingï¼‰
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;åŸç†&lt;/strong&gt;ï¼šå°†ä»»åŠ¡æ‹†åˆ†ä¸ºå¤šä¸ªå†…æ ¸ï¼Œåˆ©ç”¨å†…æ ¸å¯åŠ¨å¤©ç„¶åŒæ­¥çš„ç‰¹æ€§ã€‚
â€‹&lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt;â€‹ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;// ç¬¬ä¸€é˜¶æ®µï¼šå„å—ç‹¬ç«‹è®¡ç®—
phase1_kernel&amp;lt;&amp;lt;&amp;lt;blocks, threads&amp;gt;&amp;gt;&amp;gt;();
cudaDeviceSynchronize(); // ä¸»æœºåŒæ­¥ç­‰å¾…æ‰€æœ‰å—å®Œæˆ
// ç¬¬äºŒé˜¶æ®µï¼šå¤„ç†ç»“æœ
phase2_kernel&amp;lt;&amp;lt;&amp;lt;blocks, threads&amp;gt;&amp;gt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šç®€å•å¯é ï¼Œæ— æ­»é”é£é™©ã€‚
â€‹&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;â€‹ï¼šå†…æ ¸å¯åŠ¨å»¶è¿Ÿè¾ƒé«˜ï¼Œé¢‘ç¹æ‹†åˆ†å½±å“æ€§èƒ½ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-äº”æ–¹æ³•å¯¹æ¯”ä¸é€‰æ‹©å»ºè®®"&gt;ğŸ’ äº”ã€æ–¹æ³•å¯¹æ¯”ä¸é€‰æ‹©å»ºè®®
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;æ–¹æ³•&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;å®æ—¶æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;å¤æ‚åº¦&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;ç¡¬ä»¶è¦æ±‚&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;åŸå­æ“ä½œ+å…¨å±€å±éšœ&lt;/td&gt;
&lt;td&gt;ä½&lt;/td&gt;
&lt;td&gt;ä¸­&lt;/td&gt;
&lt;td&gt;æ‰€æœ‰æ¶æ„&lt;/td&gt;
&lt;td&gt;å…¼å®¹æ€§ä¼˜å…ˆçš„è½»é‡ä»»åŠ¡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;åä½œç»„&lt;/td&gt;
&lt;td&gt;é«˜&lt;/td&gt;
&lt;td&gt;ä½&lt;/td&gt;
&lt;td&gt;Pascal+æ¶æ„&lt;/td&gt;
&lt;td&gt;é«˜æ€§èƒ½è®¡ç®—ï¼Œéœ€ç²¾ç»†åŒæ­¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æµä¸äº‹ä»¶&lt;/td&gt;
&lt;td&gt;ä¸­&lt;/td&gt;
&lt;td&gt;ä¸­&lt;/td&gt;
&lt;td&gt;æ‰€æœ‰æ¶æ„&lt;/td&gt;
&lt;td&gt;å¤šæµä»»åŠ¡ï¼Œä¸»æœºå¯åè°ƒ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å¤šæ¬¡å†…æ ¸å¯åŠ¨&lt;/td&gt;
&lt;td&gt;ä½&lt;/td&gt;
&lt;td&gt;ä½&lt;/td&gt;
&lt;td&gt;æ‰€æœ‰æ¶æ„&lt;/td&gt;
&lt;td&gt;ç®€å•ä»»åŠ¡ï¼Œé¿å…æ­»é”&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-æ³¨æ„äº‹é¡¹"&gt;âš ï¸ æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;æ­»é”é£é™©&lt;/strong&gt;ï¼šåŸå­æ“ä½œå¾ªç¯ç­‰å¾…æ—¶ï¼Œè‹¥éƒ¨åˆ†çº¿ç¨‹å—æœªå¯åŠ¨ï¼ˆå¦‚èµ„æºä¸è¶³ï¼‰ï¼Œä¼šå¯¼è‡´æ°¸ä¹…ç­‰å¾…ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½æƒè¡¡&lt;/strong&gt;ï¼šåä½œç»„æ€§èƒ½æœ€ä¼˜ï¼Œä½†éœ€ç¡¬ä»¶æ”¯æŒï¼›åŸå­æ“ä½œå¿™ç­‰å¾…å¯èƒ½æ‹–ç´¯ååé‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¸Šä¸‹æ–‡éš”ç¦»&lt;/strong&gt;ï¼šå¤šçº¿ç¨‹ä¸»æœºç¨‹åºä¸­ï¼Œç¡®ä¿å„çº¿ç¨‹CUDAä¸Šä¸‹æ–‡äº’æ–¥æ“ä½œï¼ˆå¦‚ç”¨&lt;code&gt;std::mutex&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;æ ¹æ®å…·ä½“åœºæ™¯é€‰æ‹©æ–¹æ¡ˆï¼š&lt;strong&gt;åä½œç»„æ˜¯æœªæ¥è¶‹åŠ¿&lt;/strong&gt;ï¼Œæ—§ç¡¬ä»¶é¡¹ç›®å¯é€‰ç”¨&lt;strong&gt;åŸå­æ“ä½œ&lt;/strong&gt;æˆ–&lt;strong&gt;å†…æ ¸æ‹†åˆ†&lt;/strong&gt;ï¼Œè€Œä¾èµ–ä¸»æœºè°ƒåº¦çš„ä»»åŠ¡é€‚åˆ&lt;strong&gt;æµäº‹ä»¶&lt;/strong&gt;æœºåˆ¶ã€‚&lt;/p&gt;
&lt;h2 id="thread-block-cluster"&gt;Thread Block Cluster
&lt;/h2&gt;&lt;p&gt;Thread Block Clusterï¼ˆçº¿ç¨‹å—é›†ç¾¤ï¼‰æ˜¯NVIDIAåœ¨Hopperæ¶æ„ä¸­å¼•å…¥çš„æ–°ç‰¹æ€§ï¼Œä¸»è¦ç”¨äºä¼˜åŒ–å¤§è§„æ¨¡å¹¶è¡Œä»»åŠ¡çš„åä½œæ•ˆç‡ã€‚ä»¥ä¸‹ä»æŠ€æœ¯åŸç†ã€è·¨SMèƒ½åŠ›åŠæ€§èƒ½å½±å“ä¸‰ä¸ªæ–¹é¢ç»¼åˆåˆ†æï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-thread-block-clusteræ˜¯å¦æ”¯æŒè·¨sm"&gt;â›“ï¸ &lt;strong&gt;1. Thread Block Clusteræ˜¯å¦æ”¯æŒè·¨SMï¼Ÿ&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ”¯æŒè·¨SM&lt;/strong&gt;ï¼šThread Block Clusterè®¾è®¡ä¸º&lt;strong&gt;è·¨è¶Šå¤šä¸ªSMçš„åä½œå•å…ƒ&lt;/strong&gt;ï¼Œæœ€å¤šå¯åŒ…å«8ä¸ªçº¿ç¨‹å—ï¼ˆå¦‚Hopperæ¶æ„ï¼‰ã€‚è¿™äº›çº¿ç¨‹å—å¯åˆ†å¸ƒåœ¨ä¸åŒçš„SMä¸Šï¼Œé€šè¿‡ç¡¬ä»¶çº§åŒæ­¥æœºåˆ¶ï¼ˆå¦‚å¼ é‡å†…å­˜åŠ é€Ÿå™¨TMAï¼‰åè°ƒè®¡ç®—ä»»åŠ¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æŠ€æœ¯åŸç†&lt;/strong&gt;ï¼šé›†ç¾¤é€šè¿‡&lt;strong&gt;ç¡¬ä»¶äº’è”é€šé“ï¼ˆå¦‚NVLinkï¼‰&lt;/strong&gt; å®ç°è·¨SMé€šä¿¡ã€‚æ¯ä¸ªé›†ç¾¤å†…çš„çº¿ç¨‹å—å…±äº«åŒæ­¥å¯¹è±¡ï¼ˆå¦‚&lt;code&gt;cuda::barrier&lt;/code&gt;ï¼‰ï¼Œæ”¯æŒè®¾å¤‡çº§ï¼ˆ&lt;code&gt;thread_scope_device&lt;/code&gt;ï¼‰æˆ–é›†ç¾¤çº§ï¼ˆæ–°å¢å±‚çº§ï¼‰çš„åŒæ­¥æ“ä½œï¼Œçªç ´äº†ä¼ ç»Ÿçº¿ç¨‹å—ï¼ˆBlockï¼‰ä»…é™äºå•SMçš„çº¦æŸã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-è·¨små¯¹æ€§èƒ½çš„å½±å“"&gt;ğŸ“Š &lt;strong&gt;2. è·¨SMå¯¹æ€§èƒ½çš„å½±å“&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;è·¨SMåä½œåœ¨æå‡å¹¶è¡Œè§„æ¨¡çš„åŒæ—¶ï¼Œä¹Ÿå¼•å…¥æ–°çš„æ€§èƒ½æŒ‘æˆ˜ï¼š&lt;/p&gt;
&lt;h4 id="-1åŒæ­¥å»¶è¿Ÿæ˜¾è‘—å¢åŠ "&gt;âš¡ &lt;strong&gt;ï¼ˆ1ï¼‰åŒæ­¥å»¶è¿Ÿæ˜¾è‘—å¢åŠ &lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å±‚çº§å¯¹æ¯”&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;å•SMå†…BlockåŒæ­¥ï¼šå»¶è¿Ÿçº¦&lt;strong&gt;100â€“200ns&lt;/strong&gt;ï¼ˆé€šè¿‡å…±äº«å†…å­˜å±éšœå®ç°ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;è·¨SMé›†ç¾¤åŒæ­¥ï¼šå»¶è¿Ÿä»‹äºBlockçº§ä¸Deviceçº§ä¹‹é—´ï¼ˆçº¦&lt;strong&gt;500nsâ€“1Î¼s&lt;/strong&gt;ï¼‰ï¼Œå› éœ€åè°ƒå¤šSMçš„L2ç¼“å­˜ä¸€è‡´æ€§åŠç¡¬ä»¶ä¿¡å·ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å…¸å‹æ¡ˆä¾‹&lt;/strong&gt;ï¼šåœ¨3Då¼ é‡è¿ç®—ä¸­ï¼Œè·¨SMé›†ç¾¤åŒæ­¥å¼€é”€æ¯”å•SMé«˜70%ï¼Œä½†é€šè¿‡TMAåŠ é€ŸåŸå­æ“ä½œå¯éƒ¨åˆ†æŠµæ¶ˆã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="-2èµ„æºç«äº‰ä¸é€šä¿¡å¸¦å®½ç“¶é¢ˆ"&gt;ğŸ”„ &lt;strong&gt;ï¼ˆ2ï¼‰èµ„æºç«äº‰ä¸é€šä¿¡å¸¦å®½ç“¶é¢ˆ&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;èµ„æºç«äº‰&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;é›†ç¾¤å†…çº¿ç¨‹å—å…±äº«å…¨å±€å†…å­˜å¸¦å®½ï¼Œè‹¥ä»»åŠ¡éœ€é¢‘ç¹äº¤æ¢æ•°æ®ï¼Œå¯èƒ½å—é™äºHBMå¸¦å®½ï¼ˆå¦‚A100çš„1.5TB/sï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SMé—´çš„å¯„å­˜å™¨æ–‡ä»¶ç‹¬ç«‹ï¼Œè·¨SMæ•°æ®ä¾èµ–éœ€é€šè¿‡å…¨å±€å†…å­˜ä¼ è¾“ï¼Œå¢åŠ å»¶è¿Ÿã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;é€šä¿¡ä¼˜åŒ–&lt;/strong&gt;ï¼š
ä½¿ç”¨&lt;code&gt;cuda::memcpy_async&lt;/code&gt;å¼‚æ­¥æ‹·è´æˆ–TMAç¡¬ä»¶åŠ é€Ÿï¼Œå¯é‡å è®¡ç®—ä¸é€šä¿¡ï¼Œå‡å°‘æ˜¾å¼ç­‰å¾…æ—¶é—´ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="-3èµ„æºåˆ©ç”¨ç‡ä¸è´Ÿè½½å‡è¡¡"&gt;âš–ï¸ &lt;strong&gt;ï¼ˆ3ï¼‰èµ„æºåˆ©ç”¨ç‡ä¸è´Ÿè½½å‡è¡¡&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿åœºæ™¯&lt;/strong&gt;ï¼š
ä»»åŠ¡å¯åˆ†è§£ä¸ºç‹¬ç«‹å­é—®é¢˜æ—¶ï¼ˆå¦‚çŸ©é˜µåˆ†å—ä¹˜æ³•ï¼‰ï¼Œè·¨SMé›†ç¾¤èƒ½&lt;strong&gt;æ˜¾è‘—æå‡ååé‡&lt;/strong&gt;ï¼Œå°¤å…¶å½“å•SMèµ„æºä¸è¶³æ—¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŠ£åŠ¿åœºæ™¯&lt;/strong&gt;ï¼š
è‹¥ä»»åŠ¡ä¾èµ–å¼ºæˆ–æ•°æ®å±€éƒ¨æ€§é«˜ï¼Œè·¨SMé€šä¿¡å¼€é”€å¯èƒ½æŠµæ¶ˆå¹¶è¡Œæ”¶ç›Šï¼Œæ­¤æ—¶å•SMå†…Blockåä½œæ›´é«˜æ•ˆã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-å®é™…åº”ç”¨ä¸­çš„ä¼˜åŒ–å»ºè®®"&gt;ğŸ’¡ &lt;strong&gt;3. å®é™…åº”ç”¨ä¸­çš„ä¼˜åŒ–å»ºè®®&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å‡å°‘è·¨SMåŒæ­¥é¢‘ç‡&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä¼˜å…ˆåœ¨é›†ç¾¤å†…å®Œæˆæ•°æ®å±€éƒ¨æ€§å¼ºçš„è®¡ç®—ï¼Œä»…å¿…è¦æ—¶åŒæ­¥ï¼ˆå¦‚æœ€ç»ˆç»“æœæ±‡æ€»ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;é€šä¿¡ä¸è®¡ç®—é‡å &lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç»“åˆå¼‚æ­¥æ“ä½œï¼ˆå¦‚&lt;code&gt;cuda::pipeline&lt;/code&gt;ï¼‰éšè—é€šä¿¡å»¶è¿Ÿã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;åŠ¨æ€èµ„æºåˆ†é…&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é€šè¿‡&lt;strong&gt;Elastic Block&lt;/strong&gt;æœºåˆ¶è°ƒæ•´å„çº¿ç¨‹å—çš„å¯„å­˜å™¨/å…±äº«å†…å­˜å ç”¨ï¼Œé¿å…èµ„æºå†²çªã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="4"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;æ¶æ„æ„ŸçŸ¥è®¾è®¡&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åœ¨HopperåŠåç»­æ¶æ„ä¸­ï¼Œä¼˜å…ˆä½¿ç”¨TMAåŠ é€ŸåŸå­æ“ä½œï¼Œé™ä½è·¨SMåŒæ­¥å¼€é”€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-æ€»ç»“-1"&gt;ğŸ’ &lt;strong&gt;æ€»ç»“&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;å•SMå†…Blockåä½œ&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;è·¨SMé›†ç¾¤åä½œ&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;åŒæ­¥å»¶è¿Ÿ&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;æä½ï¼ˆ100â€“200nsï¼‰&lt;/td&gt;
&lt;td&gt;ä¸­ï¼ˆ500nsâ€“1Î¼sï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;é€‚ç”¨ä»»åŠ¡&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;é«˜æ•°æ®å±€éƒ¨æ€§ã€å¼ºä¾èµ–ä»»åŠ¡&lt;/td&gt;
&lt;td&gt;å¯åˆ†è§£ç‹¬ç«‹å­ä»»åŠ¡ã€å¼±ä¾èµ–åœºæ™¯&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;èµ„æºç“¶é¢ˆ&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;SMå†…å¯„å­˜å™¨/å…±äº«å†…å­˜&lt;/td&gt;
&lt;td&gt;å…¨å±€å†…å­˜å¸¦å®½ã€è·¨SMé€šä¿¡å»¶è¿Ÿ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;ä¼˜åŒ–å…³é”®&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;å‡å°‘å…±äº«å†…å­˜å†²çª&lt;/td&gt;
&lt;td&gt;å¼‚æ­¥é€šä¿¡+TMAç¡¬ä»¶åŠ é€Ÿ&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Thread Block Clusterçš„è·¨SMèƒ½åŠ›ä¸ºå¤§è§„æ¨¡å¹¶è¡Œä»»åŠ¡æä¾›äº†æ–°å¯èƒ½ï¼Œä½†å…¶æ€§èƒ½æ”¶ç›Š&lt;strong&gt;é«˜åº¦ä¾èµ–ä»»åŠ¡ç‰¹å¾ä¸ç¡¬ä»¶ä¼˜åŒ–&lt;/strong&gt;ã€‚åœ¨Hopperæ¶æ„ä¸‹ï¼Œåˆç†è®¾è®¡é›†ç¾¤å†…ä»»åŠ¡åˆ’åˆ†å¹¶åˆ©ç”¨ç¡¬ä»¶åŠ é€Ÿï¼Œå¯æœ€å¤§åŒ–è·¨SMåä½œçš„æ•ˆèƒ½ã€‚&lt;/p&gt;
&lt;h2 id="hash-optimization"&gt;Hash Optimization
&lt;/h2&gt;&lt;p&gt;å½“å“ˆå¸Œè¡¨çš„å¤§å°ï¼ˆ&lt;code&gt;tsize&lt;/code&gt;ï¼‰æ˜¯2çš„å¹‚ï¼ˆå¦‚16ã€32ã€64ï¼‰æ—¶ï¼Œå–æ¨¡è¿ç®—ï¼ˆ&lt;code&gt;hash % tsize&lt;/code&gt;ï¼‰å¯ä»¥æ›¿æ¢ä¸ºä½ä¸è¿ç®—ï¼ˆ&lt;code&gt;hash &amp;amp; (tsize - 1)&lt;/code&gt;ï¼‰ï¼Œè¿™æ˜¯ç”±&lt;strong&gt;äºŒè¿›åˆ¶æ•°å­¦ç‰¹æ€§&lt;/strong&gt;å’Œ&lt;strong&gt;è®¡ç®—æœºè¿ç®—ä¼˜åŒ–&lt;/strong&gt;å…±åŒå†³å®šçš„ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†è§£é‡Šï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="1-æ•°å­¦ç­‰ä»·æ€§ä½è¿ç®—ä¸å–æ¨¡çš„ç­‰æ•ˆåŸç†"&gt;1. &lt;strong&gt;æ•°å­¦ç­‰ä»·æ€§ï¼šä½è¿ç®—ä¸å–æ¨¡çš„ç­‰æ•ˆåŸç†&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å…³é”®æ¡ä»¶&lt;/strong&gt;ï¼šè‹¥ &lt;code&gt;tsize = 2^n&lt;/code&gt;ï¼ˆä¾‹å¦‚ &lt;code&gt;16 = 2^4&lt;/code&gt;ï¼‰ï¼Œåˆ™ &lt;code&gt;tsize - 1&lt;/code&gt; çš„äºŒè¿›åˆ¶å½¢å¼ä¸º&lt;strong&gt;å…¨1çš„ä½ä½&lt;/strong&gt;ï¼ˆå¦‚ &lt;code&gt;15&lt;/code&gt; çš„äºŒè¿›åˆ¶æ˜¯ &lt;code&gt;1111&lt;/code&gt;ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿ç®—ç­‰æ•ˆ&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å–æ¨¡&lt;/strong&gt;ï¼š&lt;code&gt;hash % tsize&lt;/code&gt; çš„ç»“æœæ˜¯ &lt;code&gt;hash&lt;/code&gt; é™¤ä»¥ &lt;code&gt;tsize&lt;/code&gt; çš„ä½™æ•°ï¼Œå…¶èŒƒå›´åœ¨ &lt;code&gt;[0, tsize-1]&lt;/code&gt; å†…ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä½ä¸&lt;/strong&gt;ï¼š&lt;code&gt;hash &amp;amp; (tsize - 1)&lt;/code&gt; ä¼šä¿ç•™ &lt;code&gt;hash&lt;/code&gt; çš„æœ€ä½ &lt;code&gt;n&lt;/code&gt; ä½ï¼ˆé«˜ä½å½’é›¶ï¼‰ï¼Œç»“æœåŒæ ·æ˜¯ &lt;code&gt;[0, tsize-1]&lt;/code&gt; çš„æ•´æ•°ã€‚
â€‹&lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt;â€‹ï¼š&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;int hash = 53; // äºŒè¿›åˆ¶: 110101
int tsize = 16; // 2^4, tsize-1 = 15 (äºŒè¿›åˆ¶: 001111)
int mod = 53 % 16; // ç»“æœ: 5 (äºŒè¿›åˆ¶: 0101)
int and = 53 &amp;amp; 15; // ç»“æœ: 0101 (ä¿ç•™ä½4ä½) â†’ 5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ç»“æœä¸€è‡´æ€§&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mod
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;å’Œ&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;and
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ç»“æœç›¸åŒã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="2-æ€§èƒ½ä¼˜åŠ¿ä½è¿ç®—çš„é«˜æ•ˆæ€§"&gt;2. &lt;strong&gt;æ€§èƒ½ä¼˜åŠ¿ï¼šä½è¿ç®—çš„é«˜æ•ˆæ€§&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶æ”¯æŒ&lt;/strong&gt;ï¼šä½ä¸è¿ç®—ï¼ˆ&lt;code&gt;&amp;amp;&lt;/code&gt;ï¼‰æ˜¯CPUçš„&lt;strong&gt;å•æŒ‡ä»¤æ“ä½œ&lt;/strong&gt;ï¼Œè€Œå–æ¨¡è¿ç®—ï¼ˆ&lt;code&gt;%&lt;/code&gt;ï¼‰éœ€å¤šæ¬¡é™¤æ³•/ç§»ä½æ“ä½œï¼Œæ•ˆç‡æ›´ä½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŒ–æ•ˆæœ&lt;/strong&gt;ï¼šåœ¨å“ˆå¸Œè¡¨é«˜é¢‘è®¡ç®—ç´¢å¼•çš„åœºæ™¯ä¸‹ï¼ˆå¦‚HashMapçš„&lt;code&gt;get()&lt;/code&gt;/&lt;code&gt;put()&lt;/code&gt;ï¼‰ï¼Œä½è¿ç®—æ˜¾è‘—æå‡é€Ÿåº¦ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="3-è®¾è®¡æ„ä¹‰å‡å°‘å“ˆå¸Œå†²çª"&gt;3. &lt;strong&gt;è®¾è®¡æ„ä¹‰ï¼šå‡å°‘å“ˆå¸Œå†²çª&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å‡åŒ€åˆ†å¸ƒ&lt;/strong&gt;ï¼šå½“ &lt;code&gt;tsize-1&lt;/code&gt; çš„äºŒè¿›åˆ¶ä¸ºå…¨1ï¼ˆå¦‚ &lt;code&gt;1111&lt;/code&gt;ï¼‰æ—¶ï¼Œ&lt;code&gt;hash &amp;amp; (tsize-1)&lt;/code&gt; çš„ç»“æœ&lt;strong&gt;å®Œå…¨ä¾èµ–&lt;code&gt;hash&lt;/code&gt;çš„ä½ä½å€¼&lt;/strong&gt;ã€‚è‹¥å“ˆå¸Œå‡½æ•°è´¨é‡é«˜ï¼Œä½ä½å‡åŒ€æ€§å¼ºï¼Œæ•°æ®åˆ†å¸ƒæ›´å‡è¡¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å†²çªé¿å…&lt;/strong&gt;ï¼šè‹¥ &lt;code&gt;tsize&lt;/code&gt; é2çš„å¹‚ï¼ˆå¦‚ &lt;code&gt;10&lt;/code&gt;ï¼‰ï¼Œ&lt;code&gt;tsize-1=9&lt;/code&gt;ï¼ˆäºŒè¿›åˆ¶ &lt;code&gt;1001&lt;/code&gt;ï¼‰ï¼Œä½ä¸æ“ä½œä¼š&lt;strong&gt;å¼ºåˆ¶å¿½ç•¥æŸäº›æ¯”ç‰¹ä½&lt;/strong&gt;ï¼Œå¯¼è‡´ä¸åŒå“ˆå¸Œå€¼æ˜ å°„åˆ°åŒä¸€ç´¢å¼•ï¼ˆå¦‚ &lt;code&gt;5&lt;/code&gt;ï¼ˆ&lt;code&gt;0101&lt;/code&gt;ï¼‰å’Œ &lt;code&gt;13&lt;/code&gt;ï¼ˆ&lt;code&gt;1101&lt;/code&gt;ï¼‰ä¸ &lt;code&gt;9&lt;/code&gt; ä½ä¸åå‡ä¸º &lt;code&gt;1&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="4-å®é™…åº”ç”¨java-hashmapçš„å®ç°"&gt;4. &lt;strong&gt;å®é™…åº”ç”¨ï¼šJava HashMapçš„å®ç°&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å®¹é‡å¼ºåˆ¶ä¸º2çš„å¹‚&lt;/strong&gt;ï¼šé€šè¿‡&lt;code&gt;tableSizeFor()&lt;/code&gt;æ–¹æ³•å°†åˆå§‹å®¹é‡è½¬æ¢ä¸ºâ‰¥è¾“å…¥å€¼çš„æœ€å°2æ¬¡å¹‚ï¼ˆå¦‚è¾“å…¥ &lt;code&gt;10&lt;/code&gt; â†’ è¾“å‡º &lt;code&gt;16&lt;/code&gt;ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç´¢å¼•è®¡ç®—&lt;/strong&gt;ï¼š&lt;code&gt;index = hash &amp;amp; (capacity - 1)&lt;/code&gt; æ›¿ä»£å–æ¨¡ï¼ˆæºç &lt;code&gt;indexFor()&lt;/code&gt;æ–¹æ³•ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ‰©å®¹ä¼˜åŒ–&lt;/p&gt;
&lt;p&gt;ï¼šæ‰©å®¹æ—¶ï¼ˆ&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;resize()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ï¼‰ï¼Œå…ƒç´ æ–°ä½ç½®ä»…éœ€åˆ¤æ–­&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;hash &amp;amp; old_capacity
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;çš„ç»“æœï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç»“æœä¸º &lt;code&gt;0&lt;/code&gt; â†’ ç´¢å¼•ä¸å˜ï¼›&lt;/li&gt;
&lt;li&gt;ç»“æœä¸º &lt;code&gt;1&lt;/code&gt; â†’ æ–°ç´¢å¼• = åŸä½ç½® + åŸå®¹é‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="æ€»ç»“"&gt;æ€»ç»“
&lt;/h3&gt;&lt;p&gt;å“ˆå¸Œè¡¨å¤§å°ä¸º2çš„å¹‚æ—¶ï¼Œ&lt;strong&gt;ä½ä¸è¿ç®—&lt;/strong&gt;åœ¨&lt;strong&gt;æ•°å­¦ç­‰æ•ˆæ€§&lt;/strong&gt;ã€&lt;strong&gt;æ€§èƒ½ä¼˜åŠ¿&lt;/strong&gt;å’Œ&lt;strong&gt;å†²çªæ§åˆ¶&lt;/strong&gt;ä¸Šå…¨é¢ä¼˜äºå–æ¨¡è¿ç®—ï¼Œæ˜¯å“ˆå¸Œè¡¨å®ç°çš„æ ¸å¿ƒä¼˜åŒ–æ‰‹æ®µã€‚Javaçš„HashMapé€šè¿‡&lt;code&gt;tableSizeFor()&lt;/code&gt;å’Œ&lt;code&gt;&amp;amp; (capacity-1)&lt;/code&gt;çš„è®¾è®¡ï¼Œå°†è¿™ä¸€æœºåˆ¶åº”ç”¨äºå®è·µã€‚&lt;/p&gt;
&lt;h2 id="cooperative-group"&gt;Cooperative Group
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAä¸­å°†Cooperative Groupï¼ˆåä½œç»„ï¼‰å¤§å°è®¾ä¸º8ï¼Œå¹¶è®©æ¯ä¸ªç»„è®¿é—®å…¨å±€å†…å­˜çš„ä¸åŒéƒ¨åˆ†ï¼Œè¿™ç§è®¾è®¡å¯¹æ€§èƒ½çš„å½±å“æ˜¯å¤šæ–¹é¢çš„ï¼Œæ—¢æœ‰æ½œåœ¨ä¼˜åŠ¿ä¹Ÿå¯èƒ½å¸¦æ¥æŒ‘æˆ˜ã€‚ä»¥ä¸‹æ˜¯å…³é”®åˆ†æï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-1-å†…å­˜è®¿é—®æ¨¡å¼çš„å½±å“"&gt;âš™ï¸ 1. &lt;strong&gt;å†…å­˜è®¿é—®æ¨¡å¼çš„å½±å“&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åˆå¹¶è®¿é—®çš„å¯èƒ½æ€§&lt;/strong&gt;ï¼š
è‹¥ç»„å†…8ä¸ªçº¿ç¨‹è®¿é—®&lt;strong&gt;è¿ç»­å†…å­˜åœ°å€&lt;/strong&gt;â€‹ï¼ˆå¦‚ç›¸é‚»çš„8ä¸ªfloatï¼‰ï¼Œå¯è§¦å‘åˆå¹¶è®¿é—®ï¼Œå‡å°‘å†…å­˜äº‹åŠ¡æ¬¡æ•°ï¼Œæå‡å¸¦å®½åˆ©ç”¨ç‡ã€‚
ä½†è‹¥ç»„å†…è®¿é—®&lt;strong&gt;éè¿ç»­æˆ–è·¨æ­¥è¿‡å¤§&lt;/strong&gt;â€‹ï¼ˆå¦‚é—´éš”è®¿é—®ï¼‰ï¼Œä¼šé€€åŒ–ä¸ºéåˆå¹¶è®¿é—®ï¼Œå¢åŠ å†…å­˜äº‹åŠ¡ï¼ˆå¯èƒ½ä»1æ¬¡å˜ä¸º8æ¬¡ï¼‰ï¼Œæ˜¾è‘—é™ä½ååé‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»„é—´å†…å­˜éš”ç¦»çš„åˆ©å¼Š&lt;/strong&gt;ï¼š
âœ… â€‹&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;â€‹ï¼šå„ç»„è®¿é—®ç‹¬ç«‹å†…å­˜åŒºåŸŸå¯å‡å°‘ç¼“å­˜ç«äº‰ï¼ˆå¦‚L1/L2ç¼“å­˜ï¼‰ï¼Œé¿å…ç»„é—´æ•°æ®å†²çªã€‚
âš ï¸ â€‹&lt;strong&gt;é£é™©&lt;/strong&gt;â€‹ï¼šè‹¥å…¨å±€å†…å­˜è®¿é—®èŒƒå›´åˆ†æ•£ï¼Œå¯èƒ½é™ä½ç¼“å­˜å±€éƒ¨æ€§ï¼Œå¢åŠ DRAMè®¿é—®å»¶è¿Ÿã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-2-å¹¶è¡Œæ•ˆç‡ä¸èµ„æºå ç”¨"&gt;âš¡ 2. &lt;strong&gt;å¹¶è¡Œæ•ˆç‡ä¸èµ„æºå ç”¨&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;çº¿ç¨‹å—èµ„æºåˆ©ç”¨ç‡&lt;/strong&gt;ï¼š
Groupå¤§å°8ï¼ˆå°äºæ ‡å‡†Warpçš„32çº¿ç¨‹ï¼‰å¯èƒ½å¯¼è‡´&lt;strong&gt;çº¿ç¨‹å—å†…Groupæ•°é‡å¢å¤š&lt;/strong&gt;ï¼Œä½†æ¯ä¸ªGroupçš„çº¿ç¨‹æ•°è¾ƒå°‘ã€‚è‹¥è®¡ç®—è´Ÿè½½ä¸å‡ï¼Œéƒ¨åˆ†çº¿ç¨‹å¯èƒ½é—²ç½®ï¼Œé™ä½SMï¼ˆæµå¤šå¤„ç†å™¨ï¼‰çš„å ç”¨ç‡ï¼ˆOccupancyï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŒæ­¥å¼€é”€ä¼˜åŒ–&lt;/strong&gt;ï¼š
å°è§„æ¨¡Groupï¼ˆå¦‚8çº¿ç¨‹ï¼‰çš„åŒæ­¥ï¼ˆ&lt;code&gt;sync()&lt;/code&gt;ï¼‰å»¶è¿Ÿè¿œä½äºå—çº§åŒæ­¥ï¼ˆ&lt;code&gt;__syncthreads()&lt;/code&gt;ï¼‰ï¼Œé€šå¸¸åœ¨&lt;strong&gt;çº³ç§’çº§&lt;/strong&gt;â€‹ï¼ˆå—çº§åŒæ­¥çº¦140nsï¼‰ã€‚é€‚åˆéœ€è¦&lt;strong&gt;é«˜é¢‘åŒæ­¥&lt;/strong&gt;çš„ç®—æ³•ï¼ˆå¦‚è¿­ä»£è®¡ç®—ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-3-æ•°æ®é€šä¿¡ä¸è´Ÿè½½å‡è¡¡"&gt;ğŸ”— 3. &lt;strong&gt;æ•°æ®é€šä¿¡ä¸è´Ÿè½½å‡è¡¡&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ç»„é—´é€šä¿¡éœ€æ±‚&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;p&gt;è‹¥ç®—æ³•éœ€ç»„é—´æ•°æ®äº¤æ¢ï¼ˆå¦‚å…¨å±€ç»“æœèšåˆï¼‰ï¼Œéœ€é€šè¿‡åŸå­æ“ä½œæˆ–å…¨å±€å†…å­˜ä¸­è½¬ã€‚æ­¤æ—¶ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ä½¿ç”¨&lt;code&gt;thread_scope_device&lt;/code&gt;çº§åŸå­æ“ä½œï¼ˆå»¶è¿Ÿ3â€“5Î¼sï¼‰å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;å»ºè®®ç”¨å…±äº«å†…å­˜æš‚å­˜ç»“æœï¼Œå†é›†ä¸­å†™å…¥å…¨å±€å†…å­˜ï¼Œå‡å°‘åŸå­æ“ä½œæ¬¡æ•°ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;è´Ÿè½½å‡è¡¡é—®é¢˜&lt;/strong&gt;ï¼š
å„ç»„å¤„ç†ä¸åŒå†…å­˜åŒºåŸŸæ—¶ï¼Œè‹¥æ•°æ®åˆ†å¸ƒä¸å‡ï¼ˆå¦‚ç¨€ç–çŸ©é˜µï¼‰ï¼Œå¯èƒ½é€ æˆéƒ¨åˆ†Groupè®¡ç®—é‡è¿‡å¤§ï¼Œå¯¼è‡´å»¶è¿Ÿ[ citation:5]ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-4-ä¸ç¡¬ä»¶æ¶æ„çš„ååŒæ€§"&gt;âš–ï¸ 4. &lt;strong&gt;ä¸ç¡¬ä»¶æ¶æ„çš„ååŒæ€§&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SMèµ„æºé™åˆ¶&lt;/strong&gt;ï¼š
æ¯ä¸ªSMçš„å¯„å­˜å™¨/å…±äº«å†…å­˜æ€»é‡å›ºå®šã€‚Groupå¢å¤šå¯èƒ½åŠ å‰§èµ„æºç«äº‰ï¼Œå°¤å…¶æ˜¯å…±äº«å†…å­˜ï¼ˆå¦‚æ¯ç»„å£°æ˜ç‹¬ç«‹å…±äº«å†…å­˜æ•°ç»„æ—¶ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ–°ç¡¬ä»¶ç‰¹æ€§æ”¯æŒ&lt;/strong&gt;ï¼š
NVIDIA Hopperæ¶æ„çš„&lt;strong&gt;çº¿ç¨‹å—é›†ç¾¤&lt;/strong&gt;â€‹ï¼ˆThread Block Clusterï¼‰å…è®¸8ä¸ªçº¿ç¨‹å—åä½œï¼ŒåŒæ­¥å»¶è¿Ÿä»‹äºå—çº§ä¸è®¾å¤‡çº§ä¹‹é—´ã€‚è‹¥Groupè®¾è®¡åŒ¹é…æ­¤ç»“æ„ï¼Œå¯è¿›ä¸€æ­¥é™ä½é€šä¿¡å¼€é”€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-5-ä¼˜åŒ–ç­–ç•¥å»ºè®®"&gt;ğŸš€ 5. &lt;strong&gt;ä¼˜åŒ–ç­–ç•¥å»ºè®®&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;ä¸ºæœ€å¤§åŒ–æ€§èƒ½ï¼Œå¯ç»“åˆä»¥ä¸‹å®è·µï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;å¼ºåˆ¶åˆå¹¶è®¿é—®&lt;/strong&gt;ï¼š
ç¡®ä¿ç»„å†…çº¿ç¨‹è®¿é—®è¿ç»­åœ°å€ï¼ˆå¦‚&lt;code&gt;group.thread_rank()&lt;/code&gt;æ˜ å°„åˆ°è¿ç»­ç´¢å¼•ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…±äº«å†…å­˜ç¼“å­˜&lt;/strong&gt;ï¼š
å„ç»„å…ˆå°†å…¨å±€æ•°æ®åŠ è½½åˆ°å…±äº«å†…å­˜ï¼Œç»„å†…å¤„ç†åå†å†™å›ï¼Œé¿å…ç›´æ¥éåˆå¹¶è®¿é—®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŠ¨æ€è´Ÿè½½å‡è¡¡&lt;/strong&gt;ï¼š
ä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå¦‚å…¨å±€è®¡æ•°å™¨åˆ†é…ä»»åŠ¡ï¼‰ï¼Œç¡®ä¿å„ç»„è´Ÿè½½å‡åŒ€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å ç”¨ç‡è°ƒä¼˜&lt;/strong&gt;ï¼š
é€šè¿‡&lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;é…ç½®æ‰§è¡Œå‚æ•°ï¼Œå¹³è¡¡Groupæ•°é‡ä¸SMèµ„æºã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-æ€§èƒ½å½±å“æ€»ç»“"&gt;ğŸ’ æ€§èƒ½å½±å“æ€»ç»“
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;å› ç´ &lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;æ€§èƒ½ä¼˜åŠ¿&lt;/strong&gt; âœ…&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;æ€§èƒ½æŒ‘æˆ˜&lt;/strong&gt; âš ï¸&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;å†…å­˜è®¿é—®&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;ç»„å†…è¿ç»­è®¿é—®å¯åˆå¹¶&lt;/td&gt;
&lt;td&gt;ç»„é—´åˆ†æ•£è®¿é—®å¯¼è‡´ç¼“å­˜å‘½ä¸­ç‡ä¸‹é™&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;åŒæ­¥å¼€é”€&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;å°è§„æ¨¡ç»„åŒæ­¥å»¶è¿Ÿä½ï¼ˆçº³ç§’çº§ï¼‰&lt;/td&gt;
&lt;td&gt;ç»„é—´é€šä¿¡ä¾èµ–é«˜å»¶è¿ŸåŸå­æ“ä½œ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;èµ„æºå ç”¨&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;çµæ´»é€‚é…ç»†ç²’åº¦ä»»åŠ¡&lt;/td&gt;
&lt;td&gt;SMå ç”¨ç‡å¯èƒ½é™ä½&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;æ‰©å±•æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;åŒ¹é…Hopperé›†ç¾¤æ¶æ„å¯åŠ é€Ÿ&lt;/td&gt;
&lt;td&gt;æ•°æ®åˆ†å¸ƒä¸å‡å¼•å‘è´Ÿè½½å¤±è¡¡&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-ç»“è®º-1"&gt;ğŸ’ &lt;strong&gt;ç»“è®º&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;å°†Cooperative Groupè®¾ä¸º8å¹¶åˆ†åŒºè®¿é—®å…¨å±€å†…å­˜ï¼Œåœ¨&lt;strong&gt;ç»†ç²’åº¦åŒæ­¥ç®—æ³•&lt;/strong&gt;ï¼ˆå¦‚å›¾éå†ã€è¿­ä»£æ±‚è§£å™¨ï¼‰ä¸­å¯èƒ½æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå°¤å…¶é€‚åˆç»„å†…è®¡ç®—å¯†é›†ä¸”éœ€é«˜é¢‘åŒæ­¥çš„åœºæ™¯ã€‚ç„¶è€Œï¼Œè‹¥å†…å­˜è®¿é—®æ¨¡å¼æœªä¼˜åŒ–æˆ–è´Ÿè½½ä¸å‡è¡¡ï¼Œæ€§èƒ½å¯èƒ½åŠ£äºä¼ ç»ŸWarpçº§è®¾è®¡ã€‚&lt;strong&gt;å…³é”®ä¼˜åŒ–ç‚¹&lt;/strong&gt;åœ¨äºï¼š
â‘  å¼ºåˆ¶ç»„å†…è¿ç»­å†…å­˜è®¿é—®ï¼›
â‘¡ ç”¨å…±äº«å†…å­˜å‡å°‘å…¨å±€è®¿é—®æ¬¡æ•°ï¼›
â‘¢ åŒ¹é…ç¡¬ä»¶ç‰¹æ€§ï¼ˆå¦‚é›†ç¾¤ä¸TMAåŠ é€Ÿå™¨ï¼‰ã€‚&lt;/p&gt;
&lt;h2 id="çº¿ç¨‹è§„çº¦"&gt;çº¿ç¨‹è§„çº¦
&lt;/h2&gt;&lt;p&gt;CUDAçº¿ç¨‹å—è§„çº¦ï¼ˆBlock Reduceï¼‰æ˜¯ä¸€ç§åœ¨GPUçº¿ç¨‹å—å†…é«˜æ•ˆèšåˆæ•°æ®ï¼ˆå¦‚æ±‚å’Œã€æ±‚æœ€å¤§å€¼ï¼‰çš„å…³é”®å¹¶è¡Œè®¡ç®—æŠ€æœ¯ã€‚å…¶æ ¸å¿ƒåœ¨äºåˆ©ç”¨å…±äº«å†…å­˜å’Œçº¿ç¨‹æŸï¼ˆWarpï¼‰çº§æŒ‡ä»¤å®ç°æ•°æ®çš„é«˜æ•ˆåˆå¹¶ã€‚ä»¥ä¸‹ä»å®ç°ç­–ç•¥åˆ°ä¼˜åŒ–æŠ€å·§è¿›è¡Œè¯¦ç»†è¯´æ˜ï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="-ä¸€çº¿ç¨‹å—è§„çº¦çš„æ ¸å¿ƒåŸç†"&gt;âš™ï¸ &lt;strong&gt;ä¸€ã€çº¿ç¨‹å—è§„çº¦çš„æ ¸å¿ƒåŸç†&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åˆ†å±‚è§„çº¦æ€æƒ³&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt; æ­¥éª¤1ï¼šçº¿ç¨‹ç§æœ‰è®¡ç®—
æ¯ä¸ªçº¿ç¨‹è¯»å–å¤šä¸ªå…¨å±€å†…å­˜æ•°æ®ï¼Œè¿›è¡Œå±€éƒ¨è§„çº¦ï¼ˆå¦‚ç´¯åŠ éƒ¨åˆ†å’Œï¼‰ï¼Œå‡å°‘å…¨å±€å†…å­˜è®¿é—®æ¬¡æ•°ã€‚
```
float val = 0.0f;
for (int i = threadIdx.x; i &amp;lt; n; i += blockDim.x) {
val += data[i]; // å±€éƒ¨ç´¯åŠ 
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ­¥éª¤2ï¼šå…±äº«å†…å­˜èšåˆ&lt;/strong&gt;
å°†å±€éƒ¨ç»“æœå­˜å…¥å…±äº«å†…å­˜ï¼ˆ&lt;code&gt;__shared__&lt;/code&gt;ï¼‰ï¼Œåˆ©ç”¨å—å†…çº¿ç¨‹åä½œè¿›ä¸€æ­¥è§„çº¦ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;&lt;strong&gt;çº¿ç¨‹å—å†…åŒæ­¥&lt;/strong&gt;
ä½¿ç”¨&lt;code&gt;__syncthreads()&lt;/code&gt;ç¡®ä¿æ‰€æœ‰çº¿ç¨‹å®Œæˆæ•°æ®å†™å…¥åå†è¿›è¡Œè§„çº¦ï¼Œé¿å…ç«æ€æ¡ä»¶ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-äºŒä¸»æµè§„çº¦ç­–ç•¥ä¸å®ç°"&gt;ğŸ”§ &lt;strong&gt;äºŒã€ä¸»æµè§„çº¦ç­–ç•¥ä¸å®ç°&lt;/strong&gt;
&lt;/h3&gt;&lt;h4 id="1-äº¤é”™è§„çº¦interleaved-reduction"&gt;&lt;strong&gt;1. äº¤é”™è§„çº¦ï¼ˆInterleaved Reductionï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ“ä½œæ–¹å¼&lt;/strong&gt;ï¼šçº¿ç¨‹æ¯æ¬¡å¤„ç†é—´éš”ä¸ºæ­¥é•¿çš„ä¸€åŠï¼ˆæŠ˜åŠåˆå¹¶ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä»£ç ç¤ºä¾‹&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__shared__ float sdata[1024];
sdata[threadIdx.x] = val;
__syncthreads();
for (int stride = blockDim.x / 2; stride &amp;gt; 0; stride &amp;gt;&amp;gt;= 1) {
if (threadIdx.x &amp;lt; stride) {
sdata[threadIdx.x] += sdata[threadIdx.x + stride];
}
__syncthreads();
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼šå†…å­˜è®¿é—®è¿ç»­ï¼Œåˆå¹¶åº¦é«˜ï¼ˆCoalesced Accessï¼‰ï¼Œæ€§èƒ½è¾ƒå¥½ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="2-äº¤å‰è§„çº¦sequential-reduction"&gt;&lt;strong&gt;2. äº¤å‰è§„çº¦ï¼ˆSequential Reductionï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ“ä½œæ–¹å¼&lt;/strong&gt;ï¼šç›¸é‚»çº¿ç¨‹ä¸¤ä¸¤åˆå¹¶ï¼ˆå¦‚çº¿ç¨‹0ä¸1ã€2ä¸3ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šå†…å­˜è®¿é—®ä¸è¿ç»­ï¼Œæ˜“å¯¼è‡´Bank Conflictï¼Œæ•ˆç‡è¾ƒä½ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="3-warpçº§è§„çº¦warp-shuffle"&gt;&lt;strong&gt;3. Warpçº§è§„çº¦ï¼ˆWarp Shuffleï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åŸç†&lt;/strong&gt;ï¼šåˆ©ç”¨&lt;code&gt;__shfl_down_sync&lt;/code&gt;æŒ‡ä»¤åœ¨Warpå†…ç›´æ¥äº¤æ¢å¯„å­˜å™¨æ•°æ®ï¼Œæ— éœ€å…±äº«å†…å­˜ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä»£ç ç¤ºä¾‹&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;float warp_reduce(float val) {
for (int offset = 16; offset &amp;gt; 0; offset /= 2)
val += __shfl_down_sync(0xffffffff, val, offset);
return val;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼šå»¶è¿Ÿä½ï¼ˆå¯„å­˜å™¨è®¿é—®ä»…1å‘¨æœŸï¼‰ï¼Œé€‚åˆWarpå†…èšåˆã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="4-å—å†…è§„çº¦ç»“åˆwarp-shuffle"&gt;&lt;strong&gt;4. å—å†…è§„çº¦ï¼ˆç»“åˆWarp Shuffleï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ­¥éª¤&lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æ¯ä¸ªWarpå†…å…ˆè§„çº¦åˆ°1ä¸ªå€¼ã€‚&lt;/li&gt;
&lt;li&gt;å°†å„Warpç»“æœå­˜å…¥å…±äº«å†…å­˜ã€‚&lt;/li&gt;
&lt;li&gt;ç¬¬ä¸€ä¸ªWarpå†æ¬¡è§„çº¦è¿™äº›å€¼ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;__shared__ float warp_results[32];
float warp_val = warp_reduce(val); // Warpå†…è§„çº¦
if (lane_id == 0) warp_results[warp_id] = warp_val;
__syncthreads();
if (threadIdx.x &amp;lt; 32) {
float block_val = warp_reduce(warp_results[threadIdx.x]);
if (threadIdx.x == 0) result = block_val;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;ï¼šå¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶æ•ˆç‡é«˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="5-ä½¿ç”¨cubåº“"&gt;&lt;strong&gt;5. ä½¿ç”¨CUBåº“&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ç®€åŒ–å¼€å‘&lt;/p&gt;
&lt;p&gt;ï¼šç›´æ¥è°ƒç”¨&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cub::BlockReduce
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;æ¨¡æ¿ç±»ã€‚&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;#include &amp;lt;cub/block/block_reduce.cuh&amp;gt;
__shared__ cub::BlockReduce&amp;lt;float&amp;gt;::TempStorage temp;
float block_sum = cub::BlockReduce(temp).Sum(val);
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼šè‡ªåŠ¨ä¼˜åŒ–åº•å±‚å®ç°ï¼Œæ”¯æŒå¤šç§è§„çº¦æ“ä½œï¼ˆå¦‚Sum/Maxï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="-ä¸‰æ€§èƒ½ä¼˜åŒ–å…³é”®æŠ€å·§"&gt;âš¡ &lt;strong&gt;ä¸‰ã€æ€§èƒ½ä¼˜åŒ–å…³é”®æŠ€å·§&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;é¿å…å…±äº«å†…å­˜Bank Conflict&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;äº¤é”™è§„çº¦ä¼˜äºäº¤å‰è§„çº¦ï¼Œå› æ­¥é•¿è®¿é—®æ›´è¿ç»­ã€‚&lt;/li&gt;
&lt;li&gt;è°ƒæ•´å…±äº«å†…å­˜å¸ƒå±€ï¼ˆå¦‚ä½¿ç”¨åç§»é‡ï¼‰åˆ†æ•£Bankè®¿é—®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å‘é‡åŒ–å†…å­˜è®¿é—®&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ç”¨&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;float4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;/&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;int4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ç±»å‹å•æ¬¡è¯»å†™4ä¸ªå…ƒç´ ï¼Œæå‡å¸¦å®½åˆ©ç”¨ç‡ã€‚&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;float4* data_vec = (float4*)data;
float4 tmp = data_vec[id];
val += tmp.x + tmp.y + tmp.z + tmp.w;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;çº¿ç¨‹å—é…ç½®åŸåˆ™&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Block Size&lt;/strong&gt;ï¼šè®¾ä¸º32çš„å€æ•°ï¼ˆå¦‚256/512ï¼‰ï¼Œé€‚é…Warpè°ƒåº¦ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grid Size&lt;/strong&gt;ï¼šè¦†ç›–æ€»æ•°æ®é‡ï¼Œå…¬å¼ï¼š
&lt;code&gt;grid_size = (n + block_size - 1) / block_size&lt;/code&gt;ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åŒè§„çº¦èåˆ&lt;/strong&gt;
åœ¨Softmaxç­‰åœºæ™¯ä¸­ï¼Œå¯åŒæ—¶è®¡ç®—æœ€å¤§å€¼å’Œæ±‚å’Œï¼š&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;struct { float max_val; float sum_val; } md;
md.max_val = max(a, b);
md.sum_val = exp(a - md.max_val) + exp(b - md.max_val); // æ•°å€¼ç¨³å®š
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;é€šè¿‡è‡ªå®šä¹‰è§„çº¦ç®—å­ä¸€æ¬¡æ€§å®Œæˆã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-å››åº”ç”¨åœºæ™¯"&gt;ğŸ’» &lt;strong&gt;å››ã€åº”ç”¨åœºæ™¯&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç§‘å­¦è®¡ç®—&lt;/strong&gt;ï¼šå¤§è§„æ¨¡å‘é‡æ±‚å’Œ/æ±‚æå€¼ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;æ·±åº¦å­¦ä¹ &lt;/p&gt;
&lt;p&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Softmaxä¸­çš„æœ€å¤§å€¼/æ±‚å’Œè§„çº¦ã€‚&lt;/li&gt;
&lt;li&gt;æŸå¤±å‡½æ•°è®¡ç®—ï¼ˆå¦‚äº¤å‰ç†µï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;strong&gt;å›¾åƒå¤„ç†&lt;/strong&gt;ï¼šåƒç´ çº§ç»Ÿè®¡ï¼ˆå¹³å‡äº®åº¦ã€æ–¹å·®ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="-äº”ä¸åŒç­–ç•¥æ€§èƒ½å¯¹æ¯”"&gt;ğŸ“Š &lt;strong&gt;äº”ã€ä¸åŒç­–ç•¥æ€§èƒ½å¯¹æ¯”&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;è§„çº¦ç­–ç•¥&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;å»¶è¿Ÿ&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;å…±äº«å†…å­˜ä½¿ç”¨&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;äº¤å‰è§„çº¦&lt;/td&gt;
&lt;td&gt;é«˜&lt;/td&gt;
&lt;td&gt;ä¸­&lt;/td&gt;
&lt;td&gt;ç®€å•æ•™å­¦ç¤ºä¾‹&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;äº¤é”™è§„çº¦&lt;/td&gt;
&lt;td&gt;ä¸­&lt;/td&gt;
&lt;td&gt;ä¸­&lt;/td&gt;
&lt;td&gt;é€šç”¨éœ€æ±‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Warp Shuffle&lt;/td&gt;
&lt;td&gt;æä½&lt;/td&gt;
&lt;td&gt;æ— &lt;/td&gt;
&lt;td&gt;Warpå†…èšåˆï¼ˆâ‰¤32çº¿ç¨‹ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUBåº“&lt;/td&gt;
&lt;td&gt;ä½&lt;/td&gt;
&lt;td&gt;è‡ªåŠ¨ä¼˜åŒ–&lt;/td&gt;
&lt;td&gt;ç”Ÿäº§ç¯å¢ƒé¦–é€‰&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="-æ€»ç»“-2"&gt;ğŸ’ &lt;strong&gt;æ€»ç»“&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;çº¿ç¨‹å—è§„çº¦çš„æ ¸å¿ƒæ˜¯é€šè¿‡&lt;strong&gt;åˆ†å±‚åˆå¹¶&lt;/strong&gt;ï¼ˆçº¿ç¨‹â†’Warpâ†’å—ï¼‰å’Œ&lt;strong&gt;ç¡¬ä»¶ç‰¹æ€§åˆ©ç”¨&lt;/strong&gt;ï¼ˆå…±äº«å†…å­˜/WarpæŒ‡ä»¤ï¼‰å®ç°é«˜æ•ˆèšåˆã€‚&lt;strong&gt;äº¤é”™è§„çº¦&lt;/strong&gt;å’Œ&lt;strong&gt;Warp Shuffle&lt;/strong&gt;æ˜¯æ€§èƒ½æœ€ä¼˜ç­–ç•¥ï¼Œè€Œ&lt;strong&gt;CUBåº“&lt;/strong&gt;å¯ç®€åŒ–å¼€å‘å¹¶è‡ªåŠ¨ä¼˜åŒ–ã€‚å®é™…å¼€å‘éœ€ç»“åˆæ•°æ®è§„æ¨¡ï¼ˆå¦‚Warpçº§å¤„ç†å°çŸ©é˜µè¡Œã€å—çº§å¤„ç†å¤§è¡Œï¼‰å’Œç¡¬ä»¶ç‰¹æ€§ï¼ˆå¦‚Bank Conflictè§„é¿ï¼‰ç²¾ç»†è°ƒæ•´å‚æ•°ã€‚&lt;/p&gt;</description></item><item><title>ã€CUDAã€‘LLM Queries</title><link>https://dyhes.github.io/p/cudallm-queries/</link><pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudallm-queries/</guid><description>&lt;h2 id="åä½œç»„"&gt;åä½œç»„
&lt;/h2&gt;&lt;p&gt;çº¿ç¨‹åä½œç»„ï¼ˆCooperative Groupsï¼‰æ˜¯ &lt;strong&gt;CUDA 9.0 å¼•å…¥çš„ç¼–ç¨‹æ¨¡å‹æ‰©å±•&lt;/strong&gt;ï¼Œæ—¨åœ¨æä¾›æ›´çµæ´»ã€å®‰å…¨ä¸”é«˜æ•ˆçš„çº¿ç¨‹åŒæ­¥ä¸åä½œæœºåˆ¶ã€‚å®ƒå…è®¸å¼€å‘è€…åŠ¨æ€å®šä¹‰ä¸åŒç²’åº¦çš„çº¿ç¨‹ç»„ï¼ˆå¦‚çº¿ç¨‹å—ã€warp æˆ–è‡ªå®šä¹‰å­é›†ï¼‰ï¼Œå¹¶æ”¯æŒæ˜¾å¼åŒæ­¥å’Œé›†ä½“æ“ä½œï¼Œä»è€Œä¼˜åŒ–å¹¶è¡Œè®¡ç®—çš„è®¾è®¡ã€‚ä»¥ä¸‹æ˜¯å…¶æ ¸å¿ƒè¦ç‚¹ï¼š&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒæ¦‚å¿µä¸èƒŒæ™¯"&gt;âš™ï¸ æ ¸å¿ƒæ¦‚å¿µä¸èƒŒæ™¯
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼ ç»ŸåŒæ­¥çš„å±€é™&lt;/strong&gt; ï¼šæ—©æœŸ CUDA ä»…æ”¯æŒçº¿ç¨‹å—çº§åŒæ­¥ï¼ˆ__syncthreads()ï¼‰ï¼Œæ— æ³•çµæ´»å¤„ç†æ›´ç»†ç²’åº¦ï¼ˆå¦‚å•ä¸ª warpï¼‰æˆ–è·¨çº¿ç¨‹å—åä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åä½œç»„çš„è§£å†³æ–¹æ¡ˆ&lt;/strong&gt; ï¼šå°†çº¿ç¨‹ç»„æŠ½è±¡ä¸º&lt;strong&gt;ä¸€çº§ç¨‹åºå¯¹è±¡&lt;/strong&gt; ï¼ˆfirst-class objectï¼‰ï¼Œå¼€å‘è€…å¯æ˜¾å¼åˆ›å»ºã€æ“ä½œå’ŒåŒæ­¥ä»»æ„è§„æ¨¡çš„çº¿ç¨‹ç»„ï¼Œé¿å…ä¸´æ—¶æ€§åŒæ­¥ä»£ç çš„è„†å¼±æ€§ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ ¸å¿ƒç»„ä»¶ä¸åŠŸèƒ½"&gt;ğŸ§© æ ¸å¿ƒç»„ä»¶ä¸åŠŸèƒ½
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ç»„ç±»å‹&lt;/strong&gt; ï¼š
* &lt;strong&gt;éšå¼ç»„&lt;/strong&gt; ï¼šç”± CUDA è‡ªåŠ¨å®šä¹‰ï¼ˆå¦‚ thread_block è¡¨ç¤ºæ•´ä¸ªçº¿ç¨‹å—ï¼‰ã€‚
* &lt;strong&gt;æ˜¾å¼å­ç»„&lt;/strong&gt; ï¼šé€šè¿‡åˆ†åŒºæ“ä½œç”Ÿæˆï¼ˆå¦‚ tiled_partition åˆ’åˆ† warp æˆ–è‡ªå®šä¹‰å¤§å°ç»„ï¼‰ã€‚
* &lt;strong&gt;ç½‘æ ¼çº§ç»„&lt;/strong&gt; ï¼šè·¨çº¿ç¨‹å—åŒæ­¥ï¼ˆéœ€ CUDA 11.0+ï¼Œæ€§èƒ½ä¼˜åŒ– 30%ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;åŒæ­¥æ“ä½œ&lt;/strong&gt; ï¼š
* ç»„å†…åŒæ­¥ï¼šg.sync() æˆ– cg::synchronize(g) æ›¿ä»£ä¼ ç»Ÿ __syncthreads()ã€‚
* æ”¯æŒç»†ç²’åº¦æ§åˆ¶ï¼ˆå¦‚ä»…åŒæ­¥ warp å†…çº¿ç¨‹ï¼‰ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;é›†ä½“ç®—æ³•&lt;/strong&gt; ï¼ˆéœ€ C++11ï¼‰ï¼š
* &lt;strong&gt;æ•°æ®æ¬è¿&lt;/strong&gt; ï¼šmemcpy_async() å®ç°å¼‚æ­¥å†…å­˜æ‹·è´ã€‚
* &lt;strong&gt;è§„çº¦ä¸æ‰«æ&lt;/strong&gt; ï¼šreduce()ã€inclusive_scan() ç­‰é«˜æ•ˆé›†åˆè®¡ç®—ã€‚
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;ç¡¬ä»¶åŠ é€Ÿæ”¯æŒ&lt;/strong&gt; ï¼š
* é’ˆå¯¹ç‰¹å®šç»„ç±»å‹ï¼ˆå¦‚ thread_block_tileï¼‰ä¼˜åŒ–ï¼Œç¼–è¯‘æ—¶ç”Ÿæˆé«˜æ•ˆæŒ‡ä»¤ã€‚
â €&lt;/p&gt;
&lt;h3 id="-ç¼–ç¨‹æ¨¡å‹ä¼˜åŠ¿"&gt;ğŸš€ ç¼–ç¨‹æ¨¡å‹ä¼˜åŠ¿
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;çµæ´»æ€§&lt;/strong&gt; ï¼šæ”¯æŒåŠ¨æ€çº¿ç¨‹ç»„åˆ’åˆ†ï¼ˆå¦‚ 64/128 çº¿ç¨‹çš„ tileï¼‰ï¼Œé€‚åº”å¤æ‚ç®—æ³•éœ€æ±‚ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å®‰å…¨æ€§&lt;/strong&gt; ï¼šæ˜¾å¼ç»„å¯¹è±¡å¼ºåˆ¶åŒæ­¥çº¦æŸï¼Œå‡å°‘ç«æ€æ¡ä»¶å’Œæ­»é”é£é™©ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½æå‡&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;ç»†ç²’åº¦åŒæ­¥å‡å°‘æ— æ•ˆç­‰å¾…ï¼ˆå¦‚ä»…åŒæ­¥å¿…è¦çº¿ç¨‹å­é›†ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;é›†ä½“ç®—æ³•åˆ©ç”¨ç¡¬ä»¶ç‰¹æ€§ï¼ˆå¦‚ Tensor Core åŠ é€Ÿè§„çº¦ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¯ç»´æŠ¤æ€§&lt;/strong&gt; ï¼šç»„å¯¹è±¡ä½œä¸ºå‡½æ•°å‚æ•°ä¼ é€’ï¼Œæ˜ç¡®åä½œè¾¹ç•Œï¼Œæå‡ä»£ç å¯è¯»æ€§ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-å…¸å‹åº”ç”¨åœºæ™¯"&gt;âš¡ å…¸å‹åº”ç”¨åœºæ™¯
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹&lt;/strong&gt; ï¼šä¸åŒçº¿ç¨‹ç»„åˆ†åˆ«è´Ÿè´£æ•°æ®ç”Ÿæˆä¸å¤„ç†ï¼Œé€šè¿‡æ˜¾å¼åŒæ­¥åè°ƒæµç¨‹ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;è·¨çº¿ç¨‹å—è§„çº¦&lt;/strong&gt; ï¼šä½¿ç”¨ç½‘æ ¼çº§ç»„ï¼ˆgrid_groupï¼‰å®ç°å…¨å±€æ±‚å’Œæˆ–æ‰«æã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;å¼‚æ­¥æ•°æ®ä¼ è¾“&lt;/strong&gt; ï¼š### memcpy_async() åœ¨è®¡ç®—åŒæ—¶é¢„å–æ•°æ®ï¼Œéšè—å†…å­˜å»¶è¿Ÿã€‚
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;åŠ¨æ€è´Ÿè½½å‡è¡¡&lt;/strong&gt; ï¼šæœºä¼šå¹¶è¡Œï¼ˆopportunistic parallelismï¼‰æŒ‰éœ€åˆ†é…çº¿ç¨‹ä»»åŠ¡ã€‚
â €&lt;/p&gt;
&lt;h3 id="-æ³¨æ„äº‹é¡¹"&gt;âš ï¸ æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‰ˆæœ¬ä¾èµ–&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;ç½‘æ ¼çº§ç»„éœ€ CUDA 11.0+ï¼Œé›†ä½“ç®—æ³•éœ€ C++11 ç¼–è¯‘ï¼ˆ&amp;ndash;std=c++11ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶é™åˆ¶&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;å¤§äº 32 çº¿ç¨‹çš„ tile éœ€ Compute Capability 8.0+ï¼ˆå¦‚ A100/RTX 30 ç³»åˆ—ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½æƒè¡¡&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;è¿‡åº¦ç»†åˆ†ç»„å¯èƒ½å¯¼è‡´åŒæ­¥å¼€é”€å¢åŠ ï¼Œéœ€ç»“åˆç®—æ³•ç‰¹æ€§è®¾è®¡ã€‚
â €çº¿ç¨‹åä½œç»„é€šè¿‡&lt;strong&gt;æ˜¾å¼çº¿ç¨‹ç®¡ç†&lt;/strong&gt;å’Œ&lt;strong&gt;ç¡¬ä»¶åŠ é€Ÿé›†åˆæ“ä½œ&lt;/strong&gt;ï¼Œæ˜¾è‘—æå‡äº† CUDA å¹¶è¡Œç¨‹åºçš„çµæ´»æ€§ä¸æ•ˆç‡ï¼Œå°¤å…¶é€‚åˆå¤æ‚åä½œé€»è¾‘ï¼ˆå¦‚ç§‘å­¦è®¡ç®—ã€AI æ¨ç†ï¼‰çš„å¼€å‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="warp"&gt;Warp
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œ &lt;strong&gt;Warpï¼ˆçº¿ç¨‹æŸï¼‰æ˜¯GPUæ‰§è¡ŒæŒ‡ä»¤çš„æœ€å°è°ƒåº¦å•å…ƒ&lt;/strong&gt;ï¼Œå…¶å¤§å°æ˜¯å›ºå®šçš„ç¡¬ä»¶è®¾è®¡ã€‚ä»¥ä¸‹æ˜¯å…³é”®ä¿¡æ¯æ€»ç»“ï¼š&lt;/p&gt;
&lt;h3 id="-warp-çš„æ ‡å‡†å¤§å°"&gt;âš™ï¸ Warp çš„æ ‡å‡†å¤§å°
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;å›ºå®šä¸º32çº¿ç¨‹&lt;/strong&gt;
* æ‰€æœ‰NVIDIA GPUæ¶æ„ï¼ˆä»æ—©æœŸTeslaåˆ°æœ€æ–°Ampere/Ada Lovelaceï¼‰å‡é‡‡ç”¨ &lt;strong&gt;32çº¿ç¨‹&lt;/strong&gt; ä½œä¸ºWarpçš„åŸºæœ¬å•ä½ã€‚
* è¿™ä¸€è®¾è®¡ç”±ç¡¬ä»¶å±‚å›ºåŒ–ï¼Œå¼€å‘è€…æ— æ³•ä¿®æ”¹ã€‚
â €ğŸ”§ ç¡¬ä»¶å®ç°æœºåˆ¶&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SIMTï¼ˆå•æŒ‡ä»¤å¤šçº¿ç¨‹ï¼‰æ‰§è¡Œæ¨¡å‹&lt;/strong&gt; ï¼šWarpå†…çš„32ä¸ªçº¿ç¨‹&lt;strong&gt;åŒæ­¥æ‰§è¡Œç›¸åŒæŒ‡ä»¤&lt;/strong&gt;ï¼Œä½†å¯å¤„ç†ä¸åŒæ•°æ®ï¼ˆå³å•æŒ‡ä»¤ä½œç”¨äºå¤šä¸ªæ•°æ®è·¯å¾„ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯å‘æ•£ï¼ˆDivergenceï¼‰å¤„ç†&lt;/strong&gt; ï¼šè‹¥Warpå†…çº¿ç¨‹å› æ¡ä»¶åˆ†æ”¯èµ°å‘ä¸åŒè·¯å¾„ï¼ˆå¦‚if-elseï¼‰ï¼ŒGPUä¼š&lt;strong&gt;ä¸²è¡Œæ‰§è¡Œæ‰€æœ‰åˆ†æ”¯è·¯å¾„&lt;/strong&gt;ï¼Œæ˜¾è‘—é™ä½æ•ˆç‡ã€‚éœ€é¿å…æ­¤ç±»è®¾è®¡ã€‚
â €ğŸ“Š ä¸åŒæ¶æ„ä¸‹çš„Warpç‰¹æ€§
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;GPUæ¶æ„&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Warpå¤§å°&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å…³é”®ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Tesla/Fermi/Kepler&lt;/td&gt;
&lt;td style="text-align: center"&gt;32çº¿ç¨‹&lt;/td&gt;
&lt;td style="text-align: center"&gt;åŸºç¡€SIMTæ¨¡å‹ï¼Œæ— ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Maxwell/Pascal&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;32çº¿ç¨‹&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¼•å…¥åŠ¨æ€å¹¶è¡Œï¼ŒWarpè°ƒåº¦ä¼˜åŒ–&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Volta/Ampere&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;32çº¿ç¨‹&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ”¯æŒ&lt;strong&gt;ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦ï¼ˆISAï¼‰&lt;/strong&gt; ï¼Œå‡å°‘åˆ†æ”¯å‘æ•£ä»£ä»·&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Hopper/Ada Lovelace&lt;/td&gt;
&lt;td style="text-align: center"&gt;32çº¿ç¨‹&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¢å¼ºçº¿ç¨‹å—é›†ç¾¤åä½œï¼ŒWarpçº§æ“ä½œæ›´é«˜æ•ˆ&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ç¼–ç¨‹æ³¨æ„äº‹é¡¹"&gt;ğŸ’¡ ç¼–ç¨‹æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;æ€§èƒ½ä¼˜åŒ–æ ¸å¿ƒ&lt;/strong&gt; ï¼š
* &lt;strong&gt;å†…å­˜è®¿é—®å¯¹é½&lt;/strong&gt; ï¼šç¡®ä¿Warpå†…çº¿ç¨‹è®¿é—®è¿ç»­å†…å­˜åœ°å€ï¼ˆå¦‚threadIdx.xå¯¹åº”ç›¸é‚»æ•°æ®ï¼‰ï¼Œé¿å…å…¨å±€å†…å­˜ç¢ç‰‡ã€‚
* &lt;strong&gt;å‡å°‘åˆ†æ”¯å‘æ•£&lt;/strong&gt; ï¼šé€šè¿‡é‡ç»„æ•°æ®æˆ–ä½¿ç”¨__syncwarp()æ˜¾å¼åŒæ­¥ï¼ˆVolta+æ¶æ„ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;èµ„æºåˆ†é…å½±å“&lt;/strong&gt; ï¼š
* æ¯ä¸ªSMï¼ˆæµå¤šå¤„ç†å™¨ï¼‰çš„Warpæ•°é‡å—é™äºå¯„å­˜å™¨æ–‡ä»¶ï¼ˆRegister Fileï¼‰å’Œå…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰å®¹é‡ã€‚
* ä¾‹å¦‚ï¼šKepleræ¶æ„SMæœ€å¤šé©»ç•™64ä¸ªæ´»è·ƒWarpï¼ˆå³2048çº¿ç¨‹ï¼‰ã€‚
â €ğŸŒ° ç¤ºä¾‹åœºæ™¯
è‹¥ä¸€ä¸ªçº¿ç¨‹å—ï¼ˆBlockï¼‰åŒ…å«256çº¿ç¨‹ â†’ å°†è¢«æ‹†åˆ†ä¸º &lt;strong&gt;8ä¸ªWarp&lt;/strong&gt; ï¼ˆ256/32ï¼‰ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç†æƒ³æƒ…å†µ&lt;/strong&gt; ï¼šæ‰€æœ‰çº¿ç¨‹æ‰§è¡Œç›¸åŒæŒ‡ä»¤ï¼Œæ— åˆ†æ”¯å‘æ•£ â†’ ç¡¬ä»¶åˆ©ç”¨ç‡100%ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœ€å·®æƒ…å†µ&lt;/strong&gt; ï¼š32çº¿ç¨‹åˆ†åˆ«æ‰§è¡Œ32ä¸ªä¸åŒåˆ†æ”¯ â†’ å®é™…å¹¶è¡Œåº¦é™ä¸º1/32ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€»ç»“"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å›ºå®šå¤§å°&lt;/strong&gt; ï¼šWarpæ’ä¸º&lt;strong&gt;32çº¿ç¨‹&lt;/strong&gt;ï¼Œæ˜¯GPUè°ƒåº¦çš„åŸå­å•å…ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŒ–å…³é”®&lt;/strong&gt; ï¼šé¿å…åˆ†æ”¯å‘æ•£ã€ç¡®ä¿å†…å­˜è¿ç»­è®¿é—®ï¼Œä»¥æœ€å¤§åŒ–Warpæ‰§è¡Œæ•ˆç‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¶æ„æ¼”è¿›&lt;/strong&gt; ï¼šæ–°ä¸€ä»£GPUï¼ˆVolta+ï¼‰é€šè¿‡ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦é™ä½åˆ†æ”¯ä»£ä»·ï¼Œä½†32çº¿ç¨‹åŸºç¡€ç»“æ„ä¸å˜ã€‚
â €ğŸ“Œ &lt;strong&gt;å®è·µå»ºè®®&lt;/strong&gt; ï¼šä½¿ç”¨cudaDeviceProp.warpSizeè·å–å½“å‰è®¾å¤‡çš„Warpå¤§å°ï¼ˆå§‹ç»ˆä¸º32ï¼‰ï¼Œå¹¶åœ¨å†…æ ¸è®¾è®¡ä¸­æ˜¾å¼å¯¹é½32çš„å€æ•°ï¼ˆå¦‚çº¿ç¨‹å—å°ºå¯¸è®¾ä¸º32Ã—Nï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="warp-divergence"&gt;Warp Divergence
&lt;/h2&gt;&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œâ€œä¸²è¡Œæ‰§è¡Œæ‰€æœ‰åˆ†æ”¯è·¯å¾„â€æ˜¯GPUå¤„ç†&lt;strong&gt;åˆ†æ”¯å‘æ•£ï¼ˆWarp Divergenceï¼‰&lt;/strong&gt; çš„æ ¸å¿ƒæœºåˆ¶ï¼ŒæŒ‡å½“åŒä¸€ä¸ªWarpï¼ˆ32çº¿ç¨‹ï¼‰å†…çš„çº¿ç¨‹å› æ¡ä»¶åˆ†æ”¯ï¼ˆå¦‚if-elseï¼‰èµ°å‘ä¸åŒæ‰§è¡Œè·¯å¾„æ—¶ï¼ŒGPUç¡¬ä»¶è¢«è¿«&lt;strong&gt;æŒ‰åˆ†æ”¯è·¯å¾„é¡ºåºé€æ¡æ‰§è¡Œæ‰€æœ‰è·¯å¾„&lt;/strong&gt;ï¼Œè€Œéå¹¶è¡Œå¤„ç†ã€‚å…¶å…·ä½“å«ä¹‰å’ŒåŸç†å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;h3 id="-ç¡¬ä»¶èƒŒæ™¯simtæ‰§è¡Œæ¨¡å‹"&gt;âš™ï¸ ç¡¬ä»¶èƒŒæ™¯ï¼šSIMTæ‰§è¡Œæ¨¡å‹
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Warpæ˜¯è°ƒåº¦å•å…ƒ&lt;/strong&gt; ï¼šGPUä»¥Warpï¼ˆ32çº¿ç¨‹ï¼‰ä¸ºå•ä½è°ƒåº¦æŒ‡ä»¤ï¼ŒåŒä¸€Warpå†…æ‰€æœ‰çº¿ç¨‹&lt;strong&gt;å¿…é¡»åŒæ­¥æ‰§è¡Œç›¸åŒæŒ‡ä»¤&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯å†²çªçš„ä»£ä»·&lt;/strong&gt; ï¼šè‹¥Warpå†…éƒ¨åˆ†çº¿ç¨‹æ»¡è¶³æ¡ä»¶Aï¼Œå¦ä¸€éƒ¨åˆ†æ»¡è¶³æ¡ä»¶Bï¼Œç¡¬ä»¶æ— æ³•åŒæ—¶æ‰§è¡Œä¸¤æ¡è·¯å¾„ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ä¸²è¡Œæ‰§è¡Œæ‰€æœ‰åˆ†æ”¯è·¯å¾„çš„æµç¨‹"&gt;ğŸ”„ â€œä¸²è¡Œæ‰§è¡Œæ‰€æœ‰åˆ†æ”¯è·¯å¾„â€çš„æµç¨‹
&lt;/h3&gt;&lt;p&gt;å½“Warpå†…å‡ºç°åˆ†æ”¯å‘æ•£æ—¶ï¼ŒGPUæŒ‰ä»¥ä¸‹æ­¥éª¤å¤„ç†ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;è·¯å¾„åˆ†ç¦»&lt;/strong&gt; ï¼šè¯†åˆ«Warpå†…çº¿ç¨‹çš„ä¸åŒåˆ†æ”¯è·¯å¾„ï¼ˆå¦‚ifåˆ†æ”¯å’Œelseåˆ†æ”¯ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ©ç æ¿€æ´»ä¸å±è”½&lt;/strong&gt; ï¼š
* å…ˆæ¿€æ´»æ‰§è¡Œ&lt;strong&gt;ç¬¬ä¸€æ¡è·¯å¾„çš„çº¿ç¨‹&lt;/strong&gt; ï¼ˆå¦‚æ»¡è¶³ifçš„çº¿ç¨‹ï¼‰ï¼ŒåŒæ—¶&lt;strong&gt;å±è”½å…¶ä»–çº¿ç¨‹&lt;/strong&gt; ï¼ˆå¦‚elseçº¿ç¨‹ï¼‰ã€‚
* å†æ¿€æ´»æ‰§è¡Œ&lt;strong&gt;ç¬¬äºŒæ¡è·¯å¾„çš„çº¿ç¨‹&lt;/strong&gt; ï¼ˆå¦‚elseçº¿ç¨‹ï¼‰ï¼Œå±è”½å·²æ‰§è¡Œå®Œçš„çº¿ç¨‹ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;è·¯å¾„åˆå¹¶&lt;/strong&gt; ï¼šæ‰€æœ‰è·¯å¾„æ‰§è¡Œå®Œæ¯•åï¼Œçº¿ç¨‹é‡æ–°æ±‡åˆåˆ°åŒä¸€æ‰§è¡Œç‚¹ç»§ç»­åç»­æŒ‡ä»¤ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç†æƒ³æƒ…å†µ&lt;/strong&gt; ï¼šæ‰€æœ‰32çº¿ç¨‹èµ°åŒä¸€è·¯å¾„ â†’ 1æ¬¡æ‰§è¡Œå®Œæˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯å‘æ•£&lt;/strong&gt; ï¼š16çº¿ç¨‹èµ°è·¯å¾„Aï¼Œ16çº¿ç¨‹èµ°è·¯å¾„B â†’ ç¡¬ä»¶éœ€&lt;strong&gt;å…ˆæ‰§è¡Œè·¯å¾„Aï¼ˆå±è”½è·¯å¾„Bçº¿ç¨‹ï¼‰&lt;/strong&gt; ï¼Œ &lt;strong&gt;å†æ‰§è¡Œè·¯å¾„Bï¼ˆå±è”½è·¯å¾„Açº¿ç¨‹ï¼‰&lt;/strong&gt; â†’ &lt;strong&gt;å®é™…è€—æ—¶ç¿»å€&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€§èƒ½å½±å“"&gt;âš ï¸ æ€§èƒ½å½±å“
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¹¶è¡Œåº¦éª¤é™&lt;/strong&gt; ï¼šWarpçš„å¹¶è¡Œèƒ½åŠ›ä»32çº¿ç¨‹é™è‡³å®é™…æœ‰æ•ˆçº¿ç¨‹æ•°ï¼ˆå¦‚ä»…16çº¿ç¨‹æ´»è·ƒï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;èµ„æºé—²ç½®&lt;/strong&gt; ï¼šè¢«å±è”½çš„çº¿ç¨‹å ç”¨å¯„å­˜å™¨/å†…å­˜èµ„æºï¼Œä½†æ— æ³•æ‰§è¡ŒæŒ‡ä»¤ï¼Œé€ æˆç¡¬ä»¶èµ„æºæµªè´¹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æç«¯æ¡ˆä¾‹&lt;/strong&gt; ï¼šè‹¥32çº¿ç¨‹èµ°å‘32æ¡ä¸åŒè·¯å¾„ï¼ŒGPUéœ€&lt;strong&gt;ä¸²è¡Œæ‰§è¡Œ32æ¬¡&lt;/strong&gt;ï¼Œæ€§èƒ½ä¸‹é™32å€ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ä¸cpuåˆ†æ”¯å¤„ç†çš„åŒºåˆ«"&gt;ğŸ§© ä¸CPUåˆ†æ”¯å¤„ç†çš„åŒºåˆ«
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;GPUï¼ˆSIMTæ¨¡å‹ï¼‰&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;CPUï¼ˆè¶…æ ‡é‡/ä¹±åºæ‰§è¡Œï¼‰&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;åˆ†æ”¯å¤„ç†&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸²è¡ŒåŒ–æ‰€æœ‰è·¯å¾„&lt;/td&gt;
&lt;td style="text-align: center"&gt;åˆ†æ”¯é¢„æµ‹ + æ¨æµ‹æ‰§è¡Œ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å¹¶è¡Œç²’åº¦&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;Warpï¼ˆ32çº¿ç¨‹ï¼‰ä¸ºå•ä½&lt;/td&gt;
&lt;td style="text-align: center"&gt;å•çº¿ç¨‹æŒ‡ä»¤çº§å¹¶è¡Œ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ä»£ä»·&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;è·¯å¾„æ•°è¶Šå¤šï¼Œæ€§èƒ½æŸå¤±è¶Šå¤§&lt;/td&gt;
&lt;td style="text-align: center"&gt;é¢„æµ‹å¤±è´¥æ—¶éœ€åˆ·æ–°æµæ°´çº¿&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ’¡ å…³é”®å·®å¼‚ï¼šCPUé€šè¿‡é¢„æµ‹å‡å°‘åˆ†æ”¯ä»£ä»·ï¼Œè€ŒGPUæ— åˆ†æ”¯é¢„æµ‹èƒ½åŠ›ï¼Œåªèƒ½ç¡¬æ€§ä¸²è¡ŒåŒ–ã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-ä¼˜åŒ–ç­–ç•¥"&gt;âš¡ ä¼˜åŒ–ç­–ç•¥
&lt;/h3&gt;&lt;p&gt;ä¸ºå‡å°‘ä¸²è¡Œæ‰§è¡Œçš„å¼€é”€ï¼Œå¯é‡‡å–ä»¥ä¸‹æ–¹æ³•ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;é‡æ„åˆ†æ”¯é€»è¾‘&lt;/strong&gt;
* ç”¨&lt;strong&gt;ä¸‰å…ƒè¿ç®—ç¬¦&lt;/strong&gt;æ›¿ä»£if-elseï¼š// åŸåˆ†æ”¯
* if (idx % 2 == 0) data[idx] = 1.0f;&lt;br&gt;
* else data[idx] = -1.0f;
* // ä¼˜åŒ–ä¸º
* data[idx] = (idx % 2 == 0) ? 1.0f : -1.0f;
* ä½¿ç”¨&lt;strong&gt;ä½è¿ç®—æˆ–æ©ç &lt;/strong&gt;é¿å…åˆ†æ”¯ï¼šfloat mask = (idx &amp;amp; 1) ^ 1; // å¶æ•°ä¸º1ï¼Œå¥‡æ•°ä¸º0
* data[idx] = mask * 1.0f + (1 - mask) * (-1.0f);
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ•°æ®å¸ƒå±€è°ƒæ•´&lt;/strong&gt;
* å°†&lt;strong&gt;ç›¸åŒåˆ†æ”¯è¡Œä¸ºçš„çº¿ç¨‹åˆ†ç»„&lt;/strong&gt;åˆ°åŒä¸€Warpï¼ˆå¦‚æŒ‰æ•°æ®å¥‡å¶æ€§é‡æ’è¾“å…¥ï¼‰ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;Warpçº§åŸè¯­&lt;/strong&gt;
* ä½¿ç”¨__shfl_xor()ã€__ballot()ç­‰æŒ‡ä»¤åœ¨Warpå†…äº¤æ¢æ•°æ®ï¼Œé¿å…æ˜¾å¼åˆ†æ”¯ã€‚
â €&lt;/p&gt;
&lt;h3 id="-æ€»ç»“-1"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;â€œä¸²è¡Œæ‰§è¡Œæ‰€æœ‰åˆ†æ”¯è·¯å¾„â€æ˜¯GPUåº”å¯¹&lt;strong&gt;Warp Divergenceçš„åº•å±‚ç¡¬ä»¶è¡Œä¸º&lt;/strong&gt;ï¼Œæœ¬è´¨æ˜¯SIMTæ¶æ„ä¸ºç»Ÿä¸€æŒ‡ä»¤æµçš„å¦¥åã€‚å…¶ä»£ä»·æ˜¯&lt;strong&gt;å¹¶è¡Œæ•ˆç‡çš„æ˜¾è‘—ä¸‹é™&lt;/strong&gt;ï¼Œå°¤å…¶åœ¨åˆ†æ”¯è·¯å¾„å¤šã€åˆ†å¸ƒéšæœºæ—¶ã€‚ä¼˜åŒ–éœ€èšç„¦ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;å‡å°‘åˆ†æ”¯æ•°é‡&lt;/strong&gt; ï¼ˆå¦‚æ•°å­¦ç­‰ä»·è½¬æ¢ï¼‰
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;å¯¹é½çº¿ç¨‹è¡Œä¸º&lt;/strong&gt; ï¼ˆæ•°æ®é‡æ’ï¼‰
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;åˆ©ç”¨ç¡¬ä»¶ç‰¹æ€§&lt;/strong&gt; ï¼ˆWarpçº§æŒ‡ä»¤ï¼‰ã€‚ç†è§£è¿™ä¸€æœºåˆ¶æ˜¯å†™å‡ºé«˜æ€§èƒ½CUDAä»£ç çš„å…³é”®å‰æã€‚&lt;/p&gt;
&lt;h2 id="warp-part"&gt;Warp-Part
&lt;/h2&gt;&lt;p&gt;æ˜¯çš„ï¼Œ &lt;strong&gt;çº¿ç¨‹åä½œç»„ï¼ˆCooperative Groupsï¼‰å¯ä»¥åˆ’åˆ†å¾—æ¯”32çº¿ç¨‹æ›´å°&lt;/strong&gt;ã€‚è¿™æ˜¯å…¶æ ¸å¿ƒè®¾è®¡ç›®æ ‡ä¹‹ä¸€â€”â€”æä¾›æ¯”ä¼ ç»Ÿ Warpï¼ˆå›ºå®š32çº¿ç¨‹ï¼‰æ›´çµæ´»çš„çº¿ç¨‹ç»„ç»‡ç²’åº¦ã€‚ä»¥ä¸‹æ˜¯å…³é”®è¯´æ˜ï¼š&lt;/p&gt;
&lt;h3 id="-åä½œç»„æ”¯æŒç»†ç²’åº¦åˆ’åˆ†"&gt;âš™ï¸ åä½œç»„æ”¯æŒç»†ç²’åº¦åˆ’åˆ†
&lt;/h3&gt;&lt;p&gt;çº¿ç¨‹åä½œç»„å…è®¸å¼€å‘è€…åŠ¨æ€åˆ›å»º&lt;strong&gt;ä»»æ„è§„æ¨¡&lt;/strong&gt;çš„çº¿ç¨‹å­é›†ï¼ŒåŒ…æ‹¬å°äº Warp çš„ç»„ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æœ€å°å¯åˆ’åˆ†è‡³å•çº¿ç¨‹&lt;/strong&gt; ï¼šé€šè¿‡ tiled_partition æˆ– coalesced_threads() å¯åˆ›å»º 1~31 çº¿ç¨‹çš„å­ç»„ã€‚ä¾‹å¦‚ï¼šauto tile16 = cg::tiled_partition&amp;lt;16&amp;gt;(block); // åˆ’åˆ†16çº¿ç¨‹å­ç»„&lt;/li&gt;
&lt;li&gt;auto tile8 = cg::tiled_partition&amp;lt;8&amp;gt;(block); // åˆ’åˆ†8çº¿ç¨‹å­ç»„&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶æ”¯æŒ&lt;/strong&gt; ï¼šåœ¨ Volta æ¶æ„ï¼ˆCompute Capability 7.0+ï¼‰åŠæ›´æ–° GPU ä¸Šï¼Œ &lt;strong&gt;ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦ï¼ˆISAï¼‰&lt;/strong&gt; å…è®¸å­ç»„å†…çº¿ç¨‹ç‹¬ç«‹æ‰§è¡Œåˆ†æ”¯ï¼Œé¿å…ä¼ ç»Ÿ Warp çš„åˆ†å‘æ•£é—®é¢˜ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-å…¸å‹åº”ç”¨åœºæ™¯-1"&gt;ğŸ§© å…¸å‹åº”ç”¨åœºæ™¯
&lt;/h3&gt;&lt;p&gt;å°äº Warp çš„ç»„åœ¨ä»¥ä¸‹åœºæ™¯ä¸­å°¤ä¸ºé‡è¦ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ•°æ®åˆ†å—å¤„ç†&lt;/strong&gt; ï¼šå½“æ¯è¡Œæ•°æ®å®½åº¦å°äº 32ï¼ˆå¦‚å¤„ç† 16 é€šé“å›¾åƒï¼‰ï¼Œç”¨ 16 çº¿ç¨‹å­ç»„å¯é¿å…èµ„æºæµªè´¹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»†ç²’åº¦åŒæ­¥&lt;/strong&gt; ï¼šç»„å†…ä»…éœ€åŒæ­¥å¿…è¦çº¿ç¨‹ï¼ˆå¦‚ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ï¼‰ï¼Œå‡å°‘æ— æ•ˆç­‰å¾…ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é«˜æ•ˆé›†åˆæ“ä½œ&lt;/strong&gt; ï¼šå°è§„æ¨¡è§„çº¦ï¼ˆReduceï¼‰æˆ–æ‰«æï¼ˆScanï¼‰åœ¨å­ç»„å†…å®Œæˆï¼Œå‡å°‘å…±äº«å†…å­˜äº‰ç”¨ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€§èƒ½ä¸é™åˆ¶"&gt;âš ï¸ æ€§èƒ½ä¸é™åˆ¶
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;çµæ´»æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;é€‚åº”ä¸è§„åˆ™è®¡ç®—æ¨¡å¼ï¼ˆå¦‚ç¨€ç–æ•°æ®å¤„ç†ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;è¿‡å°ç»„ï¼ˆ&amp;lt;8çº¿ç¨‹ï¼‰å¯èƒ½å¯¼è‡´å¹¶è¡Œåº¦ä¸è¶³&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;åˆ†æ”¯å‘æ•£å¤„ç†&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å­ç»„å†…åˆ†æ”¯å‘æ•£ä»£ä»·æ›´ä½ï¼ˆVolta+æ¶æ„ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ—§æ¶æ„ï¼ˆMaxwell/Pascalï¼‰ä»éœ€ä¸²è¡Œæ‰§è¡Œæ‰€æœ‰è·¯å¾„&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;èµ„æºå¼€é”€&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å‡å°‘å¯„å­˜å™¨/å…±äº«å†…å­˜å ç”¨ï¼ˆç»„è§„æ¨¡å°ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;é¢‘ç¹åˆ’åˆ†å­ç»„å¯èƒ½å¢åŠ è°ƒåº¦å¼€é”€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ’¡ &lt;strong&gt;æœ€ä½³å®è·µ&lt;/strong&gt; ï¼š&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;ä¼˜å…ˆåœ¨ &lt;strong&gt;Volta/Turing/Ampere æ¶æ„&lt;/strong&gt; ä½¿ç”¨å°è§„æ¨¡ç»„ï¼ˆå……åˆ†åˆ©ç”¨ ISAï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;é¿å…åœ¨è®¡ç®—å¯†é›†å‹ä»»åŠ¡ä¸­åˆ’åˆ†è¿‡å°ç»„ï¼ˆå¦‚ &amp;lt;8 çº¿ç¨‹ï¼‰ï¼Œç¡®ä¿ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ä»£ç ç¤ºä¾‹"&gt;ğŸ’» ä»£ç ç¤ºä¾‹
&lt;/h3&gt;&lt;h3 id="global-void-processsmalldatafloat-data-"&gt;&lt;strong&gt;global&lt;/strong&gt; void processSmallData(float* data) {
&lt;/h3&gt;&lt;h3 id="auto-block--cgthis_thread_block"&gt;auto block = cg::this_thread_block();
&lt;/h3&gt;&lt;h3 id="auto-tile16--cgtiled_partition16block--åˆ›å»º16çº¿ç¨‹å­ç»„"&gt;auto tile16 = cg::tiled_partition&amp;lt;16&amp;gt;(block); // åˆ›å»º16çº¿ç¨‹å­ç»„
&lt;/h3&gt;&lt;h3 id="if-tilethread_rank--8-"&gt;if (tilethread_rank() &amp;lt; 8) {
&lt;/h3&gt;&lt;h3 id="-å‰8çº¿ç¨‹å¤„ç†ä»»åŠ¡a"&gt;// å‰8çº¿ç¨‹å¤„ç†ä»»åŠ¡A
&lt;/h3&gt;&lt;h3 id="float-val--datatilethread_rank"&gt;float val = data[tilethread_rank()];
&lt;/h3&gt;&lt;h3 id="val--tileshflval-0--å­ç»„å†…æ•°æ®äº¤æ¢"&gt;val = tileshfl(val, 0); // å­ç»„å†…æ•°æ®äº¤æ¢
&lt;/h3&gt;&lt;h3 id="-else-"&gt;} else {
&lt;/h3&gt;&lt;h3 id="-å8çº¿ç¨‹å¤„ç†ä»»åŠ¡b"&gt;// å8çº¿ç¨‹å¤„ç†ä»»åŠ¡B
&lt;/h3&gt;&lt;h3 id="-"&gt;// &amp;hellip;
&lt;/h3&gt;&lt;h3 id="heading"&gt;}
&lt;/h3&gt;&lt;h3 id="tilesync--ä»…åŒæ­¥16çº¿ç¨‹å­ç»„"&gt;tilesync(); // ä»…åŒæ­¥16çº¿ç¨‹å­ç»„
&lt;/h3&gt;&lt;h3 id="heading-1"&gt;}
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;å…³é”®ç‚¹&lt;/strong&gt; ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tile16.shfl() å®ç°ç»„å†…æ•°æ®å¹¿æ’­ï¼ˆç¡¬ä»¶åŠ é€Ÿï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;tile16.sync() ä»…åŒæ­¥å­ç»„ï¼Œæ— éœ€ç­‰å¾…æ•´ä¸ª Warpã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€»ç»“-2"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;çº¿ç¨‹åä½œç»„&lt;strong&gt;æ”¯æŒä»»æ„å°äº Warp çš„åˆ’åˆ†&lt;/strong&gt; ï¼ˆæœ€å°è‡³å•çº¿ç¨‹ï¼‰ï¼Œé€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°é«˜æ•ˆåä½œï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;åŠ¨æ€å­ç»„åˆ›å»º&lt;/strong&gt; ï¼ˆtiled_partitionï¼‰
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;ç»†ç²’åº¦åŒæ­¥&lt;/strong&gt; ï¼ˆgroup.sync()ï¼‰
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;ç¡¬ä»¶åŠ é€Ÿé›†åˆæ“ä½œ&lt;/strong&gt; ï¼ˆå¦‚ shfl()ã€reduce()ï¼‰éœ€ç»“åˆç¡¬ä»¶æ¶æ„ï¼ˆVolta+ï¼‰å’Œä»»åŠ¡ç‰¹æ€§æƒè¡¡ç»„è§„æ¨¡ï¼Œä»¥æœ€å¤§åŒ–å¹¶è¡Œæ•ˆç‡ã€‚
æ¯”Warpï¼ˆ32çº¿ç¨‹ï¼‰æ›´å°çš„åä½œç»„ï¼ˆå¦‚16ã€8çº¿ç¨‹ï¼‰åœ¨GPUç‰©ç†ç»“æ„ä¸Šå®ç°å¹¶è¡Œï¼Œä¸»è¦ä¾èµ–ä»¥ä¸‹ç¡¬ä»¶ä¸è½¯ä»¶ååŒæœºåˆ¶ï¼š&lt;/p&gt;
&lt;h3 id="-ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦isaç¡¬ä»¶çº§æ”¯æŒ"&gt;âš™ï¸ ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦ï¼ˆISAï¼‰â€”â€”ç¡¬ä»¶çº§æ”¯æŒ
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Voltaæ¶æ„ï¼ˆ2017ï¼‰åŠæ›´æ–°GPU&lt;/strong&gt; ï¼ˆå¦‚Turing/Ampere/Hopperï¼‰å¼•å…¥&lt;strong&gt;ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦ï¼ˆISAï¼‰&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;æ¯ä¸ªçº¿ç¨‹æ‹¥æœ‰ç‹¬ç«‹çš„&lt;strong&gt;ç¨‹åºè®¡æ•°å™¨ï¼ˆPCï¼‰&lt;/strong&gt; å’Œ&lt;strong&gt;æ‰§è¡ŒçŠ¶æ€å¯„å­˜å™¨&lt;/strong&gt;ï¼Œæ‰“ç ´ä¼ ç»ŸWarpå¿…é¡»é”æ­¥æ‰§è¡Œï¼ˆSIMTï¼‰çš„é™åˆ¶ã€‚&lt;/li&gt;
&lt;li&gt;ç¡¬ä»¶å¯ä¸ºå­ç»„ï¼ˆå¦‚16çº¿ç¨‹ï¼‰åˆ†é…ç‹¬ç«‹æŒ‡ä»¤æµï¼Œå®ç°&lt;strong&gt;çœŸæ­£ç»†ç²’åº¦å¹¶è¡Œ&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ‰§è¡ŒåŸç†&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;å½“åä½œç»„ï¼ˆå¦‚16çº¿ç¨‹ï¼‰è¢«åˆ’åˆ†åï¼ŒGPUè°ƒåº¦å™¨å°†å­ç»„è§†ä¸ºç‹¬ç«‹æ‰§è¡Œå•å…ƒã€‚&lt;/li&gt;
&lt;li&gt;è‹¥å­ç»„å†…æ— åˆ†æ”¯å‘æ•£ï¼Œç¡¬ä»¶ä»æŒ‰SIMTæ¨¡å¼å¹¿æ’­æŒ‡ä»¤ï¼›è‹¥å­˜åœ¨åˆ†æ”¯ï¼Œç¡¬ä»¶è‡ªåŠ¨ä¸ºä¸åŒè·¯å¾„çº¿ç¨‹åˆ†é…ç‹¬ç«‹èµ„æºï¼Œ &lt;strong&gt;é¿å…ä¸²è¡Œæ‰§è¡Œæ‰€æœ‰è·¯å¾„&lt;/strong&gt;ã€‚
â €âœ… &lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt; ï¼š8çº¿ç¨‹å­ç»„ä¸­ï¼Œ4çº¿ç¨‹èµ°è·¯å¾„Aã€4çº¿ç¨‹èµ°è·¯å¾„B â†’ ç¡¬ä»¶å¹¶è¡Œæ‰§è¡Œä¸¤æ¡è·¯å¾„ï¼Œè€Œéä¼ ç»ŸWarpçš„ä¸²è¡ŒåŒ–ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-åŠ¨æ€å­ç»„åˆ’åˆ†ä¸èµ„æºéš”ç¦»è½¯ä»¶å±‚åä½œ"&gt;ğŸ§© åŠ¨æ€å­ç»„åˆ’åˆ†ä¸èµ„æºéš”ç¦»â€”â€”è½¯ä»¶å±‚åä½œ
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åä½œç»„APIï¼ˆå¦‚&lt;/strong&gt; tiled_partition**ï¼‰** ï¼šauto tile16 = cg::tiled_partition&amp;lt;16&amp;gt;(block); // åˆ’åˆ†16çº¿ç¨‹å­ç»„
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é€»è¾‘åˆ’åˆ†&lt;/strong&gt; ï¼šAPIå°†Warpæ‹†åˆ†ä¸ºæ›´å°çº¿ç¨‹å­é›†ï¼Œæ¯ä¸ªå­ç»„æ‹¥æœ‰&lt;strong&gt;ç‹¬ç«‹åŒæ­¥åŸè¯­&lt;/strong&gt; ï¼ˆå¦‚ tile16.sync()ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶èµ„æºæ˜ å°„&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯„å­˜å™¨æ–‡ä»¶&lt;/strong&gt; ï¼šæ¯ä¸ªçº¿ç¨‹ç‹¬å ç‰©ç†å¯„å­˜å™¨ï¼Œå­ç»„å…±äº«å¯„å­˜å™¨è®¿é—®æƒé™ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…±äº«å†…å­˜&lt;/strong&gt; ï¼šå­ç»„é€šè¿‡å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰äº¤æ¢æ•°æ®ï¼Œç¡¬ä»¶æä¾›ä½å»¶è¿Ÿè®¿é—®é€šé“ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ç»†ç²’åº¦å†…å­˜è®¿é—®ä¼˜åŒ–"&gt;ğŸš€ ç»†ç²’åº¦å†…å­˜è®¿é—®ä¼˜åŒ–
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å†…å­˜åˆå¹¶è®¿é—®&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;å°è§„æ¨¡ç»„ï¼ˆå¦‚8çº¿ç¨‹ï¼‰æ›´æ˜“å®ç°&lt;strong&gt;è¿ç»­å†…å­˜è®¿é—®&lt;/strong&gt;ï¼Œç¡¬ä»¶è‡ªåŠ¨åˆå¹¶å…¨å±€å†…å­˜è¯·æ±‚ï¼Œæå‡å¸¦å®½åˆ©ç”¨ç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…±äº«å†…å­˜å±€éƒ¨æ€§&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;å­ç»„å°†çƒ­ç‚¹æ•°æ®ç¼“å­˜è‡³å…±äº«å†…å­˜ï¼ˆå¦‚çŸ©é˜µåˆ†å—è®¡ç®—ï¼‰ï¼Œå‡å°‘å…¨å±€å†…å­˜å»¶è¿Ÿã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-åˆ†æ”¯å‘æ•£ä»£ä»·çš„è§„é¿"&gt;âš¡ åˆ†æ”¯å‘æ•£ä»£ä»·çš„è§„é¿
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å±€éƒ¨å‘æ•£æ§åˆ¶&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;åˆ†æ”¯å‘æ•£è¢«é™åˆ¶åœ¨å­ç»„å†…éƒ¨ï¼ˆå¦‚16çº¿ç¨‹ï¼‰ï¼Œè€Œéæ•´ä¸ªWarpï¼ˆ32çº¿ç¨‹ï¼‰ï¼Œ &lt;strong&gt;æœ€å¤§å‘æ•£è·¯å¾„æ•°å‡åŠ&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;ç¡¬ä»¶åªéœ€ä¸ºå­ç»„å†…å°‘æ•°è·¯å¾„åˆ†é…èµ„æºï¼Œé™ä½ä¸²è¡ŒåŒ–å¼€é”€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è°“è¯æ©ç ä¼˜åŒ–&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;å­ç»„å†…ä½¿ç”¨&lt;strong&gt;ç»„å†…æŠ•ç¥¨æŒ‡ä»¤&lt;/strong&gt; ï¼ˆå¦‚ ballot()ã€shfl()ï¼‰æ›¿ä»£æ¡ä»¶åˆ†æ”¯ï¼Œä¿æŒæŒ‡ä»¤ä¸€è‡´æ€§ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ä¸“ç”¨ç¡¬ä»¶åŠ é€Ÿé›†åˆæ“ä½œ"&gt;ğŸ§ª ä¸“ç”¨ç¡¬ä»¶åŠ é€Ÿé›†åˆæ“ä½œ
&lt;/h3&gt;&lt;p&gt;åä½œç»„æ”¯æŒé«˜æ•ˆé›†åˆæ“ä½œï¼Œç”±ç¡¬ä»¶ç›´æ¥åŠ é€Ÿï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è§„çº¦ï¼ˆReduceï¼‰&lt;/strong&gt; ï¼šå­ç»„å†…å¹¶è¡Œæ±‚å’Œï¼ˆcg::reduce()ï¼‰ï¼Œåˆ©ç”¨Warpçº§åŸè¯­ï¼ˆå¦‚ __shfl_down()ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•°æ®äº¤æ¢ï¼ˆShuffleï¼‰&lt;/strong&gt; ï¼štile16.shfl(val, src_lane) å®ç°ç»„å†…çº¿ç¨‹æ•°æ®å¹¿æ’­ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt; ï¼šå°è§„æ¨¡ç»„å‡å°‘å…±äº«å†…å­˜äº‰ç”¨ï¼Œæå‡é›†åˆæ“ä½œååé‡ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ¶æ„ä¾èµ–æ€§ä¸é™åˆ¶"&gt;âš ï¸ æ¶æ„ä¾èµ–æ€§ä¸é™åˆ¶
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ¶æ„&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ”¯æŒèƒ½åŠ›&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Volta+&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å®Œæ•´ISAæ”¯æŒï¼Œå­ç»„å¹¶è¡Œæ•ˆç‡é«˜&lt;/td&gt;
&lt;td style="text-align: center"&gt;éœ€Compute Capability â‰¥7.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Maxwell/Pascal&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ— ISAï¼Œå­ç»„å†…åˆ†æ”¯ä»ä¸²è¡Œæ‰§è¡Œ&lt;/td&gt;
&lt;td style="text-align: center"&gt;éœ€é‡æ„ç®—æ³•é¿å…åˆ†æ”¯å‘æ•£&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;è¿‡å°ç»„ï¼ˆ&amp;lt;8çº¿ç¨‹ï¼‰&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¹¶è¡Œåº¦ä¸è¶³ï¼Œå¯èƒ½é™ä½SMåˆ©ç”¨ç‡&lt;/td&gt;
&lt;td style="text-align: center"&gt;å»ºè®®ä¸è®¡ç®—å¯†é›†å‹ä»»åŠ¡æ­é…ä½¿ç”¨&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æ€»ç»“-3"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;å°äºWarpçš„åä½œç»„é€šè¿‡ &lt;strong&gt;â€œç¡¬ä»¶ç‹¬ç«‹è°ƒåº¦ï¼ˆISAï¼‰+ è½¯ä»¶åŠ¨æ€åˆ’åˆ† + å†…å­˜å±€éƒ¨æ€§ä¼˜åŒ–â€&lt;/strong&gt; ä¸‰é‡æœºåˆ¶å®ç°é«˜æ•ˆå¹¶è¡Œï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ç¡¬ä»¶çªç ´&lt;/strong&gt; ï¼šVolta+æ¶æ„çš„ISAè§£é™¤çº¿ç¨‹é”æ­¥é™åˆ¶ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;è½¯ä»¶æŠ½è±¡&lt;/strong&gt; ï¼šåä½œç»„APIé€»è¾‘åˆ’åˆ†çº¿ç¨‹ï¼Œéš”ç¦»èµ„æºä¸åŒæ­¥ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;å±€éƒ¨æ€§åˆ©ç”¨&lt;/strong&gt; ï¼šå°è§„æ¨¡ç»„æ›´æ˜“ä¼˜åŒ–å†…å­˜è®¿é—®ä¸è§„é¿åˆ†æ”¯ä»£ä»·ã€‚&lt;strong&gt;å®è·µå»ºè®®&lt;/strong&gt; ï¼šåœ¨Ampere/Hopperæ¶æ„ä¸Šä¼˜å…ˆä½¿ç”¨8-16çº¿ç¨‹å­ç»„ï¼Œç»“åˆå…±äº«å†…å­˜ä¸é›†åˆæ“ä½œï¼Œæœ€å¤§åŒ–å¹¶è¡Œæ•ˆç‡ã€‚&lt;/p&gt;
&lt;h2 id="sm-åˆ©ç”¨ç‡"&gt;SM åˆ©ç”¨ç‡
&lt;/h2&gt;&lt;p&gt;è¿‡å°çš„çº¿ç¨‹ç»„ï¼ˆå¦‚å°äº32çº¿ç¨‹çš„åä½œç»„æˆ–çº¿ç¨‹å—ï¼‰ä¼šæ˜¾è‘—é™ä½æµå¤šå¤„ç†å™¨ï¼ˆSMï¼‰çš„åˆ©ç”¨ç‡ï¼Œä¸»è¦æºäºä»¥ä¸‹ç¡¬ä»¶èµ„æºåˆ†é…å’Œè°ƒåº¦æœºåˆ¶çš„é™åˆ¶ï¼š&lt;/p&gt;
&lt;h3 id="-èµ„æºåˆ†é…ä»¥çº¿ç¨‹å—ä¸ºæœ€å°å•ä½"&gt;âš™ï¸ èµ„æºåˆ†é…ä»¥çº¿ç¨‹å—ä¸ºæœ€å°å•ä½
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å›ºå®šå¼€é”€å ç”¨&lt;/strong&gt; ï¼šSMçš„èµ„æºï¼ˆå¯„å­˜å™¨ã€å…±äº«å†…å­˜ã€çº¿ç¨‹æ§½ä½ï¼‰æŒ‰çº¿ç¨‹å—åˆ†é…ã€‚æ¯ä¸ªçº¿ç¨‹å—æ— è®ºåŒ…å«å¤šå°‘çº¿ç¨‹ï¼Œéƒ½ä¼šå ç”¨å›ºå®šçš„ç®¡ç†èµ„æºï¼ˆå¦‚å…±äº«å†…å­˜æ§½ä½ã€å¯„å­˜å™¨æ–‡ä»¶å…¥å£ï¼‰ã€‚&lt;strong&gt;é—®é¢˜&lt;/strong&gt; ï¼šè‹¥ä¸€ä¸ªçº¿ç¨‹å—ä»…å«32çº¿ç¨‹ï¼ˆ1ä¸ªWarpï¼‰ï¼Œä½†å…¶å ç”¨çš„å…±äº«å†…å­˜å’Œå¯„å­˜å™¨é‡ä¸128çº¿ç¨‹çš„å—ç›¸åŒ â†’ å¯¼è‡´SMå®é™…å¯è¿è¡Œçš„çº¿ç¨‹æ•°å¤§å¹…å‡å°‘ã€‚&lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;Tesla M6 SMæ”¯æŒæœ€å¤š2048ä¸ªå¹¶å‘çº¿ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;è‹¥æ¯ä¸ªå—ä»…32çº¿ç¨‹ â†’ SMæœ€å¤šè¿è¡Œ64ä¸ªå—ï¼ˆ32Ã—64=2048çº¿ç¨‹ï¼‰ &lt;strong&gt;ç†è®ºå¯è¡Œ&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;ä½†å®é™…å—é™äºå…±äº«å†…å­˜ï¼šè‹¥æ¯ä¸ªå—å ç”¨48KBå…±äº«å†…å­˜ï¼ŒSMæ€»å…±äº«å†…å­˜96KB â†’ &lt;strong&gt;ä»…èƒ½è¿è¡Œ2ä¸ªå—&lt;/strong&gt; â†’ å®é™…çº¿ç¨‹æ•°ä»…64ï¼ˆ32Ã—2ï¼‰ï¼Œåˆ©ç”¨ç‡éª¤é™è‡³3.1%ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-warpè°ƒåº¦å™¨é—²ç½®"&gt;âš¡ Warpè°ƒåº¦å™¨é—²ç½®
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Warpæ˜¯è°ƒåº¦å•å…ƒ&lt;/strong&gt; ï¼šSMé€šè¿‡Warpè°ƒåº¦å™¨ç®¡ç†æŒ‡ä»¤å‘å°„ï¼Œæ¯ä¸ªè°ƒåº¦å™¨éœ€æŒç»­æ¥æ”¶WarpæŒ‡ä»¤æµä»¥éšè—å»¶è¿Ÿï¼ˆå¦‚å†…å­˜è®¿é—®ï¼‰ã€‚&lt;strong&gt;é—®é¢˜&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;è¿‡å°ç»„å¯¼è‡´&lt;strong&gt;æ´»è·ƒWarpæ•°é‡ä¸è¶³&lt;/strong&gt; ï¼šè‹¥ä¸€ä¸ªSMä»…è¿è¡Œå°‘é‡Warpï¼ˆå¦‚2ä¸ªWarpï¼‰ï¼Œè°ƒåº¦å™¨æ— æ³•åˆ‡æ¢è¶³å¤Ÿä»»åŠ¡æ©ç›–å»¶è¿Ÿ â†’ ç¡¬ä»¶ç©ºé—²å‘¨æœŸå¢åŠ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æç«¯æ¡ˆä¾‹&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;SMæœ€å¤šæ”¯æŒ64ä¸ªæ´»è·ƒWarpï¼ˆTesla M6ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;è‹¥æ¯ä¸ªçº¿ç¨‹å—ä»…å«1ä¸ªWarpï¼ˆ32çº¿ç¨‹ï¼‰ï¼Œä¸”SMè¿è¡Œ2ä¸ªå— â†’ ä»…2ä¸ªæ´»è·ƒWarp â†’ &lt;strong&gt;Warpæ§½ä½åˆ©ç”¨ç‡ä»…3.1%&lt;/strong&gt; ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-å¯„å­˜å™¨ä¸å…±äº«å†…å­˜çš„ç¢ç‰‡åŒ–"&gt;ğŸ“‰ å¯„å­˜å™¨ä¸å…±äº«å†…å­˜çš„ç¢ç‰‡åŒ–
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯„å­˜å™¨åˆ†é…ç²’åº¦&lt;/strong&gt; ï¼šå¯„å­˜å™¨ä»¥Warpä¸ºå•ä½åˆ†é…ï¼ˆåˆ†é…ç²’åº¦ä¸º4ï¼‰ã€‚&lt;strong&gt;é—®é¢˜&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;è‹¥çº¿ç¨‹ç»„é32çš„æ•´æ•°å€ï¼ˆå¦‚16çº¿ç¨‹ï¼‰ï¼Œä»éœ€åˆ†é…å®Œæ•´Warpçš„å¯„å­˜å™¨èµ„æº â†’ å‰©ä½™å¯„å­˜å™¨é—²ç½®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…±äº«å†…å­˜åˆ†é…&lt;/strong&gt; ï¼šå…±äº«å†…å­˜æŒ‰å—åˆ†é…ï¼Œè‹¥ç»„è§„æ¨¡å°ä½†å…±äº«å†…å­˜éœ€æ±‚å›ºå®šï¼ˆå¦‚48KB/å—ï¼‰ï¼Œåˆ™SMå¯å®¹çº³çš„å—æ•°å—é™äºæ€»å…±äº«å†…å­˜å®¹é‡ã€‚&lt;strong&gt;å…¬å¼&lt;/strong&gt; ï¼š\text{SMåˆ©ç”¨ç‡} = \frac{\text{å®é™…è¿è¡Œçº¿ç¨‹æ•°}}{\text{SMæœ€å¤§çº¿ç¨‹æ•°}} \times 100%å½“çº¿ç¨‹ç»„è¿‡å°æ—¶ï¼Œåˆ†å­å› èµ„æºé™åˆ¶æ˜¾è‘—ç¼©å°ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-å¹¶è¡Œåº¦ä¸è¶³ä¸è´Ÿè½½ä¸å‡è¡¡"&gt;ğŸ”„ å¹¶è¡Œåº¦ä¸è¶³ä¸è´Ÿè½½ä¸å‡è¡¡
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç½‘æ ¼çº§å¹¶è¡Œç¼ºé™·&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;GPUä¾èµ–ç½‘æ ¼ï¼ˆGridï¼‰ä¸­å¤§é‡çº¿ç¨‹å—è¦†ç›–æ‰€æœ‰SMã€‚è‹¥æ¯ä¸ªå—çº¿ç¨‹æ•°è¿‡å°‘ï¼ˆå¦‚32çº¿ç¨‹ï¼‰ï¼Œéœ€æå¤šå—æ‰èƒ½å¡«æ»¡SM â†’ ä½†ç®—æ³•å¯èƒ½æ— æ³•ç”Ÿæˆè¶³å¤Ÿå—ã€‚&lt;strong&gt;æ¡ˆä¾‹&lt;/strong&gt; ï¼šå¤„ç†200Ã—768çŸ©é˜µçš„è¡Œè§„çº¦æ—¶ï¼š&lt;/li&gt;
&lt;li&gt;è‹¥æ¯è¡Œåˆ†é…1çº¿ç¨‹ â†’ ä»…200çº¿ç¨‹ â†’ è‡³å¤š2ä¸ªå— â†’ ä»…å ç”¨1-2ä¸ªSMã€‚&lt;/li&gt;
&lt;li&gt;ä¼˜åŒ–åï¼šæ¯è¡Œåˆ†é…1ä¸ªWarpï¼ˆ32çº¿ç¨‹ï¼‰ â†’ 200ä¸ªWarp â†’ 50ä¸ªå—ï¼ˆæŒ‰4 Warp/å—ï¼‰ â†’ å……åˆ†åˆ©ç”¨50ä¸ªSMã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯å‘æ•£æ”¾å¤§&lt;/strong&gt; ï¼šå°ç»„å†…åˆ†æ”¯å‘æ•£å¯èƒ½æ›´é¢‘ç¹ï¼Œè¿›ä¸€æ­¥é™ä½æœ‰æ•ˆæŒ‡ä»¤ååé‡ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€»ç»“è¿‡å°ç»„é™ä½åˆ©ç”¨ç‡çš„æœ¬è´¨"&gt;ğŸ’ æ€»ç»“ï¼šè¿‡å°ç»„é™ä½åˆ©ç”¨ç‡çš„æœ¬è´¨
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å› ç´ &lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å½±å“æœºåˆ¶&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ä¼˜åŒ–æ–¹å‘&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;èµ„æºåˆ†é…ç²’åº¦&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å›ºå®šå¼€é”€æŒ¤å å¯ç”¨çº¿ç¨‹æ•°&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¢å¤§ç»„è§„æ¨¡ï¼ˆâ‰¥128çº¿ç¨‹/å—ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Warpè°ƒåº¦éœ€æ±‚&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ´»è·ƒWarpä¸è¶³å¯¼è‡´è°ƒåº¦å™¨é—²ç½®&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç¡®ä¿æ¯SMæ´»è·ƒWarpæ•°æ¥è¿‘ä¸Šé™ï¼ˆå¦‚64ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å†…å­˜ç¢ç‰‡åŒ–&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;éæ•´Warpç»„é€ æˆå¯„å­˜å™¨/å…±äº«å†…å­˜æµªè´¹&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç»„è§„æ¨¡è®¾ä¸º32çš„å€æ•°&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ç½‘æ ¼çº§è´Ÿè½½å‡è¡¡&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å°‘é‡çº¿ç¨‹å—æ— æ³•è¦†ç›–æ‰€æœ‰SM&lt;/td&gt;
&lt;td style="text-align: center"&gt;åŠ¨æ€è°ƒæ•´å—æ•°é‡ï¼ŒåŒ¹é…SMæ€»æ•°&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ“Œ &lt;strong&gt;å®è·µå»ºè®®&lt;/strong&gt; ï¼š&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;åŸºå‡†æµ‹è¯•&lt;/strong&gt; ï¼šç”¨ &amp;ndash;ptxas-options=-v ç¼–è¯‘æŸ¥çœ‹å¯„å­˜å™¨/å…±äº«å†…å­˜å ç”¨ã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;ç»„è§„æ¨¡&lt;/strong&gt; ï¼šçº¿ç¨‹å—è‡³å°‘128çº¿ç¨‹ï¼ˆ4 Warpï¼‰ï¼Œåä½œç»„ä¸å°äº8çº¿ç¨‹ã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;èµ„æºç›‘æ§&lt;/strong&gt; ï¼šé€šè¿‡ nvidia-smi æˆ– DCGM è·Ÿè¸ª &lt;strong&gt;SMæ•ˆç‡&lt;/strong&gt; ï¼ˆæ´»è·ƒSMå æ¯”ï¼‰è€Œéä»…GPUåˆ©ç”¨ç‡ã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="launch_"&gt;&lt;strong&gt;launch_bounds&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;launch_bounds&lt;/strong&gt; æ˜¯ CUDA ç¼–ç¨‹ä¸­çš„æ ¸å¿ƒä¿®é¥°ç¬¦ï¼Œç”¨äºä¼˜åŒ–å†…æ ¸ï¼ˆKernelï¼‰åœ¨ GPU ä¸Šçš„æ‰§è¡Œæ•ˆç‡ï¼Œé€šè¿‡æ§åˆ¶èµ„æºåˆ†é…å’Œçº¿ç¨‹è°ƒåº¦æ¥æå‡æ€§èƒ½ã€‚å…¶ä¸»è¦ä½œç”¨å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;h3 id="-èµ„æºä¼˜åŒ–é™åˆ¶å¯„å­˜å™¨ä¸å…±äº«å†…å­˜ä½¿ç”¨"&gt;âš™ï¸ èµ„æºä¼˜åŒ–ï¼šé™åˆ¶å¯„å­˜å™¨ä¸å…±äº«å†…å­˜ä½¿ç”¨
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é¿å…å¯„å­˜å™¨æº¢å‡ºï¼ˆRegister Spillingï¼‰&lt;/strong&gt; é€šè¿‡ maxThreadsPerBlock æŒ‡å®šçº¿ç¨‹å—çš„æœ€å¤§çº¿ç¨‹æ•°ï¼Œç¼–è¯‘å™¨ä¼šæ®æ­¤è®¡ç®—å¯„å­˜å™¨ä½¿ç”¨ä¸Šé™ Lã€‚è‹¥å†…æ ¸åˆå§‹å¯„å­˜å™¨éœ€æ±‚è¶…è¿‡ Lï¼Œç¼–è¯‘å™¨ä¼šä¸»åŠ¨å‡å°‘å¯„å­˜å™¨ç”¨é‡ï¼ˆå¯èƒ½å¢åŠ æœ¬åœ°å†…å­˜è®¿é—®æˆ–æŒ‡ä»¤æ•°ï¼‰ï¼Œé˜²æ­¢æº¢å‡ºåˆ°ä½é€Ÿæ˜¾å­˜ã€‚
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;ç¤ºä¾‹&lt;/em&gt;ï¼šè‹¥æŒ‡å®š &lt;strong&gt;launch_bounds&lt;/strong&gt;(256)ï¼Œç¼–è¯‘å™¨ç¡®ä¿æ¯ä¸ªçº¿ç¨‹å¯„å­˜å™¨ç”¨é‡ä¸è¶…è¿‡ç¡¬ä»¶é™åˆ¶ï¼ˆå¦‚ Fermi æ¶æ„å•çº¿ç¨‹æœ€å¤š 63 å¯„å­˜å™¨ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…±äº«å†…å­˜äº‰ç”¨æ§åˆ¶&lt;/strong&gt; ç»“åˆçº¿ç¨‹å—å¤§å°é™åˆ¶ï¼Œå¯é¿å…å› å…±äº«å†…å­˜è¶…é¢åˆ†é…å¯¼è‡´ SM ä¸Šæ´»è·ƒçº¿ç¨‹å—å‡å°‘ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€§èƒ½æå‡æœ€å¤§åŒ–-sm-åˆ©ç”¨ç‡"&gt;ğŸš€ æ€§èƒ½æå‡ï¼šæœ€å¤§åŒ– SM åˆ©ç”¨ç‡
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¿éšœæœ€å°å¸¸é©»å—æ•°&lt;/strong&gt; é€šè¿‡ minBlocksPerMultiprocessor æŒ‡å®šæ¯ä¸ª SM éœ€é©»ç•™çš„æœ€å°çº¿ç¨‹å—æ•°ï¼Œç¡®ä¿è¶³å¤Ÿå¤šçš„çº¿ç¨‹å—å¹¶è¡Œæ‰§è¡Œï¼Œéšè—æŒ‡ä»¤ä¸å†…å­˜å»¶è¿Ÿã€‚
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;æ•ˆæœ&lt;/em&gt;ï¼šè‹¥ SM æœ‰ 48KB å…±äº«å†…å­˜ï¼Œæ¯ä¸ªå—éœ€ 16KBï¼Œåˆ™ minBlocksPerMultiprocessor=3 å¼ºåˆ¶ç¼–è¯‘å™¨ä¼˜åŒ–è‡³è‡³å°‘ 3 ä¸ªå—/SMï¼ˆè€Œéé»˜è®¤ 2 ä¸ªï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¹³è¡¡æŒ‡ä»¤ä¸å¯„å­˜å™¨&lt;/strong&gt; å½“å¯„å­˜å™¨åˆå§‹ç”¨é‡ä½äº L æ—¶ï¼Œç¼–è¯‘å™¨å¯èƒ½ä¸»åŠ¨ &lt;strong&gt;å¢åŠ å¯„å­˜å™¨ç”¨é‡&lt;/strong&gt; è‡³ Lï¼Œå‡å°‘æŒ‡ä»¤æ•°å¹¶ä¼˜åŒ–å•çº¿ç¨‹å»¶è¿Ÿï¼ˆå°¤å…¶åŒæ—¶æŒ‡å®š maxThreadsPerBlock å’Œ minBlocksPerMultiprocessor æ—¶ï¼‰ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-è§„é¿è¿è¡Œæ—¶é”™è¯¯"&gt;âš ï¸ è§„é¿è¿è¡Œæ—¶é”™è¯¯
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¼ºåˆ¶çº¿ç¨‹å—è§„æ¨¡é™åˆ¶&lt;/strong&gt; å†…æ ¸è‹¥ä»¥è¶…è¿‡ maxThreadsPerBlock çš„çº¿ç¨‹æ•°å¯åŠ¨ï¼Œå°†ç›´æ¥å¤±è´¥ï¼ˆé¿å…èµ„æºè¶…é™å¯¼è‡´çš„æœªå®šä¹‰è¡Œä¸ºï¼‰ã€‚
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;é”™è¯¯ç¤ºä¾‹&lt;/em&gt;ï¼šæŒ‡å®š maxThreadsPerBlock=128 å´ä»¥ &amp;laquo;&amp;lt;&amp;hellip;, 256&amp;raquo;&amp;gt; å¯åŠ¨ â†’ å†…æ ¸å´©æºƒã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœªæ¥ç¡¬ä»¶å…¼å®¹æ€§&lt;/strong&gt; æ˜¾å¼å£°æ˜çº¿ç¨‹å—ä¸Šé™å¯ç¡®ä¿ä»£ç åœ¨æ–°å‹ GPU ä¸Šä»èƒ½è¿è¡Œï¼ˆå¦‚ Ampere çš„ SM èµ„æºåˆ†é…ç­–ç•¥å˜åŒ–ï¼‰ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ä½¿ç”¨ç¤ºä¾‹ä¸æŠ€å·§"&gt;ğŸ› ï¸ ä½¿ç”¨ç¤ºä¾‹ä¸æŠ€å·§
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;ğŸ”§ åŸºæœ¬è¯­æ³•&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__launch_bounds__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxThreadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;minBlocksPerMultiprocessor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="cm"&gt;/*å‚æ•°*/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// å†…æ ¸ä»£ç 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å‚æ•°è¯´æ˜&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;maxThreadsPerBlockï¼šçº¿ç¨‹å—æœ€å¤§çº¿ç¨‹æ•°ï¼ˆå¿…é€‰ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;minBlocksPerMultiprocessorï¼šSM æœ€å°å¸¸é©»å—æ•°ï¼ˆå¯é€‰ï¼‰ã€‚
â €&lt;strong&gt;ğŸŒ æ¶æ„é€‚é…æ–¹æ¡ˆ&lt;/strong&gt;
ä¸åŒ GPU æ¶æ„éœ€ä¸åŒä¼˜åŒ–å‚æ•°ï¼Œå¯é€šè¿‡ &lt;strong&gt;CUDA_ARCH&lt;/strong&gt; åŠ¨æ€è°ƒæ•´ï¼š&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#define THREADS_PER_BLOCK 256
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#if __CUDA_ARCH__ &amp;gt;= 200 &lt;/span&gt;&lt;span class="c1"&gt;// Ampere+ æ¶æ„
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MAX_THREADS (2 * THREADS_PER_BLOCK)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MIN_BLOCKS 3
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#else &lt;/span&gt;&lt;span class="c1"&gt;// æ—§æ¶æ„
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MAX_THREADS THREADS_PER_BLOCK
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="cp"&gt;#define MY_KERNEL_MIN_BLOCKS 2
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#endif
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__launch_bounds__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MY_KERNEL_MAX_THREADS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MY_KERNEL_MIN_BLOCKS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;ğŸ“Š è°ƒè¯•ä¸éªŒè¯&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯„å­˜å™¨ç”¨é‡&lt;/strong&gt; ï¼šç¼–è¯‘æ—¶æ·»åŠ  &amp;ndash;ptxas-options=-v æŸ¥çœ‹å®é™…å¯„å­˜å™¨åˆ†é…ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SM å ç”¨ç‡&lt;/strong&gt; ï¼šä½¿ç”¨ NVIDIA Profiler åˆ†æå¸¸é©»å—æ•°é‡ä¸æ‰§è¡Œæ•ˆç‡ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€»ç»“-4"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;launch_bounds&lt;/strong&gt; çš„æ ¸å¿ƒä»·å€¼æ˜¯é€šè¿‡ &lt;strong&gt;èµ„æºçº¦æŸ+æ‰§è¡Œä¿éšœ&lt;/strong&gt; æå‡å†…æ ¸æ€§èƒ½ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;èµ„æºä¼˜åŒ–&lt;/strong&gt; ï¼šé¿å…å¯„å­˜å™¨/å…±äº«å†…å­˜æº¢å‡ºï¼Œå‡å°‘ä½é€Ÿå†…å­˜è®¿é—®ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;å¹¶è¡Œåº¦ä¿éšœ&lt;/strong&gt; ï¼šå¼ºåˆ¶æœ€å°å¸¸é©»å—æ•°ï¼Œæœ€å¤§åŒ– SM åˆ©ç”¨ç‡ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;é”™è¯¯é¢„é˜²&lt;/strong&gt; ï¼šæ˜¾å¼å£°æ˜çº¿ç¨‹å—é™åˆ¶ï¼Œå¢å¼ºä»£ç å¥å£®æ€§ã€‚
â €âš ï¸ &lt;strong&gt;æ³¨æ„&lt;/strong&gt; ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¿‡å°çš„ maxThreadsPerBlock æˆ–è¿‡é«˜çš„ minBlocksPerMultiprocessor å¯èƒ½å¯¼è‡´å¯„å­˜å™¨å‹ç¼©è¿‡åº¦ï¼Œåå¢æŒ‡ä»¤å¼€é”€ã€‚&lt;/li&gt;
&lt;li&gt;ä¼˜å…ˆé€šè¿‡æ€§èƒ½åˆ†æï¼ˆå¦‚ nvprofï¼‰ç¡®å®šæœ€ä½³å‚æ•°ï¼Œè€Œéç›²ç›®è®¾ç½®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cudamallochost"&gt;cudaMallocHost
&lt;/h2&gt;&lt;p&gt;cudaMallocHost æ˜¯ NVIDIA CUDA ç¼–ç¨‹ä¸­ç”¨äºåœ¨&lt;strong&gt;ä¸»æœºï¼ˆCPUï¼‰ä¸Šåˆ†é…é¡µé”å®šå†…å­˜ï¼ˆPinned Memoryï¼‰&lt;/strong&gt; çš„æ ¸å¿ƒå‡½æ•°ã€‚å…¶æ ¸å¿ƒä½œç”¨æ˜¯æå‡ä¸»æœºä¸è®¾å¤‡ï¼ˆGPUï¼‰é—´æ•°æ®ä¼ è¾“æ•ˆç‡ï¼Œå‡å°‘å†…å­˜å¤åˆ¶å¼€é”€ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†è§£æï¼š&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒåŠŸèƒ½ä¸åŸç†"&gt;ğŸ”§ æ ¸å¿ƒåŠŸèƒ½ä¸åŸç†
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;é¡µé”å®šå†…å­˜ï¼ˆPinned Memoryï¼‰&lt;/strong&gt;
* &lt;strong&gt;å®šä¹‰&lt;/strong&gt; ï¼šé€šè¿‡ cudaMallocHost åˆ†é…çš„å†…å­˜ç”±æ“ä½œç³»ç»Ÿå›ºå®šï¼ˆé”å®šï¼‰åœ¨ç‰©ç†åœ°å€ï¼Œ &lt;strong&gt;ä¸å¯è¢«æ¢å‡ºåˆ°ç£ç›˜&lt;/strong&gt;ï¼Œç¡®ä¿ç‰©ç†åœ°å€å§‹ç»ˆæœ‰æ•ˆã€‚
* &lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt; ï¼š
* &lt;strong&gt;é¿å…é¢å¤–æ‹·è´&lt;/strong&gt; ï¼šä¼ ç»Ÿå¯åˆ†é¡µå†…å­˜ï¼ˆPageable Memoryï¼‰éœ€å…ˆæ‹·è´åˆ°ä¸´æ—¶é¡µé”å®šç¼“å†²åŒºï¼Œå†ä¼ è¾“è‡³è®¾å¤‡ï¼›è€Œ cudaMallocHost åˆ†é…çš„å†…å­˜å¯ç›´æ¥ä¸è®¾å¤‡äº¤äº’ã€‚
* &lt;strong&gt;å¸¦å®½æå‡&lt;/strong&gt; ï¼šå‡å°‘ä¸€æ¬¡ä¸»æœºå†…å­˜æ‹·è´ï¼Œæ˜¾è‘—æå‡ PCIe ä¼ è¾“æ•ˆç‡ï¼ˆå®æµ‹å¸¦å®½å¯æå‡ 50% ä»¥ä¸Šï¼‰ã€‚
* &lt;strong&gt;æ”¯æŒå¼‚æ­¥ä¼ è¾“&lt;/strong&gt; ï¼šå¯ä¸ cudaMemcpyAsync ç»“åˆï¼Œå®ç°æ•°æ®ä¼ è¾“ä¸è®¡ç®—é‡å ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;å‡½æ•°åŸå‹&lt;/strong&gt; cudaError_t cudaMallocHost(void **ptr, size_t size);
* ptrï¼šæŒ‡å‘åˆ†é…å†…å­˜åœ°å€çš„æŒ‡é’ˆã€‚
* sizeï¼šéœ€åˆ†é…çš„å­—èŠ‚æ•°ã€‚
* &lt;strong&gt;è¿”å›å€¼&lt;/strong&gt; ï¼šcudaSuccess è¡¨ç¤ºæˆåŠŸï¼Œå¦åˆ™è¿”å›é”™è¯¯ç ï¼ˆå¦‚ cudaErrorMemoryAllocationï¼‰ã€‚
â €&lt;/p&gt;
&lt;h3 id="-é€‚ç”¨åœºæ™¯"&gt;âš¡ é€‚ç”¨åœºæ™¯
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;é«˜é¢‘ä¸»æœº-è®¾å¤‡æ•°æ®ä¼ è¾“&lt;/strong&gt;
* éœ€é¢‘ç¹æ‹·è´å¤§æ•°æ®ï¼ˆå¦‚å›¾åƒå¤„ç†ã€ç§‘å­¦è®¡ç®—ï¼‰ï¼Œé¡µé”å®šå†…å­˜å‡å°‘ä¼ è¾“å»¶è¿Ÿã€‚
* &lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt; ï¼šfloat &lt;em&gt;h_pinned;
* cudaMallocHost((void&lt;/em&gt;*)&amp;amp;h_pinned, size); // åˆ†é…é¡µé”å®šå†…å­˜
* cudaMemcpyAsync(d_data, h_pinned, size, cudaMemcpyHostToDevice, stream); // å¼‚æ­¥ä¼ è¾“
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;é›¶æ‹·è´å†…å­˜ï¼ˆUnified Memory å‰èº«ï¼‰&lt;/strong&gt;
* é€šè¿‡ cudaHostAlloc çš„ cudaHostAllocMapped æ ‡å¿—ï¼Œå¯åˆ›å»ºä¸»æœºä¸è®¾å¤‡å…±äº«çš„é›¶æ‹·è´å†…å­˜ï¼ŒGPU ç›´æ¥è®¿é—®ä¸»æœºå†…å­˜ï¼ˆéœ€ UVA æ”¯æŒï¼‰ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;GPU ç›´æ¥è®¿é—®ä¸»æœºæ•°æ®&lt;/strong&gt;
* ç»“åˆ cudaHostGetDevicePointer è·å–è®¾å¤‡ç«¯æŒ‡é’ˆï¼Œå®ç° GPU å†…æ ¸ç›´æ¥è¯»å†™ä¸»æœºå†…å­˜ï¼ˆé¿å…æ˜¾å¼æ‹·è´ï¼‰ã€‚
â €&lt;/p&gt;
&lt;h3 id="-æ³¨æ„äº‹é¡¹ä¸é™åˆ¶"&gt;âš ï¸ æ³¨æ„äº‹é¡¹ä¸é™åˆ¶
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;èµ„æºæ¶ˆè€—&lt;/strong&gt;
* é¡µé”å®šå†…å­˜å ç”¨ç‰©ç†å†…å­˜ä¸”ä¸å¯äº¤æ¢ï¼Œè¿‡é‡åˆ†é…å¯èƒ½å¯¼è‡´ç³»ç»Ÿå†…å­˜ç¢ç‰‡æˆ–è€—å°½ã€‚
* &lt;strong&gt;å»ºè®®&lt;/strong&gt; ï¼šä»…å¯¹é«˜é¢‘ä¼ è¾“æ•°æ®ä½¿ç”¨ï¼Œé‡Šæ”¾éœ€è°ƒç”¨ cudaFreeHostï¼ˆé freeï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;é”™è¯¯å¤„ç†&lt;/strong&gt; cudaError_t err = cudaMallocHost(&amp;amp;h_ptr, size);
3 if (err != cudaSuccess) {
4 printf(&amp;ldquo;Error: %s\n&amp;rdquo;, cudaGetErrorString(err));
5 }
&lt;strong&gt;6&lt;/strong&gt; &lt;strong&gt;ä¸å¯åˆ†é¡µå†…å­˜å¯¹æ¯”&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;7&lt;/strong&gt; &lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;8&lt;/strong&gt; &lt;strong&gt;å¯åˆ†é¡µå†…å­˜&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;9&lt;/strong&gt; &lt;strong&gt;é¡µé”å®šå†…å­˜&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;10&lt;/strong&gt; &lt;strong&gt;åˆ†é…å‡½æ•°&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;11 malloc / new&lt;/td&gt;
&lt;td style="text-align: center"&gt;12 cudaMallocHost&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;13&lt;/strong&gt; &lt;strong&gt;ä¼ è¾“è·¯å¾„&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;14 ä¸»æœºâ†’ä¸´æ—¶ç¼“å†²åŒºâ†’è®¾å¤‡&lt;/td&gt;
&lt;td style="text-align: center"&gt;15 ä¸»æœºâ†’è®¾å¤‡ï¼ˆç›´æ¥ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;16&lt;/strong&gt; &lt;strong&gt;å¸¦å®½æ•ˆç‡&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;17 ä½ï¼ˆå¤šä¸€æ¬¡æ‹·è´ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;18 é«˜ï¼ˆèŠ‚çœ 30%~50% æ—¶é—´ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;19&lt;/strong&gt; &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;20 ä½é¢‘å°æ•°æ®&lt;/td&gt;
&lt;td style="text-align: center"&gt;21 é«˜é¢‘å¤§æ•°æ®ä¼ è¾“&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;22&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;â €&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-ä»£ç ç¤ºä¾‹-1"&gt;ğŸ’» ä»£ç ç¤ºä¾‹
&lt;/h3&gt;&lt;p&gt;#include &amp;lt;cuda_runtime.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;&lt;/p&gt;
&lt;p&gt;int main() {
const size_t N = 1024 * 1024;
float &lt;em&gt;h_pinned, &lt;em&gt;d_data;
// åˆ†é…é¡µé”å®šå†…å­˜
cudaMallocHost((void&lt;/em&gt;&lt;/em&gt;)&amp;amp;h_pinned, N * sizeof(float));
// åˆ†é…è®¾å¤‡å†…å­˜
cudaMalloc(&amp;amp;d_data, N * sizeof(float));
// åˆå§‹åŒ–ä¸»æœºæ•°æ®
for (int i = 0; i &amp;lt; N; i++) h_pinned[i] = i;
// ä¸»æœºâ†’è®¾å¤‡ä¼ è¾“
cudaMemcpy(d_data, h_pinned, N * sizeof(float), cudaMemcpyHostToDevice);
// é‡Šæ”¾èµ„æº
cudaFree(d_data);
cudaFreeHost(h_pinned);
return 0;
}&lt;/p&gt;
&lt;h3 id="-æ€»ç»“-5"&gt;âœ… æ€»ç»“
&lt;/h3&gt;&lt;p&gt;cudaMallocHost çš„æ ¸å¿ƒä»·å€¼åœ¨äºï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;é«˜æ€§èƒ½ä¼ è¾“&lt;/strong&gt; ï¼šé€šè¿‡ç‰©ç†åœ°å€å›ºå®šï¼Œå®ç°ä¸»æœº-è®¾å¤‡é—´&lt;strong&gt;ç›´æ¥æ•°æ®ä¼ è¾“&lt;/strong&gt;ï¼Œé¿å…ä¸­é—´æ‹·è´ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;å¼‚æ­¥æ”¯æŒ&lt;/strong&gt; ï¼šä¸ cudaStream ç»“åˆï¼Œ &lt;strong&gt;é‡å è®¡ç®—ä¸æ•°æ®ä¼ è¾“&lt;/strong&gt;ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;é€‚ç”¨æ€§å¹¿&lt;/strong&gt; ï¼šé€‚ç”¨äºéœ€é«˜é¢‘äº¤äº’çš„åœºæ™¯ï¼ˆå¦‚æ·±åº¦å­¦ä¹ è®­ç»ƒã€å®æ—¶å›¾åƒå¤„ç†ï¼‰ï¼Œä½†éœ€æ³¨æ„å†…å­˜åˆ†é…å¹³è¡¡ã€‚
â €âš ï¸ æ³¨ï¼šCUDA 6.0 åæ¨å‡ºçš„&lt;strong&gt;ç»Ÿä¸€å†…å­˜ï¼ˆUnified Memoryï¼‰&lt;/strong&gt; å¯è¿›ä¸€æ­¥ç®€åŒ–ç¼–ç¨‹ï¼ˆè‡ªåŠ¨è¿ç§»æ•°æ®ï¼‰ï¼Œä½† cudaMallocHost åœ¨ç²¾ç»†æ§åˆ¶åœºæ™¯ä»ä¸å¯æ›¿ä»£ã€‚&lt;/p&gt;
&lt;h2 id="gpu-å…±äº«"&gt;GPU å…±äº«
&lt;/h2&gt;&lt;p&gt;ä¸åŒç¨‹åºåœ¨GPUä¸Šçš„å¹¶è¡Œæ‰§è¡Œèƒ½åŠ›å–å†³äºGPUç¡¬ä»¶æ¶æ„ã€æ“ä½œç³»ç»Ÿè°ƒåº¦ç­–ç•¥åŠå…·ä½“å®ç°æŠ€æœ¯ã€‚ä»¥ä¸‹æ˜¯å…³é”®æœºåˆ¶åˆ†æï¼š&lt;/p&gt;
&lt;h3 id="-ç¡¬ä»¶æ¶æ„ä¸è°ƒåº¦æœºåˆ¶"&gt;âš™ï¸ ç¡¬ä»¶æ¶æ„ä¸è°ƒåº¦æœºåˆ¶
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;GPUæ ¸å¿ƒè®¾è®¡&lt;/strong&gt; GPUæ‹¥æœ‰æ•°åƒä¸ªå°å‹è®¡ç®—æ ¸å¿ƒï¼ˆå¦‚NVIDIAçš„CUDAæ ¸å¿ƒï¼‰ï¼Œç†è®ºä¸Šæ”¯æŒå¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—ã€‚ä½†è¿™äº›æ ¸å¿ƒç”±ç»Ÿä¸€è°ƒåº¦å™¨ç®¡ç†ï¼Œ &lt;strong&gt;å•ä¸ªç¨‹åºå¯ç‹¬å æ‰€æœ‰æ ¸å¿ƒå¹¶è¡Œå¤„ç†æ•°æ®&lt;/strong&gt; ï¼ˆå¦‚çŸ©é˜µè¿ç®—ï¼‰ã€‚&lt;strong&gt;ä¸åŒç¨‹åºä¹‹é—´&lt;/strong&gt;æ— æ³•ç›´æ¥å…±äº«æ ¸å¿ƒï¼Œéœ€é€šè¿‡ç³»ç»Ÿçº§è°ƒåº¦åˆ†é…èµ„æºã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ—¶é—´ç‰‡è½®è½¬ï¼ˆTime-Slicingï¼‰&lt;/strong&gt; é»˜è®¤æƒ…å†µä¸‹ï¼ŒGPUé€šè¿‡&lt;strong&gt;æ—¶åˆ†å¤ç”¨&lt;/strong&gt;å®ç°å¤šç¨‹åºâ€œå¹¶å‘â€ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ¯ä¸ªç¨‹åºåˆ†é…å›ºå®šæ—¶é—´ç‰‡ï¼ˆå¦‚æ¯«ç§’çº§ï¼‰ï¼Œè½®æµä½¿ç”¨GPUè®¡ç®—èµ„æºã€‚&lt;/li&gt;
&lt;li&gt;ä¸Šä¸‹æ–‡åˆ‡æ¢æ¶‰åŠçŠ¶æ€ä¿å­˜/æ¢å¤ï¼Œå¯èƒ½äº§ç”Ÿ10%~20%æ€§èƒ½å¼€é”€ã€‚&lt;em&gt;ç¤ºä¾‹&lt;/em&gt;ï¼šç¨‹åºAè¿è¡Œ2msåæš‚åœï¼Œç¨‹åºBè¿è¡Œ2msï¼Œå¾ªç¯äº¤æ›¿ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;ç©ºé—´åˆ†åŒºï¼ˆMPS/MIGï¼‰&lt;/strong&gt; é«˜ç«¯GPUæ”¯æŒç‰©ç†èµ„æºåˆ†å‰²ï¼š&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¤šè¿›ç¨‹æœåŠ¡ï¼ˆMPSï¼‰&lt;/strong&gt; ï¼šå…è®¸å¤šè¿›ç¨‹å…±äº«GPUï¼Œä½†ä»ä¾èµ–æ—¶é—´ç‰‡è°ƒåº¦ï¼Œé€‚åˆè½»é‡çº§ä»»åŠ¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¤šå®ä¾‹GPUï¼ˆMIGï¼‰&lt;/strong&gt; ï¼šå°†GPUç¡¬ä»¶åˆ†å‰²ä¸ºç‹¬ç«‹å®ä¾‹ï¼ˆå¦‚NVIDIA A100å¯æ‹†7ä¸ªå®ä¾‹ï¼‰ï¼Œ &lt;strong&gt;æ¯ä¸ªå®ä¾‹å¯ç‹¬ç«‹è¿è¡Œä¸åŒç¨‹åºï¼Œå®ç°çœŸæ­£å¹¶è¡Œ&lt;/strong&gt;ï¼Œä½†èµ„æºåˆ†é…å›ºå®šã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-å®ç°å¹¶è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆ"&gt;â €ğŸ”§ å®ç°å¹¶è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆ
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æŠ€æœ¯&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;åŸç†&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;é™åˆ¶&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Time-Slicing&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ“ä½œç³»ç»Ÿè‡ªåŠ¨åˆ†é…æ—¶é—´ç‰‡&lt;/td&gt;
&lt;td style="text-align: center"&gt;é€šç”¨ç¨‹åºï¼Œæ— ç‰¹æ®Šé…ç½®éœ€æ±‚&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸Šä¸‹æ–‡åˆ‡æ¢å»¶è¿Ÿï¼Œæ€§èƒ½æ³¢åŠ¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;MPS&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;è¿›ç¨‹çº§å…±äº«SMèµ„æº&lt;/td&gt;
&lt;td style="text-align: center"&gt;è½»é‡çº§å¤šä»»åŠ¡ï¼ˆå¦‚æ¨ç†æœåŠ¡ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;å…¼å®¹æ€§é—®é¢˜ï¼Œèµ„æºç«äº‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;MIG&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç‰©ç†åˆ†å‰²GPUä¸ºç‹¬ç«‹å®ä¾‹&lt;/td&gt;
&lt;td style="text-align: center"&gt;å…³é”®ä»»åŠ¡éœ€å¼ºéš”ç¦»ï¼ˆå¦‚äº‘æœåŠ¡ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä»…æ”¯æŒç‰¹å®šæ¶æ„ï¼ˆAmpere+ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-å…³é”®æ€§èƒ½å½±å“å› ç´ "&gt;âš ï¸ å…³é”®æ€§èƒ½å½±å“å› ç´ 
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;èµ„æºäº‰ç”¨&lt;/strong&gt;
* &lt;strong&gt;æ˜¾å­˜ç“¶é¢ˆ&lt;/strong&gt; ï¼šå¤šç¨‹åºå…±äº«æ˜¾å­˜å¸¦å®½ï¼Œé¢‘ç¹æ•°æ®äº¤æ¢å¯èƒ½é™ä½æ•ˆç‡ã€‚
* &lt;strong&gt;è®¡ç®—å†²çª&lt;/strong&gt; ï¼šé«˜ä¼˜å…ˆçº§ä»»åŠ¡å¯èƒ½æŠ¢å èµ„æºï¼ˆå¦‚å®æ—¶æ¨ç†ä¸­æ–­è®­ç»ƒä»»åŠ¡ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;é€šä¿¡å¼€é”€&lt;/strong&gt; è·¨GPUæˆ–CPU-GPUæ•°æ®ä¼ è¾“ï¼ˆå¦‚PCIeæ€»çº¿ï¼‰å¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œå°¤å…¶å¤šç¨‹åºé¢‘ç¹äº¤æ¢æ•°æ®æ—¶ã€‚&lt;/p&gt;
&lt;h3 id="-æœ€ä½³å®è·µå»ºè®®"&gt;ğŸ’¡ æœ€ä½³å®è·µå»ºè®®
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‹¬ç«‹GPUå®ä¾‹&lt;/strong&gt; ï¼šå¯¹å»¶è¿Ÿæ•æ„Ÿå‹ç¨‹åºï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨MIGç‰©ç†éš”ç¦»ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å®¹å™¨åŒ–éƒ¨ç½²&lt;/strong&gt; ï¼šé€šè¿‡Kubernetesè®¾å¤‡æ’ä»¶ç®¡ç†GPUèµ„æºï¼Œè‡ªåŠ¨è°ƒåº¦Time-Slicingã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ··åˆå¹¶è¡Œç­–ç•¥&lt;/strong&gt; ï¼šç»“åˆæ•°æ®å¹¶è¡Œï¼ˆå•ç¨‹åºå¤šGPUï¼‰ä¸æ¨¡å‹å¹¶è¡Œï¼ˆå¤§æ¨¡å‹æ‹†åˆ†ï¼‰ï¼Œæœ€å¤§åŒ–åˆ©ç”¨ç‡ã€‚
â €ğŸ“Œ &lt;strong&gt;æ€»ç»“&lt;/strong&gt; ï¼šä¸åŒç¨‹åºå¯é€šè¿‡æ—¶é—´ç‰‡è½®è½¬å®ç°&lt;strong&gt;é€»è¾‘å¹¶è¡Œ&lt;/strong&gt;ï¼Œä½†å—é™äºè°ƒåº¦å¼€é”€ï¼›ç‰©ç†å¹¶è¡Œéœ€ä¾èµ–MIGç­‰é«˜çº§æŠ€æœ¯ã€‚ä¼˜åŒ–æ–¹å‘éœ€å¹³è¡¡èµ„æºéš”ç¦»éœ€æ±‚ä¸ç³»ç»Ÿåˆ©ç”¨ç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="å¤šè®¾å¤‡kernel"&gt;å¤šè®¾å¤‡Kernel
&lt;/h2&gt;&lt;p&gt;ä»CUDAç¼–ç¨‹æ¨¡å‹çš„è§’åº¦æ¥çœ‹ï¼Œ &lt;strong&gt;ä¸€ä¸ªCUDA Kernelçš„å•ä¸ªå¯åŠ¨è°ƒç”¨ï¼ˆé€šè¿‡&lt;/strong&gt;&amp;laquo;&amp;lt;&amp;raquo;&amp;gt;&lt;strong&gt;è¯­æ³•å¯åŠ¨çš„é‚£ä¸ªå®ä¾‹ï¼‰æœ¬èº«ä¸èƒ½åŒæ—¶åœ¨å¤šä¸ªç‰©ç†è®¾å¤‡ä¸Šæ‰§è¡Œã€‚&lt;/strong&gt; CUDAçš„è®¾è®¡æ ¸å¿ƒæ€æƒ³æ˜¯å•ä¸ªKernelå¯åŠ¨é’ˆå¯¹å•ä¸ªDeviceè¿›è¡Œä¼˜åŒ–è°ƒåº¦ã€‚
ä»¥ä¸‹æ˜¯å…³é”®è¦ç‚¹å’ŒåŸå› ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;è®¾å¤‡é€‰æ‹© (&lt;strong&gt;cudaSetDevice&lt;/strong&gt;)&lt;/strong&gt; :
åœ¨æ‰§è¡ŒKernelä¹‹å‰ï¼Œä½ å¿…é¡»åœ¨ä½ çš„ä¸»æœºä»£ç ä¸­æ˜ç¡®è°ƒç”¨cudaSetDevice(device_id)æ¥é€‰æ‹©å¸Œæœ›åœ¨å…¶ä¸Šå¯åŠ¨Kernelçš„GPUè®¾å¤‡ã€‚ä¾‹å¦‚ï¼šcudaSetDevice(0); // é€‰æ‹©ç¬¬ä¸€ä¸ªGPU&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// é€‰æ‹©ç¬¬ä¸€ä¸ªGPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(...);&lt;/span&gt; &lt;span class="c1"&gt;// åœ¨ GPU 0 ä¸Šå¯åŠ¨ kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// é€‰æ‹©ç¬¬äºŒä¸ªGPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(...);&lt;/span&gt; &lt;span class="c1"&gt;// åœ¨ GPU 1 ä¸Šå¯åŠ¨ï¼ˆåŒä¸€ä¸ªkernelçš„å¦ä¸€ä¸ªå®ä¾‹ï¼‰
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ä¸€ä¸ªç‰¹å®šçš„&amp;laquo;&amp;lt;&amp;raquo;&amp;gt;è¯­æ³•å¯åŠ¨çš„Kernelåªä¼šåœ¨å½“å‰è®¾ç½®çš„è®¾å¤‡ä¸Šè¿è¡Œã€‚è¯¥Kernelå†…éƒ¨çš„çº¿ç¨‹å—åªä¼šåœ¨è¿™ä¸ªç‰¹å®šè®¾å¤‡çš„SMä¸Šè°ƒåº¦æ‰§è¡Œã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;Kernelå¯åŠ¨çš„è¯­å¢ƒ&lt;/strong&gt;:
å½“ä½ å†™kernel&amp;laquo;&amp;lt;grid_size, block_size, shared_mem_size, stream&amp;raquo;&amp;gt;(arguments);æ—¶ï¼Œgrid_sizeã€block_sizeã€shared_mem_sizeã€streamä»¥åŠä¼ é€’ç»™Kernelçš„å‚æ•°ï¼Œæ‰€æœ‰è¿™äº›ä¿¡æ¯éƒ½æ˜¯é’ˆå¯¹&lt;strong&gt;å½“å‰&lt;/strong&gt;cudaSetDevice&lt;strong&gt;è®¾ç½®çš„ç‰¹å®šè®¾å¤‡ä¸Šä¸‹æ–‡&lt;/strong&gt;çš„ã€‚å®ƒå®šä¹‰äº†è¿™ä¸ªKernelå®ä¾‹å°†åœ¨å“ªä¸ªè®¾å¤‡çš„èµ„æºä¸Šè¿è¡Œã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;å†…å­˜éš”ç¦»&lt;/strong&gt;:
æ¯ä¸ªè®¾å¤‡ï¼ˆGPUï¼‰æ‹¥æœ‰è‡ªå·±ç‹¬ç«‹çš„å…¨å±€å†…å­˜ã€å¸¸é‡å†…å­˜ã€çº¹ç†å†…å­˜å’Œæœ¬åœ°å†…å­˜ï¼ˆL1/SMEMç­‰ï¼‰ã€‚
å¯åŠ¨ä¸€ä¸ªKerneléœ€è¦å°†å…¶æŒ‡å‘çš„å†…å­˜å‚æ•°ï¼ˆå¦‚è®¾å¤‡æŒ‡é’ˆï¼‰å­˜åœ¨äºåŒä¸€ä¸ªè®¾å¤‡çš„æ˜¾å­˜ä¸­ã€‚ä¸€ä¸ªKernelæ— æ³•ç›´æ¥è®¿é—®å¦ä¸€å°è®¾å¤‡ä¸Šçš„å†…å­˜ï¼ˆé™¤éé€šè¿‡æ˜¾å¼é€šä¿¡å¦‚PCIe P2Pæˆ–NVLinkï¼‰ã€‚
è®©ä¸€ä¸ªKernelâ€œåŒæ—¶â€è¿è¡Œåœ¨è®¾å¤‡Aå’Œè®¾å¤‡Bä¸Šï¼Œæ„å‘³ç€å®ƒéœ€è¦è®¿é—®å¹¶æ“ä½œä¸¤ä¸ªè®¾å¤‡ä¸Šçš„èµ„æºï¼Œè€ŒCUDAçš„åŸºç¡€ç¼–ç¨‹æ¨¡å‹å¹¶æ²¡æœ‰ä¸ºå•ä¸ªKernelå®ä¾‹æä¾›è¿™ç§è·¨è®¾å¤‡çš„é€æ˜å†…å­˜è®¿é—®æœºåˆ¶ã€‚
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;è°ƒåº¦å•å…ƒ&lt;/strong&gt;:
åœ¨CUDAçš„æ‰§è¡Œæ¨¡å‹ä¸­ï¼Œè°ƒåº¦å•å…ƒæ˜¯çº¿ç¨‹å—ã€‚ç¡¬ä»¶è°ƒåº¦å™¨æ ¹æ®è®¾å¤‡èµ„æºï¼ˆå¦‚SMæ•°é‡ã€èµ„æºå¯ç”¨æ€§ï¼‰åœ¨è®¾å¤‡çš„SMä¸Šè°ƒåº¦è¿™äº›çº¿ç¨‹å—ã€‚è°ƒåº¦å™¨æ— æ³•å°†åŒä¸€ä¸ªKernelå¯åŠ¨ä¸­çš„ä¸€ä¸ªçº¿ç¨‹å—åˆ†é…åˆ°å¦ä¸€ä¸ªç‰©ç†è®¾å¤‡ä¸Šå»æ‰§è¡Œã€‚
&lt;strong&gt;é‚£ä¹ˆï¼Œå¦‚ä½•åˆ©ç”¨å¤šä¸ªè®¾å¤‡è¿è¡ŒåŒä¸€ä¸ªKernelå‘¢ï¼Ÿ&lt;/strong&gt;
ç­”æ¡ˆæ˜¯ï¼š &lt;strong&gt;å¤šæ¬¡å¯åŠ¨åŒä¸€ä¸ªKernelå‡½æ•°ï¼Œå¹¶åœ¨æ¯æ¬¡å¯åŠ¨å‰è®¾ç½®ç›®æ ‡è®¾å¤‡ã€‚&lt;/strong&gt; è¿™æ˜¯æœ€ç›´æ¥å’Œæœ€å¸¸ç”¨çš„æ–¹æ³•ã€‚&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// å‡è®¾æœ‰ num_devices ä¸ªå¯ç”¨çš„ GPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_devices&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// è®¾ç½®ç›®æ ‡è®¾å¤‡
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// ä¸ºè¿™ä¸ªè®¾å¤‡åˆ†é…è¾“å…¥/è¾“å‡ºå†…å­˜ï¼ˆé€šå¸¸åœ¨åˆå§‹åŒ–æ—¶å®Œæˆï¼‰
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// ... (e.g., cudaMalloc, cudaMemcpyAsync for this device)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// å¯åŠ¨Kernelåœ¨è¿™ä¸ªè®¾å¤‡ä¸Šæ‰§è¡Œã€‚æ³¨æ„grid/blocké…ç½®ã€streamç­‰å¯ä»¥æŒ‰éœ€è®¾ç½®ï¼Œç”šè‡³ä¸åŒè®¾å¤‡å¯ä»¥ä¸åŒã€‚
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;myKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;gridDim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharedMemSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev_input_ptr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;dev_output_ptr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;...);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// å¯ä»¥åœ¨è¿™ä¸ªè®¾å¤‡çš„æµä¸Šè¿›è¡Œå¼‚æ­¥æ“ä½œ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// åœ¨æ‰€æœ‰è®¾å¤‡ä¸Šå¼‚æ­¥å¯åŠ¨åï¼Œä¸»æœºçº¿ç¨‹å¯ä»¥ç­‰å¾…å®ƒä»¬å®Œæˆ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_devices&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaDeviceSynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// æˆ–ç­‰å¾…è¯¥è®¾å¤‡ä¸Šçš„ç‰¹å®šæµ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å…³é”®ç‚¹ï¼š&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¤šä¸ªå®ä¾‹ï¼š&lt;/strong&gt; è¿™æ ·åšä¼šåœ¨æ¯ä¸ªè®¾å¤‡ä¸Šå¯åŠ¨ä¸€ä¸ª&lt;strong&gt;ç‹¬ç«‹&lt;/strong&gt;çš„Kernelå®ä¾‹ï¼ˆæ‰§è¡Œï¼‰ï¼Œæ¯ä¸ªå®ä¾‹è¿è¡Œåœ¨è‡ªå·±è®¾å¤‡çš„èµ„æºå’Œå†…å­˜ä¸Šã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¹¶è¡Œæ‰§è¡Œï¼š&lt;/strong&gt; åªè¦ç¡¬ä»¶æ”¯æŒï¼ˆå¤šä¸ªPCIeæ ¹èŠ‚ç‚¹/NVSwitchç­‰ï¼‰å¹¶ä¸”ä¸»æœºçº¿ç¨‹ç®¡ç†å¾—å½“ï¼ˆé€šå¸¸ä½¿ç”¨å¼‚æ­¥APIå’Œå¤šä¸ªCUDA Streamï¼‰ï¼Œè¿™äº›åœ¨ä¸åŒè®¾å¤‡ä¸Šå¯åŠ¨çš„Kernelå®ä¾‹å¯ä»¥&lt;strong&gt;å¹¶è¡Œè¿è¡Œ&lt;/strong&gt;ã€‚è¿™æ˜¯å¤šGPU/åˆ†å¸ƒå¼CUDAç¼–ç¨‹çš„æ ¸å¿ƒæ¨¡å¼ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•°æ®åˆ†å‘/å½’çº¦ï¼š&lt;/strong&gt; ä½ éœ€è¦æ‰‹åŠ¨å°†æ•´ä½“ä»»åŠ¡æ•°æ®åˆ†å‰²åˆ°å„ä¸ªè®¾å¤‡ä¸Šï¼ˆä¾‹å¦‚é€šè¿‡device_idç´¢å¼•éƒ¨åˆ†æ•°æ®ï¼‰ï¼Œå¹¶åœ¨æ‰€æœ‰è®¾å¤‡ä¸Šçš„Kernelè¿è¡Œå®Œæ¯•åï¼Œå°†ç»“æœæ”¶é›†ï¼ˆå½’çº¦ï¼‰èµ·æ¥ã€‚è¿™é€šå¸¸éœ€è¦ä½¿ç”¨cudaMemcpyï¼ˆæˆ–æ›´å¥½çš„ï¼ŒcudaMemcpyPeerAsyncç”¨äºP2Pï¼‰å’Œä¸»æœºç«¯çš„åŒæ­¥æ“ä½œã€‚
â €&lt;strong&gt;ç°ä»£é«˜çº§æŠ½è±¡æ¡†æ¶ï¼ˆç®€åŒ–å¤šè®¾å¤‡ç®¡ç†ï¼‰ï¼š&lt;/strong&gt;
æ¡†æ¶å¦‚NCCLï¼ˆç”¨äºé€šä¿¡ï¼‰ã€å¤šè¿›ç¨‹åº“ï¼ˆå¦‚torch.distributed, Horovodï¼‰ä»¥åŠæ›´é«˜å±‚æ¬¡çš„å¼‚æ„ç¼–ç¨‹æ¨¡å‹ï¼ˆå¦‚SYCL, DPC++ï¼‰å°è£…äº†åº•å±‚çš„å¤šè®¾å¤‡é€»è¾‘ï¼š&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è·¨è®¾å¤‡é€šä¿¡ï¼š&lt;/strong&gt; å®ƒä»¬æä¾›é«˜æ•ˆï¼ˆå¦‚åŸºäºNVLink/GPUDirect RDMAï¼‰çš„ç‚¹å¯¹ç‚¹é€šä¿¡ã€å¹¿æ’­ã€è§„çº¦ã€All-Gatherç­‰é›†åˆæ“ä½œåŸè¯­ï¼Œå¤§å¤§ç®€åŒ–äº†å¤šè®¾å¤‡é—´çš„æ•°æ®äº¤æ¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä»»åŠ¡åˆ†å‘ï¼š&lt;/strong&gt; å®ƒä»¬èƒ½è‡ªåŠ¨æˆ–æ›´æ–¹ä¾¿åœ°åœ¨å¤šä¸ªè®¾å¤‡ï¼ˆèŠ‚ç‚¹ï¼‰ä¸Šåˆ›å»ºKernelä»»åŠ¡å®ä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å•ç¨‹åºå¤šæ•°æ® (SPMD)ï¼š&lt;/strong&gt; åœ¨æ·±åº¦å­¦ä¹ ç­‰åœºæ™¯ä¸­ï¼Œæ¨¡å‹å¹¶è¡Œï¼ˆå°†æ¨¡å‹å±‚åˆ†æ•£åˆ°è®¾å¤‡ï¼‰ã€æ•°æ®å¹¶è¡Œï¼ˆå°†æ•°æ®æ‰¹æ¬¡åˆ†æ•£åˆ°è®¾å¤‡ï¼‰é€šå¸¸éƒ½éµå¾ªSPMDæ¨¡å¼ï¼šæ¯ä¸ªè®¾å¤‡ä¸Šçš„è¿›ç¨‹/çº¿ç¨‹è¿è¡Œç›¸åŒçš„ç¨‹åºä»£ç ï¼ˆç›¸åŒçš„Kernelï¼‰ï¼Œä½†å¤„ç†è¾“å…¥æ•°æ®çš„ä¸åŒéƒ¨åˆ†ã€‚
&lt;ul&gt;
&lt;li&gt;åœ¨CUDAå±‚é¢ï¼Œæ¯ä¸ªè®¾å¤‡ä¸Šçš„è¿›ç¨‹/çº¿ç¨‹&lt;strong&gt;å„è‡ªè°ƒç”¨&lt;/strong&gt;cudaSetDevice&lt;strong&gt;ç„¶åå¯åŠ¨æ‰€éœ€çš„Kernel&lt;/strong&gt;ã€‚å¯¹äºæ¡†æ¶çš„ä½¿ç”¨è€…æ¥è¯´ï¼Œæ¡†æ¶çš„APIè°ƒç”¨çœ‹èµ·æ¥åƒæ˜¯â€œä¸€æ¬¡è°ƒç”¨è¿è¡Œåœ¨æ‰€æœ‰è®¾å¤‡ä¸Šâ€ï¼Œä½†åœ¨åº•å±‚æ¡†æ¶å®ç°ä¸­ï¼Œå®ƒä»ç„¶æ˜¯æŒ‰ç…§cudaSetDevice + å¤šæ¬¡Kernelå¯åŠ¨çš„æ¨¡å¼åœ¨å·¥ä½œï¼Œåªä¸è¿‡æ¡†æ¶è‡ªåŠ¨å®Œæˆäº†è®¾å¤‡ç®¡ç†ã€æµç®¡ç†å’Œé€šä¿¡å·¥ä½œã€‚
â €&lt;strong&gt;æ€»ç»“:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ä¸€ä¸ªCUDA Kernelçš„&lt;strong&gt;å•ä¸ªå¯åŠ¨è°ƒç”¨&lt;/strong&gt; (&amp;laquo;&amp;lt;&amp;raquo;&amp;gt;) åªèƒ½åœ¨ä¸€ä¸ªæŒ‡å®šçš„CUDA Deviceä¸Šæ‰§è¡Œã€‚&lt;/li&gt;
&lt;li&gt;ä¸ºäº†è®©åŒä¸€ä¸ªKernelå‡½æ•°è¿è¡Œåœ¨å¤šä¸ªè®¾å¤‡ä¸Šï¼Œä½ éœ€è¦åœ¨ä½ çš„ä¸»æœºç¨‹åºä¸­ï¼š
1 å¤šæ¬¡è°ƒç”¨è¯¥Kernelå‡½æ•°ã€‚
2 åœ¨æ¯æ¬¡è°ƒç”¨å‰ï¼Œä½¿ç”¨cudaSetDevice(device_id)å°†ç›®æ ‡è®¾å¤‡è®¾ç½®ä¸ºæœŸæœ›çš„GPUã€‚
3 ç¡®ä¿æ¯ä¸ªè®¾å¤‡ä¸Šçš„Kernelæ“ä½œçš„æ•°æ®éƒ½åœ¨è¯¥è®¾å¤‡çš„å†…å­˜ä¸­ã€‚
4 ç®¡ç†å¥½å¤šä¸ªè®¾å¤‡ä¹‹é—´çš„é€šä¿¡ï¼ˆåˆ†å‘è¾“å…¥ã€æ”¶é›†è¾“å‡ºã€åŒæ­¥ç»“æœï¼‰ï¼Œè¿™é€šå¸¸éœ€è¦é¢å¤–çš„é€šä¿¡åº“(å¦‚NCCL)æˆ–è€…æ‰‹åŠ¨å®ç°çš„åŒæ­¥/é€šä¿¡ä»£ç ã€‚&lt;/li&gt;
&lt;li&gt;é«˜çº§æ¡†æ¶ï¼ˆå¦‚NCCLé…åˆçš„å¤šè¿›ç¨‹åº“ã€æ·±åº¦å­¦ä¹ æ¡†æ¶çš„åˆ†å¸ƒå¼æ¨¡å—ï¼‰å°è£…äº†è¿™äº›ç»†èŠ‚ï¼Œä½¿å¾—åœ¨å¤šä¸ªè®¾å¤‡/èŠ‚ç‚¹ä¸Šè¿è¡ŒåŒä¸€ä¸ªæ¨¡å‹/ç®—æ³•æ›´åŠ æ–¹ä¾¿ï¼Œä½†å…¶åº•å±‚å®ç°ä»ç„¶ä¾èµ–äºæ¯ä¸ªè®¾å¤‡ä¸Šçš„å¤šæ¬¡ç‹¬ç«‹Kernelå¯åŠ¨å’Œè®¾å¤‡é—´çš„æ˜¾å¼é€šä¿¡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="nvlink"&gt;NVLink
&lt;/h2&gt;&lt;p&gt;NVLinkæ˜¯ç”±NVIDIAå¼€å‘çš„é«˜é€Ÿäº’è¿æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³å¤šGPUç³»ç»ŸåŠGPUä¸CPUé—´é€šä¿¡çš„å¸¦å®½å’Œå»¶è¿Ÿç“¶é¢ˆï¼Œå°¤å…¶é€‚ç”¨äºé«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰å’Œäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰é¢†åŸŸã€‚ä»¥ä¸‹æ˜¯å…¶æ ¸å¿ƒç‰¹æ€§å’ŒæŠ€æœ¯è§£æï¼š&lt;/p&gt;
&lt;h3 id="-æŠ€æœ¯å®šä¹‰ä¸æ ¸å¿ƒç›®æ ‡"&gt;âš™ï¸ æŠ€æœ¯å®šä¹‰ä¸æ ¸å¿ƒç›®æ ‡
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;åŸºæœ¬æ¶æ„&lt;/strong&gt; NVLinké‡‡ç”¨&lt;strong&gt;ç‚¹å¯¹ç‚¹ç›´è¿ç»“æ„&lt;/strong&gt; ï¼ˆPeer-to-Peerï¼‰ï¼Œæ”¯æŒGPU-GPUã€GPU-CPUé—´ç›´æ¥é€šä¿¡ã€‚ä¸ä¼ ç»Ÿçš„æ ‘çŠ¶PCIeæ‹“æ‰‘ä¸åŒï¼ŒNVLinké€šè¿‡ç½‘çŠ¶äº’è”ï¼ˆå¦‚NVSwitchï¼‰å®ç°å¤šè®¾å¤‡é«˜æ•ˆååŒï¼Œé¿å…CPUä¸­è½¬é€ æˆçš„å»¶è¿Ÿã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;è®¾è®¡ç›®æ ‡&lt;/strong&gt; æ›¿ä»£PCIeåœ¨å¤šGPUåœºæ™¯çš„å±€é™æ€§ï¼Œæä¾›æ›´é«˜å¸¦å®½ã€æ›´ä½å»¶è¿Ÿçš„é€šä¿¡é€šé“ï¼Œæ»¡è¶³å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—éœ€æ±‚ï¼ˆå¦‚å¤§æ¨¡å‹è®­ç»ƒã€ç§‘å­¦æ¨¡æ‹Ÿï¼‰ã€‚
â €&lt;/p&gt;
&lt;h3 id="-å…³é”®æ€§èƒ½ä¼˜åŠ¿å¯¹æ¯”pcie"&gt;âš¡ï¸ å…³é”®æ€§èƒ½ä¼˜åŠ¿ï¼ˆå¯¹æ¯”PCIeï¼‰
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç»´åº¦&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;NVLink 4.0&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCIe 5.0 x16&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æå‡å€æ•°&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å¸¦å®½&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;900 GB/sï¼ˆåŒå‘ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;128 GB/sï¼ˆåŒå‘ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;7å€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å»¶è¿Ÿ&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;1.5å¾®ç§’&lt;/td&gt;
&lt;td style="text-align: center"&gt;5-10å¾®ç§’&lt;/td&gt;
&lt;td style="text-align: center"&gt;é™ä½5-10å€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;èƒ½æ•ˆ&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;1.3çš®ç„¦/å­—èŠ‚&lt;/td&gt;
&lt;td style="text-align: center"&gt;6.5çš®ç„¦/å­—èŠ‚&lt;/td&gt;
&lt;td style="text-align: center"&gt;5å€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;æ‰©å±•æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ”¯æŒ8+ GPUå…¨äº’è”&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¤šè®¾å¤‡å…±äº«å¸¦å®½&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ›´ä¼˜æ‹“æ‰‘&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ’¡ &lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt; ï¼šåœ¨è®­ç»ƒ175Bå‚æ•°çš„GPT-3æ¨¡å‹æ—¶ï¼ŒNVLinkä½¿8xA100çš„æ‰©å±•æ•ˆç‡è¾¾92%ï¼Œè€ŒPCIeä»…60%ã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æŠ€æœ¯æ¼”è¿›ä¸æ ¸å¿ƒç‰¹æ€§"&gt;ğŸ”§ æŠ€æœ¯æ¼”è¿›ä¸æ ¸å¿ƒç‰¹æ€§
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ä»£é™…å‡çº§&lt;/strong&gt;
* &lt;strong&gt;NVLink 1.0&lt;/strong&gt; ï¼ˆ2016ï¼‰ï¼šPascalæ¶æ„ï¼Œå•é“¾è·¯20GB/sï¼Œæ€»å¸¦å®½160GB/sï¼ˆTesla P100ï¼‰ã€‚
* &lt;strong&gt;NVLink 4.0&lt;/strong&gt; ï¼ˆ2022ï¼‰ï¼šHopperæ¶æ„ï¼Œå•é“¾è·¯100GB/sï¼Œæ€»å¸¦å®½900GB/sï¼ˆH100ï¼‰ï¼Œæ”¯æŒ1.8TB/sèšåˆå¸¦å®½ã€‚
* &lt;strong&gt;NVLink 5.0&lt;/strong&gt; ï¼ˆ2024ï¼‰ï¼šå¸¦å®½è¾¾1.8TB/sï¼Œè¾ƒå‰ä»£ç¿»å€ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;åˆ›æ–°æŠ€æœ¯&lt;/strong&gt;
* &lt;strong&gt;NVSwitchèŠ¯ç‰‡&lt;/strong&gt; ï¼šå®ç°å¤šGPUå…¨äº’è”æ‹“æ‰‘ï¼ˆå¦‚DGXç³»ç»Ÿä¸­çš„8å¡ç›´è¿ï¼‰ï¼Œæ¶ˆé™¤é€šä¿¡é˜»å¡ã€‚
* &lt;strong&gt;ç¼“å­˜ä¸€è‡´æ€§&lt;/strong&gt; ï¼ˆNVLink 2.0+ï¼‰ï¼šæ”¯æŒCPUä¸GPUå†…å­˜ç»Ÿä¸€å¯»å€ï¼ŒåŸå­æ“ä½œå’Œç›´æ¥åŠ è½½/å­˜å‚¨ã€‚
* &lt;strong&gt;NVLink-C2C&lt;/strong&gt; ï¼šèŠ¯ç‰‡çº§äº’è¿ï¼ˆå¦‚Grace Hopperè¶…çº§èŠ¯ç‰‡ï¼‰ï¼Œèƒ½æ•ˆæ¯”PCIe Gen5é«˜25å€ã€‚
â €&lt;/p&gt;
&lt;h3 id="-åº”ç”¨åœºæ™¯ä¸æ€§èƒ½å½±å“"&gt;ğŸ–¥ï¸ åº”ç”¨åœºæ™¯ä¸æ€§èƒ½å½±å“
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AIè®­ç»ƒ&lt;/strong&gt; ï¼šResNet-50å¤šå¡æ•ˆç‡æå‡è‡³1.8å€ï¼ˆPCIeä¸º1.5å€ï¼‰ï¼›BERT-Largeè®­ç»ƒåŠ é€Ÿ30%ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç§‘å­¦è®¡ç®—&lt;/strong&gt; ï¼šCFDä»¿çœŸä¸­é€šä¿¡æ—¶é—´å æ¯”ä»30%é™è‡³5%ï¼›åˆ†å­åŠ¨åŠ›å­¦è½¯ä»¶AMBERæ€§èƒ½ç¿»å€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¶…ç®—ç³»ç»Ÿ&lt;/strong&gt; ï¼šSummit/Sierraè¶…ç®—é€šè¿‡NVLinkè¿æ¥IBM POWER9 CPUä¸Volta GPUï¼Œå®ç°ç™¾äº¿äº¿æ¬¡è®¡ç®—ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ç¡¬ä»¶æ”¯æŒä¸é™åˆ¶"&gt;âš ï¸ ç¡¬ä»¶æ”¯æŒä¸é™åˆ¶
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ”¯æŒè®¾å¤‡&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;ä¸“ä¸šå¡ï¼šTesla P100/V100/A100/H100ï¼ˆå¸¦å®½80GB/sâ†’900GB/sï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;æ¶ˆè´¹çº§ï¼šRTX 3090æ”¯æŒNVLink 3.0ï¼ˆä½†è¢«è½¯ä»¶é™åˆ¶ï¼‰ï¼ŒRTX 4090ä¸æ”¯æŒã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;éƒ¨ç½²è¦æ±‚&lt;/strong&gt; ï¼šéœ€ä¸“ç”¨ä¸»æ¿ã€NVLinkæ¡¥æ¥å™¨åŠSXMæ¥å£ï¼Œæˆæœ¬é«˜äºPCIeæ–¹æ¡ˆã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€»ç»“-6"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;NVLinké€šè¿‡&lt;strong&gt;è¶…é«˜å¸¦å®½ã€è¶…ä½å»¶è¿Ÿã€ç‚¹å¯¹ç‚¹ç›´è¿&lt;/strong&gt;é‡å¡‘äº†å¤šGPUç³»ç»Ÿçš„é€šä¿¡èŒƒå¼ï¼Œæˆä¸ºAIè¶…ç®—ï¼ˆå¦‚DGXç³»ç»Ÿï¼‰çš„æ ¸å¿ƒåŸºçŸ³ã€‚å°½ç®¡å…¶ç”Ÿæ€ç›®å‰å±€é™äºNVIDIAç¡¬ä»¶ï¼Œä½†åœ¨å¤§æ¨¡å‹è®­ç»ƒå’ŒHPCåœºæ™¯ä¸­ï¼Œæ€§èƒ½ä¼˜åŠ¿è¿œè¶…PCIeï¼Œæ˜¯è¿½æ±‚æè‡´ç®—æ•ˆç”¨æˆ·çš„å¿…é€‰æŠ€æœ¯ã€‚æœªæ¥ï¼Œéšç€C2Cå°è£…å’Œå…‰å­é€šä¿¡æŠ€æœ¯çš„å‘å±•ï¼ŒNVLinkæˆ–å°†è¿›ä¸€æ­¥çªç ´ç‰©ç†é™åˆ¶ã€‚&lt;/p&gt;
&lt;h2 id="nvlink-ç»“æ„"&gt;NVLink ç»“æ„
&lt;/h2&gt;&lt;p&gt;NVLink æ˜¯ä¸€ç§&lt;strong&gt;èåˆç¡¬ä»¶å®ä½“ä¸è½¯ä»¶åè®®çš„ç»¼åˆæŠ€æœ¯ä½“ç³»&lt;/strong&gt;ï¼Œæ—¢åŒ…å«ç‰©ç†ç»“æ„ï¼ˆç¡¬ä»¶ï¼‰ï¼Œä¹Ÿä¾èµ–è½¯ä»¶åè®®å®ç°åŠŸèƒ½è°ƒåº¦ã€‚ä»¥ä¸‹æ˜¯å…·ä½“è§£æï¼š&lt;/p&gt;
&lt;h3 id="-ç‰©ç†ç»“æ„ç¡¬ä»¶å±‚é¢"&gt;âš™ï¸ ç‰©ç†ç»“æ„ï¼ˆç¡¬ä»¶å±‚é¢ï¼‰
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ä¸“ç”¨ç¡¬ä»¶æ¥å£ä¸é“¾è·¯&lt;/strong&gt;
* NVLink çš„ç‰©ç†å±‚ï¼ˆPhysical Layerï¼‰ç”±å¤šç»„å·®åˆ†ä¿¡å·å¯¹ï¼ˆå¦‚8å¯¹å·®åˆ†å¯¹æ„æˆ32æ¡ç‰©ç†çº¿è·¯ï¼‰ç»„æˆï¼Œé‡‡ç”¨ç›´æµè€¦åˆæŠ€æœ¯ï¼Œæ”¯æŒé«˜é€Ÿä¸²è¡Œä¼ è¾“ã€‚
* ä¾‹å¦‚ï¼Œåœ¨ Tesla P100ï¼ˆNVLink 1.0ï¼‰ä¸­ï¼Œæ¯ä¸ª GPU é›†æˆ4æ¡ç‰©ç†é“¾è·¯ï¼Œæ¯æ¡é“¾è·¯æä¾›åŒå‘40 GB/så¸¦å®½ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ¡¥æ¥å™¨ä¸äº¤æ¢èŠ¯ç‰‡&lt;/strong&gt;
* &lt;strong&gt;NVLink æ¡¥æ¥å™¨&lt;/strong&gt; ï¼šç”¨äºè¿æ¥ GPU ä¸ CPU æˆ–å…¶ä»–è®¾å¤‡ï¼Œå¦‚ IBM POWER9 å¤„ç†å™¨é€šè¿‡æ¡¥æ¥å™¨ä¸ GPU ç›´è¿ã€‚
* &lt;strong&gt;NVSwitch&lt;/strong&gt; ï¼šå¤šç«¯å£äº¤æ¢èŠ¯ç‰‡ï¼ˆå¦‚ DGX ç³»ç»Ÿä¸­çš„ NVSwitchï¼‰ï¼Œæ”¯æŒå…¨è¿æ¥æ‹“æ‰‘ã€‚ä¾‹å¦‚ H100 GPU é€šè¿‡18æ¡ NVLink 4.0 é“¾è·¯è¿æ¥ NVSwitchï¼Œæ€»å¸¦å®½è¾¾ 900 GB/sã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;å°è£…çº§é›†æˆï¼ˆNVLink-C2Cï¼‰&lt;/strong&gt;
* åœ¨ Grace Hopper è¶…çº§èŠ¯ç‰‡ä¸­ï¼ŒNVLink-C2C é€šè¿‡å…ˆè¿›å°è£…ï¼ˆå¦‚ç¡…ä¸­ä»‹å±‚ï¼‰å°† CPU å’Œ GPU è£¸ç‰‡ç›´æ¥äº’è¿ï¼Œå¸¦å®½è¾¾ 900 GB/sï¼Œèƒ½æ•ˆæ¯” PCIe é«˜ 25 å€ã€‚
â €&lt;/p&gt;
&lt;h3 id="-è½¯ä»¶åè®®åŠŸèƒ½å®ç°å±‚"&gt;ğŸ’» è½¯ä»¶åè®®ï¼ˆåŠŸèƒ½å®ç°å±‚ï¼‰
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;é€šä¿¡åè®®æ ˆ&lt;/strong&gt;
* NVLink åè®®æ ˆåˆ†ä¸ºä¸‰å±‚ï¼š
* &lt;strong&gt;ç‰©ç†å±‚ï¼ˆPLï¼‰&lt;/strong&gt; ï¼šç®¡ç†ä¿¡å·ä¼ è¾“ä¸ç”µæ°”ç‰¹æ€§ï¼›
* &lt;strong&gt;æ•°æ®é“¾è·¯å±‚ï¼ˆDLï¼‰&lt;/strong&gt; ï¼šè´Ÿè´£é”™è¯¯æ£€æµ‹ï¼ˆ25ä½ CRC æ ¡éªŒï¼‰ã€æµé‡æ§åˆ¶ä¸æ•°æ®åŒ…é‡ä¼ ï¼›
* &lt;strong&gt;ä¼ è¾“å±‚ï¼ˆTLï¼‰&lt;/strong&gt; ï¼šå¤„ç†æ•°æ®åˆ†ç»„ã€è·¯ç”±ä¸ç¼“å­˜ä¸€è‡´æ€§ï¼ˆå¦‚åŸå­æ“ä½œæ”¯æŒï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;è½¯ä»¶é©±åŠ¨ä¸ API&lt;/strong&gt;
* CUDA æä¾› cudaMemcpyPeer ç­‰ APIï¼Œæ”¯æŒ GPU é—´ç›´æ¥å†…å­˜æ‹·è´ï¼›
* NCCLï¼ˆNVIDIA Collective Communications Libraryï¼‰ä¼˜åŒ–å¤š GPU é€šä¿¡ï¼ˆå¦‚ All-Reduce æ“ä½œï¼‰ï¼Œæ˜¾è‘—æå‡åˆ†å¸ƒå¼è®­ç»ƒæ•ˆç‡ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;ç¼“å­˜ä¸€è‡´æ€§åè®®&lt;/strong&gt;
* NVLink 2.0+ é€šè¿‡ç¡¬ä»¶çº§ç¼“å­˜ä¸€è‡´æ€§åè®®ï¼Œå®ç° CPU ä¸ GPU å…±äº«ç»Ÿä¸€å†…å­˜ç©ºé—´ï¼Œå‡å°‘æ•°æ®å¤åˆ¶å¼€é”€ã€‚ä¾‹å¦‚ IBM Power9 å¯ç›´æ¥è®¿é—® GPU æ˜¾å­˜ã€‚
â €&lt;/p&gt;
&lt;h3 id="-ååŒæœºåˆ¶ç¡¬ä»¶ä¸è½¯ä»¶çš„æ·±åº¦è€¦åˆ"&gt;ğŸ”„ ååŒæœºåˆ¶ï¼šç¡¬ä»¶ä¸è½¯ä»¶çš„æ·±åº¦è€¦åˆ
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åŠ¨æ€èµ„æºåˆ†é…&lt;/strong&gt; ï¼šè½¯ä»¶åè®®æ ¹æ®è´Ÿè½½è°ƒæ•´é“¾è·¯ä½¿ç”¨ï¼ˆå¦‚æ†ç»‘å¤šæ¡é“¾è·¯æå‡å¸¦å®½ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é”™è¯¯æ¢å¤&lt;/strong&gt; ï¼šç¡¬ä»¶æ£€æµ‹ä¼ è¾“é”™è¯¯ï¼ˆå¦‚ CRC æ ¡éªŒï¼‰ï¼Œè½¯ä»¶å±‚è§¦å‘æ•°æ®é‡ä¼ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ‹“æ‰‘ç®¡ç†&lt;/strong&gt; ï¼šNVSwitch ç”±è½¯ä»¶é…ç½®è·¯ç”±ç­–ç•¥ï¼Œå®ç° GPU é—´å…¨è¿æ¥é€šä¿¡ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ä¸ä¼ ç»Ÿ-pcie-çš„å¯¹æ¯”"&gt;ğŸ†š ä¸ä¼ ç»Ÿ PCIe çš„å¯¹æ¯”
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;NVLink&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCIe&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ç‰©ç†ç»“æ„&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸“ç”¨å·®åˆ†å¯¹ã€ç›´è¿é“¾è·¯&lt;/td&gt;
&lt;td style="text-align: center"&gt;é€šç”¨ä¸²è¡Œæ€»çº¿&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å¸¦å®½&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;1.8 TB/s (NVLink 5.0)&lt;/td&gt;
&lt;td style="text-align: center"&gt;126 GB/s (PCIe 5.0 x16)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å»¶è¿Ÿ&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¾®ç§’çº§ï¼ˆ1.5 Î¼sï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;5-10 Î¼s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;è½¯ä»¶ä¾èµ–&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å®šåˆ¶åè®®æ ˆ + CUDA/NCCL&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ“ä½œç³»ç»Ÿçº§é©±åŠ¨&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æ€»ç»“-7"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;NVLink æ˜¯ &lt;strong&gt;ç¡¬ä»¶å®ä½“ï¼ˆç‰©ç†é“¾è·¯ã€äº¤æ¢èŠ¯ç‰‡ï¼‰ä¸è½¯ä»¶åè®®ï¼ˆé€šä¿¡æ ˆã€APIï¼‰çš„æ·±åº¦èåˆ&lt;/strong&gt; ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‰©ç†ç»“æ„&lt;/strong&gt; æä¾›é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ä¼ è¾“é€šé“ï¼›&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è½¯ä»¶åè®®&lt;/strong&gt; å®ç°åŠŸèƒ½è°ƒåº¦ã€é”™è¯¯æ§åˆ¶ä¸ç³»ç»Ÿä¼˜åŒ–ã€‚è¿™ç§ååŒè®¾è®¡ä½¿å…¶åœ¨ AI è®­ç»ƒï¼ˆå¦‚åƒå¡é›†ç¾¤ï¼‰ã€ç§‘å­¦è®¡ç®—ç­‰åœºæ™¯ä¸­è¿œè¶… PCIeï¼Œæˆä¸ºé«˜æ€§èƒ½è®¡ç®—çš„åŸºçŸ³ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="pcie"&gt;PCIe
&lt;/h2&gt;&lt;p&gt;PCIeï¼ˆPeripheral Component Interconnect Expressï¼‰æ˜¯ä¸€ç§&lt;strong&gt;é«˜é€Ÿä¸²è¡Œè®¡ç®—æœºæ‰©å±•æ€»çº¿æ ‡å‡†&lt;/strong&gt;ï¼Œç”±è‹±ç‰¹å°”äº2001å¹´æå‡ºï¼Œæ—¨åœ¨å–ä»£ä¼ ç»Ÿçš„PCIã€PCI-Xå’ŒAGPæ€»çº¿ï¼Œç°å·²æˆä¸ºè®¡ç®—æœºç¡¬ä»¶ä¸­ä¸»æµçš„äº’è¿æŠ€æœ¯ã€‚ä»¥ä¸‹ä»æ ¸å¿ƒç‰¹æ€§ã€æŠ€æœ¯æ¼”è¿›ã€æ¶æ„è®¾è®¡åŠåº”ç”¨åœºæ™¯ç­‰æ–¹é¢å…¨é¢è§£æï¼š&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒç‰¹æ€§ä¸è®¾è®¡åŸç†"&gt;âš™ï¸ æ ¸å¿ƒç‰¹æ€§ä¸è®¾è®¡åŸç†
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ç‚¹å¯¹ç‚¹ä¸²è¡Œæ¶æ„&lt;/strong&gt;
* PCIeé‡‡ç”¨&lt;strong&gt;ç‚¹å¯¹ç‚¹ç›´è¿&lt;/strong&gt; ï¼ˆéå…±äº«æ€»çº¿ï¼‰ï¼Œæ¯ä¸ªè®¾å¤‡ç‹¬äº«å¸¦å®½ï¼Œé¿å…ä¼ ç»ŸPCIæ€»çº¿çš„èµ„æºäº‰ç”¨é—®é¢˜ã€‚
* &lt;strong&gt;åŒå•å·¥é€šä¿¡&lt;/strong&gt; ï¼šæ”¯æŒåŒå‘åŒæ­¥æ•°æ®ä¼ è¾“ï¼ˆç±»ä¼¼å…¨åŒå·¥ï¼‰ï¼Œæ˜¾è‘—æå‡ååæ•ˆç‡ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;é€šé“é…ç½®ï¼ˆLane Scalingï¼‰&lt;/strong&gt;
* é€šé“æ•°çµæ´»é…ç½®ï¼šæ”¯æŒx1ã€x4ã€x8ã€x16ç­‰æ¨¡å¼ï¼Œå…¶ä¸­ï¼š
* &lt;strong&gt;x1&lt;/strong&gt; ï¼šå¸¦å®½250 MB/sï¼ˆPCIe 1.0ï¼‰ï¼Œç”¨äºå£°å¡ã€ç½‘å¡ç­‰ä½å¸¦å®½è®¾å¤‡ã€‚
* &lt;strong&gt;x16&lt;/strong&gt; ï¼šä¸»æµæ˜¾å¡æ¥å£ï¼Œæä¾›å•å‘4 GB/sï¼ˆPCIe 3.0ï¼‰è‡³16 GB/sï¼ˆPCIe 5.0ï¼‰å¸¦å®½ã€‚
* ç‰©ç†å…¼å®¹æ€§ï¼šçŸ­æ’æ§½è®¾å¤‡å¯æ’å…¥é•¿æ’æ§½ï¼ˆå¦‚x1å¡æ’å…¥x16æ§½ï¼‰ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;åˆ†å±‚åè®®æ ˆ&lt;/strong&gt;
* &lt;strong&gt;äº‹åŠ¡å±‚&lt;/strong&gt; ï¼šå¤„ç†æ•°æ®åŒ…ï¼ˆTLPï¼‰çš„å°è£…ä¸è·¯ç”±ï¼Œæ”¯æŒè¯»å†™ã€é…ç½®ã€ä¸­æ–­ç­‰æ“ä½œã€‚
* &lt;strong&gt;æ•°æ®é“¾è·¯å±‚&lt;/strong&gt; ï¼šé€šè¿‡CRCæ ¡éªŒã€åºåˆ—å·é‡ä¼ ï¼ˆACK/NAKæœºåˆ¶ï¼‰ç¡®ä¿ä¼ è¾“å¯é æ€§ã€‚
* &lt;strong&gt;ç‰©ç†å±‚&lt;/strong&gt; ï¼šé‡‡ç”¨å·®åˆ†ä¿¡å·ï¼ˆLVDSï¼‰å’Œå†…åµŒæ—¶é’ŸæŠ€æœ¯ï¼Œæ”¯æŒ8b/10bï¼ˆPCIe 2.0ï¼‰æˆ–128b/130bç¼–ç ï¼ˆPCIe 3.0+ï¼‰ï¼Œå‡å°‘ä¿¡å·å¹²æ‰°ã€‚
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;é«˜çº§åŠŸèƒ½æ”¯æŒ&lt;/strong&gt;
* çƒ­æ’æ‹”ã€ç”µæºç®¡ç†ã€æœåŠ¡è´¨é‡ï¼ˆQoSï¼‰ã€é”™è¯¯æŠ¥å‘Šï¼ˆAERï¼‰åŠI/Oè™šæ‹ŸåŒ–ã€‚
â €&lt;/p&gt;
&lt;h3 id="-æŠ€æœ¯æ¼”è¿›ä¸æ€§èƒ½å‡çº§"&gt;ğŸ“ˆ æŠ€æœ¯æ¼”è¿›ä¸æ€§èƒ½å‡çº§
&lt;/h3&gt;&lt;p&gt;PCIeç‰ˆæœ¬è¿­ä»£æŒç»­æå‡ä¼ è¾“é€Ÿç‡ä¸æ•ˆç‡ï¼š&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç‰ˆæœ¬&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ä¼ è¾“é€Ÿç‡&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç¼–ç æ•ˆç‡&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å•å‘å¸¦å®½ï¼ˆx16ï¼‰&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å‘å¸ƒæ—¶é—´&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 1.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;2.5 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;8b/10b (80%)&lt;/td&gt;
&lt;td style="text-align: center"&gt;4 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2003å¹´&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 2.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;5 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;8b/10b (80%)&lt;/td&gt;
&lt;td style="text-align: center"&gt;8 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2007å¹´&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 3.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;8 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;128b/130b (98.5%)&lt;/td&gt;
&lt;td style="text-align: center"&gt;16 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2010å¹´&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 4.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;16 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;128b/130b&lt;/td&gt;
&lt;td style="text-align: center"&gt;32 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2017å¹´&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 5.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;32 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;128b/130b&lt;/td&gt;
&lt;td style="text-align: center"&gt;64 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2019å¹´&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 6.0&lt;/td&gt;
&lt;td style="text-align: center"&gt;64 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;PAM4è°ƒåˆ¶&lt;/td&gt;
&lt;td style="text-align: center"&gt;128 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2022å¹´&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;PCIe 7.0ï¼ˆå¼€å‘ä¸­ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;128 GT/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;PAM4è°ƒåˆ¶&lt;/td&gt;
&lt;td style="text-align: center"&gt;256 GB/s&lt;/td&gt;
&lt;td style="text-align: center"&gt;2025å¹´ï¼ˆé¢„è®¡ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ’¡ &lt;strong&gt;å…³é”®å‡çº§&lt;/strong&gt; ï¼š&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PCIe 3.0&lt;/strong&gt; ï¼šå¼•å…¥128b/130bç¼–ç ï¼Œå¸¦å®½åˆ©ç”¨ç‡æå‡è‡³98.5%ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PCIe 6.0+&lt;/strong&gt; ï¼šé‡‡ç”¨PAM4ï¼ˆå››ç”µå¹³è„‰å†²è°ƒåˆ¶ï¼‰æŠ€æœ¯ï¼Œå•é€šé“é€Ÿç‡ç¿»å€ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ç³»ç»Ÿæ¶æ„ä¸å…³é”®ç»„ä»¶"&gt;ğŸ§© ç³»ç»Ÿæ¶æ„ä¸å…³é”®ç»„ä»¶
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ç¡¬ä»¶æ‹“æ‰‘ç»“æ„&lt;/strong&gt;
* &lt;strong&gt;Root Complexï¼ˆæ ¹å¤åˆä½“ï¼‰&lt;/strong&gt; ï¼šé›†æˆäºCPUæˆ–èŠ¯ç‰‡ç»„ï¼Œè´Ÿè´£å‘èµ·äº‹åŠ¡å’Œè¿æ¥å†…å­˜/å¤„ç†å™¨ã€‚
* &lt;strong&gt;Switchï¼ˆäº¤æ¢æœºï¼‰&lt;/strong&gt; ï¼šæ‰©å±•å¤šè®¾å¤‡è¿æ¥ï¼Œæ”¯æŒå¤æ‚æ‹“æ‰‘ï¼ˆå¦‚æœåŠ¡å™¨å¤šGPUäº’è¿ï¼‰ã€‚
* &lt;strong&gt;Endpointï¼ˆç«¯ç‚¹è®¾å¤‡ï¼‰&lt;/strong&gt; ï¼šç»ˆç«¯è®¾å¤‡ï¼ˆå¦‚æ˜¾å¡ã€SSDï¼‰ï¼Œç›´æ¥å¤„ç†æ•°æ®ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;é…ç½®ç©ºé—´ä¸åœ°å€æ˜ å°„&lt;/strong&gt;
* æ¯ä¸ªè®¾å¤‡æ‹¥æœ‰&lt;strong&gt;256Bé…ç½®ç©ºé—´&lt;/strong&gt; ï¼ˆå«Vendor IDã€Class Codeç­‰ï¼‰ï¼Œæ”¯æŒå³æ’å³ç”¨å’Œèµ„æºåˆ†é…ã€‚
* é€šè¿‡&lt;strong&gt;BARï¼ˆåŸºå€å¯„å­˜å™¨ï¼‰&lt;/strong&gt; æ˜ å°„è®¾å¤‡å†…å­˜åˆ°ç³»ç»Ÿåœ°å€ç©ºé—´ï¼Œå®ç°ä¸»æœºç›´æ¥è®¿é—®ã€‚
â €&lt;/p&gt;
&lt;h3 id="-åº”ç”¨åœºæ™¯ä¸æ€§èƒ½å½±å“-1"&gt;ğŸ–¥ï¸ åº”ç”¨åœºæ™¯ä¸æ€§èƒ½å½±å“
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;å›¾å½¢å¤„ç†&lt;/strong&gt;
* &lt;strong&gt;x16æ¥å£&lt;/strong&gt;æˆä¸ºæ˜¾å¡æ ‡é…ï¼ŒPCIe 5.0 x16å¸¦å®½è¾¾128 GB/sï¼Œæ»¡è¶³8Kæ¸¸æˆä¸AIæ¸²æŸ“éœ€æ±‚ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;é«˜é€Ÿå­˜å‚¨&lt;/strong&gt;
* NVMe SSDé€šè¿‡PCIe 4.0 x4å®ç°7 GB/sè¯»å†™é€Ÿåº¦ï¼ˆå¦‚ä¸‰æ˜Ÿ990 Proï¼‰ï¼Œæ¯”SATA SSDå¿«12å€ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;ç½‘ç»œä¸åŠ é€Ÿå¡&lt;/strong&gt;
* 100Gç½‘å¡ï¼ˆå¦‚Mellanox ConnectX-6ï¼‰ä¾èµ–PCIe 4.0 x16ï¼Œé™ä½æ•°æ®ä¸­å¿ƒå»¶è¿Ÿã€‚
* AIè®­ç»ƒå¡ï¼ˆå¦‚NVIDIA A100ï¼‰åˆ©ç”¨PCIe 5.0æå‡CPU-GPUæ•°æ®äº¤æ¢æ•ˆç‡ã€‚
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;æ‰©å±•æ€§ä¸å…¼å®¹æ€§&lt;/strong&gt;
* æ”¯æŒå¤–éƒ¨GPUï¼ˆeGPUï¼‰ã€Thunderbolt 4æ‰©å±•åç­‰åœºæ™¯ã€‚
* å‘ä¸‹å…¼å®¹ï¼šPCIe 5.0è®¾å¤‡å¯åœ¨PCIe 3.0æ’æ§½é™é€Ÿè¿è¡Œã€‚
â €&lt;/p&gt;
&lt;h3 id="-å¯¹æ¯”ä¼ ç»Ÿæ€»çº¿æŠ€æœ¯"&gt;âš–ï¸ å¯¹æ¯”ä¼ ç»Ÿæ€»çº¿æŠ€æœ¯
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCIe&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;PCI&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;AGP&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;æ¶æ„&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç‚¹å¯¹ç‚¹ä¸²è¡Œ&lt;/td&gt;
&lt;td style="text-align: center"&gt;å…±äº«å¹¶è¡Œæ€»çº¿&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸“ç”¨å›¾å½¢å¹¶è¡Œæ¥å£&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å¸¦å®½ï¼ˆå³°å€¼ï¼‰&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;256 GB/sï¼ˆPCIe 7.0 x16ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;533 MB/sï¼ˆ64ä½/66MHzï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;2.1 GB/sï¼ˆAGP 8Xï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;æ‰©å±•æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜ï¼ˆå¤šé€šé“çµæ´»é…ç½®ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä½ï¼ˆæ€»çº¿äº‰ç”¨ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä»…æ”¯æŒå•æ˜¾å¡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ä¸»æµåº”ç”¨&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;GPU/SSD/ç½‘å¡&lt;/td&gt;
&lt;td style="text-align: center"&gt;å£°å¡/ä½é€Ÿç½‘å¡&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ—§å¼æ˜¾å¡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ” PCIeå–ä»£AGPçš„å…³é”®åŸå› ï¼šå¸¦å®½ä¸è¶³ï¼ˆAGP 8Xä»…2.1GB/sï¼‰ä¸”æ— æ³•æ”¯æŒå¤šè®¾å¤‡å¹¶è¡Œã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æ€»ç»“-8"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;PCIeé€šè¿‡&lt;strong&gt;ç‚¹å¯¹ç‚¹ä¸²è¡Œæ¶æ„&lt;/strong&gt;ã€&lt;strong&gt;åˆ†å±‚åè®®æ ˆ&lt;/strong&gt;å’Œ&lt;strong&gt;æŒç»­å¸¦å®½å‡çº§&lt;/strong&gt;ï¼Œè§£å†³äº†ä¼ ç»Ÿæ€»çº¿çš„å¸¦å®½ç“¶é¢ˆä¸æ‰©å±•é™åˆ¶ã€‚å…¶æŠ€æœ¯ä¼˜åŠ¿ä½“ç°åœ¨ï¼šâœ… &lt;strong&gt;è¶…é«˜å¸¦å®½&lt;/strong&gt; ï¼šPCIe 7.0å°†è¾¾256 GB/sï¼ˆx16ï¼‰ï¼Œæ»¡è¶³AI/è¶…ç®—éœ€æ±‚ï¼›âœ… &lt;strong&gt;ä½å»¶è¿Ÿé«˜å¯é &lt;/strong&gt; ï¼šæ•°æ®é“¾è·¯å±‚é‡ä¼ æœºåˆ¶ä¿éšœä¼ è¾“å®Œæ•´æ€§ï¼›âœ… &lt;strong&gt;ç”Ÿæ€å…¼å®¹&lt;/strong&gt; ï¼šè½¯ç¡¬ä»¶å‘ä¸‹å…¼å®¹ï¼Œæ”¯æŒçƒ­æ’æ‹”ä¸è™šæ‹ŸåŒ–ã€‚
éšç€PCIe 7.0è§„èŒƒäº2025å¹´è½åœ°ï¼Œå…¶128 GT/sé€Ÿç‡å°†è¿›ä¸€æ­¥æ¨åŠ¨æ•°æ®ä¸­å¿ƒã€AIåŠ6Gé€šä¿¡æŠ€æœ¯çš„é©æ–°ã€‚&lt;/p&gt;
&lt;h2 id="__threadfence"&gt;__threadFence
&lt;/h2&gt;&lt;p&gt;__threadfence() æ˜¯ CUDA ç¼–ç¨‹ä¸­çš„ä¸€ç§&lt;strong&gt;å†…å­˜æ …æ ï¼ˆMemory Fenceï¼‰å‡½æ•°&lt;/strong&gt;ï¼Œç”¨äºç¡®ä¿çº¿ç¨‹å¯¹å†…å­˜çš„å†™å…¥æ“ä½œåœ¨æ‰§è¡Œé¡ºåºå’Œå¯è§æ€§ä¸Šæ»¡è¶³ç‰¹å®šçº¦æŸã€‚å®ƒä¸çº¿ç¨‹åŒæ­¥å‡½æ•°ï¼ˆå¦‚ __syncthreads()ï¼‰æœ‰æœ¬è´¨åŒºåˆ«ï¼š &lt;strong&gt;__threadfence()ä¸é˜»å¡çº¿ç¨‹æ‰§è¡Œï¼Œè€Œæ˜¯å¼ºåˆ¶å®Œæˆå½“å‰çº¿ç¨‹çš„å†™æ“ä½œå¹¶ä½¿å…¶å¯¹å…¶ä»–çº¿ç¨‹å¯è§&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒåŠŸèƒ½å†…å­˜å¯è§æ€§ä¿éšœ"&gt;âš™ï¸ æ ¸å¿ƒåŠŸèƒ½ï¼šå†…å­˜å¯è§æ€§ä¿éšœ
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ä½œç”¨èŒƒå›´&lt;/strong&gt;
* __threadfence()ï¼šç¡®ä¿è°ƒç”¨çº¿ç¨‹åœ¨ &lt;strong&gt;å…¨å±€å†…å­˜ï¼ˆGlobal Memoryï¼‰&lt;/strong&gt; å’Œ &lt;strong&gt;å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰&lt;/strong&gt; çš„å†™æ“ä½œï¼Œå¯¹ &lt;strong&gt;æ•´ä¸ª Grid çš„æ‰€æœ‰çº¿ç¨‹å¯è§&lt;/strong&gt; ã€‚
* __threadfence_block()ï¼šä»…ä¿è¯å†™æ“ä½œå¯¹ &lt;strong&gt;åŒä¸€ Block å†…çš„çº¿ç¨‹å¯è§&lt;/strong&gt; ã€‚
* __threadfence_system()ï¼ˆè¾ƒå°‘ç”¨ï¼‰ï¼šæ‰©å±•è‡³ CPU å’Œå…¶ä»– GPU è®¾å¤‡ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;éæ‰§è¡Œå±éšœ&lt;/strong&gt;
* &lt;strong&gt;ä¸è¦æ±‚çº¿ç¨‹åŒæ­¥åˆ°åŒä¸€ä½ç½®&lt;/strong&gt;ï¼Œä»…ä¿è¯è°ƒç”¨å‰çº¿ç¨‹çš„å†™æ“ä½œå®Œæˆåï¼Œç»“æœæ‰èƒ½è¢«å…¶ä»–çº¿ç¨‹è¯»å– ã€‚ä¾‹å¦‚ï¼š// çº¿ç¨‹ A å†™å…¥æ•°æ®
* data[threadIdx.x] = value;
* __threadfence(); // ç¡®ä¿ data å†™å…¥å®Œæˆä¸”å…¨å±€å¯è§
* flag = 1; // è®¾ç½®å®Œæˆæ ‡å¿—å…¶ä»–çº¿ç¨‹è¯»å– flag å‰ï¼Œå¿…é¡»å…ˆçœ‹åˆ° data çš„æ›´æ–°å€¼ ã€‚
â €&lt;/p&gt;
&lt;h3 id="-ä¸åŒæ­¥å‡½æ•°çš„åŒºåˆ«"&gt;âš–ï¸ ä¸åŒæ­¥å‡½æ•°çš„åŒºåˆ«
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å‡½æ•°&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ä½œç”¨åŸŸ&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;è¡Œä¸º&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å…¸å‹ç”¨é€”&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;__syncthreads()&lt;/td&gt;
&lt;td style="text-align: center"&gt;åŒä¸€ Block å†…&lt;/td&gt;
&lt;td style="text-align: center"&gt;é˜»å¡çº¿ç¨‹ç›´è‡³æ‰€æœ‰çº¿ç¨‹åˆ°è¾¾æ­¤å¤„&lt;/td&gt;
&lt;td style="text-align: center"&gt;Block å†…çº¿ç¨‹åä½œï¼ˆå¦‚è§„çº¦ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;__threadfence()&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ•´ä¸ª Grid&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä»…ä¿è¯å†…å­˜æ“ä½œå¯è§æ€§ï¼Œä¸é˜»å¡&lt;/td&gt;
&lt;td style="text-align: center"&gt;è·¨ Block æ•°æ®ä¼ é€’ï¼ˆå¦‚æ ‡å¿—ä½æ›´æ–°ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;__threadfence_block()&lt;/td&gt;
&lt;td style="text-align: center"&gt;åŒä¸€ Block å†…&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¿è¯ Block å†…å†…å­˜å¯è§æ€§&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ›¿ä»£ __syncthreads() çš„ç‰¹æ®Šåˆ†æ”¯åœºæ™¯&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;âš ï¸ &lt;strong&gt;å…³é”®åŒºåˆ«&lt;/strong&gt; ï¼š&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;__syncthreads() æ˜¯ &lt;strong&gt;æ‰§è¡Œå±éšœ&lt;/strong&gt; ï¼ˆçº¿ç¨‹ç­‰å¾…ï¼‰ï¼Œè€Œ __threadfence() æ˜¯ &lt;strong&gt;å†…å­˜å±éšœ&lt;/strong&gt; ï¼ˆå†™æ“ä½œå¯è§æ€§ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;è·¨ Block åŒæ­¥å¿…é¡»ç”¨ __threadfence()ï¼Œå›  __syncthreads() æ— æ³•åŒæ­¥ä¸åŒ Block ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-å…¸å‹åº”ç”¨åœºæ™¯-2"&gt;ğŸ§© å…¸å‹åº”ç”¨åœºæ™¯
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;è·¨ Block æ•°æ®åä½œ&lt;/strong&gt; å¤š Block åä½œä»»åŠ¡ï¼ˆå¦‚åˆ†é˜¶æ®µæ±‚å’Œï¼‰ä¸­ï¼Œéœ€ç¡®ä¿ä¸€ä¸ª Block å®Œæˆæ•°æ®å†™å…¥åï¼Œå…¶ä»– Block æ‰èƒ½è¯»å–ï¼š&lt;strong&gt;global&lt;/strong&gt; void sum_kernel(float* data, float* result) {
2 // æ­¥éª¤1ï¼šè®¡ç®—å±€éƒ¨å’Œå¹¶å†™å…¥å…¨å±€å†…å­˜
3 float partial_sum = &amp;hellip;;
4 result[blockIdx.x] = partial_sum;
5 &lt;br&gt;
6 // ç¡®ä¿ result å†™å…¥å®Œæˆä¸”å…¨å±€å¯è§
7 __threadfence();
8 &lt;br&gt;
9 // æ­¥éª¤2ï¼šåŸå­æ“ä½œæ ‡è®°å®Œæˆ
10 if (threadIdx.x == 0) {
11 int count = atomicAdd(&amp;amp;counter, 1);
12 is_last_block = (count == gridDim.x - 1);
13 }
14 &lt;br&gt;
15 // æ­¥éª¤3ï¼šæœ€åä¸€ä¸ª Block æ±‡æ€»ç»“æœ
16 if (is_last_block) {
17 float total = 0;
18 for (int i = 0; i &amp;lt; gridDim.x; i++) total += result[i];
19 *result = total;
20 }
21 }æ­¤å¤„ __threadfence() ä¿è¯ result å†™å…¥å…ˆäº atomicAdd ç”Ÿæ•ˆï¼Œé¿å…å…¶ä»– Block è¯»å–æœªå®Œæˆçš„æ•°æ® ã€‚
&lt;strong&gt;22&lt;/strong&gt; &lt;strong&gt;é¿å…å†™æ“ä½œä¹±åº&lt;/strong&gt; CUDA é»˜è®¤å…è®¸å†…å­˜æ“ä½œä¹±åºæ‰§è¡Œã€‚ä»¥ä¸‹ä»£ç å¯èƒ½å‡ºé”™ï¼šdata[threadIdx.x] = value; // å†™æ“ä½œ1
23 flag = 1; // å†™æ“ä½œ2è‹¥æ— æ …æ ï¼Œå…¶ä»–çº¿ç¨‹å¯èƒ½å…ˆçœ‹åˆ° flag=1 ä½† data æœªæ›´æ–°ã€‚æ·»åŠ  __threadfence() å¼ºåˆ¶é¡ºåºï¼šdata[threadIdx.x] = value;
24 __threadfence(); // ç¡®ä¿ data å†™å…¥å…ˆå®Œæˆ
25 flag = 1;
â €&lt;/p&gt;
&lt;h3 id="-æ³¨æ„äº‹é¡¹-1"&gt;âš ï¸ æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ä¸åŸå­æ“ä½œååŒ&lt;/strong&gt; __threadfence() å¸¸ä¸åŸå­æ“ä½œï¼ˆå¦‚ atomicAddï¼‰é…åˆï¼Œç¡®ä¿â€œå†™å…¥å®Œæˆâ€çš„æ ‡å¿—ä½ï¼ˆå¦‚ is_last_blockï¼‰è¢«å®‰å…¨è®¾ç½® ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ€§èƒ½å¼€é”€&lt;/strong&gt; é¢‘ç¹è°ƒç”¨ __threadfence() ä¼šæš´éœ²å†…å­˜å»¶è¿Ÿï¼Œé™ä½å¹¶è¡Œæ•ˆç‡ã€‚å»ºè®®ä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨ ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;ä¸æ›¿ä»£åŒæ­¥å‡½æ•°&lt;/strong&gt; Block å†…çº¿ç¨‹åä½œä»éœ€ __syncthreads()ï¼›__threadfence() ä»…è§£å†³å†…å­˜å¯è§æ€§é—®é¢˜ ã€‚
â €&lt;/p&gt;
&lt;h3 id="-æ€»ç»“-9"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;__threadfence() æ˜¯ CUDA ä¸­&lt;strong&gt;ä¿éšœå†…å­˜æ“ä½œå¯è§æ€§çš„å…³é”®å·¥å…·&lt;/strong&gt;ï¼Œå°¤å…¶é€‚ç”¨äºè·¨ Block æ•°æ®ä¼ é€’çš„åœºæ™¯ï¼šâœ… &lt;strong&gt;æ ¸å¿ƒä½œç”¨&lt;/strong&gt; ï¼šå¼ºåˆ¶å½“å‰çº¿ç¨‹çš„å†™æ“ä½œå®Œæˆåï¼Œç»“æœå¯¹æ‰€æœ‰çº¿ç¨‹å¯è§ã€‚âœ… &lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt; ï¼šè·¨ Block åä½œï¼ˆå¦‚æ ‡å¿—ä½æ›´æ–°ã€åˆ†é˜¶æ®µè§„çº¦ï¼‰ã€‚âœ… &lt;strong&gt;ç¼–ç¨‹å®è·µ&lt;/strong&gt; ï¼šä¸åŸå­æ“ä½œç»„åˆï¼ˆå†™æ•°æ® â†’ __threadfence() â†’ åŸå­æ ‡è®°ï¼‰ï¼Œé¿å…æ•°æ®ç«äº‰ ã€‚âš ï¸ &lt;strong&gt;è¯¯åŒº&lt;/strong&gt; ï¼šå®ƒä¸æ˜¯çº¿ç¨‹åŒæ­¥åŸè¯­ï¼Œä¸é˜»å¡æ‰§è¡Œæµï¼Œéœ€ä¸ __syncthreads() åŒºåˆ†åº”ç”¨åœºæ™¯ ã€‚&lt;/p&gt;
&lt;h2 id="tensor-core"&gt;Tensor Core
&lt;/h2&gt;&lt;p&gt;CUDA Core å’Œ Tensor Core æ˜¯ NVIDIA GPU ä¸­ä¸¤ç±»åŠŸèƒ½å®šä½æˆªç„¶ä¸åŒçš„è®¡ç®—æ ¸å¿ƒï¼Œå®ƒä»¬åœ¨è®¾è®¡ç›®æ ‡ã€æ¶æ„ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ä»¥ä¸‹æ˜¯åŸºäºæœ€æ–°æŠ€æœ¯çš„ç»¼åˆå¯¹æ¯”åˆ†æï¼š&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒå®šä½ä¸è®¾è®¡ç›®æ ‡"&gt;âš™ï¸ æ ¸å¿ƒå®šä½ä¸è®¾è®¡ç›®æ ‡
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;CUDA Core&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Tensor Core&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;æœ¬è´¨&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;é€šç”¨å¹¶è¡Œè®¡ç®—å•å…ƒ&lt;/strong&gt;ï¼Œå¤„ç†å„ç±»æ ‡é‡å’Œç®€å•çŸ©é˜µè¿ç®—&lt;/td&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ä¸“ç”¨åŠ é€Ÿå•å…ƒ&lt;/strong&gt;ï¼Œä¸“æ³¨çŸ©é˜µä¹˜ç´¯åŠ ï¼ˆGEMMï¼‰ç­‰å¼ é‡è¿ç®—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;è®¾è®¡ç›®æ ‡&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;çµæ´»æ”¯æŒå›¾å½¢æ¸²æŸ“ã€ç§‘å­¦è®¡ç®—ç­‰å¤šæ ·åŒ–ä»»åŠ¡&lt;/td&gt;
&lt;td style="text-align: center"&gt;æè‡´ä¼˜åŒ–æ·±åº¦å­¦ä¹ ä¸­çš„çŸ©é˜µè®¡ç®—ï¼Œæå‡AIè®­ç»ƒ/æ¨ç†æ•ˆç‡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;æ¶æ„æ¼”è¿›&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;è‡ª Fermi æ¶æ„ï¼ˆ2010å¹´ï¼‰æˆä¸ºåŸºç¡€å•å…ƒï¼ŒæŒç»­å¢å¼º&lt;/td&gt;
&lt;td style="text-align: center"&gt;Volta æ¶æ„ï¼ˆ2017å¹´ï¼‰é¦–æ¬¡å¼•å…¥ï¼Œè¿­ä»£è‡³ Blackwellï¼ˆ2024ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æ¶æ„ä¸è®¡ç®—åŸç†"&gt;ğŸ”§ æ¶æ„ä¸è®¡ç®—åŸç†
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;CUDA Coreï¼šé€šç”¨æ€§ä¸çµæ´»æ€§&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è®¡ç®—å•å…ƒ&lt;/strong&gt; ï¼šæ¯ä¸ªæ ¸å¿ƒåŒ…å«ç‹¬ç«‹çš„æµ®ç‚¹(FPU)å’Œæ•´æ•°(ALU)è¿ç®—å•å…ƒï¼Œæ”¯æŒ FP32/FP64/INT32 ç­‰ç²¾åº¦ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ‰§è¡Œæ¨¡å¼&lt;/strong&gt; ï¼šåŸºäº SIMDï¼ˆå•æŒ‡ä»¤å¤šæ•°æ®ï¼‰æ¶æ„ï¼Œå•å‘¨æœŸå®Œæˆä¸€æ¬¡ä¹˜åŠ è¿ç®—ï¼ˆå¦‚ y = a*x + bï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä»»åŠ¡ç±»å‹&lt;/strong&gt; ï¼šé€‚åˆå¤„ç†åˆ†æ”¯é€»è¾‘ã€æ•°æ®é¢„å¤„ç†ç­‰éè§„åˆ™è®¡ç®—ã€‚
â €&lt;strong&gt;Tensor Coreï¼šä¸“ç”¨æ€§ä¸é«˜æ•ˆæ€§&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®¡ç®—å•å…ƒ&lt;/strong&gt; ï¼šä»¥çŸ©é˜µå—ï¼ˆå¦‚ 4Ã—4ï¼‰ä¸ºå•ä½å¤„ç†è¿ç®—ï¼Œå•å‘¨æœŸå®Œæˆ 64 æ¬¡æ··åˆç²¾åº¦ä¹˜ç´¯åŠ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ··åˆç²¾åº¦æ”¯æŒ&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è¾“å…¥/æƒé‡&lt;/strong&gt; ï¼šFP16ã€BF16ã€INT8ã€FP8ï¼ˆèŠ‚çœå†…å­˜å¸¦å®½ï¼‰&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç´¯åŠ /è¾“å‡º&lt;/strong&gt; ï¼šFP32ï¼ˆä¿éšœç²¾åº¦ï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶ä¼˜åŒ–&lt;/strong&gt; ï¼šèåˆä¹˜åŠ ï¼ˆFMAï¼‰æµæ°´çº¿è®¾è®¡ï¼Œé¿å…æ•°æ®åå¤æ¬è¿ã€‚
â €ğŸ’¡ &lt;strong&gt;æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹&lt;/strong&gt; ï¼šNVIDIA A100 GPU ä¸­ï¼ŒTensor Core çš„ TF32 ç®—åŠ›ï¼ˆ312 TFLOPSï¼‰æ˜¯ CUDA Core FP32 ç®—åŠ›ï¼ˆ19.5 TFLOPSï¼‰çš„ &lt;strong&gt;16å€&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€§èƒ½ä¸åº”ç”¨åœºæ™¯"&gt;ğŸš€ æ€§èƒ½ä¸åº”ç”¨åœºæ™¯
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;CUDA Core ä¸»å¯¼åœºæ™¯&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å›¾å½¢æ¸²æŸ“&lt;/strong&gt; ï¼šæ¸¸æˆå…‰å½±è®¡ç®—ã€æŠ—é”¯é½¿ï¼ˆå¦‚ RTX 4090 å« 16384 CUDA Coreï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é€šç”¨è®¡ç®—&lt;/strong&gt; ï¼šç§‘å­¦æ¨¡æ‹Ÿï¼ˆæµä½“åŠ›å­¦ã€åˆ†å­åŠ¨åŠ›å­¦ï¼‰ã€è§†é¢‘ç¼–è§£ç ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI è¾…åŠ©ä»»åŠ¡&lt;/strong&gt; ï¼šæ•°æ®åŠ è½½ã€æ¿€æ´»å‡½æ•°è®¡ç®—ç­‰éçŸ©é˜µæ“ä½œã€‚
â €&lt;strong&gt;Tensor Core ä¸»å¯¼åœºæ™¯&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ·±åº¦å­¦ä¹ è®­ç»ƒ&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16+FP32ï¼‰ï¼ŒåŠ é€Ÿ Transformer/GPT ç­‰å¤§æ¨¡å‹&lt;/li&gt;
&lt;li&gt;Blackwell æ¶æ„æ”¯æŒ FP4 ç²¾åº¦ï¼Œæ¨ç†æ€§èƒ½æå‡ 30å€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨ç†ä¼˜åŒ–&lt;/strong&gt; ï¼šINT8/FP8 é‡åŒ–é™ä½å»¶è¿Ÿï¼ˆå¦‚ TensorRT éƒ¨ç½²ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HPC åŠ é€Ÿ&lt;/strong&gt; ï¼šç¨€ç–çŸ©é˜µè®¡ç®—ï¼ˆæ°”è±¡æ¨¡æ‹Ÿã€é‡å­åŒ–å­¦ï¼‰ã€‚
â €âš¡ &lt;strong&gt;åä½œç¤ºä¾‹&lt;/strong&gt; ï¼šStable Diffusion ç”Ÿæˆå›¾åƒæ—¶ï¼š&lt;/li&gt;
&lt;li&gt;Tensor Core æ‰§è¡Œæ‰©æ•£æ¨¡å‹æ¨ç†&lt;/li&gt;
&lt;li&gt;CUDA Core å¤„ç†åå¤„ç†æ¸²æŸ“ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-ååŒå·¥ä½œæ¨¡å¼"&gt;ğŸ”„ ååŒå·¥ä½œæ¨¡å¼
&lt;/h3&gt;&lt;p&gt;ç°ä»£ GPUï¼ˆå¦‚ Hopper H100ï¼‰é€šè¿‡ &lt;strong&gt;SMï¼ˆæµå¼å¤šå¤„ç†å™¨ï¼‰&lt;/strong&gt; æ•´åˆä¸¤ç±»æ ¸å¿ƒï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä»»åŠ¡åˆ†é…&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;CUDA Core å¤„ç†æ§åˆ¶æµå’Œæ ‡é‡è¿ç®—&lt;/li&gt;
&lt;li&gt;Tensor Core ä¸“æ³¨çŸ©é˜µä¹˜æ³•ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;èµ„æºè°ƒåº¦&lt;/strong&gt; ï¼šSM å†…çš„ Warp è°ƒåº¦å™¨åŠ¨æ€åˆ†é…ä»»åŠ¡è‡³ä¸¤ç±»æ ¸å¿ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å†…å­˜åä½œ&lt;/strong&gt; ï¼šå…±äº«å¯„å­˜å™¨æ–‡ä»¶ä¸ç¼“å­˜ï¼Œå‡å°‘æ•°æ®æ¬è¿å¼€é”€ã€‚
â €&lt;strong&gt;ç¡¬ä»¶å®ä¾‹&lt;/strong&gt; ï¼šNVIDIA H100 GPU åŒ…å« 18432 ä¸ª CUDA Core + 576 ä¸ª Tensor Coreï¼ŒSM å†…æ¯”ä¾‹çº¦ 32:1ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æŠ€æœ¯æ¼”è¿›è¶‹åŠ¿"&gt;ğŸ“ˆ æŠ€æœ¯æ¼”è¿›è¶‹åŠ¿
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tensor Core æŒç»­å¢å¼º&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç²¾åº¦æ‰©å±•&lt;/strong&gt; ï¼šHopper æ”¯æŒ FP8ï¼ŒBlackwell å¼•å…¥ FP4 åŠå¾®ç¼©æ”¾æ ¼å¼ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é¢†åŸŸå®šåˆ¶&lt;/strong&gt; ï¼šTransformer å¼•æ“ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUDA Core é€šç”¨æ€§å‡çº§&lt;/strong&gt; ï¼šAmpere æ¶æ„æ”¯æŒ FP32+INT å¹¶è¡Œæ‰§è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¼‚æ„è®¡ç®—èåˆ&lt;/strong&gt; ï¼šCPU-GPU-NPU åˆ†å·¥ï¼ˆå¦‚ Grace Hopper è¶…çº§èŠ¯ç‰‡ï¼‰ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-æ€»ç»“æ ¸å¿ƒå·®å¼‚å…¨æ™¯"&gt;ğŸ’ æ€»ç»“ï¼šæ ¸å¿ƒå·®å¼‚å…¨æ™¯
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç»´åº¦&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;CUDA Core&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Tensor Core&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;æ ¸å¿ƒèƒ½åŠ›&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;é€šç”¨æ ‡é‡/çŸ¢é‡è®¡ç®—&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸“ç”¨çŸ©é˜µåŠ é€Ÿï¼ˆGEMMï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å…³é”®ä¼˜åŠ¿&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;çµæ´»æ€§é«˜ï¼Œæ”¯æŒå¤æ‚é€»è¾‘&lt;/td&gt;
&lt;td style="text-align: center"&gt;ååé‡æé«˜ï¼Œèƒ½æ•ˆæ¯”ä¼˜åŒ–&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ç²¾åº¦æ”¯æŒ&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;FP32/FP64/INT32&lt;/td&gt;
&lt;td style="text-align: center"&gt;FP16/TF32/INT8/FP8/FP4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;é€‚ç”¨è´Ÿè½½&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å›¾å½¢æ¸²æŸ“ã€ç§‘å­¦è®¡ç®—&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ·±åº¦å­¦ä¹ è®­ç»ƒ/æ¨ç†ã€ç§‘å­¦çŸ©é˜µè¿ç®—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ç¡¬ä»¶å æ¯”&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ•°é‡å¤šï¼ˆåƒè‡³ä¸‡çº§ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ•°é‡å°‘ï¼ˆç™¾çº§ï¼‰ï¼Œä½†ç®—åŠ›å æ¯”é«˜&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ¤ &lt;strong&gt;åä½œä»·å€¼&lt;/strong&gt; ï¼šCUDA Core å¦‚â€œç‘å£«å†›åˆ€â€åº”å¯¹å¤šæ ·åŒ–ä»»åŠ¡ï¼ŒTensor Core å¦‚â€œæ¿€å…‰åˆ‡å‰²æœºâ€ä¸“æ”»æ·±åº¦å­¦ä¹ â€”â€”äºŒè€…ååŒæ„æˆ NVIDIA GPU åœ¨ AI ä¸ HPC é¢†åŸŸçš„ç»Ÿæ²»åŠ›åŸºçŸ³ã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="wmma"&gt;WMMA
&lt;/h2&gt;&lt;p&gt;WMMAï¼ˆWarp-level Matrix Multiply-Accumulateï¼‰æ˜¯ NVIDIA ä¸º &lt;strong&gt;Tensor Core&lt;/strong&gt; è®¾è®¡çš„ä¸“ç”¨ç¼–ç¨‹æ¥å£ï¼Œä¸¤è€…æ˜¯è½¯ä»¶æŠ½è±¡ä¸ç¡¬ä»¶å®ä½“çš„å…³ç³»ã€‚WMMA é€šè¿‡ Warp çº§åä½œæ¨¡å‹ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿé«˜æ•ˆè°ƒç”¨ Tensor Core çš„çŸ©é˜µåŠ é€Ÿèƒ½åŠ›ã€‚ä»¥ä¸‹æ˜¯ä¸¤è€…çš„æ ¸å¿ƒå…³è”åŠåä½œæœºåˆ¶ï¼š&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒå…³ç³»è½¯ä»¶æŠ½è±¡å±‚ä¸ç¡¬ä»¶åŠ é€Ÿå™¨çš„ç»‘å®š"&gt;âš™ï¸ æ ¸å¿ƒå…³ç³»ï¼šè½¯ä»¶æŠ½è±¡å±‚ä¸ç¡¬ä»¶åŠ é€Ÿå™¨çš„ç»‘å®š
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;Tensor Core çš„ç¡¬ä»¶æœ¬è´¨&lt;/strong&gt;
* &lt;strong&gt;ä¸“ç”¨è®¡ç®—å•å…ƒ&lt;/strong&gt; ï¼šTensor Core æ˜¯ GPU SMï¼ˆæµå¼å¤šå¤„ç†å™¨ï¼‰å†…çš„ä¸“ç”¨ç¡¬ä»¶ï¼Œä¸“æ³¨äºçŸ©é˜µä¹˜ç´¯åŠ ï¼ˆGEMMï¼‰æ“ä½œï¼Œå¦‚ D = A Ã— B + Cã€‚
* &lt;strong&gt;é«˜æ€§èƒ½ç‰¹æ€§&lt;/strong&gt; ï¼šå•å‘¨æœŸå®Œæˆå­çŸ©é˜µè¿ç®—ï¼ˆå¦‚ Volta æ¶æ„çš„ 4Ã—4Ã—4 çŸ©é˜µï¼‰ï¼Œååé‡è¿œè¶… CUDA Coreï¼ˆå¦‚ A100 çš„ Tensor Core FP16 ç®—åŠ›æ˜¯ FP32 CUDA Core çš„ 16 å€ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;WMMA çš„è½¯ä»¶è§’è‰²&lt;/strong&gt;
* &lt;strong&gt;ç¼–ç¨‹æ¥å£&lt;/strong&gt; ï¼šWMMA æ˜¯ CUDA æä¾›çš„ C++ API åŠ PTX æŒ‡ä»¤é›†ï¼Œå°è£…äº† Tensor Core çš„è°ƒç”¨é€»è¾‘ã€‚
* &lt;strong&gt;Warp çº§åä½œ&lt;/strong&gt; ï¼šä»¥ Warpï¼ˆ32 çº¿ç¨‹ï¼‰ä¸ºè°ƒåº¦å•å…ƒï¼ŒååŒåŠ è½½æ•°æ®ã€æ‰§è¡Œè®¡ç®—ã€å­˜å‚¨ç»“æœã€‚
â €âœ… &lt;strong&gt;å…³ç³»æœ¬è´¨&lt;/strong&gt; ï¼šWMMA æ˜¯å¼€å‘è€…è®¿é—® Tensor Core èƒ½åŠ›çš„&lt;strong&gt;å”¯ä¸€å®˜æ–¹é€”å¾„&lt;/strong&gt;ï¼ŒTensor Core æ˜¯ WMMA çš„&lt;strong&gt;ç¡¬ä»¶æ‰§è¡Œå¼•æ“&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3 id="-wmma-å¦‚ä½•é©±åŠ¨-tensor-core"&gt;ğŸ”§ WMMA å¦‚ä½•é©±åŠ¨ Tensor Core
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;å·¥ä½œæµç¨‹å››æ­¥æ›²
1&lt;/strong&gt; &lt;strong&gt;æ•°æ®åˆ†å—ä¸åŠ è½½&lt;/strong&gt;
* ä½¿ç”¨ load_matrix_sync å°†å…¨å±€å†…å­˜æˆ–å…±äº«å†…å­˜ä¸­çš„çŸ©é˜µå­å—ï¼ˆTileï¼‰åŠ è½½åˆ° &lt;strong&gt;Fragmentï¼ˆç‰‡æ®µï¼‰&lt;/strong&gt; ä¸­ã€‚
* Fragment æ˜¯å­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­çš„æ•°æ®ç»“æ„ï¼Œæ¯ä¸ªçº¿ç¨‹æŒæœ‰å­å—çš„ä¸€éƒ¨åˆ†ï¼ˆå¦‚ 16Ã—16 çŸ©é˜µåˆ†ç»™ 32 çº¿ç¨‹ï¼Œæ¯çº¿ç¨‹å­˜ 8 ä¸ªå…ƒç´ ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;çŸ©é˜µä¹˜ç´¯åŠ è®¡ç®—&lt;/strong&gt;
* è°ƒç”¨ mma_sync è§¦å‘ Tensor Core ç¡¬ä»¶æ‰§è¡Œï¼š
* è¾“å…¥ä¸¤ä¸ª Fragmentï¼ˆAã€Bï¼‰å’Œç´¯åŠ å™¨ Fragmentï¼ˆCï¼‰ï¼›
* è¾“å‡ºç»“æœ Fragmentï¼ˆD = A Ã— B + Cï¼‰ã€‚
* &lt;strong&gt;ç¡¬ä»¶ä¼˜åŒ–&lt;/strong&gt; ï¼šTensor Core ä»¥æµæ°´çº¿æ–¹å¼å¹¶è¡Œå¤„ç†å¤šä¸ªå­çŸ©é˜µï¼Œé¿å…å¯„å­˜å™¨ç“¶é¢ˆã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;ç»“æœå­˜å‚¨&lt;/strong&gt;
* é€šè¿‡ store_matrix_sync å°† Fragment æ•°æ®å†™å›å…¨å±€å†…å­˜ï¼Œå®Œæˆè®¡ç®—é—­ç¯ã€‚
&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;éšå¼åŒæ­¥æœºåˆ¶&lt;/strong&gt;
* WMMA å‡½æ•°ï¼ˆå¦‚ mma_syncï¼‰éšå« Warp å†…çº¿ç¨‹åŒæ­¥ï¼Œç¡®ä¿æ•°æ®å°±ç»ªæ€§ã€‚
â €&lt;strong&gt;å…³é”®è®¾è®¡ç‰¹ç‚¹&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ··åˆç²¾åº¦æ”¯æŒ&lt;/strong&gt; ï¼šWMMA æ”¯æŒ FP16â†’FP32ã€BF16â†’FP32ã€TF32â†’FP32 ç­‰æ··åˆç²¾åº¦æ¨¡å¼ï¼Œç”± Tensor Core ç¡¬ä»¶å®ç°æ— æŸç²¾åº¦ç´¯ç§¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å›ºå®šè®¡ç®—å°ºå¯¸&lt;/strong&gt; ï¼šæ—©æœŸä»…æ”¯æŒ 16Ã—16Ã—16 å­çŸ©é˜µï¼ˆMÃ—NÃ—Kï¼‰ï¼Œåç»­æ¶æ„æ‰©å±•è‡³æ›´å¤§å°ºå¯¸ã€‚
â €&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-tensor-core-çš„æ¶æ„æ¼”è¿›ä¸-wmma-çš„é€‚é…"&gt;âš¡ï¸ Tensor Core çš„æ¶æ„æ¼”è¿›ä¸ WMMA çš„é€‚é…
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ¶æ„&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Tensor Core å‡çº§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;WMMA æ”¯æŒå¢å¼º&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Volta&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç¬¬ä¸€ä»£ï¼Œæ”¯æŒ FP16â†’FP32&lt;/td&gt;
&lt;td style="text-align: center"&gt;CUDA 9.0 å¼•å…¥åŸºç¡€ API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Turing&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ‰©å±•è‡³ INT8/INT4 æ¨ç†&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ”¯æŒæ•´æ•°ç²¾åº¦åŠ è½½/å­˜å‚¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Ampere&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ–°å¢ TF32ï¼ˆ19ä½æµ®ç‚¹ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ–°å¢ tf32 ç‰‡æ®µç±»å‹&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Hopper&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ”¯æŒ FP8 ç²¾åº¦&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ‰©å±• FP8 çŸ©é˜µæ“ä½œ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;Blackwell&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ”¯æŒ FP4/FP6 åŠå¾®ç¼©æ”¾æ ¼å¼&lt;/td&gt;
&lt;td style="text-align: center"&gt;æœªæ¥é¢„è®¡æ‰©å±•è¶…ä½ç²¾åº¦ API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;ğŸ’¡ &lt;strong&gt;ç²¾åº¦ä¸æ€§èƒ½æƒè¡¡&lt;/strong&gt; ï¼šWMMA é€šè¿‡ç²¾åº¦ç±»å‹å‚æ•°ï¼ˆå¦‚ wmma::precision::fp16ï¼‰åŒ¹é… Tensor Core çš„ç¡¬ä»¶èƒ½åŠ›ï¼Œå®ç°æ€§èƒ½æœ€å¤§åŒ–ã€‚&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-å¼€å‘å®è·µä¸­çš„å…³é”®çº¦æŸ"&gt;âš ï¸ å¼€å‘å®è·µä¸­çš„å…³é”®çº¦æŸ
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ç¡¬ä»¶ä¾èµ–&lt;/strong&gt;
* ä»…æ”¯æŒè®¡ç®—èƒ½åŠ› â‰¥ 7.0 çš„ GPUï¼ˆVolta åŠåç»­æ¶æ„ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ•°æ®å¯¹é½è¦æ±‚&lt;/strong&gt;
* å…¨å±€å†…å­˜åœ°å€éœ€å¯¹é½è‡³ 128 å­—èŠ‚ï¼Œå¦åˆ™éœ€ä½¿ç”¨å…±äº«å†…å­˜ä¸­è½¬ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;åŠ¨æ€å½¢çŠ¶é™åˆ¶&lt;/strong&gt;
* WMMA å­çŸ©é˜µå°ºå¯¸éœ€ç¼–è¯‘æœŸç¡®å®šï¼Œä¸æ”¯æŒè¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´ã€‚
â €&lt;/p&gt;
&lt;h3 id="-æ€»ç»“wmma-ä¸-tensor-core-çš„åä½œä»·å€¼"&gt;ğŸ’ æ€»ç»“ï¼šWMMA ä¸ Tensor Core çš„åä½œä»·å€¼
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½å±‚é¢&lt;/strong&gt; ï¼šWMMA å°† Tensor Core çš„ç¡¬ä»¶åŠ é€Ÿæ½œåŠ›è½¬åŒ–ä¸ºå®é™…ç®—åŠ›ï¼Œå®ç° 10-30 å€äº CUDA Core çš„ååé‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼–ç¨‹å±‚é¢&lt;/strong&gt; ï¼šå°è£…äº†è·¨ä»£ç¡¬ä»¶å·®å¼‚ï¼Œå¼€å‘è€…æ— éœ€é‡å†™ä»£ç å³å¯é€‚é…æ–°ä¸€ä»£ Tensor Coreã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç”Ÿæ€å±‚é¢&lt;/strong&gt; ï¼šä½œä¸º cuBLAS/cuDNN çš„åº•å±‚åŸºç¡€ï¼Œæ”¯æ’‘ PyTorch/TensorFlow ç­‰æ¡†æ¶çš„æ··åˆç²¾åº¦è®­ç»ƒã€‚
â €å¼€å‘è€…åº”ä¼˜å…ˆé€šè¿‡ WMMA è°ƒç”¨ Tensor Coreï¼Œè€Œéç›´æ¥æ“ä½œ CUDA Coreï¼Œå°¤å…¶åœ¨æ·±åº¦å­¦ä¹ ã€ç§‘å­¦è®¡ç®—ç­‰çŸ©é˜µå¯†é›†å‹åœºæ™¯ä¸­ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="host-ä¸-device-å¼‚æ­¥æ•°æ®ä¼ è¾“"&gt;Host ä¸ Device å¼‚æ­¥æ•°æ®ä¼ è¾“
&lt;/h2&gt;&lt;p&gt;åœ¨GPUç¼–ç¨‹ä¸­ï¼Œä¸»æœºï¼ˆHostï¼‰å’Œè®¾å¤‡ï¼ˆDeviceï¼‰ä¹‹é—´çš„å¼‚æ­¥æ•°æ®ä¼ è¾“æ˜¯ä¼˜åŒ–è®¡ç®—æ€§èƒ½çš„å…³é”®æŠ€æœ¯ï¼Œä¸»è¦é€šè¿‡ä»¥ä¸‹æœºåˆ¶å®ç°ï¼š&lt;/p&gt;
&lt;h3 id="-å¼‚æ­¥ä¼ è¾“å‡½æ•°cudamemcpyasync"&gt;âš™ï¸ &lt;strong&gt;å¼‚æ­¥ä¼ è¾“å‡½æ•°ï¼šcudaMemcpyAsync&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åŠŸèƒ½&lt;/strong&gt; ï¼šå…è®¸æ•°æ®ä¼ è¾“æ“ä½œåœ¨GPUæ‰§è¡Œå…¶ä»–ä»»åŠ¡ï¼ˆå¦‚å†…æ ¸è®¡ç®—ï¼‰æ—¶å¹¶è¡Œè¿›è¡Œï¼Œé¿å…é˜»å¡ä¸»æœºçº¿ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;ä¸»æœºåˆ°è®¾å¤‡ï¼ˆcudaMemcpyHostToDeviceï¼‰&lt;/li&gt;
&lt;li&gt;è®¾å¤‡åˆ°ä¸»æœºï¼ˆcudaMemcpyDeviceToHostï¼‰&lt;/li&gt;
&lt;li&gt;è®¾å¤‡å†…éƒ¨ä¼ è¾“ï¼ˆéœ€è®¾å¤‡æ”¯æŒï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä»£ç ç¤ºä¾‹&lt;/strong&gt; ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dst&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="-é”é¡µå†…å­˜page-locked-memory"&gt;ğŸ“ é”é¡µå†…å­˜ï¼ˆPage-Locked Memoryï¼‰
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¿…è¦æ€§&lt;/strong&gt; ï¼šå¼‚æ­¥ä¼ è¾“è¦æ±‚ä¸»æœºå†…å­˜ä¸èƒ½è¢«æ“ä½œç³»ç»Ÿæ¢é¡µï¼ˆå³ç‰©ç†åœ°å€å›ºå®šï¼‰ï¼Œå¦åˆ™é©±åŠ¨éœ€é¢å¤–å¤åˆ¶åˆ°ä¸´æ—¶é”é¡µå†…å­˜ï¼Œé™ä½æ•ˆç‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†é…æ–¹å¼&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;cudaMallocHost(void** ptr, size_t size)ï¼šåˆ†é…é”é¡µå†…å­˜ã€‚&lt;/li&gt;
&lt;li&gt;cudaHostAlloc(void** pHost, size_t size, unsigned int flags)ï¼šæ”¯æŒæ›´å¤šæ§åˆ¶ï¼ˆå¦‚cudaHostAllocMappedæ˜ å°„åˆ°è®¾å¤‡åœ°å€ç©ºé—´ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-cudaæµstreamç®¡ç†"&gt;ğŸ” CUDAæµï¼ˆStreamï¼‰ç®¡ç†
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä½œç”¨&lt;/strong&gt; ï¼šæµæ˜¯å¼‚æ­¥æ“ä½œçš„æ‰§è¡Œåºåˆ—ï¼ŒåŒä¸€æµå†…æ“ä½œé¡ºåºæ‰§è¡Œï¼Œä¸åŒæµå¯å¹¶è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…³é”®æ­¥éª¤&lt;/strong&gt; ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;åˆ›å»ºæµ&lt;/strong&gt; ï¼šcudaStream_t stream;
2 cudaStreamCreate(&amp;amp;stream);
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;åœ¨æµä¸­æ‰§è¡Œæ“ä½œ&lt;/strong&gt; ï¼š// å¼‚æ­¥æ•°æ®ä¼ è¾“
4 cudaMemcpyAsync(&amp;hellip;, stream);
5 // å†…æ ¸å¯åŠ¨ï¼ˆæŒ‡å®šæµï¼‰
6 kernel&amp;laquo;&amp;lt;grid, block, 0, stream&amp;raquo;&amp;gt;(&amp;hellip;);
&lt;strong&gt;7&lt;/strong&gt; &lt;strong&gt;åŒæ­¥ä¸é”€æ¯&lt;/strong&gt; ï¼šcudaStreamSynchronize(stream); // ç­‰å¾…æµå†…æ“ä½œå®Œæˆ
8 cudaStreamDestroy(stream);&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-äº‹ä»¶eventåŒæ­¥"&gt;â±ï¸ äº‹ä»¶ï¼ˆEventï¼‰åŒæ­¥
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åŠŸèƒ½&lt;/strong&gt; ï¼šæ ‡è®°æµä¸­çš„ç‰¹å®šç‚¹ï¼Œç”¨äºè·¨æµä¾èµ–æ§åˆ¶æˆ–æ€§èƒ½åˆ†æã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åº”ç”¨&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è·¨æµåŒæ­¥&lt;/strong&gt; ï¼šä½¿æµBç­‰å¾…æµAä¸­çš„äº‹ä»¶å®Œæˆï¼šcudaEvent_t event;&lt;/li&gt;
&lt;li&gt;cudaEventCreate(&amp;amp;event);&lt;/li&gt;
&lt;li&gt;cudaEventRecord(event, streamA);&lt;/li&gt;
&lt;li&gt;cudaStreamWaitEvent(streamB, event); // æµBç­‰å¾…äº‹ä»¶&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®¡æ—¶&lt;/strong&gt; ï¼šcudaEventRecord(start, stream);&lt;/li&gt;
&lt;li&gt;kernel&amp;laquo;&amp;lt;&amp;hellip;, stream&amp;raquo;&amp;gt;();&lt;/li&gt;
&lt;li&gt;cudaEventRecord(stop, stream);&lt;/li&gt;
&lt;li&gt;cudaEventElapsedTime(&amp;amp;time, start, stop);&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-è®¾å¤‡èƒ½åŠ›æ£€æµ‹ä¸ä¼˜åŒ–"&gt;ğŸ”§ è®¾å¤‡èƒ½åŠ›æ£€æµ‹ä¸ä¼˜åŒ–
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶æ”¯æŒæ£€æŸ¥&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;asyncEngineCountï¼š&amp;gt;0 è¡¨ç¤ºæ”¯æŒæ•°æ®ä¼ è¾“ä¸è®¡ç®—å¹¶è¡Œï¼ˆå¦‚PCIeåŒå‘ä¼ è¾“ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;concurrentKernelsï¼š&amp;gt;0 è¡¨ç¤ºæ”¯æŒå¤šå†…æ ¸å¹¶å‘æ‰§è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¤ºä¾‹ä»£ç &lt;/strong&gt; ï¼šcudaDeviceProp prop;&lt;/li&gt;
&lt;li&gt;cudaGetDeviceProperties(&amp;amp;prop, 0);&lt;/li&gt;
&lt;li&gt;if (prop.asyncEngineCount &amp;gt; 0) {&lt;/li&gt;
&lt;li&gt;// æ”¯æŒå¼‚æ­¥å¼•æ“&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ€§èƒ½ä¼˜åŒ–ç­–ç•¥"&gt;ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é‡å è®¡ç®—ä¸ä¼ è¾“&lt;/strong&gt; ï¼šä½¿ç”¨å¤šæµå°†æ•°æ®åˆ†å—ï¼Œäº¤æ›¿æ‰§è¡Œä¼ è¾“å’Œè®¡ç®—ï¼šfor (int i = 0; i &amp;lt; nStreams; i++) {&lt;/li&gt;
&lt;li&gt;int offset = i * chunkSize;&lt;/li&gt;
&lt;li&gt;cudaMemcpyAsync(&amp;hellip;, stream[i]);&lt;/li&gt;
&lt;li&gt;kernel&amp;laquo;&amp;lt;&amp;hellip;, stream[i]&amp;raquo;&amp;gt;(&amp;hellip;, offset);&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»Ÿä¸€å†…å­˜ï¼ˆUnified Memoryï¼‰&lt;/strong&gt; ï¼šç®€åŒ–å†…å­˜ç®¡ç†ï¼ˆcudaMallocManagedï¼‰ï¼Œä½†éœ€æ³¨æ„éšå¼åŒæ­¥çš„å¼€é”€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ³¨æ„äº‹é¡¹-2"&gt;âš ï¸ æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é”™è¯¯æ£€æŸ¥&lt;/strong&gt; ï¼šæ‰€æœ‰CUDA APIè°ƒç”¨åéœ€æ£€æŸ¥è¿”å›å€¼ï¼ˆå¦‚cudaGetLastError()ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŒæ­¥ç‚¹&lt;/strong&gt; ï¼šé¿å…éšå¼åŒæ­¥æ“ä½œï¼ˆå¦‚é”é¡µå†…å­˜åˆ†é…ã€cudaMemcpyï¼‰ç ´åå¼‚æ­¥æ€§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;èµ„æºç«äº‰&lt;/strong&gt; ï¼šå¤šæµå¹¶å‘æ—¶éœ€ç¡®ä¿å†…å­˜è®¿é—®æ— å†²çªï¼ˆå¦‚ä¸åŒæµæ“ä½œä¸åŒå†…å­˜åŒºåŸŸï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ€»ç»“-10"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;å¼‚æ­¥æ•°æ®ä¼ è¾“çš„æ ¸å¿ƒæ˜¯ &lt;strong&gt;é”é¡µå†…å­˜ + CUDAæµ + å¼‚æ­¥å‡½æ•°&lt;/strong&gt;ã€‚é€šè¿‡æµé—´å¹¶è¡Œå’Œäº‹ä»¶åŒæ­¥ï¼Œæœ€å¤§åŒ–é‡å æ•°æ®ä¼ è¾“ä¸è®¡ç®—ï¼Œæ˜¾è‘—æå‡GPUåˆ©ç”¨ç‡ã€‚å®é™…åº”ç”¨ä¸­éœ€ç»“åˆè®¾å¤‡èƒ½åŠ›ï¼ˆå¦‚asyncEngineCountï¼‰è®¾è®¡åˆ†å—ç­–ç•¥ï¼Œå¹¶åˆ©ç”¨äº‹ä»¶ç›‘æ§æ€§èƒ½ç“¶é¢ˆã€‚&lt;/p&gt;
&lt;h2 id="global-memorytexture-memory-constant-memory"&gt;Global Memoryï¼ŒTexture Memory, Constant Memory
&lt;/h2&gt;&lt;p&gt;åœ¨NVIDIA GPUæ¶æ„ä¸­ï¼ŒConstant Memoryï¼ˆå¸¸é‡å†…å­˜ï¼‰ã€Texture Memoryï¼ˆçº¹ç†å†…å­˜ï¼‰å’ŒGlobal Memoryï¼ˆå…¨å±€å†…å­˜ï¼‰æ˜¯ä¸‰ç§ä¸åŒçš„å†…å­˜ç±»å‹ï¼Œå®ƒä»¬åœ¨ç‰©ç†ä½ç½®ã€è®¿é—®ç‰¹æ€§ã€æ€§èƒ½ä¼˜åŒ–åœºæ™¯åŠç¼–ç¨‹æ¨¡å‹ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ä»¥ä¸‹æ˜¯ç»¼åˆå¯¹æ¯”åˆ†æï¼š&lt;/p&gt;
&lt;h3 id="-ç‰©ç†ä½ç½®ä¸ç¡¬ä»¶æ”¯æŒ"&gt;âš™ï¸ ç‰©ç†ä½ç½®ä¸ç¡¬ä»¶æ”¯æŒ
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä½ç½®&lt;/strong&gt; ï¼šç‰‡å¤–ï¼ˆOff-chipï¼‰DRAMï¼ˆå¦‚HBMæˆ–GDDRï¼‰ï¼Œå®¹é‡æœ€å¤§ï¼ˆå¦‚H100è¾¾80GBï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶æ”¯æŒ&lt;/strong&gt; ï¼šæ— ä¸“ç”¨ç¼“å­˜ï¼Œä½†å¯é€šè¿‡L2ç¼“å­˜åŠ é€Ÿè®¿é—®ï¼ˆå»¶è¿Ÿ400-600å‘¨æœŸï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®¿é—®æƒé™&lt;/strong&gt; ï¼šæ‰€æœ‰çº¿ç¨‹å¯è¯»å†™ï¼Œæ˜¯æ•°æ®å­˜å‚¨çš„æ ¸å¿ƒåŒºåŸŸã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä½ç½®&lt;/strong&gt; ï¼šå®é™…æ•°æ®å­˜å‚¨åœ¨Global Memoryä¸­ï¼Œä½†æ¯ä¸ªSMï¼ˆæµå¼å¤šå¤„ç†å™¨ï¼‰æœ‰ä¸“ç”¨çš„&lt;strong&gt;å¸¸é‡ç¼“å­˜&lt;/strong&gt; ï¼ˆConstant Cacheï¼Œé€šå¸¸64KBï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶æ”¯æŒ&lt;/strong&gt; ï¼šåªè¯»ï¼Œé’ˆå¯¹åŒä¸€warpå†…æ‰€æœ‰çº¿ç¨‹è®¿é—®åŒä¸€å¸¸é‡æ—¶ä¼˜åŒ–ä¸ºå¹¿æ’­æœºåˆ¶ï¼ˆå•æ¬¡è®¿é—®æœåŠ¡å…¨warpï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä½ç½®&lt;/strong&gt; ï¼šæ•°æ®åŒæ ·ä½äºGlobal Memoryï¼Œä½†æ¯ä¸ªSM/TPCï¼ˆçº¿ç¨‹å¤„ç†é›†ç¾¤ï¼‰æœ‰ä¸“ç”¨çš„&lt;strong&gt;çº¹ç†ç¼“å­˜&lt;/strong&gt; ï¼ˆTexture Cacheï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶æ”¯æŒ&lt;/strong&gt; ï¼šåªè¯»ï¼Œç¼“å­˜é’ˆå¯¹ç©ºé—´å±€éƒ¨æ€§ä¼˜åŒ–ï¼ˆå¦‚2Då›¾åƒç›¸é‚»åƒç´ è®¿é—®ï¼‰ï¼Œæ”¯æŒç¡¬ä»¶æ’å€¼å’Œè¿‡æ»¤ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-è®¿é—®ç‰¹æ€§ä¸æ€§èƒ½"&gt;âš¡ï¸ è®¿é—®ç‰¹æ€§ä¸æ€§èƒ½
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;è®¿é—®å»¶è¿Ÿ&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜ï¼ˆ400-600å‘¨æœŸï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä½ï¼ˆé€šè¿‡å¸¸é‡ç¼“å­˜ï¼Œå»¶è¿Ÿâ‰ˆL1ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸­ä½ï¼ˆé€šè¿‡çº¹ç†ç¼“å­˜ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å¸¦å®½åˆ©ç”¨ç‡&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¾èµ–åˆå¹¶è®¿é—®ï¼ˆCoalesced Accessï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜ï¼ˆå¹¿æ’­æœºåˆ¶å‡å°‘é‡å¤è®¿é—®ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜ï¼ˆç©ºé—´å±€éƒ¨æ€§ä¼˜åŒ–ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;é€‚ç”¨è®¿é—®æ¨¡å¼&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;éšæœº/åˆ†æ•£è®¿é—®&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ‰€æœ‰çº¿ç¨‹è®¿é—®ç›¸åŒå¸¸é‡&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç©ºé—´å±€éƒ¨æ€§è®¿é—®ï¼ˆå¦‚å›¾åƒçº¹ç†ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;è¯»å†™æƒé™&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¯è¯»å†™&lt;/td&gt;
&lt;td style="text-align: center"&gt;åªè¯»ï¼ˆä¸»æœºåˆå§‹åŒ–ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;åªè¯»ï¼ˆæ”¯æŒåŠ¨æ€æ›´æ–°çº¹ç†ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-ç¼–ç¨‹æ¨¡å‹ä¸ä½¿ç”¨åœºæ™¯"&gt;ğŸ§© ç¼–ç¨‹æ¨¡å‹ä¸ä½¿ç”¨åœºæ™¯
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å£°æ˜æ–¹å¼&lt;/strong&gt; ï¼š&lt;strong&gt;device&lt;/strong&gt; æˆ–åŠ¨æ€åˆ†é…ï¼ˆcudaMallocï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt; ï¼šå­˜å‚¨è¾“å…¥/è¾“å‡ºæ•°æ®ã€ä¸­é—´è®¡ç®—ç»“æœï¼Œéœ€æ˜¾å¼ç®¡ç†æ•°æ®ä¼ è¾“ï¼ˆå¦‚cudaMemcpyï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŒ–å…³é”®&lt;/strong&gt; ï¼šéœ€å¯¹é½ï¼ˆAlignedï¼‰å’Œåˆå¹¶ï¼ˆCoalescedï¼‰è®¿é—®ä»¥æå‡å¸¦å®½ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å£°æ˜æ–¹å¼&lt;/strong&gt; ï¼š&lt;strong&gt;constant&lt;/strong&gt; é™æ€å£°æ˜ï¼Œä¸»æœºé€šè¿‡cudaMemcpyToSymbolåˆå§‹åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt; ï¼šå­˜å‚¨ç®—æ³•å‚æ•°ï¼ˆå¦‚å·ç§¯æ ¸æƒé‡ï¼‰ã€æ•°å­¦å¸¸é‡ç­‰ä¸å˜æ•°æ®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt; ï¼šé¿å…é‡å¤åŠ è½½ï¼Œé€‚åˆé¢‘ç¹è®¿é—®çš„å…¨å±€å¸¸é‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å£°æ˜æ–¹å¼&lt;/strong&gt; ï¼šé€šè¿‡çº¹ç†å¼•ç”¨ï¼ˆTexture Referenceï¼‰æˆ–å¯¹è±¡ï¼ˆTexture Objectï¼‰ç»‘å®šåˆ°Global Memoryã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt; ï¼šå›¾åƒå¤„ç†ã€ç§‘å­¦è®¡ç®—ä¸­çš„æ’å€¼è®¡ç®—ã€ç©ºé—´æ»¤æ³¢ç­‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹æ®ŠåŠŸèƒ½&lt;/strong&gt; ï¼šæ”¯æŒè‡ªåŠ¨æ’å€¼ï¼ˆå¦‚åŒçº¿æ€§æ»¤æ³¢ï¼‰ã€åæ ‡å½’ä¸€åŒ–ã€è¾¹ç•Œå¤„ç†ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ€§èƒ½å¯¹æ¯”ä¸é€‚ç”¨æ€§æ€»ç»“"&gt;ğŸ“Š **æ€§èƒ½å¯¹æ¯”ä¸é€‚ç”¨æ€§æ€»ç»“
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç»´åº¦&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Global Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Constant Memory&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Texture Memory&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å®¹é‡&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;è¶…å¤§ï¼ˆGBçº§ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;æå°ï¼ˆ64KBï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸­ï¼ˆä¾èµ–ç¼“å­˜å¤§å°ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;é€Ÿåº¦&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ…¢&lt;/td&gt;
&lt;td style="text-align: center"&gt;å¿«ï¼ˆç¼“å­˜å‘½ä¸­æ—¶ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä¸­å¿«ï¼ˆç¼“å­˜å‘½ä¸­æ—¶ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;è®¿é—®æ¨¡å¼ä¼˜åŒ–&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;éœ€åˆå¹¶è®¿é—®&lt;/td&gt;
&lt;td style="text-align: center"&gt;å•å€¼å¹¿æ’­&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç©ºé—´å±€éƒ¨æ€§&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;é€šç”¨æ•°æ®å­˜å‚¨ã€è¯»å†™æ“ä½œ&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜é¢‘è®¿é—®çš„å…¨å±€å¸¸é‡&lt;/td&gt;
&lt;td style="text-align: center"&gt;å›¾åƒ/ç©ºé—´æ•°æ®ã€åªè¯»é‡‡æ ·&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æ€»ç»“ä¸å»ºè®®"&gt;ğŸ’ æ€»ç»“ä¸å»ºè®®
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜å…ˆç”¨Constant Memory&lt;/strong&gt; ï¼šå½“æ‰€æœ‰çº¿ç¨‹éœ€é¢‘ç¹è¯»å–&lt;strong&gt;ç›¸åŒå¸¸é‡&lt;/strong&gt; ï¼ˆå¦‚ç®—æ³•å‚æ•°ï¼‰ï¼Œåˆ©ç”¨å…¶å¹¿æ’­æœºåˆ¶é™ä½å»¶è¿Ÿã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜å…ˆç”¨Texture Memory&lt;/strong&gt; ï¼šå¤„ç†&lt;strong&gt;ç©ºé—´å±€éƒ¨æ€§æ•°æ®&lt;/strong&gt; ï¼ˆå¦‚å›¾åƒã€åœ°å›¾ï¼‰ï¼Œåˆ©ç”¨ç¡¬ä»¶æ’å€¼å’Œç¼“å­˜ä¼˜åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŒ–Global Memory&lt;/strong&gt; ï¼šå¯¹è¯»å†™å‹æ•°æ®ï¼Œéœ€é€šè¿‡&lt;strong&gt;åˆå¹¶è®¿é—®&lt;/strong&gt;ã€åˆ©ç”¨å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰ç¼“å­˜æ•°æ®å‡å°‘å…¨å±€è®¿é—®æ¬¡æ•°ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €ğŸ’¡ &lt;strong&gt;æç¤º&lt;/strong&gt; ï¼šç°ä»£GPUï¼ˆå¦‚Hopperæ¶æ„ï¼‰é€šè¿‡TMAï¼ˆå¼ é‡å†…å­˜åŠ é€Ÿå™¨ï¼‰ä¼˜åŒ–Global Memoryä¸Shared Memoryçš„æ•°æ®ä¼ è¾“ï¼Œè¿›ä¸€æ­¥å¹³è¡¡ä¸‰è€…ä½¿ç”¨å¯æœ€å¤§åŒ–æ€§èƒ½ã€‚&lt;/p&gt;
&lt;h2 id="alignment--padding"&gt;Alignment &amp;amp; Padding
&lt;/h2&gt;&lt;p&gt;Paddingï¼ˆå¡«å……ï¼‰å’Œ Alignmentï¼ˆå¯¹é½ï¼‰æ˜¯è®¡ç®—æœºå†…å­˜ç®¡ç†ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼Œä¸»è¦ç”¨äºä¼˜åŒ–æ•°æ®è®¿é—®æ•ˆç‡ã€ä¿éšœç¡¬ä»¶å…¼å®¹æ€§åŠé¿å…ç¨‹åºé”™è¯¯ã€‚å®ƒä»¬çš„å¿…è¦æ€§æºäºç¡¬ä»¶æ¶æ„çš„è®¾è®¡ç‰¹æ€§å’Œç¼–ç¨‹è¯­è¨€çš„å†…å­˜ç®¡ç†æœºåˆ¶ã€‚ä»¥ä¸‹ä»æ¦‚å¿µã€åŸç†å’Œåº”ç”¨è§’åº¦ç»¼åˆè§£æï¼š&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒæ¦‚å¿µ"&gt;ğŸ“Œ æ ¸å¿ƒæ¦‚å¿µ
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;Alignmentï¼ˆå¯¹é½ï¼‰&lt;/strong&gt;
* &lt;strong&gt;å®šä¹‰&lt;/strong&gt; ï¼šæ•°æ®å¯¹è±¡çš„èµ·å§‹å†…å­˜åœ°å€å¿…é¡»æ»¡è¶³å…¶æ•°æ®ç±»å‹å¤§å°çš„æ•´æ•°å€ã€‚ä¾‹å¦‚ï¼š
* intï¼ˆ4å­—èŠ‚ï¼‰éœ€åœ°å€èƒ½è¢«4æ•´é™¤ï¼ˆå¦‚åœ°å€0x1000ï¼‰ã€‚
* doubleï¼ˆ8å­—èŠ‚ï¼‰éœ€åœ°å€èƒ½è¢«8æ•´é™¤ã€‚
* &lt;strong&gt;å¯¹é½å€¼&lt;/strong&gt; ï¼šé€šè¿‡ alignof(T) è·å–ï¼ˆC11æ ‡å‡†ï¼‰ï¼Œé»˜è®¤å¯¹é½å€¼é€šå¸¸ç­‰äºç±»å‹å¤§å°ï¼ˆè‡ªç„¶å¯¹é½ï¼‰ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;Paddingï¼ˆå¡«å……ï¼‰&lt;/strong&gt;
* &lt;strong&gt;å®šä¹‰&lt;/strong&gt; ï¼šç¼–è¯‘å™¨ä¸ºæ»¡è¶³å¯¹é½è¦æ±‚ï¼Œåœ¨ç»“æ„ä½“æˆå‘˜ä¹‹é—´æˆ–æœ«å°¾æ’å…¥çš„â€œæ— ç”¨å­—èŠ‚â€ã€‚ä¾‹å¦‚ï¼šstruct Example {
* char a; // 1å­—èŠ‚
* // ç¼–è¯‘å™¨æ’å…¥3å­—èŠ‚å¡«å……ï¼ˆå‡è®¾intéœ€4å­—èŠ‚å¯¹é½ï¼‰
* int b; // 4å­—èŠ‚
* };
* ç»“æ„ä½“å¤§å°ä»ç†è®ºå€¼5å­—èŠ‚å˜ä¸ºå®é™…8å­—èŠ‚ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-ä¸ºä½•éœ€è¦å¯¹é½ä¸å¡«å……"&gt;âš™ï¸ ä¸ºä½•éœ€è¦å¯¹é½ä¸å¡«å……ï¼Ÿ
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. ç¡¬ä»¶æ€§èƒ½ä¼˜åŒ–&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPUè®¿å­˜æœºåˆ¶&lt;/strong&gt; ï¼šCPUä»¥å›ºå®šå­—é•¿ï¼ˆå¦‚4/8å­—èŠ‚ï¼‰è¯»å–å†…å­˜ã€‚è‹¥æ•°æ®æœªå¯¹é½ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯¹é½è®¿é—®&lt;/strong&gt; ï¼šå•æ¬¡è®¿å­˜å³å¯å®Œæˆï¼ˆå¦‚è¯»å–4å­—èŠ‚intï¼Œåœ°å€0x1000ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœªå¯¹é½è®¿é—®&lt;/strong&gt; ï¼šéœ€å¤šæ¬¡è®¿å­˜å¹¶æ‹¼æ¥æ•°æ®ï¼ˆå¦‚è¯»å–è·¨è¶Šä¸¤ä¸ª4å­—èŠ‚å—çš„intåœ°å€0x1003ï¼‰ï¼Œå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ˆARM/MIPSæ¶æ„å°¤ä¸ºä¸¥é‡ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SIMDæŒ‡ä»¤è¦æ±‚&lt;/strong&gt; ï¼šSSE/AVXç­‰å‘é‡æŒ‡ä»¤å¼ºåˆ¶è¦æ±‚æ•°æ®å¯¹é½ï¼Œå¦åˆ™è§¦å‘æœªå®šä¹‰è¡Œä¸ºã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. åŸå­æ€§ä¸ç¨³å®šæ€§&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åŸå­æ“ä½œä¿éšœ&lt;/strong&gt; ï¼šå¯¹é½è®¿é—®åœ¨å¤šæ•°æ¶æ„ä¸­æ˜¯åŸå­çš„ï¼ˆå¦‚64ä½ç³»ç»Ÿä¸‹çš„8å­—èŠ‚å¯¹é½æ•°æ®ï¼‰ã€‚æœªå¯¹é½è®¿é—®å¯èƒ½ç ´ååŸå­æ€§ï¼Œå¼•å‘å¹¶å‘é—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶å…¼å®¹æ€§&lt;/strong&gt; ï¼šéƒ¨åˆ†æ¶æ„ï¼ˆå¦‚ARM v5ã€MIPSï¼‰ä¸æ”¯æŒæœªå¯¹é½è®¿é—®ï¼Œç›´æ¥è§¦å‘å¯¹é½å¼‚å¸¸ï¼ˆAlignment Faultï¼‰å¯¼è‡´ç¨‹åºå´©æºƒã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;3. ç¼–ç¨‹è¯­è¨€ä¸ç¼–è¯‘å™¨å®ç°&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç»“æ„ä½“å†…å­˜å¸ƒå±€&lt;/strong&gt; ï¼šCæ ‡å‡†å…è®¸ç¼–è¯‘å™¨æ’å…¥å¡«å……ï¼ˆÂ§6.7.2.1ï¼‰ï¼Œç¡®ä¿æˆå‘˜åœ°å€å¯¹é½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è·¨å¹³å°ä¸€è‡´æ€§&lt;/strong&gt; ï¼šä¸åŒç¼–è¯‘å™¨/æ¶æ„çš„å¯¹é½è§„åˆ™å¯èƒ½ä¸åŒï¼ˆå¦‚32ä½ä¸64ä½ç³»ç»Ÿï¼‰ï¼Œå¡«å……æœºåˆ¶é¿å…ä»£ç ç§»æ¤æ—¶çš„æ‰‹åŠ¨è°ƒæ•´ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;4. å†…å­˜ç©ºé—´ä¸æ€§èƒ½çš„æƒè¡¡&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¡«å……çš„ä»£ä»·&lt;/strong&gt; ï¼šç»“æ„ä½“å¡«å……å¯èƒ½å¯¼è‡´å†…å­˜æµªè´¹ï¼ˆå¦‚44%ç©ºé—´æµªè´¹æ¡ˆä¾‹ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½ä¼˜å…ˆ&lt;/strong&gt; ï¼šç‰ºç‰²å°‘é‡ç©ºé—´æ¢å–è®¿é—®é€Ÿåº¦ï¼Œç¬¦åˆâ€œç©ºé—´æ¢æ—¶é—´â€åŸåˆ™ã€‚ä¾‹å¦‚ï¼š
&lt;ul&gt;
&lt;li&gt;é¢‘ç¹è®¿é—®çš„æ•°ç»„å¯¹é½åï¼Œæ€§èƒ½å¯æå‡æ•°å€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-å®é™…åº”ç”¨ä¸é—®é¢˜è§„é¿"&gt;ğŸ’» å®é™…åº”ç”¨ä¸é—®é¢˜è§„é¿
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. ç»“æ„ä½“ä¼˜åŒ–è®¾è®¡&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æˆå‘˜æ’åºç­–ç•¥&lt;/strong&gt; ï¼šæŒ‰å¯¹é½å€¼é™åºæ’åˆ—æˆå‘˜ï¼ˆå¦‚double â†’ int â†’ charï¼‰ï¼Œæœ€å°åŒ–å¡«å……ã€‚// ä¼˜åŒ–å‰ï¼š12å­—èŠ‚ï¼ˆ1+3å¡«å……+4+1+3å¡«å……ï¼‰&lt;/li&gt;
&lt;li&gt;struct Bad { char a; int b; char c; };&lt;/li&gt;
&lt;li&gt;// ä¼˜åŒ–åï¼š8å­—èŠ‚ï¼ˆ4+1+1+2å¡«å……ï¼‰&lt;/li&gt;
&lt;li&gt;struct Good { int b; char a; char c; };&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ‰‹åŠ¨æ§åˆ¶å¡«å……&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;ç¼–è¯‘å™¨æŒ‡ä»¤ï¼ˆå¦‚#pragma pack(1)æˆ–GCCçš„__attribute__((packed))ï¼‰ç¦ç”¨å¡«å……ï¼Œä½†éœ€æ‰¿æ‹…æ€§èƒ½æŸå¤±å’Œç§»æ¤é£é™©ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. è·¨å¹³å°æ•°æ®äº¤æ¢&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é¿å…ç›´æ¥ä¼ é€’ç»“æ„ä½“&lt;/strong&gt; ï¼šç½‘ç»œä¼ è¾“æˆ–æ–‡ä»¶å­˜å‚¨æ—¶ï¼Œåºåˆ—åŒ–ä¸ºå­—èŠ‚æµï¼ˆæ‰‹åŠ¨å¤„ç†å¯¹é½ï¼‰ï¼Œè€Œéç›´æ¥memcpyç»“æ„ä½“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆå§‹åŒ–æ¸…é›¶&lt;/strong&gt; ï¼šmemset(&amp;amp;obj, 0, sizeof(obj)) é¿å…æœªåˆå§‹åŒ–å¡«å……ä½æ®‹ç•™è„æ•°æ®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;3. æŒ‡é’ˆä¸ç±»å‹è½¬æ¢çš„é™·é˜±&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æœªå¯¹é½è®¿é—®é£é™©&lt;/strong&gt; ï¼šchar data[10];&lt;/li&gt;
&lt;li&gt;int &lt;em&gt;p = (int&lt;/em&gt;)&amp;amp;data[1]; // åœ°å€æœªå¯¹é½&lt;/li&gt;
&lt;li&gt;*p = 10; // ARM/MIPSä¸‹å´©æºƒï¼Œx86æ€§èƒ½ä¸‹é™
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ›¿ä»£æ–¹æ¡ˆ&lt;/strong&gt; ï¼šç”¨memcpyå¤åˆ¶æ•°æ®è€ŒéæŒ‡é’ˆè½¬æ¢ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-ä¸åŒæ¶æ„ä¸‹çš„å¯¹é½æ”¯æŒå¯¹æ¯”"&gt;ğŸ“Š ä¸åŒæ¶æ„ä¸‹çš„å¯¹é½æ”¯æŒå¯¹æ¯”
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ¶æ„&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æœªå¯¹é½è®¿é—®æ”¯æŒ&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ€§èƒ½å½±å“&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;x86/x64&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;âœ… ç¡¬ä»¶è‡ªåŠ¨å¤„ç†&lt;/td&gt;
&lt;td style="text-align: center"&gt;âš ï¸ æŸå¤±10%~30%&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ¡Œé¢/æœåŠ¡å™¨åº”ç”¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ARM v8+&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;âœ… éƒ¨åˆ†æ”¯æŒ&lt;/td&gt;
&lt;td style="text-align: center"&gt;âš ï¸ æŸå¤±æ˜¾è‘—ï¼ˆSIMDé™¤å¤–ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;ç§»åŠ¨/åµŒå…¥å¼è®¾å¤‡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ARM v5/MIPS&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;âŒ è§¦å‘Alignment Fault&lt;/td&gt;
&lt;td style="text-align: center"&gt;ğŸ”¥ ç¨‹åºå´©æºƒ&lt;/td&gt;
&lt;td style="text-align: center"&gt;æ—§åµŒå…¥å¼ç³»ç»Ÿ&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æ€»ç»“-11"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯¹é½ï¼ˆAlignmentï¼‰&lt;/strong&gt; ï¼šç¡¬ä»¶é«˜æ•ˆè®¿é—®å†…å­˜çš„åŸºç¡€è¦æ±‚ï¼Œé¿å…æ€§èƒ½æŸå¤±å’Œç¨‹åºå¼‚å¸¸ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¡«å……ï¼ˆPaddingï¼‰&lt;/strong&gt; ï¼šç¼–è¯‘å™¨ä¸ºå®ç°å¯¹é½çš„è‡ªåŠ¨ä¼˜åŒ–æ‰‹æ®µï¼Œä»¥ç©ºé—´æ¢å–æ—¶é—´æ•ˆç‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¿…è¦æ€§æ ¸å¿ƒ&lt;/strong&gt; ï¼šğŸ’¡ &lt;strong&gt;ç¡¬ä»¶æ•ˆç‡&lt;/strong&gt; ï¼šå¯¹é½å‡å°‘CPUè®¿å­˜æ¬¡æ•°ï¼Œæé€Ÿå…³é”®æ“ä½œï¼›ğŸ’¡ &lt;strong&gt;ç¨³å®šä¿éšœ&lt;/strong&gt; ï¼šé¿å…æ¶æ„ç›¸å…³çš„å´©æºƒï¼ˆå¦‚ARMçš„Alignment Faultï¼‰ï¼›ğŸ’¡ &lt;strong&gt;å¼€å‘å‹å¥½&lt;/strong&gt; ï¼šç¼–è¯‘å™¨è‡ªåŠ¨å¡«å……ç®€åŒ–ä»£ç ï¼Œä½†éœ€è­¦æƒ•è·¨å¹³å°å·®å¼‚ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €å®é™…å¼€å‘ä¸­ï¼Œåº”å–„ç”¨sizeofå’Œoffsetofè·å–å†…å­˜å¸ƒå±€ï¼Œä¼˜å…ˆé€šè¿‡æˆå‘˜æ’åºå‡å°‘å¡«å……ï¼Œä»…åœ¨å¿…è¦æ—¶ï¼ˆå¦‚åµŒå…¥å¼å†…å­˜ç´§ç¼ºåœºæ™¯ï¼‰æ‰‹åŠ¨æ§åˆ¶å¯¹é½ï¼Œå¹¶ä¸¥æ ¼æµ‹è¯•æ€§èƒ½ä¸ç¨³å®šæ€§ã€‚&lt;/p&gt;
&lt;h4 id="__restrict__"&gt;__restrict__
&lt;/h4&gt;&lt;p&gt;ç¨‹åºå‘˜å‘ç¼–è¯‘å™¨æ‰¿è¯º&lt;strong&gt;æŒ‡é’ˆæ— åˆ«å&lt;/strong&gt;ï¼Œæ¢å–æ›´æ¿€è¿›çš„ä¼˜åŒ–&lt;/p&gt;
&lt;h2 id="warp-sync"&gt;warp sync
&lt;/h2&gt;&lt;p&gt;åœ¨ CUDA ç¼–ç¨‹ä¸­ï¼Œ__syncwarp() ä¸ Cooperative Groupsï¼ˆåä½œç»„ï¼‰ä¸­å®šä¹‰ä¸º Warp å¤§å°çš„çº¿ç¨‹ç»„å†è°ƒç”¨ .sync()è™½ç„¶éƒ½ç”¨äº Warp çº§åˆ«çš„çº¿ç¨‹åŒæ­¥ï¼Œä½†ä¸¤è€…åœ¨&lt;strong&gt;è®¾è®¡ç†å¿µã€ä½¿ç”¨æ–¹å¼ã€å®‰å…¨æ€§å’Œé€‚ç”¨èŒƒå›´&lt;/strong&gt;ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ä»¥ä¸‹ä»å¤šä¸ªç»´åº¦åˆ†æå®ƒä»¬çš„åŒºåˆ«ï¼š&lt;/p&gt;
&lt;h3 id="-è®¾è®¡ç†å¿µä¸ç¼–ç¨‹æ¨¡å‹"&gt;ğŸ§© è®¾è®¡ç†å¿µä¸ç¼–ç¨‹æ¨¡å‹
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; __syncwarp()&lt;strong&gt;ï¼šåº•å±‚æ˜¾å¼åŒæ­¥åŸè¯­&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å®šä½&lt;/strong&gt; ï¼šCUDA æ—©æœŸå¼•å…¥çš„ Warp çº§åŒæ­¥æŒ‡ä»¤ï¼Œéœ€å¼€å‘è€…&lt;strong&gt;æ‰‹åŠ¨æŒ‡å®šå‚ä¸åŒæ­¥çš„çº¿ç¨‹æ©ç ï¼ˆMaskï¼‰&lt;/strong&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŒæ­¥ç²’åº¦&lt;/strong&gt; ï¼šé€šè¿‡æ©ç ï¼ˆå¦‚ 0xFFFFFFFF è¡¨ç¤ºæ•´ä¸ª Warpï¼‰æ§åˆ¶å“ªäº›çº¿ç¨‹éœ€åŒæ­¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å†…å­˜æ …æ &lt;/strong&gt; ï¼šéšå«å†…å­˜å±éšœï¼ˆMemory Fenceï¼‰ï¼Œç¡®ä¿åŒæ­¥ç‚¹å‰åå†…å­˜æ“ä½œå¯¹å…¶ä»–çº¿ç¨‹å¯è§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. Cooperative Groupsï¼šé¢å‘å¯¹è±¡çš„å®‰å…¨æŠ½è±¡&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å®šä½&lt;/strong&gt; ï¼šCUDA 9+ å¼•å…¥çš„ç°ä»£çº¿ç¨‹ç»„æ¨¡å‹ï¼Œå°†çº¿ç¨‹ç»„è§†ä¸º&lt;strong&gt;ä¸€çº§å¯¹è±¡ï¼ˆFirst-class Objectï¼‰&lt;/strong&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŒæ­¥æ–¹å¼&lt;/strong&gt; ï¼šé€šè¿‡çº¿ç¨‹ç»„å¯¹è±¡ï¼ˆå¦‚ cooperative_groups::thread_block_tile&amp;lt;32&amp;gt;ï¼‰è°ƒç”¨ .sync() æ–¹æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;éšå¼å…³ç³»&lt;/strong&gt; ï¼šç»„å†…çº¿ç¨‹å…³ç³»åœ¨å¯¹è±¡åˆ›å»ºæ—¶ç¡®å®šï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç†æ©ç ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-ä½¿ç”¨æ–¹å¼ä¸ä»£ç å®‰å…¨"&gt;âš™ï¸ ä½¿ç”¨æ–¹å¼ä¸ä»£ç å®‰å…¨
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; __syncwarp() &lt;strong&gt;çš„é™·é˜±ä¸é™åˆ¶&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ©ç é”™è¯¯é£é™©&lt;/strong&gt; ï¼šéœ€å¼€å‘è€…ç¡®ä¿æ©ç ä¸æ´»è·ƒçº¿ç¨‹åŒ¹é…ï¼Œå¦åˆ™å¯¼è‡´&lt;strong&gt;æœªå®šä¹‰è¡Œä¸º&lt;/strong&gt; ï¼ˆå¦‚éƒ¨åˆ†çº¿ç¨‹æœªè°ƒç”¨åŒæ­¥ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯å‘æ•£é—®é¢˜&lt;/strong&gt; ï¼šåœ¨åˆ†æ”¯ä»£ç ä¸­ç›´æ¥ä½¿ç”¨ __activemask() ç”Ÿæˆçš„æ©ç å¯èƒ½ä¸å®Œæ•´ï¼ˆéæ‰€æœ‰åˆ†æ”¯çº¿ç¨‹éƒ½å‚ä¸ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¤ºä¾‹é—®é¢˜&lt;/strong&gt; ï¼šä»¥ä¸‹ä»£ç åœ¨åˆ†æ”¯å†…ä½¿ç”¨ __activemask() å¯èƒ½å¯¼è‡´éƒ¨åˆ†çº¿ç¨‹æœªåŒæ­¥ï¼šif (threadIdx.x &amp;lt; 16) {&lt;/li&gt;
&lt;li&gt;unsigned mask = __activemask(); // é”™è¯¯ï¼åˆ†æ”¯å†…æ©ç å¯èƒ½ç¼ºå¤±&lt;/li&gt;
&lt;li&gt;val = __shfl_sync(mask, val, 0); // éƒ¨åˆ†çº¿ç¨‹æœªå‚ä¸&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. Cooperative Groups çš„æ˜¾å¼å®‰å…¨&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è‡ªåŠ¨æ©ç ç®¡ç†&lt;/strong&gt; ï¼šåˆ›å»ºçº¿ç¨‹ç»„æ—¶è‡ªåŠ¨ç»‘å®šæ´»è·ƒçº¿ç¨‹ï¼Œ.sync() æ—¶éšå«æ­£ç¡®æ©ç ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ”¯å…¼å®¹æ€§&lt;/strong&gt; ï¼šæ”¯æŒåœ¨å‘æ•£åˆ†æ”¯ä¸­å®‰å…¨åŒæ­¥ï¼ˆç»„å¯¹è±¡åœ¨åˆ†æ”¯å‰åˆ›å»ºï¼‰ï¼šauto tile = cg::tiled_partition&amp;lt;32&amp;gt;(cg::this_thread_block());&lt;/li&gt;
&lt;li&gt;if (condition) {&lt;/li&gt;
&lt;li&gt;// ç»„å†…æ‰€æœ‰çº¿ç¨‹ï¼ˆåŒ…æ‹¬æœªè¿›åˆ†æ”¯çš„ï¼‰å‡é€šè¿‡ tile.sync() åŒæ­¥&lt;/li&gt;
&lt;li&gt;tile.sync();&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-åŠŸèƒ½æ‰©å±•æ€§ä¸ç¡¬ä»¶æ”¯æŒ"&gt;ğŸ›¡ï¸ åŠŸèƒ½æ‰©å±•æ€§ä¸ç¡¬ä»¶æ”¯æŒ
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; __syncwarp() &lt;strong&gt;çš„å±€é™æ€§&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä»…é™åŒæ­¥&lt;/strong&gt; ï¼šä»…æä¾›åŒæ­¥åŠŸèƒ½ï¼Œä¸åŒ…å«é›†ä½“æ“ä½œï¼ˆå¦‚è§„çº¦ã€æ‰«æï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¾èµ–æ¶æ„&lt;/strong&gt; ï¼šåœ¨ Volta æ¶æ„å‰ï¼ŒWarp æ˜¯ä¸¥æ ¼åŒæ­¥çš„ï¼ˆSIMTï¼‰ï¼Œä½† Volta åæ”¯æŒ&lt;strong&gt;ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦&lt;/strong&gt; ï¼ˆIndependent Thread Schedulingï¼‰ï¼Œéœ€æ˜¾å¼åŒæ­¥é¿å…ç«äº‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. Cooperative Groups çš„ä¸°å¯Œé›†ä½“æ“ä½œ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å†…ç½®ç®—æ³•&lt;/strong&gt; ï¼šæ”¯æŒ reduce()ã€scan()ã€memcpy_async() ç­‰é›†ä½“æ“ä½œï¼Œå¯ç›´æ¥è°ƒç”¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è·¨ç²’åº¦æ”¯æŒ&lt;/strong&gt; ï¼šä¸ä»…æ”¯æŒ Warpï¼Œè¿˜å¯å®šä¹‰ &lt;strong&gt;Blockã€Grid ç”šè‡³å¤š GPU çš„çº¿ç¨‹ç»„åŒæ­¥&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶åŠ é€Ÿ&lt;/strong&gt; ï¼šå¦‚ Hopper æ¶æ„çš„ wgmma.mma_async æŒ‡ä»¤éœ€é…åˆåä½œç»„å®ç°å¼‚æ­¥çŸ©é˜µä¹˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ€§èƒ½ä¸å…¼å®¹æ€§"&gt;âš–ï¸ æ€§èƒ½ä¸å…¼å®¹æ€§
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç»´åº¦&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;__syncwarp()&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;Cooperative Groups&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ä»£ç å®‰å…¨æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä½ï¼ˆéœ€æ‰‹åŠ¨ç®¡ç†æ©ç ï¼Œæ˜“å‡ºé”™ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜ï¼ˆå¯¹è±¡åŒ–ç®¡ç†ï¼Œé¿å…æ©ç é”™è¯¯ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å¯ç»´æŠ¤æ€§&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä½ï¼ˆé€»è¾‘åˆ†æ•£ï¼Œéš¾é€‚é…æ–°æ¶æ„ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜ï¼ˆæ¥å£ç»Ÿä¸€ï¼Œå‘å‰å…¼å®¹ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;åŠŸèƒ½ä¸°å¯Œåº¦&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;ä»…åŒæ­¥&lt;/td&gt;
&lt;td style="text-align: center"&gt;åŒæ­¥ + é›†ä½“ç®—æ³• + è·¨ç²’åº¦ç»„æ“ä½œ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;é€‚ç”¨æ¶æ„&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;å…¨æ¶æ„æ”¯æŒï¼ˆä½† Volta+ éœ€æ›´è°¨æ…ï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;CUDA 9.0+ï¼ˆéœ€ Compute Capability 6.0+ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-æ€»ç»“å¦‚ä½•é€‰æ‹©"&gt;ğŸ’ æ€»ç»“ï¼šå¦‚ä½•é€‰æ‹©ï¼Ÿ
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ä¼˜å…ˆ Cooperative Groups çš„åœºæ™¯&lt;/strong&gt; ï¼š
* éœ€è¦å®‰å…¨åŒæ­¥ï¼ˆå¦‚åˆ†æ”¯ä»£ç ã€åº“å‡½æ•°å¼€å‘ï¼‰ã€‚
* éœ€é›†ä½“æ“ä½œï¼ˆå¦‚ Warp çº§è§„çº¦/æ‰«æï¼‰ã€‚
* è·¨æ¶æ„å…¼å®¹æ€§è¦æ±‚é«˜ï¼ˆå¦‚æ”¯æŒ Volta/Ampere/Hopperï¼‰ã€‚
2 &lt;strong&gt;__syncwarp() çš„é€‚ç”¨åœºæ™¯&lt;/strong&gt; ï¼š
* å¯¹æ—§æ¶æ„ï¼ˆMaxwell/Pascalï¼‰çš„å…¼å®¹æ€§ç»´æŠ¤ã€‚
* æé«˜æ€§èƒ½æ•æ„Ÿåœºæ™¯ï¼ˆéœ€æ‰‹åŠ¨ä¼˜åŒ–æ©ç å‡å°‘å¼€é”€ï¼‰ã€‚
* ç®€å•åŒæ­¥ä¸”èƒ½ä¿è¯æ©ç æ­£ç¡®æ€§ï¼ˆå¦‚éåˆ†æ”¯ä»£ç ï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;strong&gt;è¿ç§»å»ºè®®&lt;/strong&gt; ï¼šæ—§ä»£ç ä¸­å¤§é‡ä½¿ç”¨ __syncwarp() æ—¶ï¼Œå¯é€æ­¥æ›¿æ¢ä¸ºåä½œç»„å¯¹è±¡ï¼ˆå¦‚ cg::thread_block_tile&amp;lt;32&amp;gt;ï¼‰ï¼Œæå‡å®‰å…¨æ€§ä¸å¯è¯»æ€§ã€‚åœ¨å¼‚æ­¥æ“ä½œï¼ˆå¦‚ WGMMAï¼‰ä¸­ï¼Œåä½œç»„ä¸ TMAï¼ˆTensor Memory Acceleratorï¼‰çš„ç»“åˆæ›´èƒ½å‘æŒ¥æ–°ä¸€ä»£ GPU æ€§èƒ½ã€‚&lt;/p&gt;
&lt;h2 id="cache-hint"&gt;Cache Hint
&lt;/h2&gt;&lt;p&gt;Cache Hintsï¼ˆç¼“å­˜æç¤ºï¼‰æ˜¯NVIDIA GPUä¸­ç”¨äºæ˜¾å¼æŒ‡å¯¼ç¼“å­˜è¡Œä¸ºçš„ç¼–ç¨‹æŠ€æœ¯ï¼Œé€šè¿‡__ldg()ã€nvvm_prefetchç­‰æŒ‡ä»¤æˆ–é™å®šç¬¦ï¼ˆå¦‚const &lt;strong&gt;restrict&lt;/strong&gt;ï¼‰å®ç°ï¼Œæ—¨åœ¨ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼ï¼Œæå‡å¹¶è¡Œæ•ˆç‡ã€‚å…¶æ ¸å¿ƒåœ¨äºæ ¹æ®æ•°æ®è®¿é—®ç‰¹æ€§é€‚é…ç¼“å­˜ç­–ç•¥ï¼Œå‡å°‘å†—ä½™æ•°æ®ç¼“å­˜å’Œå»¶è¿Ÿã€‚ä»¥ä¸‹æ˜¯ä¸‰ç±»Cache Hintsçš„è¯¦ç»†è§£æï¼š&lt;/p&gt;
&lt;h3 id="-load-hintsåŠ è½½æç¤º"&gt;âš™ï¸ Load Hintsï¼ˆåŠ è½½æç¤ºï¼‰
&lt;/h3&gt;&lt;p&gt;ç”¨äºä¼˜åŒ–&lt;strong&gt;æ•°æ®è¯»å–&lt;/strong&gt;é˜¶æ®µçš„ç¼“å­˜è¡Œä¸ºï¼Œä¸»è¦åŒ…å«ä¸¤ç§ç­–ç•¥ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;æµå¼åŠ è½½ï¼ˆStreaming Loadï¼‰&lt;/strong&gt;
* &lt;strong&gt;ä½œç”¨&lt;/strong&gt; ï¼šæ ‡è®°æ•°æ®ä¸º&lt;strong&gt;çŸ­æœŸä½¿ç”¨&lt;/strong&gt;ï¼ŒåŠ è½½åä¸ä¿ç•™åœ¨ç¼“å­˜ä¸­ï¼Œé¿å…æ±¡æŸ“ç¼“å­˜ç©ºé—´ã€‚
* &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; ï¼šå¤§è§„æ¨¡é¡ºåºè®¿é—®æ•°æ®ï¼ˆå¦‚ç§‘å­¦è®¡ç®—çš„æµå¼å¤„ç†ï¼‰ï¼Œåç»­æ— é‡å¤è®¿é—®éœ€æ±‚ã€‚
* &lt;strong&gt;å®ç°æ–¹å¼&lt;/strong&gt; ï¼š// ä½¿ç”¨PTXæŒ‡ä»¤æ˜¾å¼å£°æ˜æµå¼åŠ è½½
* asm volatile(&amp;ldquo;prefetch.global.L2 [%0];&amp;rdquo; :: &amp;ldquo;l&amp;rdquo;(ptr));
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;ç¼“å­˜ä¿ç•™åŠ è½½ï¼ˆCached Loadï¼‰&lt;/strong&gt;
* &lt;strong&gt;ä½œç”¨&lt;/strong&gt; ï¼šæç¤ºGPUå°†æ•°æ®ä¿ç•™åœ¨L1/L2ç¼“å­˜ï¼Œ &lt;strong&gt;åŠ é€Ÿåç»­é‡å¤è®¿é—®&lt;/strong&gt;ã€‚
* &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; ï¼šé¢‘ç¹è®¿é—®çš„æŸ¥æ‰¾è¡¨ï¼ˆLUTï¼‰ã€å…±äº«ç³»æ•°çŸ©é˜µç­‰ã€‚
* &lt;strong&gt;å®ç°æ–¹å¼&lt;/strong&gt; ï¼š// ä½¿ç”¨__ldg()å‡½æ•°å¼ºåˆ¶é€šè¿‡çº¹ç†ç¼“å­˜ï¼ˆåªè¯»ï¼‰
* float val = __ldg(&amp;amp;data[index]); // è§¦å‘L1ç¼“å­˜ä¿ç•™&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-store-hintså­˜å‚¨æç¤º"&gt;ğŸ’¾ Store Hintsï¼ˆå­˜å‚¨æç¤ºï¼‰
&lt;/h3&gt;&lt;p&gt;ç”¨äºä¼˜åŒ–&lt;strong&gt;æ•°æ®å†™å…¥&lt;/strong&gt;é˜¶æ®µçš„ç¼“å­˜è¡Œä¸ºï¼Œå‡å°‘ä¸å¿…è¦çš„ç¼“å­˜å ç”¨ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;æµå¼å­˜å‚¨ï¼ˆStreaming Storeï¼‰&lt;/strong&gt;
* &lt;strong&gt;ä½œç”¨&lt;/strong&gt; ï¼šæ•°æ®å†™å…¥å&lt;strong&gt;ç«‹å³åˆ·å‡ºç¼“å­˜&lt;/strong&gt;ï¼Œä¸å ç”¨ç¼“å­˜ç©ºé—´ã€‚
* &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; ï¼šä¸€æ¬¡æ€§å†™å…¥ç»“æœï¼ˆå¦‚æ¸²æŸ“è¾“å‡ºåˆ°å¸§ç¼“å†²åŒºï¼‰ï¼Œæ— éœ€åç»­è¯»å–ã€‚
* &lt;strong&gt;å®ç°æ–¹å¼&lt;/strong&gt; ï¼š// ä½¿ç”¨__stwtæŒ‡ä»¤ï¼ˆAmpere+æ¶æ„ï¼‰
* __stwt(&amp;amp;output[addr], value); // ç»•è¿‡L1ï¼Œç›´å†™L2/æ˜¾å­˜
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;å†™åˆå¹¶ï¼ˆWrite-Combiningï¼‰&lt;/strong&gt;
* &lt;strong&gt;ä½œç”¨&lt;/strong&gt; ï¼šåˆå¹¶å¤šä¸ªçº¿ç¨‹çš„å†™å…¥æ“ä½œï¼Œå‡å°‘ç¼“å­˜è¡Œè®¿é—®æ¬¡æ•°ã€‚
* &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; ï¼šåŸå­æ“ä½œï¼ˆAtomicï¼‰æˆ–è§„çº¦ï¼ˆReductionï¼‰ä¸­çš„ä¸´æ—¶ç»“æœå†™å…¥ã€‚
* &lt;strong&gt;ç¡¬ä»¶æ”¯æŒ&lt;/strong&gt; ï¼šNVIDIA GPUçš„L2ç¼“å­˜è‡ªåŠ¨åˆå¹¶éƒ¨åˆ†å†™å…¥è¯·æ±‚ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-read-only-hintsåªè¯»æç¤º"&gt;ğŸ“– Read-Only Hintsï¼ˆåªè¯»æç¤ºï¼‰
&lt;/h3&gt;&lt;p&gt;ä¸“ä¸º&lt;strong&gt;å¸¸é‡æ•°æ®&lt;/strong&gt;è®¾è®¡ï¼Œé€šè¿‡åªè¯»ç¼“å­˜è·¯å¾„æå‡æ€§èƒ½ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;çº¹ç†/å¸¸é‡ç¼“å­˜è·¯å¾„&lt;/strong&gt;
* &lt;strong&gt;ä½œç”¨&lt;/strong&gt; ï¼šå°†æ•°æ®æ ‡è®°ä¸ºåªè¯»ï¼Œè§¦å‘çº¹ç†ç¼“å­˜ï¼ˆTexture Cacheï¼‰æˆ–å¸¸é‡ç¼“å­˜ï¼ˆConstant Cacheï¼‰æœºåˆ¶ã€‚
* &lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt; ï¼š
* çº¹ç†ç¼“å­˜é’ˆå¯¹2Dç©ºé—´å±€éƒ¨æ€§ä¼˜åŒ–ï¼Œé€‚åˆå›¾åƒ/çŸ©é˜µæ•°æ®ã€‚
* å¸¸é‡ç¼“å­˜å¹¿æ’­æœºåˆ¶ï¼šå•åœ°å€è¯»å–å¯å¹¿æ’­åˆ°æ•´ä¸ªWarpï¼Œå‡å°‘è®¿é—®æ¬¡æ•°ã€‚
* &lt;strong&gt;å®ç°æ–¹å¼&lt;/strong&gt; ï¼š// ä½¿ç”¨const __restrict__é™å®šç¬¦
* void kernel(const float* &lt;strong&gt;restrict&lt;/strong&gt; data) {
* // ç¼–è¯‘å™¨è‡ªåŠ¨ä½¿ç”¨__ldg()æˆ–çº¹ç†è·¯å¾„
* }
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;ç»Ÿä¸€å†…å­˜åªè¯»ä¼˜åŒ–&lt;/strong&gt;
* åœ¨Unified Memoryï¼ˆUMï¼‰ä¸­ï¼Œåªè¯»æç¤ºå¯é¿å…æ•°æ®å›è¿è‡³CPUï¼Œå‡å°‘PCIeä¼ è¾“ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æŠ€æœ¯åŸç†ä¸æ€§èƒ½å½±å“"&gt;âš–ï¸ æŠ€æœ¯åŸç†ä¸æ€§èƒ½å½±å“
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æœºåˆ¶&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;ç¡¬ä»¶è¡Œä¸º&lt;/strong&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;&lt;strong&gt;æ€§èƒ½æ”¶ç›Š&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;ç¼“å­˜å±‚çº§é€‰æ‹©&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;HintsæŒ‡å¯¼æ•°æ®ç¼“å­˜äºL1ï¼ˆé«˜é‡ç”¨ï¼‰æˆ–è·³è¿‡L1ï¼ˆæµå¼æ•°æ®ï¼‰ï¼Œå‡å°‘L1æ±¡æŸ“&lt;/td&gt;
&lt;td style="text-align: center"&gt;æå‡ç¼“å­˜å‘½ä¸­ç‡ï¼Œé™ä½å¹³å‡å»¶è¿Ÿ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;å¸¦å®½ä¼˜åŒ–&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;æµå¼æ“ä½œå‡å°‘ç¼“å­˜å ç”¨ï¼Œé‡Šæ”¾å¸¦å®½ç»™å…¶ä»–ä»»åŠ¡&lt;/td&gt;
&lt;td style="text-align: center"&gt;é«˜åååœºæ™¯ä¸‹æå‡å¹¶è¡Œåº¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;strong&gt;èµ„æºç«äº‰ç¼“è§£&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;é¿å…åªè¯»æ•°æ®ä¸è¯»å†™æ•°æ®å…±ç”¨ç¼“å­˜è¡Œï¼Œå‡å°‘ä¼ªå…±äº«ï¼ˆFalse Sharingï¼‰&lt;/td&gt;
&lt;td style="text-align: center"&gt;æå‡å¤šçº¿ç¨‹ç¨³å®šæ€§&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="-ä½¿ç”¨æ³¨æ„äº‹é¡¹"&gt;âš ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;æ¶æ„å·®å¼‚æ€§&lt;/strong&gt;
* PascalåŠæ›´æ—©æ¶æ„ï¼š__ldg()å¯¹å…¨å±€å†…å­˜æ— æ•ˆï¼Œéœ€ä¾èµ–const &lt;strong&gt;restrict&lt;/strong&gt;ã€‚
* Volta+ï¼šå¼•å…¥ç‹¬ç«‹çš„&lt;strong&gt;åªè¯»æ•°æ®ç¼“å­˜&lt;/strong&gt; ï¼ˆRead-Only Data Cacheï¼‰ï¼Œæ˜¾å¼æç¤ºæ•ˆæœæ›´æ˜¾è‘—ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;è¿‡åº¦ä½¿ç”¨çš„é£é™©&lt;/strong&gt;
* é”™è¯¯æ ‡è®°æµå¼åŠ è½½å¯èƒ½å¯¼è‡´é‡å¤è®¿é—®æ•°æ®æ—¶åå¤ä»æ˜¾å­˜åŠ è½½ï¼Œæ€§èƒ½åé™ã€‚
* åªè¯»æç¤ºè¯¯ç”¨äºå¯å˜æ•°æ®ä¼šå¼•å‘æœªå®šä¹‰è¡Œä¸ºï¼ˆå¦‚æ•°æ®ä¸ä¸€è‡´ï¼‰ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;è°ƒè¯•å·¥å…·ä¾èµ–&lt;/strong&gt;
* éœ€é€šè¿‡nvprofæˆ–Nsight Computeåˆ†æç¼“å­˜å‘½ä¸­ç‡ï¼ˆl1tex__t_sectors_per_requestæŒ‡æ ‡ï¼‰éªŒè¯ä¼˜åŒ–æ•ˆæœã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ€»ç»“-12"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;Cache Hintsæ˜¯NVIDIA GPUä¸­&lt;strong&gt;ç²¾ç»†åŒ–æ§åˆ¶å†…å­˜å­ç³»ç»Ÿ&lt;/strong&gt;çš„å…³é”®æŠ€æœ¯ï¼Œå…¶ä»·å€¼åœ¨äºï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç²¾å‡†é€‚é…åœºæ™¯&lt;/strong&gt; ï¼šæµå¼æ•°æ®é¿ç¼“å­˜ã€åªè¯»æ•°æ®èµ°é«˜é€Ÿè·¯å¾„ã€å†™å…¥æ“ä½œå‡æ±¡æŸ“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é‡Šæ”¾ç¡¬ä»¶æ½œåŠ›&lt;/strong&gt; ï¼šç»“åˆGPUç¼“å­˜å±‚çº§ï¼ˆL1/L2/çº¹ç†ï¼‰å’Œè®¿é—®ç‰¹æ€§ï¼ˆå¦‚å¹¿æ’­ã€åˆå¹¶ï¼‰ï¼Œæœ€å¤§åŒ–å¹¶è¡Œååã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼–ç¨‹å¯æ§æ€§&lt;/strong&gt; ï¼šä»ç¼–è¯‘å™¨é™å®šç¬¦åˆ°æ±‡ç¼–æŒ‡ä»¤ï¼Œæä¾›å¤šå±‚æ¬¡æ§åˆ¶æ¥å£ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €å¼€å‘è€…åº”åœ¨æ€§èƒ½åˆ†æé©±åŠ¨ä¸‹ï¼Œé’ˆå¯¹æ€§ä½¿ç”¨Hintsä¼˜åŒ–çƒ­ç‚¹å†…å­˜è®¿é—®ï¼Œé¿å…ç›²ç›®åº”ç”¨ã€‚å¯¹å»¶è¿Ÿæ•æ„Ÿå‹å†…æ ¸ï¼ˆå¦‚å…‰çº¿è¿½è¸ªG-Bufferè¯»å–ï¼‰ï¼Œåˆç†é…ç½®åªè¯»æç¤ºå¯è·æ˜¾è‘—åŠ é€Ÿï¼›è€Œå¯¹æµå¼å¤„ç†ï¼ˆå¦‚ç²’å­æ¨¡æ‹Ÿï¼‰ï¼Œæ˜¾å¼æµå¼åŠ è½½èƒ½ç¼“è§£ç¼“å­˜æŠ–åŠ¨ã€‚&lt;/p&gt;
&lt;h2 id="barrier"&gt;Barrier
&lt;/h2&gt;&lt;p&gt;Barrierï¼ˆå±éšœï¼‰åœ¨CUDAç¼–ç¨‹ä¸­æ˜¯ä¸€ç§&lt;strong&gt;å…³é”®åŒæ­¥æœºåˆ¶&lt;/strong&gt;ï¼Œç”¨äºåè°ƒåŒä¸€çº¿ç¨‹å—ï¼ˆBlockï¼‰å†…å¤šä¸ªçº¿ç¨‹çš„æ‰§è¡Œé¡ºåºï¼Œç¡®ä¿æ‰€æœ‰çº¿ç¨‹åœ¨ç‰¹å®šç‚¹è¾¾åˆ°ä¸€è‡´çŠ¶æ€åå†ç»§ç»­æ‰§è¡Œã€‚å…¶æ ¸å¿ƒä½œç”¨æ˜¯è§£å†³å¹¶è¡Œè®¡ç®—ä¸­çš„æ•°æ®ç«äº‰å’Œé¡ºåºä¾èµ–é—®é¢˜ã€‚ä¸‹é¢ä»åŸç†ã€ç±»å‹ã€å®ç°åŠæ³¨æ„äº‹é¡¹å±•å¼€è¯´æ˜ï¼š&lt;/p&gt;
&lt;h3 id="-barrierçš„æ ¸å¿ƒåŸç†"&gt;âš™ï¸ Barrierçš„æ ¸å¿ƒåŸç†
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;åŒæ­¥é€»è¾‘&lt;/strong&gt; å½“çº¿ç¨‹è°ƒç”¨Barrieræ—¶ï¼Œä¼šæš‚åœæ‰§è¡Œå¹¶ç­‰å¾…åŒçº¿ç¨‹å—å†…çš„æ‰€æœ‰å…¶ä»–çº¿ç¨‹ä¹Ÿåˆ°è¾¾è¯¥Barrierç‚¹ã€‚åªæœ‰å½“æ‰€æœ‰çº¿ç¨‹éƒ½æŠµè¾¾åï¼Œæ‰èƒ½ç»§ç»­æ‰§è¡Œåç»­ä»£ç ã€‚&lt;strong&gt;ç±»æ¯”&lt;/strong&gt; ï¼šç±»ä¼¼äºå¤šäººåä½œä»»åŠ¡ä¸­çš„â€œé›†åˆç‚¹â€ï¼Œæ‰€æœ‰äººå¿…é¡»åˆ°é½åæ‰èƒ½è¿›è¡Œä¸‹ä¸€æ­¥ã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ&lt;/strong&gt;
* &lt;strong&gt;æ•°æ®ç«äº‰&lt;/strong&gt; ï¼šé˜²æ­¢çº¿ç¨‹Aåœ¨å†™å…¥å…±äº«å†…å­˜æ—¶ï¼Œçº¿ç¨‹Bæå‰è¯»å–æœªå®Œæˆè®¡ç®—çš„æ•°æ®ã€‚
* &lt;strong&gt;é¡ºåºä¾èµ–&lt;/strong&gt; ï¼šç¡®ä¿å‰åºæ“ä½œï¼ˆå¦‚æ•°æ®åŠ è½½ã€è®¡ç®—ï¼‰å®Œæˆåå†æ‰§è¡Œåç»­æ“ä½œï¼ˆå¦‚æ±‡æ€»ç»“æœï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-cudaä¸­çš„barrierç±»å‹"&gt;ğŸ§© CUDAä¸­çš„Barrierç±»å‹
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. ****__syncthreads()&lt;/strong&gt;ï¼ˆæ˜¾å¼å±éšœï¼‰ ****&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä½œç”¨èŒƒå›´&lt;/strong&gt; ï¼šä»…åŒæ­¥åŒä¸€çº¿ç¨‹å—ï¼ˆBlockï¼‰å†…çš„çº¿ç¨‹ï¼Œæ— æ³•è·¨BlockåŒæ­¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;å…±äº«å†…å­˜æ“ä½œï¼ˆå¦‚è§„çº¦æ±‚å’Œï¼‰å‰ç¡®ä¿æ•°æ®åŠ è½½å®Œæˆã€‚&lt;/li&gt;
&lt;li&gt;é¿å…è¯»å†™å†²çªï¼ˆä¾‹å¦‚å…ˆè¯»åå†™åŒä¸€å…±äº«å˜é‡ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä»£ç ç¤ºä¾‹&lt;/strong&gt; ï¼š&lt;strong&gt;shared&lt;/strong&gt; float s_data[128];&lt;/li&gt;
&lt;li&gt;s_data[threadIdx.x] = input_data; // å†™å…¥å…±äº«å†…å­˜&lt;/li&gt;
&lt;li&gt;__syncthreads(); // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å†™å…¥å®Œæˆ&lt;/li&gt;
&lt;li&gt;// å®‰å…¨è¯»å–å…¶ä»–çº¿ç¨‹å†™å…¥çš„æ•°æ®&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. å¼‚æ­¥Barrierï¼ˆCUDA 11+ï¼‰&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å®ç°æ–¹å¼&lt;/strong&gt; ï¼šé€šè¿‡__mbarrier_*ç³»åˆ—å‡½æ•°ï¼ˆå¦‚__mbarrier_arriveï¼‰æ§åˆ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;æ”¯æŒæ›´ç»†ç²’åº¦çš„åŒæ­¥ï¼ˆå¦‚åˆ†é˜¶æ®µè®¡æ•°ã€çº¿ç¨‹åŠ¨æ€é€€å‡ºï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;å¯å‡å°‘é˜»å¡ç­‰å¾…æ—¶é—´ï¼Œæå‡å¹¶è¡Œæ•ˆç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; ï¼šç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ã€åŠ¨æ€ä»»åŠ¡åˆ†é…ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;3. å…¨å±€åŒæ­¥ï¼ˆéšå¼å±éšœï¼‰&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æœºåˆ¶&lt;/strong&gt; ï¼šé€šè¿‡cudaDeviceSynchronize()å¼ºåˆ¶CPUç­‰å¾…æ‰€æœ‰GPUçº¿ç¨‹å®Œæˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt; ï¼šé¢‘ç¹ä½¿ç”¨ä¼šæ˜¾è‘—é™ä½æ€§èƒ½ï¼Œåº”å°½é‡é€šè¿‡å†…æ ¸æ‹†åˆ†æ›¿ä»£ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-å…³é”®æ³¨æ„äº‹é¡¹"&gt;âš ï¸ å…³é”®æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;æ¡ä»¶åˆ†æ”¯ä¸­çš„é£é™©&lt;/strong&gt; åœ¨æ¡ä»¶åˆ†æ”¯å†…ä½¿ç”¨Barrieréœ€ç¡®ä¿&lt;strong&gt;æ‰€æœ‰çº¿ç¨‹å‡æ‰§è¡Œç›¸åŒåˆ†æ”¯&lt;/strong&gt;ï¼Œå¦åˆ™ä¼šå¯¼è‡´æ­»é”ï¼ˆéƒ¨åˆ†çº¿ç¨‹æ°¸ä¹…ç­‰å¾…ï¼‰ã€‚&lt;strong&gt;é”™è¯¯ç¤ºä¾‹&lt;/strong&gt; ï¼š### if (threadIdx.x % 2 == 0) {&lt;/p&gt;
&lt;h3 id="2-----__syncthreads--å¶çº¿ç¨‹ç­‰å¾…"&gt;2 __syncthreads(); // å¶çº¿ç¨‹ç­‰å¾…
&lt;/h3&gt;&lt;p&gt;3 } else {
4 __syncthreads(); // å¥‡çº¿ç¨‹ç­‰å¾…ï¼Œä½†å®é™…æ— æ³•ä¿è¯åŒæ­¥ç‚¹ä¸€è‡´
5 }
&lt;strong&gt;6&lt;/strong&gt; &lt;strong&gt;è·¨çº¿ç¨‹å—åŒæ­¥ä¸å¯è¡Œ&lt;/strong&gt; CUDAçš„çº¿ç¨‹å—ç‹¬ç«‹æ‰§è¡Œï¼Œè‹¥éœ€è·¨BlockåŒæ­¥ï¼Œéœ€æ‹†åˆ†å†…æ ¸æˆ–ä½¿ç”¨å¤šçº§åŒæ­¥ç­–ç•¥ã€‚
&lt;strong&gt;7&lt;/strong&gt; &lt;strong&gt;æ€§èƒ½ä¼˜åŒ–&lt;/strong&gt;
* å‡å°‘Barrierè°ƒç”¨æ¬¡æ•°ï¼ˆæ¯æ¬¡åŒæ­¥å‡æœ‰å¼€é”€ï¼‰ã€‚
* ä¼˜å…ˆä½¿ç”¨å…±äº«å†…å­˜+__syncthreads()æ›¿ä»£å…¨å±€åŒæ­¥ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ€»ç»“-13"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åŸºç¡€åœºæ™¯&lt;/strong&gt; ï¼šçº¿ç¨‹å—å†…åŒæ­¥é¦–é€‰__syncthreads()ï¼Œç¡®ä¿å…±äº«å†…å­˜æ“ä½œå®‰å…¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é«˜çº§éœ€æ±‚&lt;/strong&gt; ï¼šåŠ¨æ€æˆ–åˆ†é˜¶æ®µåŒæ­¥ä½¿ç”¨å¼‚æ­¥Barrierï¼ˆ_&lt;em&gt;mbarrier&lt;/em&gt;*ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…¨å±€åŒæ­¥&lt;/strong&gt; ï¼šè°¨æ…ä½¿ç”¨cudaDeviceSynchronize()ï¼Œé¿å…æ€§èƒ½ç“¶é¢ˆã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €Barrieræ˜¯CUDAå¹¶è¡Œæ­£ç¡®æ€§çš„åŸºçŸ³ï¼Œç†è§£å…¶é€‚ç”¨åœºæ™¯å’Œé™åˆ¶ï¼Œæ–¹èƒ½é«˜æ•ˆè§„é¿ç«æ€æ¡ä»¶å¹¶ä¼˜åŒ–è®¡ç®—æ•ˆç‡ã€‚&lt;/p&gt;
&lt;h2 id="cudapipeline"&gt;cuda::pipeline
&lt;/h2&gt;&lt;p&gt;ä»¥ä¸‹æ˜¯å¯¹ CUDA ä¸­ cuda::pipeline çš„è¯¦ç»†ä»‹ç»ï¼Œç»“åˆå…¶è®¾è®¡åŸç†ã€æ ¸å¿ƒç»„ä»¶ã€ä½¿ç”¨åœºæ™¯åŠä¼˜åŒ–ç­–ç•¥å±•å¼€è¯´æ˜ï¼š&lt;/p&gt;
&lt;h3 id="-cudapipeline-çš„æ ¸å¿ƒè®¾è®¡ç›®æ ‡"&gt;âš™ï¸ cuda::pipeline çš„æ ¸å¿ƒè®¾è®¡ç›®æ ‡
&lt;/h3&gt;&lt;p&gt;cuda::pipeline æ˜¯ CUDA æä¾›çš„ä¸€ç§&lt;strong&gt;å¼‚æ­¥æ•°æ®æ‹·è´ä¸è®¡ç®—é‡å &lt;/strong&gt;çš„åŒæ­¥æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³ GPU è®¡ç®—ä¸­å†…å­˜è®¿é—®å»¶è¿Ÿä¸è®¡ç®—èµ„æºåˆ©ç”¨ç‡ä¸è¶³çš„é—®é¢˜ã€‚å…¶æ ¸å¿ƒç›®æ ‡åŒ…æ‹¬ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;éšè—å†…å­˜å»¶è¿Ÿ&lt;/strong&gt; ï¼šé€šè¿‡å¼‚æ­¥æ‹·è´ï¼ˆå¦‚ memcpy_asyncï¼‰å°†æ•°æ®ä»å…¨å±€å†…å­˜é¢„å–åˆ°å…±äº«å†…å­˜ï¼Œä¸è®¡ç®—ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;èµ„æºé«˜æ•ˆåˆ©ç”¨&lt;/strong&gt; ï¼šåˆ©ç”¨æµæ°´çº¿ï¼ˆPipelineï¼‰çš„å¤šé˜¶æ®µç¼“å†²ï¼Œå®ç°è®¡ç®—ä¸æ•°æ®ä¼ è¾“çš„æ·±åº¦é‡å ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;çº¿ç¨‹çº§åä½œ&lt;/strong&gt; ï¼šåŸºäºçº¿ç¨‹å—ï¼ˆThread Blockï¼‰èŒƒå›´å†…çš„åŒæ­¥ï¼Œç¡®ä¿æ•°æ®ä¾èµ–æ­£ç¡®æ€§ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ ¸å¿ƒç»„ä»¶ä¸å·¥ä½œæµç¨‹"&gt;ğŸ§© æ ¸å¿ƒç»„ä»¶ä¸å·¥ä½œæµç¨‹
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. æµæ°´çº¿å¯¹è±¡ï¼ˆPipeline Objectï¼‰&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç»“æ„&lt;/strong&gt; ï¼šä¸€ä¸ª FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰é˜Ÿåˆ—ï¼ŒåŒ…å«å¤šä¸ª&lt;strong&gt;é˜¶æ®µï¼ˆStageï¼‰&lt;/strong&gt; ï¼Œæ¯ä¸ªé˜¶æ®µå­˜å‚¨ä¸€ç»„å¼‚æ­¥æ“ä½œï¼ˆå¦‚æ•°æ®æ‹·è´ï¼‰ã€‚
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;å‡½æ•°&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;ä½œç”¨&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;producer_acquire()&lt;/td&gt;
&lt;td&gt;è·å–ä¸€ä¸ªç©ºé—²çš„æµæ°´çº¿é˜¶æ®µï¼Œç”¨äºæäº¤æ–°æ“ä½œã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;producer_commit()&lt;/td&gt;
&lt;td&gt;æäº¤å½“å‰é˜¶æ®µçš„æ‰€æœ‰å¼‚æ­¥æ“ä½œï¼ˆå¦‚ memcpy_asyncï¼‰ï¼Œå°†å…¶åŠ å…¥æµæ°´çº¿é˜Ÿåˆ—ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consumer_wait()&lt;/td&gt;
&lt;td&gt;ç­‰å¾…æµæ°´çº¿ä¸­æœ€æ—§é˜¶æ®µçš„æ“ä½œå®Œæˆã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consumer_release()&lt;/td&gt;
&lt;td&gt;é‡Šæ”¾æœ€æ—§é˜¶æ®µï¼Œä½¿å…¶å¯è¢«ç”Ÿäº§è€…é‡æ–°è·å–ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. å¼‚æ­¥æ‹·è´æ“ä½œï¼ˆ&lt;strong&gt;memcpy_async&lt;/strong&gt;ï¼‰&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å°†æ•°æ®ä»å…¨å±€å†…å­˜ï¼ˆGlobal Memoryï¼‰å¼‚æ­¥å¤åˆ¶åˆ°å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰ï¼Œæ— éœ€é˜»å¡çº¿ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶åŠ é€Ÿ&lt;/strong&gt; ï¼šåœ¨ Compute Capability â‰¥ 8.0ï¼ˆå¦‚ Ampereã€Hopperæ¶æ„ï¼‰çš„è®¾å¤‡ä¸Šï¼Œç›´æ¥ç»•è¿‡å¯„å­˜å™¨ï¼Œæå‡æ‹·è´æ•ˆç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;3. å·¥ä½œæµç¨‹ç¤ºä¾‹ï¼ˆå•é˜¶æ®µæµæ°´çº¿ï¼‰&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cuda/pipeline&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;global_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;global_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;block&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;extern&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;[];&lt;/span&gt; &lt;span class="c1"&gt;// å…±äº«å†…å­˜ç¼“å†²åŒº
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;pipeline_shared_state&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;thread_scope&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_pipeline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;batch_sz&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// ç”Ÿäº§è€…ï¼šè·å–é˜¶æ®µå¹¶æäº¤å¼‚æ­¥æ‹·è´
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;producer_acquire&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;memcpy_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_in&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;producer_commit&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// æ¶ˆè´¹è€…ï¼šç­‰å¾…ä¸Šä¸€é˜¶æ®µæ‹·è´å®Œæˆ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;consumer_wait&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;compute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;global_out&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// è®¡ç®—ä»»åŠ¡
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;consumer_release&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// é‡Šæ”¾é˜¶æ®µ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;æµç¨‹è§£æ&lt;/strong&gt; ï¼š
&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ç”Ÿäº§è€…æäº¤ä»»åŠ¡&lt;/strong&gt; ï¼šè·å–é˜¶æ®µ â†’ æäº¤å¼‚æ­¥æ‹·è´ â†’ æäº¤é˜¶æ®µã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ¶ˆè´¹è€…å¤„ç†ä»»åŠ¡&lt;/strong&gt; ï¼šç­‰å¾…æ‹·è´å®Œæˆ â†’ æ‰§è¡Œè®¡ç®— â†’ é‡Šæ”¾é˜¶æ®µã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;é‡å å®ç°&lt;/strong&gt; ï¼šå½“è®¡ç®—ä»»åŠ¡ï¼ˆcomputeï¼‰å¤„ç†å½“å‰æ•°æ®æ—¶ï¼Œå¼‚æ­¥æ‹·è´å·²å¼€å§‹é¢„å–ä¸‹ä¸€æ‰¹æ•°æ®ã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-å¤šé˜¶æ®µæµæ°´çº¿ä¸æ€§èƒ½ä¼˜åŒ–"&gt;âš¡ å¤šé˜¶æ®µæµæ°´çº¿ä¸æ€§èƒ½ä¼˜åŒ–
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. å¤šé˜¶æ®µè®¾è®¡ï¼ˆå¦‚åŒç¼“å†²ï¼‰&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åŸç†&lt;/strong&gt; ï¼šä½¿ç”¨å¤šä¸ªç¼“å†²åŒºï¼ˆå¦‚ Stage=2ï¼‰ï¼Œå®ç°â€œè®¡ç®—-æ‹·è´â€çš„æ·±åº¦é‡å ã€‚constexpr size_t stages_count = 2; // åŒé˜¶æ®µæµæ°´çº¿&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;shared&lt;/strong&gt; cuda::pipeline_shared_state&amp;lt;cuda::thread_scope::block, stages_count&amp;gt; state;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è®¡ç®—ä¸æ‹·è´å®Œå…¨é‡å &lt;/strong&gt; ï¼šä¸€ä¸ªé˜¶æ®µç”¨äºè®¡ç®—æ—¶ï¼Œå¦ä¸€ä¸ªé˜¶æ®µåŒæ—¶è¿›è¡Œæ•°æ®é¢„å–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å‡å°‘çº¿ç¨‹ç©ºé—²&lt;/strong&gt; ï¼šé¿å…å› ç­‰å¾…æ•°æ®æ‹·è´è€Œé˜»å¡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;2. ä¸ç¡¬ä»¶ç‰¹æ€§ç»“åˆ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hopper æ¶æ„çš„å¢å¼º&lt;/strong&gt; ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TMAï¼ˆTensor Memory Acceleratorï¼‰&lt;/strong&gt; ï¼šæ”¯æŒå¤§å—æ•°æ®çš„é«˜æ•ˆå¼‚æ­¥ä¼ è¾“ï¼Œå‡å°‘çº¿ç¨‹å¼€é”€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WGMMAï¼ˆWarp Group Matrix Multiply-Accumulateï¼‰&lt;/strong&gt; ï¼šæµæ°´çº¿ä¸ºå¼ é‡æ ¸å¿ƒï¼ˆTensor Coreï¼‰æŒç»­ä¾›åº”æ•°æ®ï¼Œé¿å…è®¡ç®—å•å…ƒé—²ç½®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;strong&gt;3. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å…±äº«å†…å­˜åˆ†é…&lt;/strong&gt; ï¼šç¡®ä¿æ¯ä¸ªé˜¶æ®µçš„æ•°æ®å—å¤§å°é€‚é…å…±äº«å†…å­˜å®¹é‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;çº¿ç¨‹å—é…ç½®&lt;/strong&gt; ï¼šçº¿ç¨‹æ•°è®¾ä¸º 32 çš„å€æ•°ï¼ˆWarp å¯¹é½ï¼‰ï¼Œé¿å… Bank Conflictã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æµæ°´çº¿æ·±åº¦&lt;/strong&gt; ï¼šæ ¹æ®è®¡ç®—ä¸æ‹·è´çš„è€—æ—¶æ¯”ä¾‹ï¼Œè°ƒæ•´é˜¶æ®µæ•°é‡ï¼ˆé€šå¸¸ 2-4 é˜¶æ®µï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-åº”ç”¨åœºæ™¯"&gt;ğŸš€ åº”ç”¨åœºæ™¯
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰&lt;/strong&gt;
* åœ¨çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ã€å·ç§¯ç­‰è®¡ç®—å¯†é›†å‹ä»»åŠ¡ä¸­ï¼Œé€šè¿‡æµæ°´çº¿éšè—å…¨å±€å†…å­˜è®¿é—®å»¶è¿Ÿã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;æ·±åº¦å­¦ä¹ è®­ç»ƒ/æ¨ç†&lt;/strong&gt;
* åŠ é€Ÿç¥ç»ç½‘ç»œå±‚çš„æ•°æ®åŠ è½½ä¸è®¡ç®—é‡å ï¼Œå°¤å…¶é€‚ç”¨äºå¤§æ¨¡å‹ï¼ˆå¦‚ Transformerï¼‰ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;æµå¼æ•°æ®å¤„ç†&lt;/strong&gt;
* å®æ—¶å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®æµï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ï¼‰ï¼Œç¡®ä¿è®¡ç®—å•å…ƒæŒç»­å·¥ä½œã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ³¨æ„äº‹é¡¹ä¸é™åˆ¶-1"&gt;âš ï¸ æ³¨æ„äº‹é¡¹ä¸é™åˆ¶
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; &lt;strong&gt;ä½œç”¨åŸŸé™åˆ¶&lt;/strong&gt; ### cuda::pipeline ä»…æ”¯æŒçº¿ç¨‹å—ï¼ˆthread_scope::blockï¼‰å†…çš„åŒæ­¥ï¼Œæ— æ³•è·¨å—åä½œã€‚
&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;èµ„æºå¼€é”€&lt;/strong&gt;
* å¤šé˜¶æ®µæµæ°´çº¿éœ€é¢å¤–å…±äº«å†…å­˜ï¼Œå¯èƒ½å‡å°‘å¯ç”¨è®¡ç®—èµ„æºã€‚
* é˜¶æ®µè¿‡å¤šå¯èƒ½å¯¼è‡´è°ƒåº¦å¤æ‚åº¦ä¸Šå‡ã€‚
&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;å…¼å®¹æ€§è¦æ±‚&lt;/strong&gt;
* å¼‚æ­¥æ‹·è´ç¡¬ä»¶åŠ é€Ÿéœ€ Compute Capability â‰¥ 8.0ï¼ˆAmpere+ï¼‰ã€‚
* æ—§æ¶æ„éœ€é€šè¿‡çº¿ç¨‹æŸä¸“ä¸šåŒ–ï¼ˆWarp Specializationï¼‰æ¨¡æ‹Ÿç±»ä¼¼æ•ˆæœã€‚&lt;/p&gt;
&lt;p&gt;â €&lt;/p&gt;
&lt;h3 id="-æ€»ç»“-14"&gt;ğŸ’ æ€»ç»“
&lt;/h3&gt;&lt;p&gt;cuda::pipeline æ˜¯ CUDA ä¸­å®ç°&lt;strong&gt;è®¡ç®—-é€šä¿¡é‡å &lt;/strong&gt;çš„æ ¸å¿ƒå·¥å…·ï¼Œé€šè¿‡å¤šé˜¶æ®µæµæ°´çº¿æœºåˆ¶æ˜¾è‘—æå‡ GPU åˆ©ç”¨ç‡ã€‚å…¶è®¾è®¡è¦ç‚¹åŒ…æ‹¬ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹&lt;/strong&gt; ï¼šé€šè¿‡ producer_acquire/commit å’Œ consumer_wait/release å®ç°ç²¾ç»†åŒæ­¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡¬ä»¶åä½œ&lt;/strong&gt; ï¼šç»“åˆ memcpy_async å’Œ TMA ç­‰ç‰¹æ€§ï¼Œæœ€å¤§åŒ–æ•°æ®ä¼ è¾“æ•ˆç‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; ï¼šé€‚ç”¨äºéœ€é«˜ååã€ä½å»¶è¿Ÿçš„å¹¶è¡Œä»»åŠ¡ï¼ˆå¦‚æ·±åº¦å­¦ä¹ ã€ç§‘å­¦è®¡ç®—ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â €å¼€å‘è€…å¯é€šè¿‡è°ƒæ•´æµæ°´çº¿é˜¶æ®µæ•°ã€ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼åŠé€‚é…æ–°ä¸€ä»£ GPU æ¶æ„ï¼ˆå¦‚ Hopperï¼‰ï¼Œè¿›ä¸€æ­¥é‡Šæ”¾æ€§èƒ½æ½œåŠ›ã€‚&lt;/p&gt;</description></item><item><title>ã€CUDAã€‘Programming Guide</title><link>https://dyhes.github.io/p/cudaprogramming-guide/</link><pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudaprogramming-guide/</guid><description>&lt;h2 id="introduction"&gt;Introduction
&lt;/h2&gt;&lt;p&gt;In general, an application has a mix of parallel parts and sequential parts, so systems are designed with a mix of GPUs and CPUs in order to maximize overall performance.Â 
&lt;img src="https://i.ibb.co/7xgqKH7d/image.png"
loading="lazy"
&gt;
The challenge is to develop application software that transparently scales its parallelism to leverage the increasing number of processor cores.
At its core are three key abstractions â€” a hierarchy of &lt;strong&gt;thread groups&lt;/strong&gt;, &lt;strong&gt;shared memories&lt;/strong&gt;, and &lt;strong&gt;barrier synchronization&lt;/strong&gt; â€” that are simply exposed to the programmer as a minimal set of language extensions.
Each block of threads can be scheduled on any of the available multiprocessors within a GPU, in any order, concurrently or sequentially, so that a compiled CUDA program can execute on any number of multiprocessors.
&lt;img src="https://i.ibb.co/hxDXmRFY/image-2.png"
loading="lazy"
&gt;&lt;/p&gt;
&lt;h2 id="programming-model"&gt;Programming Model
&lt;/h2&gt;&lt;h3 id="kernel"&gt;Kernel
&lt;/h3&gt;&lt;p&gt;CUDA C++ extends C++ by allowing the programmer to define C++ functions, calledÂ &lt;em&gt;kernels&lt;/em&gt;, that, when called, are executed N times in parallel by N differentÂ &lt;em&gt;CUDA threads&lt;/em&gt;, as opposed to only once like regular C++ functions.
A kernel is defined using theÂ &lt;strong&gt;global&lt;/strong&gt;Â declaration specifier and the number of CUDA threads that execute that kernel for a given kernel call is specified using a newÂ &amp;laquo;&amp;lt;&amp;hellip;&amp;raquo;&amp;gt;&lt;em&gt;execution configuration&lt;/em&gt;Â syntax (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;). Each thread that executes the kernel is given a &lt;strong&gt;uniqueÂ &lt;em&gt;thread ID&lt;/em&gt;&lt;/strong&gt;Â that is accessible within the kernel through built-in variables.&lt;/p&gt;
&lt;h3 id="thread-hierarchy"&gt;Thread Hierarchy
&lt;/h3&gt;&lt;p&gt;For convenience,Â threadIdxÂ is a &lt;strong&gt;3-component vector&lt;/strong&gt;, so that threads can be identified using a one-dimensional, two-dimensional, or three-dimensionalÂ &lt;em&gt;thread index&lt;/em&gt;, forming a one-dimensional, two-dimensional, or three-dimensional block of threads, called aÂ &lt;em&gt;thread block&lt;/em&gt;.
The index of a thread and its thread ID relate to each other in a straightforward way: For a one-dimensional block, they are the &lt;strong&gt;same&lt;/strong&gt;; for a two-dimensional block of sizeÂ &lt;em&gt;(Dx, Dy)&lt;/em&gt;, the thread ID of a thread of indexÂ &lt;em&gt;(x, y)&lt;/em&gt;Â isÂ &lt;em&gt;(&lt;strong&gt;x + y Dx&lt;/strong&gt;)&lt;/em&gt;; for a three-dimensional block of sizeÂ &lt;em&gt;(Dx, Dy, Dz)&lt;/em&gt;, the thread ID of a thread of indexÂ &lt;em&gt;(x, y, z)&lt;/em&gt;Â isÂ &lt;em&gt;(&lt;strong&gt;x + y Dx + z Dx Dy&lt;/strong&gt;)&lt;/em&gt;.
There is a limit to the number of threads per block, since all threads of a block are expected to &lt;strong&gt;reside&lt;/strong&gt; on the same streaming multiprocessor core and must &lt;strong&gt;share&lt;/strong&gt; the limited memory resources of that core. On current GPUs, a thread block may contain &lt;strong&gt;up to 1024&lt;/strong&gt; threads.
Blocks are organized into a one-dimensional, two-dimensional, or three-dimensionalÂ &lt;em&gt;grid&lt;/em&gt;Â of thread blocks.
&lt;img src="https://i.ibb.co/tpTsSt42/image-3.png"
loading="lazy"
&gt;
The number of threads per block and the number of blocks per grid specified in theÂ &amp;laquo;&amp;lt;&amp;hellip;&amp;raquo;&amp;gt;Â syntax can be of typeÂ intÂ orÂ dim3.
Each block within the grid can be identified by a one-dimensional, two-dimensional, or three-dimensional unique index accessible within the kernel through the built-inÂ blockIdxÂ variable. The dimension of the thread block is accessible within the kernel through the built-inÂ blockDimÂ variable.
A thread block size of 16x16 (256 threads), although arbitrary in this case, is a common choice.Â 
Thread blocks are required to execute &lt;strong&gt;independently&lt;/strong&gt;. It must be possible to execute blocks in any order, &lt;strong&gt;in parallel or in series&lt;/strong&gt;. This independence requirement allows thread blocks to be scheduled in any order and across any number of cores.
Threads within a block can &lt;strong&gt;cooperate&lt;/strong&gt; by sharing data through someÂ &lt;em&gt;shared memory&lt;/em&gt;Â and by synchronizing their execution to coordinate memory accesses. More precisely, one can specify synchronization points in the kernel by calling theÂ &lt;strong&gt;__syncthreads()&lt;/strong&gt;Â intrinsic function;Â __syncthreads()Â acts as a barrier at which all threads in the block must wait before any is allowed to proceed.Â &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory" target="_blank" rel="noopener"
&gt;Shared Memory&lt;/a&gt;Â gives an example of using shared memory. In addition toÂ __syncthreads(), theÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cooperative-groups" target="_blank" rel="noopener"
&gt;Cooperative Groups API&lt;/a&gt;Â provides a rich set of thread-synchronization primitives.
With the introduction of NVIDIAÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-9-0" target="_blank" rel="noopener"
&gt;Compute Capability 9.0&lt;/a&gt;, the CUDA programming model introduces an &lt;strong&gt;optional&lt;/strong&gt; level of hierarchy called Thread Block Clusters that are made up of thread blocks. Similar to how threads in a thread block are guaranteed to be co-scheduled on a streaming multiprocessor, thread blocks in a cluster are also guaranteed to be co-scheduled on a GPU Processing Cluster (GPC) in the GPU.
Similar to thread blocks, clusters are also organized into a one-dimension, two-dimension, or three-dimension grid of thread block clusters. The number of thread blocks in a cluster can be user-defined, and &lt;strong&gt;a maximum of 8 thread blocks&lt;/strong&gt; in a cluster is supported as a portable cluster size in CUDA. Note that on GPU hardware or MIG configurations which are too small to support 8 multiprocessors the maximum cluster size will be reduced accordingly. Identification of these smaller configurations, as well as of larger configurations supporting a thread block cluster size beyond 8, is &lt;strong&gt;architecture-specific&lt;/strong&gt; and can be queried using theÂ &lt;strong&gt;&lt;code&gt;cudaOccupancyMaxPotentialClusterSize&lt;/code&gt;&lt;/strong&gt;Â API.
&lt;img src="https://i.ibb.co/G3HT4zGK/image-4.png"
loading="lazy"
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In a kernel launched using cluster support, the gridDim variable still denotes the size in terms of number of thread blocks, for &lt;strong&gt;compatibility&lt;/strong&gt; purposes. The rank of a block in a cluster can be found using theÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg" target="_blank" rel="noopener"
&gt;Cluster Group&lt;/a&gt;Â API.
A thread block cluster can be enabled in a kernel either using a &lt;strong&gt;compile-time&lt;/strong&gt; kernel attribute usingÂ &lt;strong&gt;cluster_dims&lt;/strong&gt;(X,Y,Z)Â or using the CUDA kernel launch APIÂ &lt;code&gt;cudaLaunchKernelEx&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Kernel definition
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Compile time cluster size 2 in X-dimension and 1 in Y and Z dimension
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__cluster_dims__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;cluster_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Kernel invocation with compile time cluster size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// The grid dimension is not affected by cluster launch, and is still enumerated
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// using number of blocks.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// The grid dimension must be a multiple of cluster size.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cluster_kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Kernel definition
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// No compile time attribute attached to the kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;cluster_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Kernel invocation with runtime cluster size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaLaunchConfig_t&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// The grid dimension is not affected by cluster launch, and is still enumerated
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// using number of blocks.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// The grid dimension should be a multiple of cluster size.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gridDim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;blockDim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threadsPerBlock&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaLaunchAttribute&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cudaLaunchAttributeClusterDimension&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusterDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// Cluster size in X-dimension
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusterDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clusterDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numAttrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaLaunchKernelEx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cluster_kernel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In GPUs with compute capability &lt;strong&gt;9.0&lt;/strong&gt;, all the thread blocks in the cluster are guaranteed to be co-scheduled on a single &lt;strong&gt;GPU Processing Cluster (GPC)&lt;/strong&gt; and allow thread blocks in the cluster to perform &lt;strong&gt;hardware-supported synchronization&lt;/strong&gt; using theÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg" target="_blank" rel="noopener"
&gt;Cluster Group&lt;/a&gt;Â APIÂ &lt;code&gt;cluster.sync()&lt;/code&gt;. Cluster group also provides member functions to query cluster group size in terms of number of threads or number of blocks usingÂ &lt;code&gt;num_threads()&lt;/code&gt;Â andÂ &lt;code&gt;num_blocks()&lt;/code&gt;Â API respectively. The rank of a thread or block in the cluster group can be queried usingÂ &lt;code&gt;dim_threads()&lt;/code&gt;Â andÂ &lt;code&gt;dim_blocks()&lt;/code&gt;Â API respectively.
Thread blocks that belong to a cluster have access to the &lt;strong&gt;Distributed Shared Memory&lt;/strong&gt;. Thread blocks in a cluster have the ability to read, write, and perform atomics to any address in the distributed shared memory.&lt;/p&gt;
&lt;h3 id="memory-hierarchy"&gt;Memory Hierarchy
&lt;/h3&gt;&lt;p&gt;&lt;img src="https://i.ibb.co/qMRxr4DF/image-5.png"
loading="lazy"
&gt;
There are also two additional read-only memory spaces accessible by all threads: the constant and texture memory spaces. The global, constant, and texture memory spaces are &lt;strong&gt;optimized for different memory usages&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="heterogeneous-programming"&gt;Heterogeneous Programming
&lt;/h3&gt;&lt;p&gt;The CUDA programming model also assumes that both the host and the device maintain their &lt;strong&gt;own&lt;/strong&gt; separate memory spaces in DRAM, referred to asÂ &lt;em&gt;host memory&lt;/em&gt;Â andÂ &lt;em&gt;device memory&lt;/em&gt;, respectively. Therefore, a program manages the global, constant, and texture memory spaces visible to kernels through calls to the CUDA runtime (described inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-interface" target="_blank" rel="noopener"
&gt;Programming Interface&lt;/a&gt;). This includes device memory &lt;strong&gt;allocation&lt;/strong&gt; and &lt;strong&gt;deallocation&lt;/strong&gt; as well as data &lt;strong&gt;transfer&lt;/strong&gt; between host and device memory.
Unified Memory providesÂ &lt;em&gt;managed memory&lt;/em&gt;Â to &lt;strong&gt;bridge&lt;/strong&gt; the host and device memory spaces. Managed memory is accessible from all CPUs and GPUs in the system as a single, coherent memory image with a common address space. This capability enables &lt;strong&gt;oversubscription&lt;/strong&gt; of device memory and can greatly simplify the task of porting applications by eliminating the need to explicitly mirror data on host and device.&lt;/p&gt;
&lt;h3 id="asynchronous-simt-programming-model"&gt;Asynchronous SIMT Programming Model
&lt;/h3&gt;&lt;p&gt;In the CUDA programming model a thread is the lowest level of abstraction for doing a computation or a memory operation. Starting with devices based on theÂ &lt;strong&gt;NVIDIA Ampere GPU Architecture&lt;/strong&gt;, the CUDA programming model provides acceleration to memory operations via the asynchronous programming model. The asynchronous programming model defines the behavior of asynchronous operations with respect to CUDA threads.
The asynchronous programming model defines the behavior ofÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#aw-barrier" target="_blank" rel="noopener"
&gt;Asynchronous Barrier&lt;/a&gt;Â for synchronization between CUDA threads. The model also explains and defines howÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-data-copies" target="_blank" rel="noopener"
&gt;cuda::memcpy_async&lt;/a&gt;Â can be used to move data asynchronously from global memory while computing in the GPU.
An asynchronous operation is defined as an operation that is &lt;strong&gt;initiated by a&lt;/strong&gt; CUDA thread and is &lt;strong&gt;executed asynchronously as-if by another&lt;/strong&gt; thread. In a well formed program one or more CUDA threads synchronize with the &lt;strong&gt;asynchronous operation&lt;/strong&gt;. The CUDA thread that initiated the asynchronous operation is not required to be among the synchronizing threads.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;å‘èµ·å¼‚æ­¥æ“ä½œçš„CUDAçº¿ç¨‹æ— éœ€å‚ä¸è¯¥æ“ä½œçš„åŒæ­¥ç­‰å¾…è¿‡ç¨‹ï¼Œå…¶ä»–çº¿ç¨‹å¯ä»¥ä»£æ›¿å®ƒå®ŒæˆåŒæ­¥
Such an asynchronous thread (an as-if thread) is always associated with the CUDA thread that initiated the asynchronous operation. An asynchronous operation uses a synchronization object to synchronize the completion of the operation. Such a synchronization object can be explicitly managed by a user (e.g.,Â cuda::memcpy_async) or implicitly managed within a library (e.g.,Â cooperative_groups::memcpy_async).
A synchronization object could be aÂ cuda::barrierÂ or aÂ cuda::pipeline. These objects are explained in detail inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#aw-barrier" target="_blank" rel="noopener"
&gt;Asynchronous Barrier&lt;/a&gt;Â andÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-data-copies" target="_blank" rel="noopener"
&gt;Asynchronous Data Copies using cuda::pipeline&lt;/a&gt;.
These synchronization objects can be used at &lt;strong&gt;different thread scopes&lt;/strong&gt;. A scope defines the set of threads that may use the synchronization object to synchronize with the asynchronous operation. The following table defines the thread scopes available in CUDA C++ and the threads that can be synchronized with each.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Thread Scope&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_thread&lt;/td&gt;
&lt;td&gt;Only the CUDA thread which initiated asynchronous operations synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_block&lt;/td&gt;
&lt;td&gt;All or any CUDA threads within the same thread block as the initiating thread synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_device&lt;/td&gt;
&lt;td&gt;All or any CUDA threads in the same GPU device as the initiating thread synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cuda::thread_scope::thread_scope_system&lt;/td&gt;
&lt;td&gt;All or any CUDA or CPU threads in the same system as the initiating thread synchronizes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;These thread scopes are implemented as extensions to standard C++ in theÂ &lt;a class="link" href="https://nvidia.github.io/libcudacxx/extended_api/memory_model.html#thread-scopes" target="_blank" rel="noopener"
&gt;CUDA Standard C++&lt;/a&gt;Â library.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;
&lt;h2 id="programming-interface"&gt;Programming Interface
&lt;/h2&gt;&lt;p&gt;CUDA C++ provides a simple path for users familiar with the C++ programming language to easily write programs for execution by the device.
It consists of a &lt;strong&gt;minimal set of extensions&lt;/strong&gt; to the C++ language and a &lt;strong&gt;runtime&lt;/strong&gt; library.
Any source file that contains some of these extensions must be compiled withÂ &lt;code&gt;nvcc&lt;/code&gt;.
The runtime provides C and C++ functions that execute on the host to allocate and deallocate device memory, transfer data between host memory and device memory, manage systems with multiple devices, etc.Â 
The runtime is built on top of &lt;strong&gt;a lower-level C API, the CUDA driver API&lt;/strong&gt;, which is also accessible by the application. The driver API provides an additional level of control by exposing lower-level concepts such as &lt;strong&gt;CUDA contexts&lt;/strong&gt; - the analogue of host processes for the device - and &lt;strong&gt;CUDA modules&lt;/strong&gt; - the analogue of dynamically loaded libraries for the device. Most applications do not use the driver API as they do not need this &lt;strong&gt;additional&lt;/strong&gt; level of control and when using the runtime, context and module management are &lt;strong&gt;implicit&lt;/strong&gt;, resulting in more concise code. As the runtime is interoperable with the driver API, most applications that need some driver API features can default to use the runtime API and only use the driver API where &lt;strong&gt;needed&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="nvcc"&gt;NVCC
&lt;/h3&gt;&lt;p&gt;Kernels can be written using the CUDA instruction set architecture, calledÂ &lt;em&gt;&lt;strong&gt;PTX&lt;/strong&gt;&lt;/em&gt;, which is described in the PTX reference manual. It is however usually &lt;strong&gt;more effective&lt;/strong&gt; to use a high-level programming language such as C++. In both cases, kernels must be compiled into binary code byÂ nvccÂ to execute on the device.
nvccÂ is a compiler driver that simplifies the process of compilingÂ &lt;em&gt;C++&lt;/em&gt;Â orÂ &lt;em&gt;PTX&lt;/em&gt;Â code: It provides simple and familiar command line options and executes them by invoking the collection of tools that implement the different compilation stages.Â 
Only a subset of C++ is fully supported for the device code.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CUDAè®¾å¤‡ä»£ç ï¼ˆdevice codeï¼‰ä»…æ”¯æŒéƒ¨åˆ†C++è¯­æ³•ï¼Œè¿™æ˜¯ç”±GPUç¡¬ä»¶æ¶æ„ã€æ‰§è¡Œæ¨¡å‹å’Œç¼–è¯‘å™¨è®¾è®¡çš„æœ¬è´¨å·®å¼‚å†³å®šçš„ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="offline-compilation"&gt;Offline Compilation
&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;Source files compiled withÂ nvccÂ can include a mix of host code (i.e., code that executes on the host) and device code (i.e., code that executes on the device).Â nvccâ€™s basic workflow consists in **separating** device code from host code and then:
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;compiling the device code into an &lt;strong&gt;assembly form&lt;/strong&gt; (&lt;em&gt;PTX&lt;/em&gt;Â code) and/or &lt;strong&gt;binary form&lt;/strong&gt; (&lt;em&gt;cubin&lt;/em&gt;Â object),&lt;/li&gt;
&lt;li&gt;and modifying the host code by &lt;strong&gt;replacing&lt;/strong&gt; theÂ &amp;laquo;&amp;lt;&amp;hellip;&amp;raquo;&amp;gt;Â syntax introduced inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#kernels" target="_blank" rel="noopener"
&gt;Kernels&lt;/a&gt;Â (and described in more details inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;) by the necessary CUDA runtime function calls to load and launch each compiled kernel &lt;strong&gt;from&lt;/strong&gt; theÂ &lt;em&gt;PTX&lt;/em&gt;Â code and/orÂ &lt;em&gt;cubin&lt;/em&gt;Â object.
The modified host code is output either as C++ code that is left to be compiled using another tool or as object code directly by lettingÂ nvccÂ invoke the host compiler during the last compilation stage.
Applications can then:&lt;/li&gt;
&lt;li&gt;Either link to the compiled host code (this is the most common case),&lt;/li&gt;
&lt;li&gt;Or &lt;strong&gt;ignore&lt;/strong&gt; the modified host code (if any) and use the CUDA driver API (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#driver-api" target="_blank" rel="noopener"
&gt;Driver API&lt;/a&gt;) to load and execute theÂ &lt;em&gt;PTX&lt;/em&gt;Â code orÂ &lt;em&gt;cubin&lt;/em&gt;Â object.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="just-in-time-compilation"&gt;Just-in-Time Compilation
&lt;/h4&gt;&lt;p&gt;AnyÂ &lt;em&gt;PTX&lt;/em&gt;Â code loaded by an application at runtime is &lt;strong&gt;compiled further to binary code&lt;/strong&gt; by the device driver. This is calledÂ &lt;em&gt;just-in-time compilation&lt;/em&gt;. Just-in-time compilation increases application load time, but allows the application to &lt;strong&gt;benefit&lt;/strong&gt; from any new compiler improvements coming with each new device driver. It is also the only way for applications to run on devices that &lt;strong&gt;did not exist&lt;/strong&gt; at the time the application was compiled.
As an alternative to usingÂ &lt;code&gt;nvcc&lt;/code&gt;Â to compile CUDA C++ device code, &lt;strong&gt;NVRTC&lt;/strong&gt; can be used to compile CUDA C++ device code to PTX at runtime.&lt;/p&gt;
&lt;h4 id="compatibility"&gt;Compatibility
&lt;/h4&gt;&lt;p&gt;Binary code is &lt;strong&gt;architecture-specific.&lt;/strong&gt; AÂ &lt;em&gt;cubin&lt;/em&gt;Â object is generated using the compiler optionÂ &lt;code&gt;-code&lt;/code&gt;Â that specifies the targeted architecture: For example, compiling withÂ &lt;code&gt;-code=sm_80&lt;/code&gt;Â produces binary code for devices ofÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability" target="_blank" rel="noopener"
&gt;compute capability&lt;/a&gt;Â 8.0. Binary compatibility is guaranteed from one minor revision to the next one, but not from one minor revision to the previous one or across major revisions. In other words, aÂ &lt;em&gt;cubin&lt;/em&gt;Â object generated for compute capabilityÂ &lt;em&gt;X.y&lt;/em&gt;Â will only execute on devices of compute capabilityÂ &lt;em&gt;X.z&lt;/em&gt;Â whereÂ &lt;em&gt;zâ‰¥y&lt;/em&gt;.
SomeÂ &lt;em&gt;PTX&lt;/em&gt;Â instructions are &lt;strong&gt;only supported on devices of higher compute capabilities&lt;/strong&gt;. For example,Â &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-shuffle-functions" target="_blank" rel="noopener"
&gt;Warp Shuffle Functions&lt;/a&gt;Â are only supported on devices of compute capability 5.0 and above. TheÂ &lt;code&gt;-arch&lt;/code&gt;Â compiler option &lt;strong&gt;specifies the compute capability that is assumed when compiling C++ toÂ &lt;em&gt;PTX&lt;/em&gt;Â code&lt;/strong&gt;. So, code that contains warp shuffle, for example, must be compiled withÂ -arch=compute_50Â (or higher).
&lt;em&gt;PTX&lt;/em&gt;Â code produced for some specific compute capability can always be compiled to binary code of &lt;strong&gt;greater or equal&lt;/strong&gt; compute capability. Note that a binary compiled from an earlier PTX version &lt;strong&gt;may not&lt;/strong&gt; make use of some hardware features. For example, a binary targeting devices of compute capability 7.0 (Volta) compiled from PTX generated for compute capability 6.0 (Pascal) will not make use of Tensor Core instructions, since these were not available on Pascal. As a result, the final binary may &lt;strong&gt;perform worse&lt;/strong&gt; than would be possible if the binary were generated using the latest version of PTX.
&lt;em&gt;PTX&lt;/em&gt;Â code compiled to targetÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#architecture-specific-features" target="_blank" rel="noopener"
&gt;Architecture-Specific Features&lt;/a&gt;Â only runs on &lt;strong&gt;the exact same&lt;/strong&gt; physical architecture and nowhere else. Architecture-specificÂ &lt;em&gt;PTX&lt;/em&gt;Â code is not forward and backward compatible. Example code compiled withÂ sm_90aÂ orÂ compute_90aÂ only runs on devices with compute capability 9.0 and is not backward or forward compatible.
&lt;em&gt;PTX&lt;/em&gt;Â code compiled to targetÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#family-specific-features" target="_blank" rel="noopener"
&gt;Family-Specific Features&lt;/a&gt;Â only runs on the exact same physical architecture and other architectures in the same family. Family-specificÂ &lt;em&gt;PTX&lt;/em&gt;Â code is &lt;strong&gt;forward&lt;/strong&gt; compatible with other devices in the same family, and is not backward compatible. Example code compiled withÂ sm_100fÂ orÂ compute_100fÂ only runs on devices with compute capability 10.0 and 10.3.
WhichÂ &lt;em&gt;PTX&lt;/em&gt;Â and binary code gets embedded in a CUDA C++ application is controlled by theÂ -archÂ andÂ -codeÂ compiler options or theÂ -gencodeÂ compiler option.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;nvcc x.cu -gencode &lt;span class="nv"&gt;arch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;compute_50,code&lt;span class="o"&gt;=&lt;/span&gt;sm_50
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Applications using the driver API &lt;strong&gt;must&lt;/strong&gt; compile code to separate files and explicitly load and execute the most appropriate file at runtime.&lt;/p&gt;
&lt;h3 id="runtime"&gt;Runtime
&lt;/h3&gt;&lt;p&gt;The runtime is implemented in theÂ cudartÂ library, which is linked to the application, either &lt;strong&gt;statically&lt;/strong&gt; viaÂ &lt;code&gt;cudart.lib&lt;/code&gt;Â orÂ &lt;code&gt;libcudart.a&lt;/code&gt;, or dynamically viaÂ &lt;code&gt;cudart.dll&lt;/code&gt;Â orÂ &lt;code&gt;libcudart.so&lt;/code&gt;. Applications that requireÂ cudart.dllÂ and/orÂ cudart.soÂ for dynamic linking typically include them as part of the application installation package. It is only safe to pass the address of CUDA runtime symbols between components that link to the same instance of the CUDA runtime.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;cudart.lib å’Œ libcudart.a éƒ½æ˜¯ &lt;strong&gt;CUDA Runtime åº“çš„é™æ€é“¾æ¥ç‰ˆæœ¬&lt;/strong&gt;ï¼Œæ ¸å¿ƒåŒºåˆ«åœ¨äº &lt;strong&gt;æ“ä½œç³»ç»Ÿå¹³å°å’Œç¼–è¯‘å·¥å…·é“¾çš„å…¼å®¹æ€§&lt;/strong&gt;ã€‚
&lt;strong&gt;cudart.lib&lt;/strong&gt; / &lt;strong&gt;cudart.dll&lt;/strong&gt;: windows
&lt;strong&gt;libcudart.a&lt;/strong&gt; / cudart.soÂ : Linux / macos
All its entry points are &lt;strong&gt;prefixed withÂ cuda&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="initialization"&gt;Initialization
&lt;/h4&gt;&lt;p&gt;CUDA 12.0&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ ¸å¿ƒå˜åŒ–&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cudaInitDevice() ä¸ cudaSetDevice() &lt;strong&gt;åœ¨CUDA 12.0ä¸­æˆä¸º&lt;/strong&gt;æ˜¾å¼åˆå§‹åŒ–å…¥å£&lt;/strong&gt;ã€‚è°ƒç”¨äºŒè€…ä¹‹ä¸€ä¼šç«‹å³ï¼šâœ… åˆå§‹åŒ–CUDAè¿è¡Œæ—¶åº“âœ… åˆ›å»ºæŒ‡å®šè®¾å¤‡çš„Primary Contextï¼ˆä¸»ä¸Šä¸‹æ–‡ï¼‰&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœªè°ƒç”¨æ—¶çš„é»˜è®¤è¡Œä¸º&lt;/strong&gt; ï¼šè¿è¡Œæ—¶è‡ªåŠ¨é€‰æ‹©device 0ï¼Œå¹¶åœ¨é¦–æ¬¡éœ€è¦æ—¶éšå¼åˆå§‹åŒ–ï¼ˆå¦‚è°ƒç”¨cudaMallocæˆ–å†…æ ¸å¯åŠ¨ï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å·¥ç¨‹æ„ä¹‰&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½åˆ†æ&lt;/strong&gt; ï¼šæ˜¾å¼åˆå§‹åŒ–å°†è€—æ—¶é›†ä¸­åœ¨å¯æ§é˜¶æ®µï¼Œé¿å…é¦–æ¬¡APIè°ƒç”¨çš„å»¶è¿Ÿå¹²æ‰°è®¡æ—¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é”™è¯¯å¤„ç†&lt;/strong&gt; ï¼šå¿…é¡»æ£€æŸ¥cudaSetDevice()çš„è¿”å›å€¼ï¼ˆå¦‚cudaError_tï¼‰ï¼Œå› å…¶å¯èƒ½è¿”å›è®¾å¤‡åˆå§‹åŒ–é”™è¯¯ï¼ˆå¦‚cudaErrorInvalidDeviceï¼‰
å†å²è¡Œä¸ºï¼ˆCUDA 11.xåŠæ›´æ—©ï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaSetDevice()çš„å±€é™æ€§ &lt;strong&gt;ï¼šä»…è®¾ç½®å½“å‰è®¾å¤‡ï¼Œ&lt;/strong&gt; ä¸è§¦å‘è¿è¡Œæ—¶åˆå§‹åŒ–&lt;/strong&gt;ã€‚è¿è¡Œæ—¶éœ€é€šè¿‡å…¶ä»–APIè°ƒç”¨è¢«åŠ¨åˆå§‹åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaFree(0)çš„å¦™ç”¨ &lt;strong&gt;ï¼šå¼€å‘è€…è°ƒç”¨æ­¤&amp;quot;ç©ºæ“ä½œ&amp;quot;å‡½æ•°ï¼ˆé‡Šæ”¾ç©ºæŒ‡é’ˆï¼‰ä½œä¸º&lt;/strong&gt;æ˜¾å¼åˆå§‹åŒ–è§¦å‘å™¨&lt;/strong&gt;ï¼Œç›®çš„åŒ…æ‹¬ï¼šâœ… éš”ç¦»åˆå§‹åŒ–è€—æ—¶ï¼ˆæ–¹ä¾¿æ€§èƒ½åˆ†æï¼‰âœ… æå‰æ•è·åˆå§‹åŒ–é”™è¯¯ï¼ˆé¿å…é¦–æ¬¡ä¸šåŠ¡APIè°ƒç”¨å¤±è´¥ï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaSetDevice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// è®¾ç½®è®¾å¤‡ï¼ˆä¸åˆå§‹åŒ–è¿è¡Œæ—¶ï¼‰
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// å¼ºåˆ¶åˆå§‹åŒ–è¿è¡Œæ—¶å¹¶æ£€æŸ¥é”™è¯¯
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaError_t&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cudaGetLastError&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// éªŒè¯åˆå§‹åŒ–çŠ¶æ€
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The runtime creates a CUDA context for each device in the system (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#context" target="_blank" rel="noopener"
&gt;Context&lt;/a&gt;Â for more details on CUDA contexts). This context is theÂ &lt;strong&gt;primary context&lt;/strong&gt;Â for this device and is initialized at &lt;strong&gt;the first runtime&lt;/strong&gt; function which requires an active context on this device. It is &lt;strong&gt;shared among all the host threads&lt;/strong&gt; of the application. As part of this context creation, the device code is just-in-time compiled if necessary (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#just-in-time-compilation" target="_blank" rel="noopener"
&gt;Just-in-Time Compilation&lt;/a&gt;) and loaded into device memory. This all happens transparently.&lt;/p&gt;
&lt;h4 id="device-memory"&gt;Device Memory
&lt;/h4&gt;&lt;p&gt;Device memory can be allocated either asÂ &lt;em&gt;&lt;strong&gt;linear memory&lt;/strong&gt;&lt;/em&gt;Â or asÂ &lt;em&gt;&lt;strong&gt;CUDA arrays&lt;/strong&gt;&lt;/em&gt;.
CUDA arrays are opaque memory layouts optimized for texture fetching. They are described inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#texture-and-surface-memory" target="_blank" rel="noopener"
&gt;Texture and Surface Memory&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¸é€æ˜å†…å­˜å¸ƒå±€ï¼ˆOpaque Memory Layoutï¼‰&lt;/strong&gt; ï¼šCUDAæ•°ç»„çš„ç‰©ç†å­˜å‚¨ç»“æ„å¯¹å¼€å‘è€…å®Œå…¨éšè—ï¼Œæ— æ³•é€šè¿‡æŒ‡é’ˆç›´æ¥è®¿é—®å†…éƒ¨æ•°æ®ã€‚å…¶å¸ƒå±€ç”±GPUé©±åŠ¨åŠ¨æ€ä¼˜åŒ–ï¼Œä¸“ä¸º&lt;strong&gt;çº¹ç†æ‹¾å–ï¼ˆTexture Fetchingï¼‰&lt;/strong&gt; åœºæ™¯è®¾è®¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;çº¹ç†/è¡¨é¢å†…å­˜ä¼˜åŒ–&lt;/strong&gt; ï¼šæ•°æ®ä»¥é€‚åˆçº¹ç†ç¼“å­˜çš„æ ¼å¼å­˜å‚¨ï¼Œæ”¯æŒç¡¬ä»¶åŠ é€Ÿçš„&lt;strong&gt;åæ ‡å¯»å€ã€æ»¤æ³¢ï¼ˆå¦‚åŒçº¿æ€§æ’å€¼ï¼‰å’Œè¾¹ç•Œå¤„ç†&lt;/strong&gt; ï¼ˆé’³ä½/å¾ªç¯æ¨¡å¼ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¤šç»´æ•°æ®ç»“æ„&lt;/strong&gt; ï¼šå¤©ç„¶æ”¯æŒ&lt;strong&gt;ä¸€ç»´ã€äºŒç»´æˆ–ä¸‰ç»´&lt;/strong&gt;æ•°æ®ï¼ˆå¦‚å›¾åƒã€ä½“æ¸²æŸ“æ•°æ®ï¼‰ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—å†…å­˜æ­¥é•¿ï¼ˆPitchï¼‰ã€‚
Linear memory is allocated in a single unified address space, which means that separately allocated entities can reference one another via pointers, for example, in a binary tree or linked list.Â 
æ”¯æŒä»»æ„æ•°æ®ç»“æ„ï¼Œä½†&lt;strong&gt;å¤šç»´æ•°æ®éœ€å¯¹é½&lt;/strong&gt; ï¼ˆç”¨cudaMallocPitch/cudaMalloc3Dé¿å…Bank Conflictï¼‰
Linear memory is typically allocated usingÂ &lt;code&gt;cudaMalloc()&lt;/code&gt;Â and freed usingÂ &lt;code&gt;cudaFree()&lt;/code&gt;Â and data transfer between host memory and device memory are typically done usingÂ &lt;code&gt;cudaMemcpy()&lt;/code&gt;.
Linear memory can also be allocated throughÂ &lt;code&gt;cudaMallocPitch()&lt;/code&gt;Â andÂ &lt;code&gt;cudaMalloc3D()&lt;/code&gt;. These functions are recommended for allocations of 2D or 3D arrays as it makes sure that the allocation is &lt;strong&gt;appropriately padded&lt;/strong&gt; to meet the alignment requirements described inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses" target="_blank" rel="noopener"
&gt;Device Memory Accesses&lt;/a&gt;, therefore &lt;strong&gt;ensuring best performance&lt;/strong&gt; when accessing the row addresses or performing copies between 2D arrays and other regions of device memory (using theÂ &lt;code&gt;cudaMemcpy2D()&lt;/code&gt;Â andÂ &lt;code&gt;cudaMemcpy3D()&lt;/code&gt;Â functions). The returned pitch (or stride) must be used to access array elements.Â &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Host code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaMallocPitch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Device code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MyKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;devPtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)((&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;devPtr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;pitch&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Pitch: &lt;strong&gt;æ¯è¡Œå®é™…åˆ†é…çš„å­—èŠ‚æ•°&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="shared-memory"&gt;Shared Memory
&lt;/h4&gt;&lt;p&gt;&lt;img src="https://i.ibb.co/jNV47KT/image-6.png"
loading="lazy"
&gt;
Thread Block ä¸­çš„æ¯ä¸ª Thread åˆåŠ›è¿›è¡Œæ•°æ®åŠ è½½ï¼Œä¸€æ¬¡åŠ è½½ä¸€å—&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrices are stored in row-major order:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// M(row, col) = *(M.elements + row * M.stride + col)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;typedef&lt;/span&gt; &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Get a matrix element
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;GetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Set a matrix element
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;SetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Get the BLOCK_SIZExBLOCK_SIZE sub-matrix Asub of A that is
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// located col sub-matrices to the right and row sub-matrices down
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// from the upper-left corner of A
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="nf"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Thread block size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#define BLOCK_SIZE 16
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Forward declaration of the matrix multiplication kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MatMulKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrix multiplication - Host code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrix dimensions are assumed to be multiples of BLOCK_SIZE
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MatMul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Load A and B to device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Allocate C in device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stride&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Invoke kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;dim3&lt;/span&gt; &lt;span class="n"&gt;dimGrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;MatMulKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dimGrid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dimBlock&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Read C from device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Free device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_C&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elements&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Matrix multiplication kernel called by MatMul()
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;MatMulKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Block row and column
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;blockRow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;blockCol&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Each thread block computes one sub-matrix Csub of C
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Csub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockRow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockCol&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Each thread computes one element of Csub
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// by accumulating results into Cvalue
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;Cvalue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Thread row and column within Csub
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Loop over all the sub-matrices of A and B that are
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// required to compute Csub
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Multiply each pair of sub-matrices together
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// and accumulate the results
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Get sub-matrix Asub of A
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Asub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockRow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Get sub-matrix Bsub of B
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="n"&gt;Bsub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetSubMatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockCol&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Shared memory used to store Asub and Bsub respectively
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;As&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;Bs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Load Asub and Bsub from device memory to shared memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Each thread loads one element of each sub-matrix
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;As&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Asub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Bs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Bsub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Synchronize to make sure the sub-matrices are loaded
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// before starting the computation
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__syncthreads&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Multiply Asub and Bsub together
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;BLOCK_SIZE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Cvalue&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;As&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Bs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Synchronize to make sure that the preceding
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// computation is done before loading two new
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// sub-matrices of A and B in the next iteration
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;__syncthreads&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Write Csub to device memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Each thread writes one element
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;SetElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Csub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Cvalue&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id="distributed-shared-memory"&gt;Distributed Shared Memory
&lt;/h4&gt;&lt;p&gt;Accessing data in distributed shared memory requires all the thread blocks to exist. A user can &lt;strong&gt;guarantee&lt;/strong&gt; that all thread blocks have started executing usingÂ &lt;code&gt;cluster.sync()&lt;/code&gt;Â fromÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg" target="_blank" rel="noopener"
&gt;Cluster Group&lt;/a&gt;Â API. The user also needs to ensure that all distributed shared memory operations happen &lt;strong&gt;before the exit&lt;/strong&gt; of a thread block, e.g., if a remote thread block is trying to read a given thread blockâ€™s shared memory, user needs to ensure that the shared memory read by remote thread block is completed before it can exit.&lt;/p&gt;
&lt;h4 id="page-locked-host-memory"&gt;Page-Locked Host Memory
&lt;/h4&gt;&lt;p&gt;Page-locked host memoryï¼ˆé¡µé”å®šä¸»æœºå†…å­˜ï¼Œä¹Ÿç§°ä¸º â€œå›ºå®šå†…å­˜â€ æˆ– â€œ pinned memoryâ€ï¼‰æ˜¯ä¸€ç§ç‰¹æ®Šçš„ä¸»æœºå†…å­˜åˆ†é…æ–¹å¼ï¼Œåœ¨ CUDA ç¼–ç¨‹ä¸­å…·æœ‰é‡è¦æ€§èƒ½ä¼˜åŒ–ä½œç”¨ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ™®é€šå†…å­˜ï¼ˆpageable memoryï¼‰&lt;/strong&gt;ï¼šç”±æ“ä½œç³»ç»ŸåŠ¨æ€ç®¡ç†ï¼Œå¯è¢«æ¢å‡ºåˆ°è™šæ‹Ÿå†…å­˜ï¼ŒCPU è®¿é—®æ—¶éœ€é€šè¿‡é¡µè¡¨æ˜ å°„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é¡µé”å®šå†…å­˜&lt;/strong&gt;ï¼šé€šè¿‡cudaHostAllocæˆ–cudaHostRegisterç­‰ API åˆ†é…ï¼Œå…¶ç‰©ç†åœ°å€åœ¨å†…å­˜ä¸­ä¿æŒå›ºå®šï¼Œ&lt;strong&gt;ä¸ä¼šè¢«æ“ä½œç³»ç»Ÿæ¢å‡º&lt;/strong&gt;ï¼Œä¸” CPU å’Œ GPU å¯ç›´æ¥è®¿é—®å…¶ç‰©ç†åœ°å€ã€‚
é¡µé”å®šå†…å­˜ç»•è¿‡äº†æ“ä½œç³»ç»Ÿçš„è™šæ‹Ÿå†…å­˜ç®¡ç†æœºåˆ¶ï¼Œç›´æ¥æ˜ å°„åˆ°ç‰©ç†å†…å­˜ï¼Œé¿å…äº†é¡µé¢è°ƒåº¦ï¼ˆpage faultï¼‰çš„å¼€é”€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="memory-synchronization"&gt;Memory Synchronization
&lt;/h4&gt;&lt;p&gt;As the GPU cannot know at the time of execution which writes have been guaranteed at the source level to be visible and which are visible only by chance timing, it must cast a conservatively wide net for in-flight memory operations.
This sometimes leads to interference: because the GPU is waiting on memory operations it is not required to at the source level, the fence/flush may take longer than necessary.&lt;/p&gt;
&lt;h3 id="asynchronous-concurrent-execution"&gt;Asynchronous Concurrent Execution
&lt;/h3&gt;&lt;p&gt;CUDA exposes the following operations as independent tasks that can operate concurrently with one another:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computation on the host;&lt;/li&gt;
&lt;li&gt;Computation on the device;&lt;/li&gt;
&lt;li&gt;Memory transfers from the host to the device;&lt;/li&gt;
&lt;li&gt;Memory transfers from the device to the host;&lt;/li&gt;
&lt;li&gt;Memory transfers within the memory of a given device;&lt;/li&gt;
&lt;li&gt;Memory transfers among devices.
The level of concurrency achieved between these operations will depend on the feature set and compute capability of the device
Using asynchronous calls, many device operations can be queued up together to be executed by the CUDA driver when appropriate device resources are available. This relieves the host thread of much of the responsibility to manage the device, leaving it free for other tasks.
Kernel launches are &lt;strong&gt;synchronous&lt;/strong&gt; if hardware counters are collected via a &lt;strong&gt;profiler&lt;/strong&gt; (Nsight, Visual Profiler) unless concurrent kernel profiling is enabled.Â AsyncÂ memory copies might also be synchronous if they involve host memory that is &lt;strong&gt;not page-locked&lt;/strong&gt;.
Concurrent host execution is facilitated through asynchronous library functions that &lt;strong&gt;return control to the host thread before the device completes the requested task&lt;/strong&gt;. Using asynchronous calls, many device operations can be queued up together to be executed by the CUDA driver when appropriate device resources are available.Â 
Programmers can globally disable asynchronicity of kernel launches for all CUDA applications running on a system by setting theÂ &lt;strong&gt;CUDA_LAUNCH_BLOCKING&lt;/strong&gt;Â environment variable to 1. This feature is provided for &lt;strong&gt;debugging purposes only&lt;/strong&gt; and should not be used as a way to make production software run reliably.
A kernel from one CUDA context cannot execute concurrently with a kernel from another CUDA context. The GPU may time slice to provide forward progress to each context. If a user wants to run kernels from multiple process simultaneously on the SM, one must &lt;strong&gt;enable MPS&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="stream"&gt;Stream
&lt;/h3&gt;&lt;p&gt;Applications manage the concurrent operations described above throughÂ &lt;em&gt;&lt;strong&gt;streams&lt;/strong&gt;&lt;/em&gt;. A stream is &lt;strong&gt;a sequence of commands&lt;/strong&gt; (possibly issued by &lt;strong&gt;different&lt;/strong&gt; host threads) that execute in order. Different streams, on the other hand, may execute their commands out of order with respect to one another or concurrently; this behavior is not guaranteed and should therefore not be relied upon for correctness (for example, inter-kernel communication is undefined). The commands issued on a stream may execute &lt;strong&gt;when all the dependencies of the command are met&lt;/strong&gt;. The dependencies could be previously launched commands on &lt;strong&gt;same&lt;/strong&gt; stream or dependencies from &lt;strong&gt;other&lt;/strong&gt; streams. The successful completion of &lt;strong&gt;synchronize&lt;/strong&gt; call guarantees that all the commands launched are completed.&lt;/p&gt;
&lt;h4 id="default-stream"&gt;default stream
&lt;/h4&gt;&lt;p&gt;Kernel launches and hostÂ device memory copies that &lt;strong&gt;do not specify&lt;/strong&gt; any stream parameter, or equivalently that set the stream parameter to &lt;strong&gt;zero&lt;/strong&gt;, are issued to the &lt;strong&gt;default&lt;/strong&gt; stream. They are therefore executed in order.
For code that is compiled using theÂ &lt;code&gt;--default-streamÂ per-thread&lt;/code&gt;Â compilation flag (or that defines theÂ &lt;code&gt;CUDA_API_PER_THREAD_DEFAULT_STREAM&lt;/code&gt;Â macro before including CUDA headers (cuda.hÂ andÂ cuda_runtime.h)), the default stream is a regular stream and each host thread has its own default stream.
For code that is compiled using theÂ &lt;code&gt;â€”default-streamÂ legacy&lt;/code&gt;Â compilation flag, the default stream is a special stream called theÂ &lt;em&gt;&lt;strong&gt;NULL stream&lt;/strong&gt;&lt;/em&gt;Â and each device has a single NULL stream used for all host threads. The NULL stream is special as it causes implicit synchronization.
For code that is compiled without specifying aÂ &lt;code&gt;â€”default-streamÂ compilation&lt;/code&gt; flag,Â &lt;code&gt;â€”default-streamÂ legacy&lt;/code&gt;Â is assumed as the &lt;strong&gt;default&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id="explicit-synchronization"&gt;explicit synchronization
&lt;/h4&gt;&lt;p&gt;There are various ways to explicitly synchronize streams with each other.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cudaDeviceSynchronize&lt;/strong&gt;()Â waits until all preceding commands in all streams of all host threads have completed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaStreamSynchronize&lt;/strong&gt;()takes a stream as a parameter and waits until all preceding commands in the given stream have completed. It can be used to synchronize the host with a specific stream, allowing other streams to continue executing on the device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaStreamWaitEvent&lt;/strong&gt;()takes a stream and an event as parameters (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#events" target="_blank" rel="noopener"
&gt;Events&lt;/a&gt;Â for a description of events)and makes all the commands added to the given stream after the call toÂ cudaStreamWaitEvent()delay their execution until the given event has completed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cudaStreamQuery&lt;/strong&gt;()provides applications with a way to know if all preceding commands in a stream have completed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="implicit-synchronization"&gt;implicit synchronization
&lt;/h4&gt;&lt;p&gt;Two operations from different streams cannot run concurrently if any CUDA operation on the &lt;strong&gt;NULL stream is submitted in-between&lt;/strong&gt; them, &lt;strong&gt;unless&lt;/strong&gt; the streams are &lt;strong&gt;non-blocking streams&lt;/strong&gt; (created with theÂ cudaStreamNonBlockingÂ flag).
Applications should follow these guidelines to improve their potential for concurrent kernel execution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All independent operations should be issued before dependent operations,&lt;/li&gt;
&lt;li&gt;Synchronization of any kind should be delayed as long as possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;é»˜è®¤æµï¼ˆNULLæµï¼‰çš„é˜»å¡æ€§&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NULLæµçš„ç‰¹æ€§&lt;/strong&gt; ï¼šé»˜è®¤æµï¼ˆæœªæ˜¾å¼æŒ‡å®šæµæ—¶ä½¿ç”¨çš„æµï¼‰å…·æœ‰&lt;strong&gt;éšå¼åŒæ­¥ä½œç”¨&lt;/strong&gt;ã€‚å½“ä¸»æœºå‘NULLæµæäº¤æ“ä½œï¼ˆå¦‚cudaMemcpyæˆ–æ ¸å‡½æ•°ï¼‰æ—¶ï¼Œå®ƒä¼šå¼ºåˆ¶ç­‰å¾…&lt;strong&gt;æ‰€æœ‰å…ˆå‰æäº¤åˆ°ä»»ä½•æµä¸­çš„æ“ä½œå®Œæˆ&lt;/strong&gt;ï¼Œè‡ªèº«æ‰§è¡Œç»“æŸååˆä¼šé˜»å¡åç»­å…¶ä»–æµçš„æ“ä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¹¶å‘ä¸­æ–­åŸå› &lt;/strong&gt; ï¼šè‹¥åœ¨ä¸¤ä¸ªä¸åŒæµçš„æ“ä½œä¹‹é—´æ’å…¥NULLæµæ“ä½œï¼ˆä¾‹å¦‚ï¼šStreamAæ“ä½œ â†’ NULLæµæ“ä½œ â†’ StreamBæ“ä½œï¼‰ï¼Œåˆ™ï¼š
&lt;ul&gt;
&lt;li&gt;NULLæµæ“ä½œä¼šç­‰å¾…StreamAæ“ä½œå®Œæˆæ‰å¼€å§‹ï¼›&lt;/li&gt;
&lt;li&gt;StreamBæ“ä½œå¿…é¡»ç­‰å¾…NULLæµæ“ä½œå®Œæˆåæ‰èƒ½å¯åŠ¨ã€‚&lt;em&gt;ç»“æœ&lt;/em&gt;ï¼šStreamAå’ŒStreamBçš„æ“ä½œè¢«&lt;strong&gt;å¼ºåˆ¶ä¸²è¡ŒåŒ–&lt;/strong&gt;ï¼Œæ— æ³•å¹¶å‘æ‰§è¡Œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;éé˜»å¡æµçš„ä¾‹å¤–&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åˆ›å»ºæ–¹å¼&lt;/strong&gt; ï¼šä½¿ç”¨cudaStreamCreateWithFlags(&amp;amp;stream, cudaStreamNonBlocking)åˆ›å»ºçš„æµç§°ä¸º&lt;strong&gt;éé˜»å¡æµ&lt;/strong&gt; ï¼ˆNon-Blocking Streamï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è§„é¿é˜»å¡&lt;/strong&gt; ï¼šéé˜»å¡æµ&lt;strong&gt;ä¸ä¸NULLæµåŒæ­¥&lt;/strong&gt;ï¼Œå› æ­¤ï¼š
&lt;ul&gt;
&lt;li&gt;å³ä½¿NULLæµæ“ä½œæ’å…¥åœ¨éé˜»å¡æµçš„æ“ä½œä¹‹é—´ï¼ˆå¦‚NonBlockingStreamAæ“ä½œ â†’ NULLæµæ“ä½œ â†’ NonBlockingStreamBæ“ä½œï¼‰ï¼ŒNonBlockingStreamAå’ŒNonBlockingStreamBçš„æ“ä½œä»å¯&lt;strong&gt;å¹¶å‘æ‰§è¡Œ&lt;/strong&gt; ã€‚&lt;/li&gt;
&lt;li&gt;NULLæµæ“ä½œä»…é˜»å¡è‡ªèº«ï¼Œä¸å½±å“éé˜»å¡æµçš„ç‹¬ç«‹æ€§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="host-functions"&gt;&lt;strong&gt;Host Functions&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;The runtime provides a way to insert a CPU function call at any point into a stream viaÂ &lt;strong&gt;cudaLaunchHostFunc&lt;/strong&gt;(). The provided function is executed on the host once all commands issued to the stream before the callback have completed.
A host function enqueued into a stream must not make CUDA API calls (directly or indirectly), as it might end up waiting on itself if it makes such a call leading to a deadlock.&lt;/p&gt;
&lt;h4 id="priority"&gt;Priority
&lt;/h4&gt;&lt;p&gt;The relative priorities of streams can be specified at creation usingÂ cudaStreamCreateWithPriority(). The range of allowable priorities, ordered as [ greatest priority, least priority ] can be obtained using theÂ cudaDeviceGetStreamPriorityRange()Â function.
These priorities serve as hints rather than guarantees.&lt;/p&gt;
&lt;h4 id="dependent-launch"&gt;Dependent Launch
&lt;/h4&gt;&lt;p&gt;TheÂ &lt;em&gt;Programmatic Dependent Launch&lt;/em&gt;Â mechanism allows for a dependentÂ &lt;em&gt;secondary&lt;/em&gt;Â kernel to launch &lt;strong&gt;before&lt;/strong&gt; theÂ &lt;em&gt;primary&lt;/em&gt;Â kernel it depends on in the same CUDA stream has finished executing. Available starting with devices of &lt;strong&gt;compute capability 9.0&lt;/strong&gt;, this technique can provide performance benefits when theÂ &lt;em&gt;secondary&lt;/em&gt;Â kernel can complete &lt;strong&gt;significant&lt;/strong&gt; work that does not depend on the results of theÂ &lt;em&gt;primary&lt;/em&gt;Â kernel.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;primary_kernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Initial work that should finish before starting secondary kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Trigger the secondary kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaTriggerProgrammaticLaunchCompletion&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Work that can coincide with the secondary kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;secondary_kernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Independent work
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Will block until all primary kernels the secondary kernel is dependent on have completed and flushed results to global memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaGridDependencySynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Dependent work
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaLaunchAttribute&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cudaLaunchAttributeProgrammaticStreamSerialization&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;programmaticStreamSerializationAllowed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;configSecondary&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;configSecondary&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numAttrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;primary_kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;grid_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;block_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaLaunchKernelEx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;configSecondary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;secondary_kernel&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="events"&gt;Events
&lt;/h3&gt;&lt;p&gt;The runtime also provides a way to closely monitor the deviceâ€™s progress, as well as perform accurate timing, by letting the application asynchronously recordÂ &lt;em&gt;&lt;strong&gt;events&lt;/strong&gt;&lt;/em&gt;Â at any point in the program, and query when these events are completed. An event has completed when all tasks - or optionally, all commands in a given stream - preceding the event have completed. Events in &lt;strong&gt;stream zero&lt;/strong&gt; are completed after all preceding tasks and commands in &lt;strong&gt;all streams&lt;/strong&gt; are completed.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEvent_t&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventCreate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventCreate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventDestroy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventDestroy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Timing&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventRecord&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputHost&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;MyKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputHost&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;outputDev&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventRecord&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventSynchronize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;elapsedTime&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaEventElapsedTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;elapsedTime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="error-checking"&gt;Error Checking
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;All runtime functions return an error code&lt;/strong&gt;, but for an asynchronous function (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-concurrent-execution" target="_blank" rel="noopener"
&gt;Asynchronous Concurrent Execution&lt;/a&gt;), this error code cannot possibly report any of the asynchronous errors that could occur on the device since the function returns before the device has completed the task; the error code only reports errors that occur on the host prior to executing the task, typically related to parameter validation; if an asynchronous error occurs, it will be reported by some subsequent unrelated runtime function call.
The only way to check for asynchronous errors just after some asynchronous function call is therefore to &lt;strong&gt;synchronize just after the call&lt;/strong&gt; by callingÂ cudaDeviceSynchronize()Â (or by using any other synchronization mechanisms described inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-concurrent-execution" target="_blank" rel="noopener"
&gt;Asynchronous Concurrent Execution&lt;/a&gt;) and checking the error code returned byÂ cudaDeviceSynchronize().
The runtime maintains an error variable for each host thread that is initialized toÂ cudaSuccessÂ and is overwritten by the error code every time an error occurs (be it a parameter validation error or an asynchronous error).Â &lt;strong&gt;cudaPeekAtLastError&lt;/strong&gt;()Â returns this variable.Â &lt;strong&gt;cudaGetLastError&lt;/strong&gt;()Â returns this variable and &lt;strong&gt;resets&lt;/strong&gt; it toÂ cudaSuccess.
Kernel launches do not return any error code, soÂ cudaPeekAtLastError()Â orÂ cudaGetLastError()Â &lt;strong&gt;must be called just after the kernel launch to retrieve any pre-launch errors&lt;/strong&gt;. To ensure that any error returned byÂ cudaPeekAtLastError()Â orÂ cudaGetLastError()Â does not originate from calls prior to the kernel launch, one has to make sure that the runtime error variable is set toÂ cudaSuccessÂ just before the kernel launch, for example, by callingÂ cudaGetLastError()Â just before the kernel launch. Kernel launches are asynchronous, so to check for asynchronous errors, the application must &lt;strong&gt;synchronize in-between&lt;/strong&gt; the kernel launch and the call toÂ cudaPeekAtLastError()Â orÂ cudaGetLastError().
Note thatÂ cudaErrorNotReadyÂ that may be returned byÂ cudaStreamQuery()Â andÂ cudaEventQuery()Â is not considered an error and is therefore not reported byÂ cudaPeekAtLastError()Â orÂ cudaGetLastError().&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®¾è®¡é€»è¾‘&lt;/strong&gt; ï¼šcudaErrorNotReady æ˜¯æ­£å¸¸çŠ¶æ€ï¼ˆè¡¨ç¤ºâ€œè¿›è¡Œä¸­â€ï¼‰ï¼Œè€Œéé”™è¯¯&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="compute-mode"&gt;Compute Mode
&lt;/h3&gt;&lt;p&gt;On Tesla solutions running Windows Server 2008 and later or Linux, one can set any device in a system in one of the three following modes using &lt;strong&gt;NVIDIAâ€™s System Management Interface (nvidia-smi)&lt;/strong&gt;, which is a tool distributed as part of the driver:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Default&lt;/em&gt;Â compute mode&lt;/strong&gt;: Multiple host threads can use the device (by callingÂ cudaSetDevice()Â on this device, when using the runtime API, or by making current a context associated to the device, when using the driver API) at the same time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Exclusive-process&lt;/em&gt;Â compute mode&lt;/strong&gt;: Only one CUDA context may be created on the device across all processes in the system. The context may be current to as many threads as desired within the process that created that context.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Prohibited&lt;/em&gt;Â compute mode&lt;/strong&gt;: No CUDA context can be created on the device.
â €This means, in particular, that a host thread using the runtime API without explicitly callingÂ cudaSetDevice()Â might be associated with a device &lt;strong&gt;other than device 0&lt;/strong&gt; if device 0 turns out to be in prohibited mode or in exclusive-process mode and used by another process.Â cudaSetValidDevices()Â can be used to set a device from a prioritized list of devices.
Note also that, for devices featuring the Pascal architecture onwards (compute capability with major revision number 6 and higher), there exists support for &lt;strong&gt;Compute Preemption&lt;/strong&gt;. This allows compute tasks to be preempted at instruction-level granularity, rather than thread block granularity as in prior Maxwell and Kepler GPU architecture, with the benefit that applications with long-running kernels can be prevented from either monopolizing the system or timing out. However, there will be &lt;strong&gt;context switch overheads&lt;/strong&gt; associated with Compute Preemption, which is &lt;strong&gt;automatically enabled&lt;/strong&gt; on those devices for which support exists. The individual attribute query functionÂ cudaDeviceGetAttribute()Â with the attributeÂ &lt;strong&gt;cudaDevAttrComputePreemptionSupported&lt;/strong&gt;Â can be used to determine if the device in use supports Compute Preemption. Users wishing to avoid context switch overheads associated with different processes can ensure that only one process is active on the GPU by &lt;strong&gt;selecting exclusive-process mode&lt;/strong&gt;.
Applications may query the compute mode of a device by checking theÂ computeModeÂ device property (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-enumeration" target="_blank" rel="noopener"
&gt;Device Enumeration&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="hardware-implementation"&gt;Hardware Implementation
&lt;/h2&gt;&lt;p&gt;The NVIDIA GPU architecture is built around a &lt;strong&gt;scalable&lt;/strong&gt; array of &lt;strong&gt;multithreadedÂ &lt;em&gt;Streaming Multiprocessors&lt;/em&gt;&lt;/strong&gt;Â (&lt;em&gt;SMs&lt;/em&gt;). When a CUDA program on the host CPU invokes a kernel grid, the blocks of the grid are enumerated and distributed to multiprocessors with available execution capacity. The threads of a thread block execute concurrently on one multiprocessor, and multiple thread blocks can execute concurrently on one multiprocessor. As thread blocks terminate, new blocks are launched on the vacated multiprocessors.
A multiprocessor is designed to execute hundreds of threads concurrently. To manage such a large number of threads, it employs a unique architecture calledÂ &lt;em&gt;&lt;strong&gt;SIMT&lt;/strong&gt;&lt;/em&gt;Â (&lt;em&gt;Single-Instruction, Multiple-Thread&lt;/em&gt;) that is described inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture" target="_blank" rel="noopener"
&gt;SIMT Architecture&lt;/a&gt;. The instructions are pipelined, leveraging instruction-level parallelism within a single thread, as well as extensive thread-level parallelism through simultaneous hardware multithreading as detailed inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading" target="_blank" rel="noopener"
&gt;Hardware Multithreading&lt;/a&gt;. Unlike CPU cores, they are issued in order and there is no branch prediction or speculative execution.
The NVIDIA GPU architecture uses a &lt;strong&gt;little-endian&lt;/strong&gt; representation.&lt;/p&gt;
&lt;h3 id="simt"&gt;SIMT
&lt;/h3&gt;&lt;p&gt;The multiprocessor creates, manages, schedules, and executes threads in &lt;strong&gt;groups of 32 parallel threads&lt;/strong&gt; calledÂ &lt;em&gt;warps&lt;/em&gt;. Individual threads composing a warp start together at the same program address, but they have their own instruction address counter and register state and are therefore free to branch and execute independently. The termÂ &lt;em&gt;warp&lt;/em&gt;Â originates from &lt;strong&gt;weaving&lt;/strong&gt;, the first parallel thread technology. AÂ &lt;em&gt;half-warp&lt;/em&gt;Â is either the first or second half of a warp. AÂ &lt;em&gt;quarter-warp&lt;/em&gt;Â is either the first, second, third, or fourth quarter of a warp.
When a multiprocessor is &lt;strong&gt;given one or more thread blocks&lt;/strong&gt; to execute, it partitions them into warps and each warp gets scheduled by aÂ &lt;em&gt;&lt;strong&gt;warp scheduler&lt;/strong&gt;&lt;/em&gt;Â for execution. The way a block is partitioned into warps is always the same; each warp contains threads of consecutive, increasing thread IDs with the first warp containing thread 0.Â &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy" target="_blank" rel="noopener"
&gt;Thread Hierarchy&lt;/a&gt;Â describes how thread IDs relate to thread indices in the block.
A warp executes one common instruction at a time, so &lt;strong&gt;full&lt;/strong&gt; efficiency is realized when all 32 threads of a warp &lt;strong&gt;agree&lt;/strong&gt; on their execution path. If threads of a warp diverge via a data-dependent conditional branch, the warp &lt;strong&gt;executes each&lt;/strong&gt; branch path taken, disabling threads that are not on that path. Branch divergence occurs only within a warp; different warps execute independently regardless of whether they are executing common or disjoint code paths.
The SIMT architecture is &lt;strong&gt;akin&lt;/strong&gt; to SIMD (Single Instruction, Multiple Data) vector organizations in that a single instruction controls multiple processing elements. A key difference is that SIMD vector organizations expose the SIMD width to the software, whereas SIMT instructions specify the execution and branching behavior of a single thread. In contrast with SIMD vector machines, SIMT enables programmers to write &lt;strong&gt;thread-level parallel&lt;/strong&gt; code for independent, scalar threads, as well as data-parallel code for coordinated threads. For the purposes of correctness, the programmer can essentially ignore the SIMT behavior; however, substantial performance improvements can be realized by taking care that the code seldom requires threads in a warp to diverge. In practice, this is analogous to the role of cache lines in traditional code: Cache line size can be safely ignored when designing for correctness but must be considered in the code structure when designing for peak performance. Vector architectures, on the other hand, require the software to coalesce loads into vectors and manage divergence manually.
&lt;strong&gt;Prior to NVIDIA Volta, warps used a single program counter shared amongst all 32 threads in the warp together with an active mask specifying the active threads of the warp&lt;/strong&gt;. As a result, threads from the same warp in divergent regions or different states of execution cannot signal each other or exchange data, and algorithms requiring fine-grained sharing of data guarded by locks or mutexes can easily lead to deadlock, depending on which warp the contending threads come from.
Starting with the NVIDIA Volta architecture,Â &lt;em&gt;&lt;strong&gt;Independent Thread Scheduling&lt;/strong&gt;&lt;/em&gt;Â allows full concurrency between threads, regardless of warp. With Independent Thread Scheduling, the GPU maintains execution state per thread, including a program counter and call stack, and can yield execution at a per-thread granularity, either to make better use of execution resources or to allow one thread to wait for data to be produced by another. &lt;strong&gt;A schedule optimizer determines how to group active threads from the same warp together into SIMT units&lt;/strong&gt;. This retains the high throughput of SIMT execution as in prior NVIDIA GPUs, but with much more flexibility: threads can now diverge and reconverge at sub-warp granularity.
Independent Thread Scheduling can lead to a rather different set of threads participating in the executed code than intended if the developer made assumptions about warp-synchronicity&lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#fn2" target="_blank" rel="noopener"
&gt;2&lt;/a&gt;Â of previous hardware architectures. In particular, any warp-synchronous code (such as synchronization-free, intra-warp reductions) should be &lt;strong&gt;revisited&lt;/strong&gt; to ensure compatibility with NVIDIA Volta and beyond. SeeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x" target="_blank" rel="noopener"
&gt;Compute Capability 7.x&lt;/a&gt;Â for further details.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The threads of a warp that are participating in the current instruction are called theÂ &lt;em&gt;&lt;strong&gt;active&lt;/strong&gt;&lt;/em&gt;Â threads, whereas threads not on the current instruction areÂ &lt;em&gt;inactive&lt;/em&gt;Â (disabled). Threads can be inactive for a variety of reasons including having exited earlier than other threads of their warp, having taken a different branch path than the branch path currently executed by the warp, or being the last threads of a block whose number of threads is not a multiple of the warp size.
If a &lt;strong&gt;non-atomic&lt;/strong&gt; instruction executed by a warp writes to the same location in global or shared memory for more than one of the threads of the warp, the number of serialized writes that occur to that location varies depending on the compute capability of the device (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-5-x" target="_blank" rel="noopener"
&gt;Compute Capability 5.x&lt;/a&gt;,Â &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-6-x" target="_blank" rel="noopener"
&gt;Compute Capability 6.x&lt;/a&gt;, andÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x" target="_blank" rel="noopener"
&gt;Compute Capability 7.x&lt;/a&gt;), and which thread performs the final write is undefined.
If anÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions" target="_blank" rel="noopener"
&gt;atomic&lt;/a&gt;Â instruction executed by a warp reads, modifies, and writes to the same location in global memory for more than one of the threads of the warp, each read/modify/write to that location occurs and they are all serialized, but the order in which they occur is undefined.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="hardware-multithreading"&gt;Hardware Multithreading
&lt;/h3&gt;&lt;p&gt;The execution &lt;strong&gt;context&lt;/strong&gt; (program counters, registers, and so on) for each warp processed by a multiprocessor is maintained on-chip during the entire lifetime of the warp. Therefore, switching from one execution context to another has &lt;strong&gt;no&lt;/strong&gt; &lt;strong&gt;cost&lt;/strong&gt;, and at every instruction issue time, a warp scheduler &lt;strong&gt;selects&lt;/strong&gt; a warp that has threads ready to execute its next instruction (theÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture-notes" target="_blank" rel="noopener"
&gt;active threads&lt;/a&gt;Â of the warp) and issues the instruction to those threads.
In particular, each multiprocessor has a set of 32-bit registers that are partitioned among the warps, and aÂ &lt;em&gt;parallel data cache&lt;/em&gt;Â orÂ &lt;em&gt;&lt;strong&gt;shared memory&lt;/strong&gt;&lt;/em&gt;Â that is partitioned among the thread blocks.
The number of blocks and warps that can reside and be processed together on the multiprocessor for a given kernel depends on the amount of registers and shared memory used by the kernel and the amount of registers and shared memory available on the multiprocessor. There are also a &lt;strong&gt;maximum number&lt;/strong&gt; of resident blocks and a maximum number of resident warps per multiprocessor. These limits as well the amount of registers and shared memory available on the multiprocessor are a function of the compute capability of the device and are given inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities" target="_blank" rel="noopener"
&gt;Compute Capabilities&lt;/a&gt;. If there are not enough registers or shared memory available per multiprocessor to process &lt;strong&gt;at least one block&lt;/strong&gt;, the kernel will fail to launch.&lt;/p&gt;
&lt;h2 id="cooperative-groups"&gt;Cooperative Groups
&lt;/h2&gt;&lt;p&gt;Cooperative Groups is an extension to the CUDA programming model, introduced in &lt;strong&gt;CUDA 9&lt;/strong&gt;, for organizing groups of communicating threads. Cooperative Groups allows developers to express the granularity at which threads are communicating, helping them to express richer, more efficient parallel decompositions.
Historically, the CUDA programming model has provided a single, simple construct for synchronizing cooperating threads: a barrier across all threads of a thread &lt;strong&gt;block&lt;/strong&gt;, as implemented with theÂ &lt;strong&gt;__syncthreads()&lt;/strong&gt;Â intrinsic function. However, programmers would like to define and synchronize groups of threads at other granularities to enable greater performance, design flexibility, and software reuse in the form of â€œcollectiveâ€ group-wide function interfaces. In an effort to express broader patterns of parallel interaction, many performance-oriented programmers have resorted to writing their own ad hoc and unsafe primitives for synchronizing threads within a single warp, or across sets of thread blocks running on a single GPU. Whilst the performance improvements achieved have often been valuable, this has resulted in an ever-growing collection of brittle code that is expensive to write, tune, and maintain over time and across GPU generations. Cooperative Groups addresses this by providing a &lt;strong&gt;safe&lt;/strong&gt; and &lt;strong&gt;future-proof&lt;/strong&gt; mechanism to enable performant code.
header.h&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Primary header is compatible with pre-C++11, collective algorithm headers require C++11
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Optionally include for memcpy_async() collective
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Optionally include for reduce() collective
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/reduce.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="c1"&gt;// Optionally include for inclusive_scan() and exclusive_scan() collectives
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/scan.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;namespace&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// Alternatively use an alias to avoid polluting the namespace with collective algorithms
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;cg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="group-type"&gt;Group Type
&lt;/h3&gt;&lt;h4 id="implicit-groups"&gt;Implicit Groups
&lt;/h4&gt;&lt;p&gt;Implicit groups represent the &lt;strong&gt;launch configuration&lt;/strong&gt; of the kernel. Regardless of how your kernel is written, it always has a set number of threads, blocks and block dimensions, a single grid and grid dimensions. In addition, if the &lt;strong&gt;multi-device cooperative launch API&lt;/strong&gt; is used, it can have multiple grids (single grid per device). These groups provide a starting point for decomposition into finer grained groups which are typically HW accelerated and are more specialized for the problem the developer is solving.
Although you can create an implicit group anywhere in the code, it is &lt;strong&gt;dangerous&lt;/strong&gt; to do so. Creating a handle for an implicit group is a collective operationâ€”&lt;strong&gt;all&lt;/strong&gt; threads in the group must participate. If the group was created in a conditional branch that not all threads reach, this can lead to deadlocks or data corruption. For this reason, it is recommended that you create a handle for the implicit group &lt;strong&gt;upfront&lt;/strong&gt; (as early as possible, before any branching has occurred) and use that handle throughout the kernel. Group handles must be initialized at declaration time (there is no default constructor) for the same reason and copy-constructing them is discouraged.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thread Block Group
Any CUDA programmer is already familiar with a certain group of threads: the thread block. The Cooperative Groups extension introduces a new datatype,Â &lt;strong&gt;thread_block&lt;/strong&gt;, to explicitly represent this concept within the kernel.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_block&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Cluster Group
This group object represents all the threads launched in a single cluster. Refer toÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-block-clusters" target="_blank" rel="noopener"
&gt;Thread Block Clusters&lt;/a&gt;. The APIs are available on all hardware with Compute &lt;strong&gt;Capability 9.0+&lt;/strong&gt;. In such cases, when a non-cluster grid is launched, the APIs assume a &lt;strong&gt;1x1x1&lt;/strong&gt; cluster.&lt;/li&gt;
&lt;li&gt;Grid Group
This group object represents all the threads launched in a single grid. APIs other thanÂ sync()Â are available at all times, but to be able to synchronize across the grid, you need to use the &lt;strong&gt;cooperative launch API&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;grid_group&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_grid&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id="explicit-groups"&gt;Explicit Groups
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Thread Block Tile
A templated version of a tiled group, where a &lt;strong&gt;template parameter&lt;/strong&gt; is used to specify the size of the tile - with this known at compile time there is the potential for more optimal execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;cooperative_kernel&lt;/span&gt;&lt;span class="p"&gt;(...)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// obtain default &amp;#34;current thread block&amp;#34; group
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;thread_block&lt;/span&gt; &lt;span class="n"&gt;my_block&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// subdivide into 32-thread, tiled subgroups
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Tiled subgroups evenly partition a parent group into
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// adjacent sets of threads - in this case each one warp in size
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;my_tile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tiled_partition&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_block&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// This operation will be performed by only the
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// first 32-thread tile of each block
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_tile&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;meta_group_rank&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// ...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;my_tile&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sync&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Single Thread Group&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;memcpy_async&lt;/strong&gt;Â API uses aÂ thread_group, to copy an int element from source to destination:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;memcpy_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Coalesced Groups
In CUDAâ€™s SIMT architecture, at the hardware level the multiprocessor executes threads in groups of 32 called warps. If there exists a data-dependent conditional branch in the application code such that threads within a warp diverge, then the warp serially executes each branch disabling threads not on that path. &lt;strong&gt;The threads that remain active on the path are referred to as coalesced&lt;/strong&gt;. Cooperative Groups has functionality to discover, and create, a group containing all coalesced threads.
Constructing the group handle viaÂ &lt;strong&gt;coalesced_threads&lt;/strong&gt;()Â is opportunistic. It returns the set of active threads at that point in time, and makes no guarantee about which threads are returned (as long as they are active) or that they will stay coalesced throughout execution (they will be brought back together for the execution of a collective but can diverge again afterwards).&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;active&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coalesced_threads&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="group-partitioning"&gt;Group Partitioning
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;ParentT&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ParentT&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;tiled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;ParentT&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;thread_group&lt;/span&gt; &lt;span class="nf"&gt;tiled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;thread_group&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;parent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;tilesz&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TheÂ &lt;strong&gt;tiled_partition&lt;/strong&gt;Â method is a collective operation that partitions the parent group into a one-dimensional, row-major, tiling of subgroups. A total of ((size(parent)/tilesz) subgroups will be created, therefore the parent group size &lt;strong&gt;must be evenly divisible&lt;/strong&gt; by theÂ Size. The allowed parent groups areÂ thread_blockÂ orÂ thread_block_tile.
The implementation may cause the calling thread to &lt;strong&gt;wait&lt;/strong&gt; until all the members of the parent group have invoked the operation before resuming execution. Functionality is limited to native hardware sizes, 1/2/4/8/16/32 and theÂ cg::size(parent)Â must be greater than theÂ SizeÂ parameter. The templated version ofÂ tiled_partitionÂ supports 64/128/256/512 sizes as well, but some additional steps are required on Compute Capability 7.5 or lower.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;labeled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;coalesced_group&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;labeled_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Label&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Label&lt;/strong&gt;Â can be any integral type.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="nf"&gt;binary_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;coalesced_group&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;coalesced_group&lt;/span&gt; &lt;span class="n"&gt;binary_partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;thread_block_tile&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Size&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is a specialized form ofÂ &lt;strong&gt;labeled_partition&lt;/strong&gt;(), where the label can only be 0 or 1.&lt;/p&gt;
&lt;h3 id="group-collectives"&gt;Group Collectives
&lt;/h3&gt;&lt;p&gt;Cooperative Groups library provides a set of &lt;strong&gt;collective operations&lt;/strong&gt; that can be performed by a group of threads. These operations require &lt;strong&gt;participation of all threads&lt;/strong&gt; in the specified group in order to complete the operation. All threads in the group need to pass the &lt;strong&gt;same&lt;/strong&gt; values for corresponding arguments to each collective call, unless different values are explicitly allowed in the argument description. Otherwise the behavior of the call is undefined.&lt;/p&gt;
&lt;h4 id="memcpy_async"&gt;memcpy_async
&lt;/h4&gt;&lt;p&gt;memcpy_asyncÂ is a &lt;strong&gt;group-wide&lt;/strong&gt; collective memcpy that utilizes hardware accelerated support for non-blocking memory transactions &lt;strong&gt;from global to shared memory&lt;/strong&gt;. Given a set of threads named in the group,Â memcpy_asyncÂ will move specified amount of bytes or elements of the input type through a single pipeline stage. Additionally for achieving best performance when using theÂ memcpy_asyncÂ API, &lt;strong&gt;an alignment of 16 bytes&lt;/strong&gt; for both shared memory and global memory is required. It is important to note that while this is a memcpy in the general case, it is only asynchronous if the source is global memory and the destination is shared memory and both &lt;strong&gt;can be addressed with 16, 8, or 4 byte alignments&lt;/strong&gt;. Asynchronously copied data should only be read following a call to wait or wait_prior which signals that the corresponding stage has completed moving data to shared memory.
Having to wait on all outstanding requests can lose some flexibility (but gain simplicity). In order to efficiently overlap data transfer and execution, its important to be able to kick off anÂ &lt;strong&gt;N+1&lt;/strong&gt;memcpy_asyncÂ request while waiting on and operating on requestÂ &lt;strong&gt;N&lt;/strong&gt;. To do so, useÂ memcpy_asyncÂ and wait on it using the collective stage-basedÂ wait_priorÂ API.Â &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;/// This example streams elementsPerThreadBlock worth of data from global memory
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;/// into a limited sized shared memory (elementsInShared) block to operate on.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cooperative_groups/memcpy_async.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;cg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cooperative_groups&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;global_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;thread_block&lt;/span&gt; &lt;span class="n"&gt;tb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread_block&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;elementsInShared&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;local_smem&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elementsInShared&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;copy_count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;memcpy_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tb&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;local_smem&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elementsInShared&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_data&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;copy_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;elementsInShared&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elementsPerThreadBlock&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;cg&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tb&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// Work with local_smem
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;copy_count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="multi-device"&gt;Multi-Device
&lt;/h3&gt;&lt;p&gt;In order to enable synchronization across multiple devices with Cooperative Groups, use of theÂ &lt;strong&gt;cudaLaunchCooperativeKernelMultiDevice&lt;/strong&gt;Â CUDA API is required. This, a significant departure from existing CUDA APIs, will allow a single host thread to launch a kernel across multiple devices.
Deprecation Notice:Â &lt;strong&gt;cudaLaunchCooperativeKernelMultiDevice&lt;/strong&gt;Â has been deprecated in CUDA 11.3 for all devices. Example of an alternative approach can be found in the multi device conjugate gradient sample.
Optimal performance in multi-device synchronization is achieved by enabling peer access viaÂ &lt;strong&gt;cuCtxEnablePeerAccess&lt;/strong&gt;Â orÂ &lt;strong&gt;cudaDeviceEnablePeerAccess&lt;/strong&gt;Â for all participating devices.&lt;/p&gt;
&lt;h2 id="c-language-extensions"&gt;C++ Language Extensions
&lt;/h2&gt;&lt;h3 id="function-execution-space-specifier"&gt;Function Execution Space Specifier
&lt;/h3&gt;&lt;h4 id="__global__"&gt;__global__
&lt;/h4&gt;&lt;p&gt;TheÂ __global__Â execution space specifier declares a function as &lt;strong&gt;being a kernel&lt;/strong&gt;.Â Such a function is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executed on the device,&lt;/li&gt;
&lt;li&gt;Callable from the host,&lt;/li&gt;
&lt;li&gt;Callable from the device for devices of compute capability 5.0 or higherÂ 
AÂ __global__Â function must have &lt;strong&gt;void&lt;/strong&gt; return type, and cannot be a member of a class.
Any call to aÂ __global__Â function must specify its &lt;strong&gt;execution configuration&lt;/strong&gt; as described inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;.
A call to aÂ __global__Â function is &lt;strong&gt;asynchronous&lt;/strong&gt;, meaning it returns before the device has completed its execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="__device__"&gt;__device__
&lt;/h4&gt;&lt;p&gt;TheÂ __device__Â execution space specifier declares a function that is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executed on the device,&lt;/li&gt;
&lt;li&gt;Callable from the &lt;strong&gt;device only&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="__host__"&gt;__host__Â 
&lt;/h4&gt;&lt;p&gt;â €TheÂ __host__Â execution space specifier declares a function that is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executed on the host,&lt;/li&gt;
&lt;li&gt;Callable from the &lt;strong&gt;host only.&lt;/strong&gt;
It is equivalent to declare a function &lt;strong&gt;with only&lt;/strong&gt; theÂ __host__Â execution space specifier or to declare it &lt;strong&gt;without&lt;/strong&gt; any of theÂ __host__,Â __device__, orÂ __global__Â execution space specifier; in either case the function is compiled for the host only.
TheÂ __device__Â andÂ __host__Â execution space specifiers can be used together however, in which case the function is &lt;strong&gt;compiled for both&lt;/strong&gt; the host and the device. TheÂ __CUDA_ARCH__Â macro introduced inÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#application-compatibility" target="_blank" rel="noopener"
&gt;Application Compatibility&lt;/a&gt;Â can be used to differentiate code paths between host and device:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="nf"&gt;func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#if __CUDA_ARCH__ &amp;gt;= 800
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 8.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif __CUDA_ARCH__ &amp;gt;= 700
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 7.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif __CUDA_ARCH__ &amp;gt;= 600
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 6.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif __CUDA_ARCH__ &amp;gt;= 500
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Device code path for compute capability 5.x
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#elif !defined(__CUDA_ARCH__)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="c1"&gt;// Host code path
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#endif
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id="inline"&gt;inline
&lt;/h4&gt;&lt;p&gt;The compiler inlines anyÂ __device__Â function when &lt;strong&gt;deemed&lt;/strong&gt; appropriate.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TheÂ __noinline__Â function qualifier can be used as a hint for the compiler &lt;strong&gt;not to inline&lt;/strong&gt; the function if possible.&lt;/li&gt;
&lt;li&gt;TheÂ __forceinline__Â function qualifier can be used to &lt;strong&gt;force&lt;/strong&gt; the compiler to inline the function.&lt;/li&gt;
&lt;li&gt;TheÂ __inline_hint__Â qualifier enables more &lt;strong&gt;aggressive&lt;/strong&gt; inlining in the compiler. UnlikeÂ __forceinline__, it does not imply that the function is inline. It can be used to improve inlining across modules when using LTO.
TheÂ __noinline__Â andÂ __forceinline__Â function qualifiers cannot be used together, and neither function qualifier can be applied to an inline function.
Neither theÂ __noinline__Â nor theÂ __forceinline__Â function qualifier can be used with theÂ __inline_hint__Â function qualifier.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="variable-memory-space-specifier"&gt;Variable Memory Space Specifier
&lt;/h3&gt;&lt;h4 id="__device__-1"&gt;__device__
&lt;/h4&gt;&lt;p&gt;TheÂ __device__Â memory space specifier declares a variable that &lt;strong&gt;resides on the device&lt;/strong&gt;.
At most one of __constant__, __managed__ and __shared__ may be used together withÂ __device__Â to further denote which memory space the variable belongs to. If none of them is present, the variable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resides in &lt;strong&gt;global&lt;/strong&gt; memory space,&lt;/li&gt;
&lt;li&gt;Has the lifetime of the CUDA context in which it is created,&lt;/li&gt;
&lt;li&gt;Has a distinct object per device,&lt;/li&gt;
&lt;li&gt;Is accessible from all the threads within the grid and from the host through the runtime libraryÂ (cudaGetSymbolAddress()Â /Â cudaGetSymbolSize()Â /Â cudaMemcpyToSymbol()Â /Â cudaMemcpyFromSymbol()).&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;GPU ä¸Šçš„çº¿ç¨‹å¯ç›´æ¥è¯»å†™è¯¥å˜é‡ï¼›ä¸»æœºï¼ˆCPUï¼‰éœ€é€šè¿‡ CUDA Runtime API é—´æ¥è®¿é—®&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="__shared__"&gt;__shared__
&lt;/h4&gt;&lt;p&gt;TheÂ __shared__Â memory space specifier, optionally used together withÂ __device__, declares a variable that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resides in the shared memory space of a thread block,&lt;/li&gt;
&lt;li&gt;Has the lifetime of the block,&lt;/li&gt;
&lt;li&gt;Has a &lt;strong&gt;distinct object per block&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;Is only accessible from all the threads within the block,&lt;/li&gt;
&lt;li&gt;Does not have a &lt;strong&gt;constant address&lt;/strong&gt;.
â €When declaring a variable in shared memory as an external array such as&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;extern&lt;/span&gt; &lt;span class="n"&gt;__shared__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;[];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;the size of the array is &lt;strong&gt;determined at launch time&lt;/strong&gt; (seeÂ &lt;a class="link" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration" target="_blank" rel="noopener"
&gt;Execution Configuration&lt;/a&gt;). All variables declared in this fashion, start at the same address in memory, so that the layout of the variables in the array must be &lt;strong&gt;explicitly managed&lt;/strong&gt; through offsets.&lt;/p&gt;
&lt;h3 id="dim3"&gt;dim3
&lt;/h3&gt;&lt;p&gt;This type is an integer vector type based onÂ &lt;strong&gt;uint3&lt;/strong&gt;Â that is used to specify dimensions. When defining a variable of typeÂ dim3, any component left unspecified is &lt;strong&gt;initialized to 1&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="built-in-variables"&gt;Built-in Variables
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;gridDim(dim3)&lt;/li&gt;
&lt;li&gt;BlockDim(dim3)&lt;/li&gt;
&lt;li&gt;blockIdx(uint3)&lt;/li&gt;
&lt;li&gt;threadIdx(uint3)&lt;/li&gt;
&lt;li&gt;warpSize(int)&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>ã€CUDAã€‘Notes</title><link>https://dyhes.github.io/p/cudanotes/</link><pubDate>Mon, 19 May 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudanotes/</guid><description>&lt;h2 id="__forceinline__"&gt;__forceinline__
&lt;/h2&gt;&lt;p&gt;åœ¨ CUDA ç¼–ç¨‹ä¸­ï¼Œ&lt;code&gt;__forceinline__&lt;/code&gt; æ˜¯ä¸€ä¸ªç¼–è¯‘å™¨æŒ‡ä»¤ï¼Œç”¨äºå¼ºåˆ¶å°†å‡½æ•°å†…è”ï¼ˆInlineï¼‰åˆ°è°ƒç”¨ä½ç½®ï¼Œå³ä½¿ç¼–è¯‘å™¨è‡ªèº«çš„ä¼˜åŒ–ç­–ç•¥ä¸å»ºè®®å†…è”ã€‚ä»¥ä¸‹æ˜¯å¯¹å…¶æ ¸å¿ƒæœºåˆ¶å’Œåº”ç”¨åœºæ™¯çš„ç»¼åˆè§£æï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="æ ¸å¿ƒä½œç”¨ä¸è¯­ä¹‰"&gt;æ ¸å¿ƒä½œç”¨ä¸è¯­ä¹‰
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å¼ºåˆ¶å†…è”çš„æ„å›¾&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;__forceinline__&lt;/code&gt; é€šè¿‡è¦†ç›–ç¼–è¯‘å™¨çš„é»˜è®¤ä¼˜åŒ–ç­–ç•¥ï¼Œ&lt;strong&gt;å¼ºåˆ¶å°†å‡½æ•°ä½“ç›´æ¥åµŒå…¥è°ƒç”¨å¤„&lt;/strong&gt;ï¼Œä»¥æ¶ˆé™¤å‡½æ•°è°ƒç”¨çš„å¼€é”€ï¼ˆå¦‚å‚æ•°ä¼ é€’ã€æ ˆå¸§ç®¡ç†ï¼‰ã€‚è¿™ç§æœºåˆ¶å¸¸ç”¨äºé«˜é¢‘è°ƒç”¨çš„çŸ­å°å‡½æ•°ï¼ˆå¦‚æ•°å­¦è¿ç®—ã€å†…å­˜æ“ä½œï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ä¸ &lt;code&gt;inline&lt;/code&gt; çš„åŒºåˆ«&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;inline&lt;/code&gt;ï¼šä»…å‘ç¼–è¯‘å™¨å‘å‡ºå»ºè®®ï¼Œæœ€ç»ˆæ˜¯å¦å†…è”ç”±ç¼–è¯‘å™¨å†³å®šï¼ˆå¯èƒ½å› å‡½æ•°å¤æ‚åº¦æˆ–ä¼˜åŒ–çº§åˆ«è¢«å¿½ç•¥ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__forceinline__&lt;/code&gt;ï¼šç»•è¿‡ç¼–è¯‘å™¨çš„å¯å‘å¼åˆ†æï¼Œ&lt;strong&gt;å¼ºåˆ¶å†…è”&lt;/strong&gt;ï¼ˆé™¤éé‡åˆ°ç¡¬ä»¶æˆ–è¯­æ³•é™åˆ¶ï¼‰ã€‚ä¾‹å¦‚åœ¨ CUDA çš„å½’çº¦æ“ä½œä¸­ï¼Œé«˜é¢‘è°ƒç”¨çš„è¾…åŠ©å‡½æ•°å¸¸ä½¿ç”¨æ­¤å…³é”®å­—ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CUDA è®¾å¤‡å‡½æ•°çš„ç‰¹æ®Šæ”¯æŒ&lt;/strong&gt;&lt;br&gt;
CUDA å…è®¸åœ¨ &lt;code&gt;__device__&lt;/code&gt; æˆ– &lt;code&gt;__global__&lt;/code&gt; å‡½æ•°å‰ä½¿ç”¨ &lt;code&gt;__forceinline__&lt;/code&gt;ï¼Œä»¥ä¼˜åŒ– GPU çº¿ç¨‹çš„æ‰§è¡Œæ•ˆç‡ã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="é€‚ç”¨åœºæ™¯ä¸æ€§èƒ½å½±å“"&gt;é€‚ç”¨åœºæ™¯ä¸æ€§èƒ½å½±å“
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;é«˜é¢‘çŸ­å‡½æ•°ä¼˜åŒ–&lt;/strong&gt;&lt;br&gt;
é€‚ç”¨äºå¾ªç¯å†…éƒ¨æˆ–çº¿ç¨‹çº§é«˜é¢‘è°ƒç”¨çš„ç®€å•æ“ä½œï¼ˆå¦‚å‘é‡åŠ æ³•ã€æ¯”è¾ƒè¿ç®—ï¼‰ã€‚ä¾‹å¦‚åœ¨ Warp çº§å½’çº¦ï¼ˆWarp Reduceï¼‰ä¸­ï¼Œé€šè¿‡å¼ºåˆ¶å†…è”å‡å°‘æŒ‡ä»¤å»¶è¿Ÿï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;warpReduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;__shfl_down_sync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0xffffffff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;é¿å…å‡½æ•°è°ƒç”¨å¼€é”€&lt;/strong&gt;&lt;br&gt;
åœ¨ GPU æ ¸å‡½æ•°ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹çš„ç‹¬ç«‹æ‰§è¡Œè·¯å¾„è‹¥é¢‘ç¹è°ƒç”¨å¤–éƒ¨å‡½æ•°ï¼Œå†…è”å¯å‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢æˆæœ¬ã€‚ä¾‹å¦‚å°†å…±äº«å†…å­˜çš„å½’çº¦é€»è¾‘ç›´æ¥åµŒå…¥ä¸»æ ¸å‡½æ•°ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ä»£ç è†¨èƒ€çš„æƒè¡¡&lt;/strong&gt;&lt;br&gt;
å¼ºåˆ¶å†…è”å¯èƒ½å¯¼è‡´&lt;strong&gt;ä»£ç ä½“ç§¯å¢å¤§&lt;/strong&gt;ï¼Œå½±å“æŒ‡ä»¤ç¼“å­˜æ•ˆç‡ã€‚éœ€åœ¨ä»¥ä¸‹åœºæ™¯è°¨æ…ä½¿ç”¨ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å‡½æ•°ä½“è¾ƒå¤§ï¼ˆå¦‚åŒ…å«å¤æ‚åˆ†æ”¯æˆ–å¾ªç¯ï¼‰&lt;/li&gt;
&lt;li&gt;è¢«å¤šå¤„è°ƒç”¨çš„é€šç”¨å‡½æ•°&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="é™åˆ¶ä¸ç¼–è¯‘å™¨è¡Œä¸º"&gt;é™åˆ¶ä¸ç¼–è¯‘å™¨è¡Œä¸º
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ— æ³•å†…è”çš„æƒ…å†µ&lt;/strong&gt;&lt;br&gt;
å³ä½¿ä½¿ç”¨ &lt;code&gt;__forceinline__&lt;/code&gt;ï¼Œä»¥ä¸‹æƒ…å†µä»å¯èƒ½é˜»æ­¢å†…è”ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å‡½æ•°åŒ…å«é€’å½’è°ƒç”¨æˆ–è™šå‡½æ•°&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨åŠ¨æ€å‚æ•°åˆ—è¡¨ï¼ˆVariadic Argumentsï¼‰&lt;/li&gt;
&lt;li&gt;åŒ…å«å†…è”æ±‡ç¼–ï¼ˆInline Assemblyï¼‰æˆ– &lt;code&gt;__declspec(naked)&lt;/code&gt; ä¿®é¥°&lt;/li&gt;
&lt;li&gt;è°ƒè¯•æ¨¡å¼ï¼ˆå¦‚ CUDA çš„ &lt;code&gt;-G&lt;/code&gt; ç¼–è¯‘é€‰é¡¹ç¦ç”¨ä¼˜åŒ–ï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç¼–è¯‘å™¨å…¼å®¹æ€§&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CUDA å·¥å…·é“¾&lt;/strong&gt;ï¼šå®Œå…¨æ”¯æŒ &lt;code&gt;__forceinline__&lt;/code&gt;ï¼Œå¸¸ç”¨äºè®¾å¤‡å‡½æ•°ä¼˜åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…¶ä»–ç¼–è¯‘å™¨&lt;/strong&gt;ï¼šéæ ‡å‡†å…³é”®å­—ï¼Œéœ€ä½¿ç”¨ç¼–è¯‘å™¨ç‰¹å®šæ‰©å±•ï¼ˆå¦‚ GCC çš„ &lt;code&gt;__attribute__((always_inline))&lt;/code&gt; æˆ– MSVC çš„ &lt;code&gt;__forceinline&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="æœ€ä½³å®è·µ"&gt;æœ€ä½³å®è·µ
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ä¼˜å…ˆç”¨äºå°å‹è®¾å¤‡å‡½æ•°&lt;/strong&gt;&lt;br&gt;
åœ¨ CUDA ä¸­ï¼Œå°†çŸ­å°çš„ &lt;code&gt;__device__&lt;/code&gt; å‡½æ•°æ ‡è®°ä¸º &lt;code&gt;__forceinline__&lt;/code&gt;ï¼Œå°¤å…¶æ˜¯åœ¨ Warp çº§æˆ– Block çº§å¹¶è¡Œæ“ä½œä¸­ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;compute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç»“åˆæ€§èƒ½åˆ†æå·¥å…·&lt;/strong&gt;&lt;br&gt;
ä½¿ç”¨ &lt;code&gt;nvprof&lt;/code&gt; æˆ– &lt;code&gt;Nsight Compute&lt;/code&gt; éªŒè¯å†…è”æ•ˆæœï¼Œç¡®ä¿å¼ºåˆ¶å†…è”æœªå¯¼è‡´å¯„å­˜å™¨æº¢å‡ºæˆ–ç¼“å­˜å‘½ä¸­ç‡ä¸‹é™ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ›¿ä»£æ–¹æ¡ˆï¼šæ¨¡æ¿ä¸å®&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡æ¿å…ƒç¼–ç¨‹&lt;/strong&gt;ï¼šé€šè¿‡ç¼–è¯‘æ—¶å±•å¼€å®ç°ç±»ä¼¼å†…è”æ•ˆæœï¼ˆå¦‚ CUDA çš„å‘é‡åŒ–åŠ è½½æ“ä½œï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å®å‡½æ•°&lt;/strong&gt;ï¼šé€‚ç”¨äºæç®€æ“ä½œï¼Œä½†ç¼ºä¹ç±»å‹å®‰å…¨æ£€æŸ¥ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="ä»£ç ç¤ºä¾‹cuda-å½’çº¦ä¼˜åŒ–"&gt;ä»£ç ç¤ºä¾‹ï¼ˆCUDA å½’çº¦ä¼˜åŒ–ï¼‰
&lt;/h3&gt;&lt;p&gt;ä»¥ä¸‹å±•ç¤ºäº† &lt;code&gt;__forceinline__&lt;/code&gt; åœ¨ Warp çº§å½’çº¦ä¸­çš„åº”ç”¨ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// ä½¿ç”¨ __forceinline__ å¼ºåˆ¶å†…è”å½’çº¦é€»è¾‘
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__forceinline__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;warpReduceSum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;__shfl_down_sync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0xffffffff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;reduceKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;warpReduceSum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// å†…è”å±•å¼€ï¼Œæ— å‡½æ•°è°ƒç”¨å¼€é”€
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="æ€»ç»“"&gt;æ€»ç»“
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__forceinline__&lt;/code&gt; æ˜¯ CUDA ä¸­ç”¨äºæ€§èƒ½è°ƒä¼˜çš„åˆ©å™¨ï¼Œä½†å…¶ä½¿ç”¨éœ€æƒè¡¡ä»£ç è†¨èƒ€ä¸æ‰§è¡Œæ•ˆç‡ã€‚åœ¨è®¾å¤‡ç«¯é«˜é¢‘è°ƒç”¨çš„çŸ­å‡½æ•°ã€Warp çº§æ“ä½œä¸­åˆç†ä½¿ç”¨ï¼Œå¯æ˜¾è‘—æå‡å¹¶è¡Œè®¡ç®—æ€§èƒ½ï¼Œä½†éœ€ç»“åˆç¼–è¯‘å™¨é™åˆ¶å’Œå®é™…ç¡¬ä»¶è¡Œä¸ºè¿›è¡ŒéªŒè¯ã€‚&lt;/p&gt;
&lt;h2 id="__global__"&gt;__global__
&lt;/h2&gt;&lt;p&gt;åœ¨ CUDA ç¼–ç¨‹ä¸­ï¼Œ&lt;code&gt;__global__&lt;/code&gt; æ˜¯ä¸€ä¸ªæ ¸å¿ƒå…³é”®å­—ï¼Œç”¨äºå£°æ˜ GPU æ ¸å‡½æ•°ï¼ˆKernel Functionï¼‰ã€‚ä»¥ä¸‹æ˜¯å…¶å…³é”®ç‰¹æ€§çš„ç»¼åˆä»‹ç»ï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="åŸºæœ¬å®šä¹‰ä¸æ ¸å¿ƒä½œç”¨"&gt;åŸºæœ¬å®šä¹‰ä¸æ ¸å¿ƒä½œç”¨
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__global__&lt;/code&gt; ä¿®é¥°çš„å‡½æ•°æ˜¯ &lt;strong&gt;ä¸»æœºï¼ˆCPUï¼‰è°ƒç”¨ã€è®¾å¤‡ï¼ˆGPUï¼‰æ‰§è¡Œ&lt;/strong&gt; çš„å¹¶è¡Œè®¡ç®—å…¥å£ç‚¹ã€‚å®ƒé€šè¿‡ç‰¹æ®Šçš„ &lt;code&gt;&amp;lt;&amp;lt;&amp;lt;grid_size, block_size&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; è¯­æ³•å¯åŠ¨ï¼Œå…è®¸å¼€å‘è€…å°†å¤§è§„æ¨¡è®¡ç®—ä»»åŠ¡åˆ†è§£ä¸ºå¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="cm"&gt;/* GPU æ‰§è¡Œçš„ä»£ç  */&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// å¯åŠ¨ 256 ä¸ªçº¿ç¨‹
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;cudaDeviceSynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="æ ¸å¿ƒç‰¹æ€§"&gt;æ ¸å¿ƒç‰¹æ€§
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ‰§è¡Œä½ç½®ä¸è°ƒç”¨å…³ç³»&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åªèƒ½åœ¨ &lt;strong&gt;GPU ä¸Šæ‰§è¡Œ&lt;/strong&gt;ï¼Œä½†å¿…é¡»ç”± &lt;strong&gt;CPU ä»£ç æ˜¾å¼è°ƒç”¨&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;ä¸èƒ½ç›´æ¥è°ƒç”¨ä¸»æœºå‡½æ•°ï¼ˆå¦‚æ ‡å‡† C åº“å‡½æ•°ï¼‰ï¼Œå¦åˆ™ä¼šæŠ¥é”™ &lt;code&gt;error: calling a __host__ function from a __global__ function&lt;/code&gt;ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å‡½æ•°ç­¾åé™åˆ¶&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¿…é¡»è¿”å› &lt;code&gt;void&lt;/code&gt; ç±»å‹ã€‚&lt;/li&gt;
&lt;li&gt;å‚æ•°ä¼ é€’ä»…æ”¯æŒ &lt;strong&gt;å€¼ä¼ é€’&lt;/strong&gt;ï¼Œä¸èƒ½ä½¿ç”¨å¼•ç”¨æˆ–ä¸»æœºå†…å­˜æŒ‡é’ˆï¼ˆéœ€é€šè¿‡è®¾å¤‡å†…å­˜ä¼ é€’ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;çº¿ç¨‹ç»„ç»‡æ–¹å¼&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é€šè¿‡ &lt;code&gt;blockIdx&lt;/code&gt;ï¼ˆçº¿ç¨‹å—ç´¢å¼•ï¼‰ã€&lt;code&gt;threadIdx&lt;/code&gt;ï¼ˆçº¿ç¨‹ç´¢å¼•ï¼‰å’Œ &lt;code&gt;gridDim&lt;/code&gt;ï¼ˆç½‘æ ¼ç»´åº¦ï¼‰ç­‰å†…ç½®å˜é‡å®šä½çº¿ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;ç¤ºä¾‹è®¡ç®—å…¨å±€ç´¢å¼•ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// ä¸€ç»´ç½‘æ ¼ä¸­çš„çº¿ç¨‹ç´¢å¼•
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å†…å­˜è®¿é—®æƒé™&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¯ç›´æ¥è®¿é—®å…¨å±€å†…å­˜ï¼ˆå¦‚ &lt;code&gt;cudaMalloc&lt;/code&gt; åˆ†é…çš„æ˜¾å­˜ï¼‰ã€å…±äº«å†…å­˜ã€å¸¸é‡å†…å­˜ç­‰ GPU å†…å­˜ç©ºé—´ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="ä½¿ç”¨åœºæ™¯"&gt;ä½¿ç”¨åœºæ™¯
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—&lt;/strong&gt;&lt;br&gt;
é€‚ç”¨äº &lt;strong&gt;æ•°ç»„è¿ç®—&lt;/strong&gt;ï¼ˆå¦‚å‘é‡åŠ æ³•ï¼‰ã€&lt;strong&gt;çŸ©é˜µä¹˜æ³•&lt;/strong&gt;ã€&lt;strong&gt;å›¾åƒå¤„ç†&lt;/strong&gt; ç­‰éœ€è¦é«˜å¹¶å‘å¤„ç†çš„åœºæ™¯ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ä»»åŠ¡åˆ†å‘å…¥å£&lt;/strong&gt;&lt;br&gt;
ä½œä¸º GPU è®¡ç®—çš„é¡¶å±‚é€»è¾‘ï¼Œè°ƒç”¨ &lt;code&gt;__device__&lt;/code&gt; è¾…åŠ©å‡½æ•°å®Œæˆå…·ä½“è®¡ç®—å•å…ƒã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;vector_add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;...;&lt;/span&gt; &lt;span class="c1"&gt;// è®¡ç®—ç´¢å¼•
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt; &lt;span class="c1"&gt;// è°ƒç”¨è®¾å¤‡å‡½æ•°
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="ä¸å…¶ä»–å…³é”®å­—çš„å¯¹æ¯”"&gt;ä¸å…¶ä»–å…³é”®å­—çš„å¯¹æ¯”
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;å…³é”®å­—&lt;/th&gt;
&lt;th&gt;è°ƒç”¨è€…&lt;/th&gt;
&lt;th&gt;æ‰§è¡Œä½ç½®&lt;/th&gt;
&lt;th&gt;è¿”å›å€¼é™åˆ¶&lt;/th&gt;
&lt;th&gt;å…¸å‹ç”¨é€”&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__global__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;å¿…é¡»ä¸º &lt;code&gt;void&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;å¹¶è¡Œä»»åŠ¡å…¥å£ï¼ˆæ ¸å‡½æ•°ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__device__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;ä»»æ„ç±»å‹&lt;/td&gt;
&lt;td&gt;è¾…åŠ©è®¡ç®—ï¼ˆå¯å¤ç”¨æ¨¡å—ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__host__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;æ— é™åˆ¶&lt;/td&gt;
&lt;td&gt;æ™®é€š CPU å‡½æ•°&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="æ³¨æ„äº‹é¡¹"&gt;æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åŠ¨æ€å¹¶è¡Œæ”¯æŒ&lt;/strong&gt;&lt;br&gt;
ä»è®¡ç®—èƒ½åŠ› 3.5 çš„ GPU å¼€å§‹ï¼Œå…è®¸åœ¨è®¾å¤‡ä»£ç ä¸­è°ƒç”¨ &lt;code&gt;__global__&lt;/code&gt; å‡½æ•°ï¼ˆéœ€å¯ç”¨ç¼–è¯‘é€‰é¡¹ï¼‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ€§èƒ½ä¼˜åŒ–&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é¿å…åœ¨ &lt;code&gt;__global__&lt;/code&gt; å‡½æ•°ä¸­é¢‘ç¹è°ƒç”¨å¤æ‚ &lt;code&gt;__device__&lt;/code&gt; å‡½æ•°ï¼Œå¯èƒ½å¯¼è‡´å¯„å­˜å™¨æº¢å‡ºï¼Œå¯é€šè¿‡ &lt;code&gt;__launch_bounds__&lt;/code&gt; ä¼˜åŒ–çº¿ç¨‹é…ç½®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;é”™è¯¯ç¤ºä¾‹&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;error_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;// é”™è¯¯ï¼šå¿…é¡»è¿”å› void
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;error_call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;// é”™è¯¯ï¼šå‚æ•°ä¸èƒ½ä½¿ç”¨å¼•ç”¨
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="æ€»ç»“-1"&gt;æ€»ç»“
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__global__&lt;/code&gt; æ˜¯ CUDA å¹¶è¡Œè®¡ç®—çš„åŸºçŸ³ï¼Œé€šè¿‡çº¿ç¨‹ç½‘æ ¼ä¸å—çš„çµæ´»é…ç½®ï¼Œå¯å®ç° GPU èµ„æºçš„æè‡´åˆ©ç”¨ã€‚å¼€å‘è€…éœ€æ³¨æ„å…¶ä¸ &lt;code&gt;__device__&lt;/code&gt;ã€&lt;code&gt;__host__&lt;/code&gt; çš„ååŒå…³ç³»ï¼Œå¹¶éµå¾ªå†…å­˜ç®¡ç†å’Œå‚æ•°ä¼ é€’è§„åˆ™ï¼Œæ‰èƒ½é«˜æ•ˆå‘æŒ¥ GPU çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;h2 id="__constant__"&gt;__constant__
&lt;/h2&gt;&lt;p&gt;åœ¨ CUDA ç¼–ç¨‹ä¸­ï¼Œ&lt;code&gt;__constant__&lt;/code&gt; æ˜¯ä¸€ç§ç‰¹æ®Šçš„å†…å­˜ä¿®é¥°ç¬¦ï¼Œç”¨äºå£°æ˜&lt;strong&gt;å¸¸é‡å†…å­˜&lt;/strong&gt;ã€‚ä»¥ä¸‹æ˜¯å…¶æ ¸å¿ƒç‰¹æ€§çš„ç»¼åˆä»‹ç»ï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="åŸºæœ¬å®šä¹‰ä¸æ ¸å¿ƒä½œç”¨-1"&gt;åŸºæœ¬å®šä¹‰ä¸æ ¸å¿ƒä½œç”¨
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__constant__&lt;/code&gt; ç”¨äºåœ¨ GPU ä¸Šå£°æ˜&lt;strong&gt;åªè¯»çš„å…¨å±€å¸¸é‡æ•°æ®&lt;/strong&gt;ï¼Œç‰¹ç‚¹å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ä¸»æœºåˆå§‹åŒ–ï¼Œè®¾å¤‡åªè¯»&lt;/strong&gt;&lt;br&gt;
å¸¸é‡å†…å­˜ç”±ä¸»æœºï¼ˆCPUï¼‰é€šè¿‡ &lt;code&gt;cudaMemcpyToSymbol&lt;/code&gt; æˆ– &lt;code&gt;cudaMemcpy&lt;/code&gt; åˆå§‹åŒ–ï¼Œè®¾å¤‡ï¼ˆGPUï¼‰ä»£ç åªèƒ½è¯»å–ï¼Œä¸å¯ä¿®æ”¹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é™æ€åˆ†é…ï¼Œå…¨å±€å¯è§&lt;/strong&gt;&lt;br&gt;
å¿…é¡»åœ¨å…¨å±€ä½œç”¨åŸŸå£°æ˜ï¼ˆå³æ ¸å‡½æ•°å¤–ï¼‰ï¼Œä¸”å¯¹åŒä¸€ç¼–è¯‘å•å…ƒå†…çš„æ‰€æœ‰æ ¸å‡½æ•°å¯è§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å®¹é‡é™åˆ¶&lt;/strong&gt;&lt;br&gt;
é€šå¸¸ä¸º &lt;strong&gt;64KB&lt;/strong&gt;ï¼Œè¶…è¿‡æ­¤é™åˆ¶éœ€ä½¿ç”¨å…¨å±€å†…å­˜æˆ–å…¶ä»–å­˜å‚¨ç±»å‹ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ç¤ºä¾‹ä»£ç ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__constant__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt; &lt;span class="c1"&gt;// å£°æ˜å¸¸é‡å†…å­˜
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// ä¸»æœºç«¯åˆå§‹åŒ–
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaMemcpyToSymbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="æ ¸å¿ƒç‰¹æ€§ä¸ä¼˜åŒ–æœºåˆ¶"&gt;æ ¸å¿ƒç‰¹æ€§ä¸ä¼˜åŒ–æœºåˆ¶
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å¸¸é‡ç¼“å­˜ä¸å¹¿æ’­&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¼“å­˜æœºåˆ¶&lt;/strong&gt;ï¼šæ¯ä¸ª SMï¼ˆæµå¼å¤šå¤„ç†å™¨ï¼‰æœ‰ç‹¬ç«‹çš„ 64KB å¸¸é‡ç¼“å­˜ï¼ŒåŠ é€Ÿé‡å¤è®¿é—®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¹¿æ’­æœºåˆ¶&lt;/strong&gt;ï¼šå½“åŠçº¿ç¨‹æŸï¼ˆ16 ä¸ªçº¿ç¨‹ï¼‰è®¿é—®åŒä¸€å¸¸é‡å†…å­˜åœ°å€æ—¶ï¼ŒGPU ä¼šåˆå¹¶ä¸ºå•æ¬¡è¯»å–æ“ä½œï¼Œå¹¶å¹¿æ’­æ•°æ®åˆ°æ‰€æœ‰çº¿ç¨‹ï¼Œå‡å°‘å†…å­˜å¸¦å®½æ¶ˆè€—ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ€§èƒ½ä¼˜åŠ¿åœºæ™¯&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;çº¿ç¨‹æŸå†…ç»Ÿä¸€è®¿é—®&lt;/strong&gt;ï¼šæ‰€æœ‰çº¿ç¨‹è¯»å–ç›¸åŒåœ°å€æ—¶æ€§èƒ½æœ€ä½³ï¼ˆå¦‚å…±äº«çš„æ•°å­¦ç³»æ•°ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ•£è®¿é—®åŠ£åŠ¿&lt;/strong&gt;ï¼šè‹¥çº¿ç¨‹è®¿é—®ä¸åŒåœ°å€ï¼Œå¯èƒ½å¯¼è‡´ä¸²è¡ŒåŒ–ï¼ˆæ€§èƒ½ä¸‹é™ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="ä½¿ç”¨åœºæ™¯-1"&gt;ä½¿ç”¨åœºæ™¯
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;é«˜é¢‘è¯»å–çš„å›ºå®šæ•°æ®&lt;/strong&gt;&lt;br&gt;
å¦‚æ»¤æ³¢å™¨ç³»æ•°ã€ç‰©ç†å¸¸æ•°ã€æŸ¥æ‰¾è¡¨ç­‰éœ€é¢‘ç¹è®¿é—®çš„åªè¯»æ•°æ®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ›¿ä»£å…¨å±€å†…å­˜çš„ä¼˜åŒ–&lt;/strong&gt;&lt;br&gt;
å½“æ•°æ®é‡å°ä¸”è®¿é—®æ¨¡å¼ç¬¦åˆå¹¿æ’­ç‰¹æ€§æ—¶ï¼Œå¯å‡å°‘å…¨å±€å†…å­˜å¸¦å®½å‹åŠ›ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ç¤ºä¾‹ï¼šä¸€ç»´å·ç§¯æ ¸ï¼ˆStencilï¼‰è®¡ç®—ï¼Œå°†ç³»æ•°å­˜å…¥å¸¸é‡å†…å­˜åŠ é€Ÿè®¿é—®ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__constant__&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;stencil_coeff&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt; &lt;span class="c1"&gt;// å£°æ˜å·ç§¯æ ¸ç³»æ•°
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// ä¸»æœºåˆå§‹åŒ–åï¼Œè®¾å¤‡ç«¯æ‰€æœ‰çº¿ç¨‹è¯»å–åŒä¸€ç³»æ•°
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="åˆå§‹åŒ–ä¸æ“ä½œ"&gt;åˆå§‹åŒ–ä¸æ“ä½œ
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ä¸»æœºç«¯åˆå§‹åŒ–&lt;/strong&gt;&lt;br&gt;
å¿…é¡»ä½¿ç”¨ &lt;code&gt;cudaMemcpyToSymbol&lt;/code&gt; æˆ– &lt;code&gt;cudaMemcpy&lt;/code&gt;ï¼ˆéœ€å…ˆè·å–ç¬¦å·åœ°å€ï¼‰ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// æ–¹æ³•1ï¼šç›´æ¥æ‹·è´åˆ°ç¬¦å·
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;cudaMemcpyToSymbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// æ–¹æ³•2ï¼šé€šè¿‡åœ°å€æ“ä½œ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;dev_ptr&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaGetSymbolAddress&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;dev_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dev_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®¾å¤‡ç«¯è®¿é—®&lt;/strong&gt;&lt;br&gt;
æ ¸å‡½æ•°å†…ç›´æ¥é€šè¿‡å˜é‡åè¯»å–ï¼Œå¦‚ &lt;code&gt;float val = coefficients[threadIdx.x];&lt;/code&gt;ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="ä¸å…¶ä»–å†…å­˜ç±»å‹çš„å¯¹æ¯”"&gt;ä¸å…¶ä»–å†…å­˜ç±»å‹çš„å¯¹æ¯”
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;å†…å­˜ç±»å‹&lt;/th&gt;
&lt;th&gt;å¯ç¼–ç¨‹æ€§&lt;/th&gt;
&lt;th&gt;ä½œç”¨åŸŸ&lt;/th&gt;
&lt;th&gt;è®¿é—®é€Ÿåº¦&lt;/th&gt;
&lt;th&gt;å…¸å‹ç”¨é€”&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__constant__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;åªè¯»&lt;/td&gt;
&lt;td&gt;å…¨å±€&lt;/td&gt;
&lt;td&gt;å¿«ï¼ˆç¼“å­˜ï¼‰&lt;/td&gt;
&lt;td&gt;é«˜é¢‘è¯»å–çš„å›ºå®šæ•°æ®&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å…¨å±€å†…å­˜&lt;/td&gt;
&lt;td&gt;å¯è¯»å†™&lt;/td&gt;
&lt;td&gt;å…¨å±€&lt;/td&gt;
&lt;td&gt;æ…¢&lt;/td&gt;
&lt;td&gt;é€šç”¨æ•°æ®å­˜å‚¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;çº¹ç†å†…å­˜&lt;/td&gt;
&lt;td&gt;åªè¯»&lt;/td&gt;
&lt;td&gt;å…¨å±€&lt;/td&gt;
&lt;td&gt;ä¸­ç­‰&lt;/td&gt;
&lt;td&gt;ç©ºé—´å±€éƒ¨æ€§å¼ºçš„æ•°æ®&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å…±äº«å†…å­˜&lt;/td&gt;
&lt;td&gt;å¯è¯»å†™&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹å—å†…&lt;/td&gt;
&lt;td&gt;æœ€å¿«&lt;/td&gt;
&lt;td&gt;å—å†…çº¿ç¨‹åä½œ&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="æ³¨æ„äº‹é¡¹-1"&gt;æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;é¿å…è¿‡åº¦ä½¿ç”¨&lt;/strong&gt;&lt;br&gt;
ä»…å½“æ•°æ®è®¿é—®æ¨¡å¼ç¬¦åˆå¹¿æ’­ç‰¹æ€§æ—¶ä½¿ç”¨ï¼Œå¦åˆ™å¯èƒ½åŠ£äºå…¨å±€å†…å­˜+åªè¯»ç¼“å­˜ï¼ˆå¦‚ &lt;code&gt;__ldg&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»“æ„ä½“ä¸åŠ¨æ€æ•°æ®&lt;/strong&gt;&lt;br&gt;
æ”¯æŒç»“æ„ä½“ï¼Œä½†éœ€æ•´ä½“åˆå§‹åŒ–ï¼›åŠ¨æ€æ•°æ®éœ€ç»“åˆå…¨å±€å†…å­˜ç®¡ç†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¶æ„å…¼å®¹æ€§&lt;/strong&gt;&lt;br&gt;
å¸¸é‡ç¼“å­˜åœ¨æ‰€æœ‰ NVIDIA GPU ä¸­é€šç”¨ï¼Œä½† Kepler æ¶æ„åçš„åªè¯»ç¼“å­˜ï¼ˆ&lt;code&gt;__ldg&lt;/code&gt;ï¼‰åœ¨åˆ†æ•£è®¿é—®æ—¶æ›´å…·ä¼˜åŠ¿ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="æ€»ç»“-2"&gt;æ€»ç»“
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;__constant__&lt;/code&gt; å†…å­˜é€šè¿‡ç¼“å­˜å’Œå¹¿æ’­æœºåˆ¶ä¼˜åŒ–é«˜é¢‘è¯»å–åœºæ™¯ï¼Œæ˜¯ CUDA æ€§èƒ½è°ƒä¼˜çš„é‡è¦å·¥å…·ã€‚å¼€å‘è€…éœ€ç»“åˆæ•°æ®ç‰¹æ€§å’Œç¡¬ä»¶æ¶æ„ï¼Œåˆç†é€‰æ‹©å¸¸é‡å†…å­˜ã€åªè¯»ç¼“å­˜æˆ–å…±äº«å†…å­˜ï¼Œä»¥å®ç° GPU èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ã€‚&lt;/p&gt;
&lt;h2 id="å­˜å‚¨å±‚æ¬¡ç»“æ„"&gt;å­˜å‚¨å±‚æ¬¡ç»“æ„
&lt;/h2&gt;&lt;p&gt;ä»¥ä¸‹æ˜¯ CUDA å­˜å‚¨å±‚æ¬¡ç»“æ„çš„ç»¼åˆä»‹ç»ï¼Œç»“åˆç¡¬ä»¶ç‰¹æ€§å’Œç¼–ç¨‹æ¨¡å‹è¿›è¡Œåˆ†å±‚è§£æï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="å­˜å‚¨å±‚æ¬¡æ¦‚è§ˆ"&gt;å­˜å‚¨å±‚æ¬¡æ¦‚è§ˆ
&lt;/h3&gt;&lt;p&gt;CUDA å­˜å‚¨å±‚æ¬¡ç”±&lt;strong&gt;å¯ç¼–ç¨‹å­˜å‚¨&lt;/strong&gt;å’Œ&lt;strong&gt;ä¸å¯ç¼–ç¨‹ç¼“å­˜&lt;/strong&gt;ç»„æˆï¼Œè®¾è®¡ç›®æ ‡æ˜¯åˆ©ç”¨æ•°æ®å±€éƒ¨æ€§ä¼˜åŒ–è®¿é—®æ•ˆç‡ã€‚å…¶æ ¸å¿ƒç»“æ„æŒ‰è®¿é—®é€Ÿåº¦å’ŒèŒƒå›´å¯åˆ†ä¸ºä»¥ä¸‹å±‚çº§ï¼š&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;å­˜å‚¨ç±»å‹&lt;/th&gt;
&lt;th&gt;ä½œç”¨åŸŸ&lt;/th&gt;
&lt;th&gt;ç”Ÿå‘½å‘¨æœŸ&lt;/th&gt;
&lt;th&gt;è®¿é—®é€Ÿåº¦&lt;/th&gt;
&lt;th&gt;ä¸»è¦ç”¨é€”&lt;/th&gt;
&lt;th&gt;ä¼˜åŒ–ç‰¹æ€§&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;å¯„å­˜å™¨&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹ç§æœ‰&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹æ‰§è¡Œå‘¨æœŸ&lt;/td&gt;
&lt;td&gt;æœ€å¿«&lt;/td&gt;
&lt;td&gt;å­˜å‚¨é¢‘ç¹ä½¿ç”¨çš„å±€éƒ¨å˜é‡&lt;/td&gt;
&lt;td&gt;ç¼–è¯‘å™¨è‡ªåŠ¨åˆ†é…ï¼Œæ— æ˜¾å¼ç®¡ç†&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å…±äº«å†…å­˜&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹å—å†…å…±äº«&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹å—æ‰§è¡Œå‘¨æœŸ&lt;/td&gt;
&lt;td&gt;å¿«&lt;/td&gt;
&lt;td&gt;å—å†…çº¿ç¨‹åä½œæ•°æ®äº¤æ¢&lt;/td&gt;
&lt;td&gt;æ‰‹åŠ¨æ§åˆ¶ï¼Œä½å»¶è¿Ÿé€šä¿¡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å¸¸é‡å†…å­˜&lt;/td&gt;
&lt;td&gt;å…¨å±€&lt;/td&gt;
&lt;td&gt;åº”ç”¨ç”Ÿå‘½å‘¨æœŸ&lt;/td&gt;
&lt;td&gt;ä¸­ç­‰&lt;/td&gt;
&lt;td&gt;å­˜å‚¨åªè¯»æ•°æ®ï¼ˆå¦‚ç³»æ•°è¡¨ï¼‰&lt;/td&gt;
&lt;td&gt;ç¡¬ä»¶å¹¿æ’­æœºåˆ¶ä¼˜åŒ–ç»Ÿä¸€è¯»å–&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;çº¹ç†å†…å­˜&lt;/td&gt;
&lt;td&gt;å…¨å±€&lt;/td&gt;
&lt;td&gt;åº”ç”¨ç”Ÿå‘½å‘¨æœŸ&lt;/td&gt;
&lt;td&gt;ä¸­ç­‰&lt;/td&gt;
&lt;td&gt;ç©ºé—´å±€éƒ¨æ€§å¼ºçš„æ•°æ®è®¿é—®&lt;/td&gt;
&lt;td&gt;ç¡¬ä»¶æ’å€¼å’Œç¼“å­˜ä¼˜åŒ–&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å…¨å±€å†…å­˜&lt;/td&gt;
&lt;td&gt;å…¨å±€&lt;/td&gt;
&lt;td&gt;åº”ç”¨ç”Ÿå‘½å‘¨æœŸ&lt;/td&gt;
&lt;td&gt;æ…¢&lt;/td&gt;
&lt;td&gt;å¤§è§„æ¨¡æ•°æ®å­˜å‚¨ä¸äº¤æ¢&lt;/td&gt;
&lt;td&gt;éœ€å¯¹é½å’Œåˆå¹¶è®¿é—®ä¼˜åŒ–&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœ¬åœ°å†…å­˜&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹ç§æœ‰&lt;/td&gt;
&lt;td&gt;çº¿ç¨‹æ‰§è¡Œå‘¨æœŸ&lt;/td&gt;
&lt;td&gt;æ…¢&lt;/td&gt;
&lt;td&gt;å¯„å­˜å™¨æº¢å‡ºæ—¶çš„ä¸´æ—¶å­˜å‚¨&lt;/td&gt;
&lt;td&gt;è‡ªåŠ¨åˆ†é…ï¼Œé¿å…å¯„å­˜å™¨ä¸è¶³&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="æ ¸å¿ƒå­˜å‚¨ç±»å‹è¯¦è§£"&gt;æ ¸å¿ƒå­˜å‚¨ç±»å‹è¯¦è§£
&lt;/h3&gt;&lt;h4 id="å¯„å­˜å™¨register"&gt;&lt;strong&gt;å¯„å­˜å™¨ï¼ˆRegisterï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;ï¼šæ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹æ‹¥æœ‰ï¼Œè®¿é—®é€Ÿåº¦æœ€å¿«ï¼Œå®¹é‡æœ‰é™ï¼ˆå¦‚ Fermi æ¶æ„æ¯çº¿ç¨‹æœ€å¤š 63 ä¸ªå¯„å­˜å™¨ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt;ï¼šå­˜å‚¨å¾ªç¯ç´¢å¼•ã€ä¸´æ—¶å˜é‡ç­‰é«˜é¢‘è®¿é—®æ•°æ®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŒ–è¦ç‚¹&lt;/strong&gt;ï¼šå‡å°‘å¯„å­˜å™¨ä½¿ç”¨å¯æå‡çº¿ç¨‹å¹¶è¡Œåº¦ï¼Œé¿å…æº¢å‡ºåˆ°æœ¬åœ°å†…å­˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="å…±äº«å†…å­˜shared-memory"&gt;&lt;strong&gt;å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;ï¼šçº¿ç¨‹å—å†…å…±äº«ï¼Œç±»ä¼¼ CPU çš„ L1 ç¼“å­˜ï¼Œä½†å¯ç¼–ç¨‹æ§åˆ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt;ï¼šçŸ©é˜µåˆ†å—è®¡ç®—ã€å½’çº¦æ“ä½œç­‰éœ€çº¿ç¨‹åä½œçš„ä»»åŠ¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†é…æ–¹å¼&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;é™æ€åˆ†é…ï¼š&lt;code&gt;__shared__ int buffer[128];&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;åŠ¨æ€åˆ†é…ï¼šå†…æ ¸å¯åŠ¨æ—¶æŒ‡å®šå¤§å°ï¼ˆ&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;grid, block, sharedMemSize&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŒæ­¥æœºåˆ¶&lt;/strong&gt;ï¼šé€šè¿‡ &lt;code&gt;__syncthreads()&lt;/code&gt; ç¡®ä¿çº¿ç¨‹å—å†…æ•°æ®ä¸€è‡´æ€§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="å…¨å±€å†…å­˜global-memory"&gt;&lt;strong&gt;å…¨å±€å†…å­˜ï¼ˆGlobal Memoryï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;ï¼šå®¹é‡æœ€å¤§ï¼ˆGB çº§ï¼‰ï¼Œä½†å»¶è¿Ÿé«˜ï¼Œéœ€é€šè¿‡ L2 ç¼“å­˜è®¿é—®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŒ–ç­–ç•¥&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯¹é½è®¿é—®&lt;/strong&gt;ï¼šé¦–åœ°å€ä¸º 32B/128B çš„æ•´æ•°å€ä»¥å‡å°‘äº‹åŠ¡æ¬¡æ•°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆå¹¶è®¿é—®&lt;/strong&gt;ï¼šçº¿ç¨‹æŸå†…è¿ç»­è®¿é—®å†…å­˜å—ï¼ˆå¦‚æ­¥é•¿ä¸º 1ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;**ä½¿ç”¨ &lt;code&gt;cudaMallocManaged&lt;/code&gt; å®ç°ç»Ÿä¸€å†…å­˜ç®¡ç†ï¼ˆUVAï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="å¸¸é‡å†…å­˜constant-memory"&gt;&lt;strong&gt;å¸¸é‡å†…å­˜ï¼ˆConstant Memoryï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;ï¼šåªè¯»ï¼Œ64KB å®¹é‡ï¼Œé€šè¿‡ä¸“ç”¨ç¼“å­˜åŠ é€Ÿã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt;ï¼šå­˜å‚¨æ»¤æ³¢å™¨ç³»æ•°ã€ç‰©ç†å¸¸æ•°ç­‰å¹¿æ’­å¼è¯»å–æ•°æ®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆå§‹åŒ–æ–¹æ³•&lt;/strong&gt;ï¼šä¸»æœºç«¯é€šè¿‡ &lt;code&gt;cudaMemcpyToSymbol&lt;/code&gt; å†™å…¥æ•°æ®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="çº¹ç†å†…å­˜texture-memory"&gt;&lt;strong&gt;çº¹ç†å†…å­˜ï¼ˆTexture Memoryï¼‰&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹æ€§&lt;/strong&gt;ï¼šä¸“ä¸º 2D/3D æ•°æ®è®¾è®¡ï¼Œæ”¯æŒç¡¬ä»¶æ’å€¼å’Œè¾¹ç•Œå¤„ç†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt;ï¼šå›¾åƒå¤„ç†ã€ç©ºé—´æ’å€¼è®¡ç®—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼šè‡ªåŠ¨ç¼“å­˜ç©ºé—´å±€éƒ¨æ€§æ•°æ®ï¼Œå‡å°‘æ˜¾å¼å†…å­˜ç®¡ç†ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="å­˜å‚¨è®¿é—®ä¼˜åŒ–åŸåˆ™"&gt;å­˜å‚¨è®¿é—®ä¼˜åŒ–åŸåˆ™
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;æ—¶é—´å±€éƒ¨æ€§&lt;/strong&gt;ï¼šé€šè¿‡å…±äº«å†…å­˜ç¼“å­˜é‡å¤è®¿é—®æ•°æ®ï¼ˆå¦‚çŸ©é˜µä¹˜æ³•ä¸­çš„å­çŸ©é˜µå¤ç”¨ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç©ºé—´å±€éƒ¨æ€§&lt;/strong&gt;ï¼šç»„ç»‡æ•°æ®è¿ç»­å­˜å‚¨ï¼Œåˆ©ç”¨ç¼“å­˜è¡Œé¢„å–ï¼ˆå¦‚ç»“æ„ä½“æ•°ç»„ vs æ•°ç»„ç»“æ„ä½“ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å‡å°‘ä¸»æœº-è®¾å¤‡ä¼ è¾“&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;ä½¿ç”¨ &lt;code&gt;cudaMallocHost&lt;/code&gt; åˆ†é…å›ºå®šå†…å­˜ï¼ˆPinned Memoryï¼‰æå‡ä¼ è¾“å¸¦å®½ã€‚&lt;/li&gt;
&lt;li&gt;é›¶æ‹·è´å†…å­˜ï¼ˆZero-Copyï¼‰å…è®¸ GPU ç›´æ¥è®¿é—®ä¸»æœºå†…å­˜ï¼Œé¿å…æ˜¾å¼æ‹·è´ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="å…¸å‹åº”ç”¨åœºæ™¯å¯¹æ¯”"&gt;å…¸å‹åº”ç”¨åœºæ™¯å¯¹æ¯”
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;åœºæ™¯&lt;/th&gt;
&lt;th&gt;æ¨èå­˜å‚¨ç±»å‹&lt;/th&gt;
&lt;th&gt;åŸå› &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;çº¿ç¨‹ç§æœ‰ä¸´æ—¶å˜é‡&lt;/td&gt;
&lt;td&gt;å¯„å­˜å™¨&lt;/td&gt;
&lt;td&gt;é€Ÿåº¦å¿«ï¼Œæ— ç«äº‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å—å†…æ•°æ®å…±äº«&lt;/td&gt;
&lt;td&gt;å…±äº«å†…å­˜&lt;/td&gt;
&lt;td&gt;ä½å»¶è¿Ÿï¼Œæ”¯æŒåŸå­æ“ä½œå’ŒåŒæ­¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å¤§è§„æ¨¡è¾“å…¥/è¾“å‡º&lt;/td&gt;
&lt;td&gt;å…¨å±€å†…å­˜&lt;/td&gt;
&lt;td&gt;å®¹é‡å¤§ï¼Œæ”¯æŒå¼‚æ­¥ä¼ è¾“&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;é«˜é¢‘åªè¯»æ•°æ®&lt;/td&gt;
&lt;td&gt;å¸¸é‡å†…å­˜&lt;/td&gt;
&lt;td&gt;åˆ©ç”¨ç¼“å­˜å’Œå¹¿æ’­æœºåˆ¶å‡å°‘å¸¦å®½å‹åŠ›&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å›¾åƒå¤„ç†&lt;/td&gt;
&lt;td&gt;çº¹ç†å†…å­˜&lt;/td&gt;
&lt;td&gt;ç¡¬ä»¶ä¼˜åŒ–ç©ºé—´å±€éƒ¨æ€§è®¿é—®&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="é«˜çº§ç‰¹æ€§ä¸æ³¨æ„äº‹é¡¹"&gt;é«˜çº§ç‰¹æ€§ä¸æ³¨æ„äº‹é¡¹
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ç»Ÿä¸€å†…å­˜ï¼ˆUnified Memoryï¼‰&lt;/strong&gt;ï¼šCUDA 6.0+ æ”¯æŒè‡ªåŠ¨è¿ç§»æ•°æ®ï¼Œç®€åŒ–ç¼–ç¨‹ï¼ˆéœ€ UVA æ¶æ„ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;L1/L2 ç¼“å­˜æ§åˆ¶&lt;/strong&gt;ï¼šé€šè¿‡ç¼–è¯‘é€‰é¡¹ï¼ˆå¦‚ &lt;code&gt;-Xptxas -dlcm=ca&lt;/code&gt;ï¼‰æ˜¾å¼å¯ç”¨/ç¦ç”¨ L1 ç¼“å­˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŸå­æ“ä½œ&lt;/strong&gt;ï¼šå…¨å±€å†…å­˜æ”¯æŒåŸå­åŠ å‡ï¼ˆ&lt;code&gt;atomicAdd&lt;/code&gt;ï¼‰ï¼Œä½†éœ€æ³¨æ„æ€§èƒ½æŸè€—ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;é€šè¿‡åˆç†é€‰æ‹©å­˜å‚¨ç±»å‹å’Œä¼˜åŒ–è®¿é—®æ¨¡å¼ï¼Œå¼€å‘è€…å¯æ˜¾è‘—æå‡ CUDA ç¨‹åºæ€§èƒ½ã€‚ä¾‹å¦‚ï¼ŒçŸ©é˜µä¹˜æ³•ä¸­ç»“åˆå…±äº«å†…å­˜åˆ†å—å’Œå…¨å±€å†…å­˜åˆå¹¶è®¿é—®ï¼Œå¯å®ç°æ¥è¿‘ç†è®ºå³°å€¼çš„è®¡ç®—æ•ˆç‡ã€‚&lt;/p&gt;
&lt;h2 id="æ‰§è¡ŒèŒƒå¼"&gt;æ‰§è¡ŒèŒƒå¼
&lt;/h2&gt;&lt;p&gt;æ˜¯çš„ï¼ŒCUDAå†…æ ¸çš„æ‰§è¡ŒèŒƒå¼ç¡®å®æ˜¯ç”±CPUï¼ˆä¸»æœºç«¯ï¼‰é€šè¿‡æŒ‡ä»¤ç”³è¯·GPUå†…å­˜å¹¶è°ƒç”¨&lt;code&gt;__global__&lt;/code&gt;å†…æ ¸å‡½æ•°å¯åŠ¨è®¡ç®—çš„ã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„æ‰§è¡Œæµç¨‹åŠå…³é”®ç»†èŠ‚ï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="æ‰§è¡ŒèŒƒå¼æ ¸å¿ƒæ­¥éª¤"&gt;æ‰§è¡ŒèŒƒå¼æ ¸å¿ƒæ­¥éª¤
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ä¸»æœºç«¯åˆå§‹åŒ–ä¸å†…å­˜ç”³è¯·&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GPUå†…å­˜åˆ†é…&lt;/strong&gt;ï¼šCPUé€šè¿‡CUDA APIï¼ˆå¦‚&lt;code&gt;cudaMalloc&lt;/code&gt;ï¼‰æ˜¾å¼ç”³è¯·è®¾å¤‡ï¼ˆGPUï¼‰å†…å­˜ã€‚ä¾‹å¦‚ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// ç”±CPUæŒ‡ä»¤åˆ†é…GPUå†…å­˜
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»Ÿä¸€å†…å­˜ç®¡ç†&lt;/strong&gt;ï¼ˆå¯é€‰ï¼‰ï¼šä½¿ç”¨&lt;code&gt;cudaMallocManaged&lt;/code&gt;å¯åˆ†é…ä¸»æœºä¸è®¾å¤‡å…±äº«çš„ç»Ÿä¸€å†…å­˜ï¼Œç®€åŒ–æ•°æ®ä¼ è¾“ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ•°æ®æ‹·è´&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPUé€šè¿‡&lt;code&gt;cudaMemcpy&lt;/code&gt;å°†è¾“å…¥æ•°æ®ä»ä¸»æœºå†…å­˜æ‹·è´åˆ°è®¾å¤‡å†…å­˜ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// ä¸»æœºâ†’è®¾å¤‡ä¼ è¾“
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å†…æ ¸è°ƒç”¨&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPUé€šè¿‡&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;grid, block&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;è¯­æ³•å¯åŠ¨&lt;code&gt;__global__&lt;/code&gt;å†…æ ¸å‡½æ•°ï¼ŒæŒ‡å®šçº¿ç¨‹ç½‘æ ¼ï¼ˆGridï¼‰å’Œçº¿ç¨‹å—ï¼ˆBlockï¼‰çš„ç»´åº¦ã€‚ä¾‹å¦‚ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;myKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_data&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// å¯åŠ¨128ä¸ªå—ï¼Œæ¯å—256çº¿ç¨‹
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¼‚æ­¥æ‰§è¡Œ&lt;/strong&gt;ï¼šå†…æ ¸è°ƒç”¨åç«‹å³è¿”å›ï¼ŒCPUæ— éœ€ç­‰å¾…GPUå®Œæˆè®¡ç®—ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç»“æœåŒæ­¥ä¸å›æ”¶&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åŒæ­¥æœºåˆ¶&lt;/strong&gt;ï¼šCPUé€šè¿‡&lt;code&gt;cudaDeviceSynchronize()&lt;/code&gt;ç­‰å¾…GPUå®Œæˆè®¡ç®—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•°æ®å›ä¼ &lt;/strong&gt;ï¼šé€šè¿‡&lt;code&gt;cudaMemcpy&lt;/code&gt;å°†ç»“æœä»è®¾å¤‡å†…å­˜æ‹·è´å›ä¸»æœºå†…å­˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å†…å­˜é‡Šæ”¾&lt;/strong&gt;ï¼šä½¿ç”¨&lt;code&gt;cudaFree&lt;/code&gt;é‡Šæ”¾GPUå†…å­˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="å†…æ ¸æ‰§è¡Œç‰¹æ€§"&gt;å†…æ ¸æ‰§è¡Œç‰¹æ€§
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;çº¿ç¨‹ç»„ç»‡æ¨¡å‹&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;çº¿ç¨‹æŒ‰**ç½‘æ ¼ï¼ˆGridï¼‰â†’ å—ï¼ˆBlockï¼‰â†’ çº¿ç¨‹ï¼ˆThreadï¼‰**çš„å±‚çº§ç»„ç»‡ã€‚&lt;/li&gt;
&lt;li&gt;é€šè¿‡&lt;code&gt;blockIdx&lt;/code&gt;ã€&lt;code&gt;threadIdx&lt;/code&gt;ç­‰å†…ç½®å˜é‡å®šä½çº¿ç¨‹çš„å…¨å±€ç´¢å¼•ã€‚ä¾‹å¦‚ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// ä¸€ç»´ç´¢å¼•
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç¡¬ä»¶æ‰§è¡Œæœºåˆ¶&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SIMTæ¶æ„&lt;/strong&gt;ï¼šGPUä»¥**çº¿ç¨‹æŸï¼ˆWarpï¼Œ32çº¿ç¨‹ï¼‰**ä¸ºè°ƒåº¦å•ä½ï¼ŒåŒä¸€Warpå†…çº¿ç¨‹æ‰§è¡Œç›¸åŒæŒ‡ä»¤ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SMè°ƒåº¦&lt;/strong&gt;ï¼šçº¿ç¨‹å—ï¼ˆBlockï¼‰è¢«åˆ†é…åˆ°æµå¤šå¤„ç†å™¨ï¼ˆSMï¼‰ä¸Šæ‰§è¡Œï¼ŒSMé€šè¿‡å¤šçº§ç¼“å­˜ï¼ˆå…±äº«å†…å­˜ã€L1/L2ï¼‰åŠ é€Ÿæ•°æ®è®¿é—®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ä¼˜åŒ–å…³é”®ç‚¹&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å†…å­˜è®¿é—®åˆå¹¶&lt;/strong&gt;ï¼šç¡®ä¿çº¿ç¨‹æŸå†…è¿ç»­è®¿é—®å…¨å±€å†…å­˜ï¼Œå‡å°‘äº‹åŠ¡æ¬¡æ•°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…±äº«å†…å­˜å¤ç”¨&lt;/strong&gt;ï¼šæ‰‹åŠ¨ç¼“å­˜é‡å¤è®¿é—®çš„æ•°æ®ï¼Œå‡å°‘å…¨å±€å†…å­˜å¸¦å®½å‹åŠ›ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="ä¸å…¶ä»–ç¼–ç¨‹æ¨¡å‹çš„å¯¹æ¯”"&gt;ä¸å…¶ä»–ç¼–ç¨‹æ¨¡å‹çš„å¯¹æ¯”
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;é˜¶æ®µ&lt;/th&gt;
&lt;th&gt;CPUèŒè´£&lt;/th&gt;
&lt;th&gt;GPUèŒè´£&lt;/th&gt;
&lt;th&gt;äº¤äº’æ–¹å¼&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;å†…å­˜ç®¡ç†&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;åˆ†é…/é‡Šæ”¾è®¾å¤‡å†…å­˜&lt;/td&gt;
&lt;td&gt;æä¾›æ˜¾å­˜ç©ºé—´&lt;/td&gt;
&lt;td&gt;é€šè¿‡CUDA APIï¼ˆå¦‚&lt;code&gt;cudaMalloc&lt;/code&gt;ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;å†…æ ¸æ‰§è¡Œ&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;å¯åŠ¨å†…æ ¸å¹¶æŒ‡å®šçº¿ç¨‹é…ç½®&lt;/td&gt;
&lt;td&gt;å¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—&lt;/td&gt;
&lt;td&gt;å¼‚æ­¥è°ƒç”¨ï¼ˆ&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;...&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;è¯­æ³•ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;æ•°æ®ä¼ è¾“&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;ä¸»æœºâ†”è®¾å¤‡æ•°æ®æ‹·è´&lt;/td&gt;
&lt;td&gt;æ— ç›´æ¥å‚ä¸&lt;/td&gt;
&lt;td&gt;æ˜¾å¼æ‹·è´æˆ–ç»Ÿä¸€å†…å­˜è‡ªåŠ¨è¿ç§»&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;åŒæ­¥æ§åˆ¶&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;æ˜¾å¼ç­‰å¾…GPUå®Œæˆï¼ˆ&lt;code&gt;cudaDeviceSynchronize&lt;/code&gt;ï¼‰&lt;/td&gt;
&lt;td&gt;æ— ä¸»åŠ¨é€šçŸ¥æœºåˆ¶&lt;/td&gt;
&lt;td&gt;é˜»å¡å¼åŒæ­¥æˆ–æµå¼å¼‚æ­¥&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id="å…¸å‹ä»£ç ç¤ºä¾‹å®Œæ•´æµç¨‹"&gt;å…¸å‹ä»£ç ç¤ºä¾‹ï¼ˆå®Œæ•´æµç¨‹ï¼‰
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__global__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;addKernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;blockIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;blockDim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;threadIdx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;h_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// ä¸»æœºå†…å­˜åˆ†é…ä¸åˆå§‹åŒ–
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;h_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="nf"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;h_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="nf"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// ...åˆå§‹åŒ–h_aå’Œh_b...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// GPUå†…å­˜åˆ†é…
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaMalloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// æ•°æ®æ‹·è´è‡³GPU
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// å¯åŠ¨å†…æ ¸ï¼ˆ256çº¿ç¨‹/å—ï¼‰
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;numBlocks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;addKernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;numBlocks&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// åŒæ­¥å¹¶æ‹·è´ç»“æœå›ä¸»æœº
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaDeviceSynchronize&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaMemcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;// é‡Šæ”¾å†…å­˜
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="nf"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;cudaFree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nf"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="é«˜çº§ç‰¹æ€§æ‰©å±•"&gt;é«˜çº§ç‰¹æ€§æ‰©å±•
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åŠ¨æ€å¹¶è¡Œ&lt;/strong&gt;ï¼ˆCompute Capability â‰¥3.5ï¼‰&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å…è®¸GPUå†…æ ¸å†…éƒ¨åµŒå¥—å¯åŠ¨å…¶ä»–å†…æ ¸ï¼Œå‡å°‘ä¸»æœºäº¤äº’å¼€é”€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å¤šæµå¹¶å‘&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä½¿ç”¨CUDAæµï¼ˆStreamï¼‰å®ç°è®¡ç®—ä¸æ•°æ®ä¼ è¾“é‡å ï¼Œæå‡ååé‡ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;cudaStream_t&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaStreamCreate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nf"&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class="p"&gt;(...,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// å¼‚æ­¥ä¼ è¾“
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;...,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// æµå†…æ‰§è¡Œ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç»Ÿä¸€å†…å­˜ä¼˜åŒ–&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é€šè¿‡&lt;code&gt;cudaMallocManaged&lt;/code&gt;å®ç°è‡ªåŠ¨å†…å­˜è¿ç§»ï¼Œé¿å…æ˜¾å¼æ‹·è´ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;ç»¼ä¸Šï¼ŒCUDAçš„æ‰§è¡ŒèŒƒå¼ç¡®å®ç”±CPUä¸»å¯¼å†…å­˜ç®¡ç†ä¸å†…æ ¸è°ƒç”¨ï¼Œè€ŒGPUä¸“æ³¨äºå¹¶è¡Œè®¡ç®—ã€‚è¿™ä¸€è®¾è®¡å¹³è¡¡äº†CPUçš„æ§åˆ¶èƒ½åŠ›ä¸GPUçš„å¹¶è¡Œæ€§èƒ½ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®å¹¶è¡Œä»»åŠ¡ã€‚&lt;/p&gt;</description></item><item><title>ã€CUDAã€‘Function</title><link>https://dyhes.github.io/p/cudafunction/</link><pubDate>Tue, 22 Apr 2025 00:00:00 +0000</pubDate><guid>https://dyhes.github.io/p/cudafunction/</guid><description>&lt;p&gt;åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œé”™è¯¯ä¿¡æ¯ &lt;code&gt;&amp;quot;calling a __host__ function from a __host__ __device__ function is not allowed&amp;quot;&lt;/code&gt; è¡¨ç¤ºä½ å°è¯•åœ¨ &lt;strong&gt;åŒæ—¶æ”¯æŒä¸»æœºï¼ˆCPUï¼‰å’Œè®¾å¤‡ï¼ˆGPUï¼‰è°ƒç”¨çš„å‡½æ•°&lt;/strong&gt; ä¸­ï¼Œè°ƒç”¨äº†ä¸€ä¸ª &lt;strong&gt;ä»…æ”¯æŒä¸»æœºç«¯æ‰§è¡Œ&lt;/strong&gt; çš„å‡½æ•°ã€‚ä»¥ä¸‹æ˜¯å…·ä½“è§£æå’Œè§£å†³æ–¹æ¡ˆï¼š&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="é”™è¯¯åŸå› è§£æ"&gt;é”™è¯¯åŸå› è§£æ
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å‡½æ•°ä¿®é¥°ç¬¦çš„ä½œç”¨&lt;/strong&gt; ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;__host__&lt;/code&gt;ï¼šå‡½æ•°ä»…åœ¨CPUä¸Šæ‰§è¡Œï¼Œåªèƒ½è¢«CPUè°ƒç”¨ï¼ˆé»˜è®¤ä¿®é¥°ç¬¦ï¼Œå¯çœç•¥ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__device__&lt;/code&gt;ï¼šå‡½æ•°ä»…åœ¨GPUä¸Šæ‰§è¡Œï¼Œåªèƒ½è¢«GPUçº¿ç¨‹è°ƒç”¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__host__ __device__&lt;/code&gt;ï¼šå‡½æ•°å¯ä»¥åŒæ—¶åœ¨CPUå’ŒGPUä¸Šç¼–è¯‘å’Œæ‰§è¡Œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å†²çªåœºæ™¯&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å½“ä¸€ä¸ªè¢«æ ‡è®°ä¸º &lt;code&gt;__host__ __device__&lt;/code&gt; çš„å‡½æ•°ï¼ˆä¾‹å¦‚ &lt;code&gt;__host__ __device__ void foo()&lt;/code&gt;ï¼‰åœ¨å…¶å†…éƒ¨è°ƒç”¨äº†å¦ä¸€ä¸ªä»…æ ‡è®°ä¸º &lt;code&gt;__host__&lt;/code&gt; çš„å‡½æ•°ï¼ˆä¾‹å¦‚ &lt;code&gt;void bar()&lt;/code&gt;ï¼‰æ—¶ï¼Œä¼šå¯¼è‡´æ­¤é”™è¯¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ ¸å¿ƒçŸ›ç›¾&lt;/strong&gt;ï¼šåœ¨GPUæ‰§è¡Œè·¯å¾„ä¸­ï¼ˆå³ &lt;code&gt;__device__&lt;/code&gt; åˆ†æ”¯ï¼‰ï¼Œ&lt;code&gt;bar()&lt;/code&gt; ä½œä¸ºçº¯ä¸»æœºå‡½æ•°æ— æ³•åœ¨è®¾å¤‡ç«¯è¢«è°ƒç”¨ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="å…¸å‹ç¤ºä¾‹"&gt;å…¸å‹ç¤ºä¾‹
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// çº¯ä¸»æœºå‡½æ•°ï¼ˆé»˜è®¤ __host__ï¼‰
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;host_only_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="cm"&gt;/* CPUé€»è¾‘ */&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;// æ··åˆä¿®é¥°ç¬¦å‡½æ•°ï¼šæ”¯æŒCPUå’ŒGPUè°ƒç”¨
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;hybrid_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;host_only_func&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// é”™è¯¯ï¼è‹¥åœ¨GPUæ‰§è¡Œè·¯å¾„ä¸­è°ƒç”¨çº¯ä¸»æœºå‡½æ•°
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id="è§£å†³æ–¹æ¡ˆ"&gt;è§£å†³æ–¹æ¡ˆ
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ£€æŸ¥è¢«è°ƒç”¨å‡½æ•°çš„ä¿®é¥°ç¬¦&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è‹¥ &lt;code&gt;host_only_func()&lt;/code&gt; éœ€è¦åœ¨GPUä¸­è¢«è°ƒç”¨ï¼Œéœ€æ·»åŠ  &lt;code&gt;__device__&lt;/code&gt; ä¿®é¥°ç¬¦ï¼š
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;host_device_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="cm"&gt;/* å…¼å®¹é€»è¾‘ */&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;è‹¥è¯¥å‡½æ•°æ— æ³•ä¿®æ”¹ï¼ˆå¦‚ç¬¬ä¸‰æ–¹åº“å‡½æ•°ï¼‰ï¼Œéœ€é‡æ„ä»£ç é€»è¾‘ï¼Œé¿å…åœ¨è®¾å¤‡ç«¯è·¯å¾„ä¸­è°ƒç”¨å®ƒã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åˆ©ç”¨æ¡ä»¶ç¼–è¯‘éš”ç¦»é€»è¾‘&lt;/strong&gt; ï¼š&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-cpp" data-lang="cpp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;__host__&lt;/span&gt; &lt;span class="n"&gt;__device__&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;hybrid_func&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#ifdef __CUDA_ARCH__ &lt;/span&gt;&lt;span class="c1"&gt;// ä»…åœ¨GPUç¼–è¯‘æ—¶ç”Ÿæ•ˆ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt; &lt;span class="n"&gt;device_logic&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// è®¾å¤‡ç«¯ä¸“ç”¨ä»£ç 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#else
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt; &lt;span class="n"&gt;host_only_func&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// ä¸»æœºç«¯ä¸“ç”¨ä»£ç 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c1"&gt;&lt;/span&gt;&lt;span class="cp"&gt;#endif
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç»Ÿä¸€å‡½æ•°çš„è®¾å¤‡ç«¯å…¼å®¹æ€§&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è‹¥éœ€è·¨è®¾å¤‡é€šç”¨ï¼Œç¡®ä¿æ‰€æœ‰å†…éƒ¨è°ƒç”¨çš„å‡½æ•°ä¹Ÿæ”¯æŒ &lt;code&gt;__device__&lt;/code&gt;ï¼Œä¾‹å¦‚ä½¿ç”¨ &lt;code&gt;__host__ __device__&lt;/code&gt; ä¿®é¥°ç¬¦æˆ–ä»…ä¾èµ–CUDAæ”¯æŒçš„æ•°å­¦å‡½æ•°ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="æ‰©å±•å»ºè®®"&gt;æ‰©å±•å»ºè®®
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è°ƒè¯•å·¥å…·&lt;/strong&gt;ï¼šä½¿ç”¨ &lt;code&gt;cuda-gdb&lt;/code&gt; æˆ– &lt;code&gt;cuda-memcheck&lt;/code&gt; å®šä½å…·ä½“æŠ¥é”™ä½ç½®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä»£ç è§„èŒƒ&lt;/strong&gt;ï¼šé¿å…åœ¨æ··åˆä¿®é¥°ç¬¦å‡½æ•°ä¸­ç›´æ¥è°ƒç”¨éCUDAå…¼å®¹çš„åº“å‡½æ•°ï¼ˆå¦‚STLå®¹å™¨ï¼‰ï¼Œè¿™ç±»å‡½æ•°é€šå¸¸ä»…æ”¯æŒä¸»æœºç«¯ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ­¤é”™è¯¯æœ¬è´¨æ˜¯ &lt;strong&gt;ä½œç”¨åŸŸéš”ç¦»é—®é¢˜&lt;/strong&gt;ï¼Œé€šè¿‡åˆç†ä½¿ç”¨ä¿®é¥°ç¬¦å’Œæ¡ä»¶ç¼–è¯‘å¯æœ‰æ•ˆè§£å†³ã€‚&lt;/p&gt;</description></item></channel></rss>